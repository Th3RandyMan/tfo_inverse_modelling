{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the Divervgence Between Data Distributions\n",
    "The goal is to show that the data distribution shifts much more rapidly for change in depth compared to change in saturation. If that is the case, it becomes really difficult for any transformation to exist that can reliably distinguish changes in saturation agnostic of depth. For the distribution metric, I would want to use KLD for now. But something else might also work. KLD Formula used: Assuming P and Q are the two distributions(normalized)\n",
    "$$\n",
    "KLD(P || Q) = \\sum_{P \\neq 0, Q\\neq 0} (P \\times log(P / Q))\n",
    "$$\n",
    "For now, we are disregarding the 0 values.\n",
    "\n",
    "## Defining the KLD function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Ranges [(x_min, x_max), .. ]: [(0.002708744248845596, 2.7176158915920587), (0.0006329672221848659, 2.7159320454335245), (0.00029391334555917137, 2.714085742181309)]\n",
      "Non-Zero Mask Length (AND condition): 0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Find distribution ranges per dimension\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "def find_ranges(dist1: np.ndarray, dist2: np.ndarray) -> List[Tuple[float, float]]:\n",
    "    assert dist1.shape[1] == dist2.shape[1], \"The two distributions must have the same number of dimensions\"\n",
    "    ranges = []\n",
    "    for i in range(dist1.shape[1]):\n",
    "        min_val = min(np.min(dist1[:, i]), np.min(dist2[:, i]))\n",
    "        max_val = max(np.max(dist1[:, i]), np.max(dist2[:, i]))\n",
    "        ranges.append((min_val, max_val))\n",
    "    return ranges\n",
    "\n",
    "def custom_kld(dist1: np.ndarray, dist2: np.ndarray, bin_count: int = 20, verbose: bool = False) -> float:\n",
    "    value_ranges = find_ranges(dist1, dist2)\n",
    "    if verbose:\n",
    "        print(f\"Value Ranges [(x_min, x_max), .. ]: {value_ranges}\")\n",
    "    # Create a histogram of the two distributions\n",
    "    hist1, _ = np.histogramdd(dist1, bins=bin_count, range=value_ranges)\n",
    "    hist2, _ = np.histogramdd(dist2, bins=bin_count, range=value_ranges)\n",
    "    # Normalize the histograms\n",
    "    hist1 = hist1 / np.sum(hist1)\n",
    "    hist2 = hist2 / np.sum(hist2)\n",
    "    \n",
    "    # Create the mask\n",
    "    non_zero_mask = (hist1 > 0) & (hist2 > 0)\n",
    "    if verbose:\n",
    "        print(\"Non-Zero Mask Length (AND condition):\", np.sum(non_zero_mask))\n",
    "    # Compute the KLD\n",
    "    kld = np.sum(hist1[non_zero_mask] * np.log(hist1[non_zero_mask] / hist2[non_zero_mask]))\n",
    "    return kld\n",
    "\n",
    "# Test Case\n",
    "dist1 = np.exp(np.random.rand(1000, 3))\n",
    "dist2 = np.random.rand(1000, 3)\n",
    "print(custom_kld(dist1, dist2, 40, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybercat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
