{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the Divervgence Between Data Distributions\n",
    "The goal is to show that the data distribution shifts much more rapidly for change in depth compared to change in saturation. If that is the case, it becomes really difficult for any transformation to exist that can reliably distinguish changes in saturation agnostic of depth. For the distribution metric, I would want to use KLD for now. But something else might also work. KLD Formula used: Assuming P and Q are the two distributions(normalized)\n",
    "$$\n",
    "KLD(P || Q) = \\sum_{P \\neq 0, Q\\neq 0} (P \\times log(P / Q))\n",
    "$$\n",
    "For now, we are disregarding the 0 values.\n",
    "\n",
    "## Defining the KLD function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find distribution ranges per dimension\n",
    "from typing import List, Tuple, Callable\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "\n",
    "def find_ranges(dist1: np.ndarray, dist2: np.ndarray) -> List[Tuple[float, float]]:\n",
    "    assert dist1.shape[1] == dist2.shape[1], \"The two distributions must have the same number of dimensions\"\n",
    "    ranges = []\n",
    "    for i in range(dist1.shape[1]):\n",
    "        min_val = min(np.min(dist1[:, i]), np.min(dist2[:, i]))\n",
    "        max_val = max(np.max(dist1[:, i]), np.max(dist2[:, i]))\n",
    "        ranges.append((min_val, max_val))\n",
    "    return ranges\n",
    "\n",
    "\n",
    "DistanceFunctionOutputType = Callable[[np.ndarray, np.ndarray, np.ndarray], float]\n",
    "\n",
    "\n",
    "distance_functions: List[DistanceFunctionOutputType] = []\n",
    "\n",
    "\n",
    "def register_distance_function(func: DistanceFunctionOutputType):\n",
    "    distance_functions.append(func)\n",
    "    return func\n",
    "\n",
    "\n",
    "@register_distance_function\n",
    "def custom_kld(hist1: np.ndarray, hist2: np.ndarray, non_zero_mask: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    A customized version of the Kullback-Leibler Divergence that ignores zero bins in either distribution\n",
    "    :param hist1: The first distribution\n",
    "    :param hist2: The second distribution\n",
    "    :param non_zero_mask: A mask that is True where both distributions are non-zero\n",
    "    \"\"\"\n",
    "    # Assert that the dimensions match\n",
    "    assert hist1.shape == hist2.shape == non_zero_mask.shape, \"All inputs must have the same shape\"\n",
    "    result = np.sum(hist1[non_zero_mask] * np.log(hist1[non_zero_mask] / hist2[non_zero_mask]))\n",
    "    return float(result)\n",
    "\n",
    "\n",
    "@register_distance_function\n",
    "def true_distance(hist1: np.ndarray, hist2: np.ndarray, non_zero_mask: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the true distance between two distributions. This distance is defined as the sum of the absolute\n",
    "    differences between each of the bins of the two distributions\n",
    "    :param hist1: The first distribution\n",
    "    :param hist2: The second distribution\n",
    "    :param non_zero_mask: A mask that is True where both distributions are non-zero\n",
    "    \"\"\"\n",
    "    return np.sum(np.abs(hist1 - hist2), axis=None)\n",
    "\n",
    "\n",
    "@register_distance_function\n",
    "def total_variation_distance(hist1: np.ndarray, hist2: np.ndarray, non_zero_mask: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the total variation distance between two distributions. This distance is defined as the maximum\n",
    "    absolute difference between each of the bins of the two distributions\n",
    "    :param hist1: The first distribution\n",
    "    :param hist2: The second distribution\n",
    "    :param non_zero_mask: A mask that is True where both distributions are non-zero\n",
    "    \"\"\"\n",
    "    return np.max(np.abs(hist1 - hist2), axis=None)\n",
    "\n",
    "\n",
    "@register_distance_function\n",
    "def kld_smoothened(hist1: np.ndarray, hist2: np.ndarray, non_zero_mask: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the Kullback-Leibler Divergence between two distributions. The distributions are smoothened before\n",
    "    calculation to avoid collapse in KLD formula\n",
    "    :param hist1: The first distribution\n",
    "    :param hist2: The second distribution\n",
    "    :param non_zero_mask: A mask that is True where both distributions are non-zero\n",
    "    \"\"\"\n",
    "    # Smoothen\n",
    "    hist1 = gaussian_filter(hist1, sigma=1)\n",
    "    hist2 = gaussian_filter(hist2, sigma=1)\n",
    "    # Renormalize the histograms\n",
    "    hist1 = hist1 / np.sum(hist1)\n",
    "    hist2 = hist2 / np.sum(hist2)\n",
    "    return float(np.sum(hist1 * np.log(hist1 / hist2)))\n",
    "\n",
    "\n",
    "@register_distance_function\n",
    "def kld_biased(hist1: np.ndarray, hist2: np.ndarray, non_zero_mask: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the Kullback-Leibler Divergence between two distributions. This version of the KLD adds a tiny epsilon to\n",
    "    zero terms to prevent collapse\n",
    "    :param hist1: The first distribution\n",
    "    :param hist2: The second distribution\n",
    "    :param non_zero_mask: A mask that is True where both distributions are non-zero\n",
    "    \"\"\"\n",
    "    epsilon = 1e-30\n",
    "    bias_matrix1 = np.ones_like(hist1) * epsilon\n",
    "    bias_matrix1 = bias_matrix1 * (hist1 == 0)\n",
    "    bias_matrix2 = np.ones_like(hist2) * epsilon\n",
    "    bias_matrix2 = bias_matrix2 * (hist2 == 0)\n",
    "    hist1 = hist1 + bias_matrix1\n",
    "    hist2 = hist2 + bias_matrix2\n",
    "    # Renormalize the histograms\n",
    "    hist1 = hist1 / np.sum(hist1)\n",
    "    hist2 = hist2 / np.sum(hist2)\n",
    "    return float(np.sum(hist1 * np.log(hist1 / hist2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization Functions\n",
    "def minmax_normalization(data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalizes the data to the range [-1 1]\n",
    "    :param data: The data to normalize\n",
    "    \"\"\"\n",
    "    data = np.abs(data)\n",
    "    return (data - np.min(data, axis=0)) / (np.max(data, axis=0) - np.min(data, axis=0)) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Ranges [(x_min, x_max), .. ]: [(0.0006827445785481112, 3.997011158927622), (0.0007516782886578532, 3.998653870547394), (0.0005716123686845265, 3.9976904488410834)]\n",
      "Non-Zero Mask Length (AND condition): 20\n",
      "1.9320000000000004\n"
     ]
    }
   ],
   "source": [
    "def distribution_distance(\n",
    "    dist1: np.ndarray,\n",
    "    dist2: np.ndarray,\n",
    "    bin_count: int = 20,\n",
    "    distance_function: DistanceFunctionOutputType = custom_kld,\n",
    "    normalization_func: Callable[[np.ndarray], np.ndarray] = lambda x: x,\n",
    "    verbose: bool = False,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate the distance between two distributions using a custom distance function\n",
    "    \n",
    "    :param dist1: The first set of D dimensional data (N x D)\n",
    "    :param dist2: The second set of D dimensional data (N x D)\n",
    "    :param bin_count: The number of bins to use for the histogram\n",
    "    :param distance_function: The distance function to use on the normalized histograms\n",
    "    :param normalization_func: The normalization function to use on the data before calculating the histogram\n",
    "    :verbose: Whether to print out results from the intermediate steps\n",
    "    \"\"\"\n",
    "    # Normalize the Data\n",
    "    dist1 = normalization_func(dist1)\n",
    "    dist2 = normalization_func(dist2)\n",
    "    \n",
    "    # Find Values Ranges for both distributions combined\n",
    "    value_ranges = find_ranges(dist1, dist2)\n",
    "    if verbose:\n",
    "        print(f\"Value Ranges [(x_min, x_max), .. ]: {value_ranges}\")\n",
    "    \n",
    "    # Create a histogram of the two distributions\n",
    "    hist1, _ = np.histogramdd(dist1, bins=bin_count, range=value_ranges)\n",
    "    hist2, _ = np.histogramdd(dist2, bins=bin_count, range=value_ranges)\n",
    "    \n",
    "    # Normalize the histograms to sum up to 1\n",
    "    hist1 = hist1 / np.sum(hist1)\n",
    "    hist2 = hist2 / np.sum(hist2)\n",
    "\n",
    "    # Create the mask\n",
    "    non_zero_mask = (hist1 > 0) & (hist2 > 0)\n",
    "    if verbose:\n",
    "        print(\"Non-Zero Mask Length (AND condition):\", np.sum(non_zero_mask))\n",
    "    # Compute the KLD\n",
    "    distance = distance_function(hist1, hist2, non_zero_mask)\n",
    "    return distance\n",
    "\n",
    "\n",
    "# Test Case\n",
    "# dist1 = np.exp(np.random.rand(1000, 3))\n",
    "dist1 = np.random.rand(1000, 3) * 4\n",
    "dist2 = np.random.rand(1000, 3)\n",
    "print(distribution_distance(dist1, dist2, 10, distance_function=true_distance, verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Simulation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the log intensity data\n",
    "pulsation_ratio_path = Path().resolve().parent.parent / \"data\" / \"processed_data\" / \"pulsation_ratio.pkl\"\n",
    "data = pd.read_pickle(pulsation_ratio_path)\n",
    "pulsation_ratio_config_path = pulsation_ratio_path.with_suffix('.json')\n",
    "with open(pulsation_ratio_config_path, 'r') as file:\n",
    "    pulsation_ratio_config = json.load(file)\n",
    "pr_columns = pulsation_ratio_config['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of filtered columns: 5\n"
     ]
    }
   ],
   "source": [
    "# Way too many pulsation ratio features. Keep only 5 per wavelength - 10 in total\n",
    "chosen_sdds = ['10', '33', '50', '72', '94']\n",
    "filtered_columns = [col for col in pr_columns if col.split('_')[-1] in chosen_sdds]\n",
    "filtered_columns = filtered_columns[:5] # WV1\n",
    "# filtered_columns += [\"Fetal Saturation\"]\n",
    "print(\"Length of filtered columns:\", len(filtered_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_to_use = kld_biased\n",
    "metric_to_use = true_distance\n",
    "normalization_func = minmax_normalization\n",
    "# normalization_func = lambda x: x        # No normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate DIstribution Shift For Changing Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Ranges [(x_min, x_max), .. ]: [(-1.0, 1.0), (-1.0, 1.0), (-1.0, 1.0), (-1.0, 1.0), (-1.0, 1.0)]\n",
      "Non-Zero Mask Length (AND condition): 51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.9865319865319875"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_depths = data['Maternal Wall Thickness'].unique()\n",
    "all_depths.sort()\n",
    "\n",
    "depth0_data = (data[data['Maternal Wall Thickness'] == all_depths[0]])[filtered_columns].to_numpy()\n",
    "depth1_data = (data[data['Maternal Wall Thickness'] == all_depths[1]])[filtered_columns].to_numpy()\n",
    "\n",
    "distribution_distance(np.abs(depth0_data), np.abs(depth1_data), 20, metric_to_use, normalization_func, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Distribution Shift For Changing Saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Ranges [(x_min, x_max), .. ]: [(-1.0, 1.0), (-1.0, 1.0), (-1.0, 1.0), (-1.0, 1.0), (-1.0, 1.0)]\n",
      "Non-Zero Mask Length (AND condition): 744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14182144020853693"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_fetal_sat = data['Fetal Saturation'].unique()\n",
    "all_fetal_sat.sort()\n",
    "\n",
    "fetal_sat0_data = (data[data['Fetal Saturation'] == all_fetal_sat[0]])[filtered_columns].to_numpy()\n",
    "fetal_sat1_data = (data[data['Fetal Saturation'] == all_fetal_sat[2]])[filtered_columns].to_numpy()\n",
    "\n",
    "distribution_distance(np.abs(fetal_sat0_data), np.abs(fetal_sat1_data), 20, metric_to_use, normalization_func, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Distribution Shift For Changing Saturation in a Fixed Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Ranges [(x_min, x_max), .. ]: [(-1.0, 1.0), (-1.0, 1.0), (-1.0, 1.0), (-1.0, 1.0), (-1.0, 1.0)]\n",
      "Non-Zero Mask Length (AND condition): 218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4040404040404084"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_depth = all_depths[4]\n",
    "\n",
    "fetal_sat0_data = (data[(data['Fetal Saturation'] == all_fetal_sat[0]) & (data[\"Maternal Wall Thickness\"] == chosen_depth)])[filtered_columns].to_numpy()\n",
    "fetal_sat1_data = (data[(data['Fetal Saturation'] == all_fetal_sat[1]) & (data[\"Maternal Wall Thickness\"] == chosen_depth)])[filtered_columns].to_numpy()\n",
    "\n",
    "# distribution_distance(np.abs(fetal_sat0_data), np.abs(fetal_sat1_data), 20, distance_function=metric_to_use, verbose=True)\n",
    "distribution_distance(fetal_sat0_data, fetal_sat1_data, 20, metric_to_use, normalization_func, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybercat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
