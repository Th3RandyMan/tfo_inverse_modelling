{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training A Neural Netowrk Using PyTorch and My Custom Libraries\n",
    "This notebook will go through and explain the steps involved in creating a NN model and training it given some dataset\n",
    "\n",
    "## Composer Pattern\n",
    "Model training is set-up using the composer pattern. Where, you create different components and compose them onto a ModelTrainer, which ultimately takes care of the training/validation process. \n",
    "![Pics](./composer.png)\n",
    "\n",
    "\n",
    "## Setting GPU\n",
    "The first step for systems with multiple GPUs is to set which one we want to use. In torch, this is done by changing the environment varaible **CUDA_VISIBLE_DEVICES**. This makes cuda only 'see' that one specific GPU. i.e., all data will be loaded to that GPU. Pytorch will then regard this GPU as 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Dataset\n",
    "Let's define a random dataset. Most of our data is stored as pandas dataframes. I have convinience functions that can convert these DataFrames onto Pytorch DataLoaders. Which, as the name suggests, fetches data during model training. However, you can also manually define your own DataLoader class to use some other types of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output type is <class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from inverse_modelling_tfo.data.data_loader_gen import generate_data_loaders\n",
    "\n",
    "dummy_data = pd.DataFrame({\n",
    "        'A': [1, 2, 3, 4, 5],\n",
    "        'B': [2, 3, 4, 5, 6],\n",
    "        'C': [3, 5, 7, 9, 11]})\n",
    "data_loader_params = {\n",
    "    'batch_size': 2,    # The size of the batches that the dataloader will output\n",
    "    'shuffle': True,    # The dataloader will shuffle its outputs at each epoch\n",
    "    'num_workers': 0,   # The number of workers that the dataloader will use to generate the batches\n",
    "}\n",
    "train_loader, validation_loader = generate_data_loaders(dummy_data, data_loader_params, ['A', 'B'], ['C'])\n",
    "print(\"The output type is\", type(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notes__: The data generated from these loaders are by default set to be stored on CUDA. More specifically, the first GPU on CUDA. You can change the device parameter on **generate_data_loaders** to set this\n",
    "\n",
    "## Validation Method\n",
    "You can pass different validation strategies to alter the training and validation loader behavior. By default, the validation strategy is a RandomSplit(0.8). But, we have a few more options. Here are a few examples. For more info, check the test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inverse_modelling_tfo.models.validation_methods import RandomSplit, ValidationMethod, HoldOneOut, CVSplit, CombineMethods\n",
    "\n",
    "train_loader, validation_loader = generate_data_loaders(dummy_data, data_loader_params, ['A', 'B'], ['C'], CVSplit(2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "The next component we need for training a model is a LossFunction. I have a custom wrapper around pytorch's native loss functions. The benefits of this are two-fold. This wrapper allows us to track the losses over each step and each epoch of the training. Making for a far easier loss tracking/plotting expreience. Additionally, this extends the loss function to include more exotic losses which can take extra inputs(other than model labels and preidctions). This includes physics losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inverse_modelling_tfo.models import TorchLossWrapper\n",
    "import torch.nn as nn   # PyTorch's neural network module\n",
    "\n",
    "criterion = TorchLossWrapper(nn.MSELoss(), name=\"label_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Trainer and Model Trainer Factory\n",
    "Training is done using a ModelTrainer module. This makes training/validation both easier and allows us to keep track of the setup as well for reporducibility. ModelTrainer are usually created from the Factory class, which allows us to put all the parameters in before hand. One last piece we need is the model architecture. We have a custom_models file containing a bunch of custom Pytorch models which are much faster/easier to initialize.    \n",
    "\n",
    "The model example we use here is a fully connected perceptron with BatchNormalization and Dropout layers, called PerceptronBD. The 'node_counts' here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inverse_modelling_tfo.models import ModelTrainerFactory\n",
    "from inverse_modelling_tfo.models.custom_models import PerceptronBD\n",
    "\n",
    "trainer_factory = ModelTrainerFactory(\n",
    "    PerceptronBD, {\"node_counts\": [2, 2, 1]}, generate_data_loaders, data_loader_params, 5, criterion\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybercat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
