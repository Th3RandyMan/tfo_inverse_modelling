{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Saturation-based Simulation Data\n",
    "In this notebook, we try to fit intensity data generated using a saturation based method. The mu_a for each of the maternal and fetal layer are based on a set oxygen saturation and HB concentration. The impact of all other pigments on mu_a are ignored. The goal for this experiment is to see if we can train a model to determine these hidden variables - the Hb conc. and the saturation just by looking at the intensity values!\n",
    "\n",
    "# Instructions\n",
    "I have the parameter search in one of the cells. Run eveerything above it to be able to run that cell.\n",
    "If you don't want to search, ignore that cell and run everything above and below. \n",
    "\n",
    "# V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from inverse_modelling_tfo.models import train_model, train_model_wtih_reporting\n",
    "from inverse_modelling_tfo.data import generate_data_loaders, equidistance_detector_normalization, constant_detector_count_normalization, generate_differential_data_loaders\n",
    "from inverse_modelling_tfo.data.intensity_interpolation import get_interpolate_fit_params_custom, interpolate_exp\n",
    "from inverse_modelling_tfo.data.interpolation_function_zoo import *\n",
    "from inverse_modelling_tfo.models.custom_models import SplitChannelCNN, PerceptronReLU\n",
    "from inverse_modelling_tfo.features.build_features import create_ratio, create_spatial_intensity\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import torchinfo\n",
    "# Set my GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SDD</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>Wave Int</th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Maternal Hb Concentration</th>\n",
       "      <th>Maternal Saturation</th>\n",
       "      <th>Fetal Hb Concentration</th>\n",
       "      <th>Fetal Saturation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>-4.999507</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>-7.171885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>-9.277114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>-10.143018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>-10.149250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SDD  Intensity  Wave Int  Maternal Wall Thickness  \\\n",
       "0   10  -4.999507       1.0                      6.0   \n",
       "1   14  -7.171885       1.0                      6.0   \n",
       "2   19  -9.277114       1.0                      6.0   \n",
       "3   23 -10.143018       1.0                      6.0   \n",
       "4   28 -10.149250       1.0                      6.0   \n",
       "\n",
       "   Maternal Hb Concentration  Maternal Saturation  Fetal Hb Concentration  \\\n",
       "0                       12.0                  0.9                    0.11   \n",
       "1                       12.0                  0.9                    0.11   \n",
       "2                       12.0                  0.9                    0.11   \n",
       "3                       12.0                  0.9                    0.11   \n",
       "4                       12.0                  0.9                    0.11   \n",
       "\n",
       "   Fetal Saturation  \n",
       "0               0.1  \n",
       "1               0.1  \n",
       "2               0.1  \n",
       "3               0.1  \n",
       "4               0.1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.read_pickle(r'/home/rraiyan/personal_projects/tfo_inverse_modelling/data/intensity/s_based_intensity.pkl')\n",
    "# data = pd.read_pickle(r'/home/rraiyan/personal_projects/tfo_inverse_modelling/data/intensity/s_based_intensity_low_conc.pkl')\n",
    "data = pd.read_pickle(r'/home/rraiyan/personal_projects/tfo_inverse_modelling/data/intensity/s_based_intensity_low_conc2.pkl')\n",
    "equidistance_detector_normalization(data)\n",
    "\n",
    "# Drop Uterus Thickness for now\n",
    "data = data.drop(columns='Uterus Thickness')\n",
    "\n",
    "# Interpolate intensity to remove noise\n",
    "data = interpolate_exp(data, weights=[1, -1])\n",
    "data['Intensity'] = data['Interpolated Intensity']\n",
    "data = data.drop(columns='Interpolated Intensity')\n",
    "\n",
    "# Manual log(intensity) normalization\n",
    "data['Intensity'] = np.log10(data['Intensity'])        # Far values wayy to small to affect anything. Take log\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Maternal Hb Concentration</th>\n",
       "      <th>Maternal Saturation</th>\n",
       "      <th>Fetal Hb Concentration</th>\n",
       "      <th>Fetal Saturation</th>\n",
       "      <th>10_1.0</th>\n",
       "      <th>14_1.0</th>\n",
       "      <th>19_1.0</th>\n",
       "      <th>23_1.0</th>\n",
       "      <th>28_1.0</th>\n",
       "      <th>...</th>\n",
       "      <th>55_2.0</th>\n",
       "      <th>59_2.0</th>\n",
       "      <th>64_2.0</th>\n",
       "      <th>68_2.0</th>\n",
       "      <th>73_2.0</th>\n",
       "      <th>77_2.0</th>\n",
       "      <th>82_2.0</th>\n",
       "      <th>86_2.0</th>\n",
       "      <th>91_2.0</th>\n",
       "      <th>95_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-4.784362</td>\n",
       "      <td>-5.887022</td>\n",
       "      <td>-6.560915</td>\n",
       "      <td>-7.015157</td>\n",
       "      <td>-7.712442</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.639869</td>\n",
       "      <td>-22.003357</td>\n",
       "      <td>-25.265887</td>\n",
       "      <td>-28.112349</td>\n",
       "      <td>-31.952534</td>\n",
       "      <td>-35.240710</td>\n",
       "      <td>-39.608559</td>\n",
       "      <td>-43.300212</td>\n",
       "      <td>-48.150422</td>\n",
       "      <td>-52.211376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.225</td>\n",
       "      <td>-4.783804</td>\n",
       "      <td>-5.882596</td>\n",
       "      <td>-6.550246</td>\n",
       "      <td>-6.998650</td>\n",
       "      <td>-7.687817</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.677858</td>\n",
       "      <td>-22.046210</td>\n",
       "      <td>-25.314961</td>\n",
       "      <td>-28.166499</td>\n",
       "      <td>-32.013139</td>\n",
       "      <td>-35.306559</td>\n",
       "      <td>-39.681050</td>\n",
       "      <td>-43.378082</td>\n",
       "      <td>-48.235089</td>\n",
       "      <td>-52.301534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-4.783210</td>\n",
       "      <td>-5.877882</td>\n",
       "      <td>-6.538860</td>\n",
       "      <td>-6.980969</td>\n",
       "      <td>-7.661314</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.715011</td>\n",
       "      <td>-22.088109</td>\n",
       "      <td>-25.362928</td>\n",
       "      <td>-28.219417</td>\n",
       "      <td>-32.072350</td>\n",
       "      <td>-35.370881</td>\n",
       "      <td>-39.751845</td>\n",
       "      <td>-43.454117</td>\n",
       "      <td>-48.317744</td>\n",
       "      <td>-52.389537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.475</td>\n",
       "      <td>-4.782576</td>\n",
       "      <td>-5.872834</td>\n",
       "      <td>-6.526638</td>\n",
       "      <td>-6.961915</td>\n",
       "      <td>-7.632599</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.751362</td>\n",
       "      <td>-22.129094</td>\n",
       "      <td>-25.409836</td>\n",
       "      <td>-28.271155</td>\n",
       "      <td>-32.130227</td>\n",
       "      <td>-35.433740</td>\n",
       "      <td>-39.821015</td>\n",
       "      <td>-43.528395</td>\n",
       "      <td>-48.398473</td>\n",
       "      <td>-52.475475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-4.781896</td>\n",
       "      <td>-5.867394</td>\n",
       "      <td>-6.513429</td>\n",
       "      <td>-6.941227</td>\n",
       "      <td>-7.601231</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.786945</td>\n",
       "      <td>-22.169203</td>\n",
       "      <td>-25.455727</td>\n",
       "      <td>-28.321760</td>\n",
       "      <td>-32.186822</td>\n",
       "      <td>-35.495197</td>\n",
       "      <td>-39.888626</td>\n",
       "      <td>-43.600986</td>\n",
       "      <td>-48.477353</td>\n",
       "      <td>-52.559433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Maternal Wall Thickness  Maternal Hb Concentration  Maternal Saturation  \\\n",
       "0                      2.0                       12.0                  0.9   \n",
       "1                      2.0                       12.0                  0.9   \n",
       "2                      2.0                       12.0                  0.9   \n",
       "3                      2.0                       12.0                  0.9   \n",
       "4                      2.0                       12.0                  0.9   \n",
       "\n",
       "   Fetal Hb Concentration  Fetal Saturation    10_1.0    14_1.0    19_1.0  \\\n",
       "0                    0.11             0.100 -4.784362 -5.887022 -6.560915   \n",
       "1                    0.11             0.225 -4.783804 -5.882596 -6.550246   \n",
       "2                    0.11             0.350 -4.783210 -5.877882 -6.538860   \n",
       "3                    0.11             0.475 -4.782576 -5.872834 -6.526638   \n",
       "4                    0.11             0.600 -4.781896 -5.867394 -6.513429   \n",
       "\n",
       "     23_1.0    28_1.0  ...     55_2.0     59_2.0     64_2.0     68_2.0  \\\n",
       "0 -7.015157 -7.712442  ... -19.639869 -22.003357 -25.265887 -28.112349   \n",
       "1 -6.998650 -7.687817  ... -19.677858 -22.046210 -25.314961 -28.166499   \n",
       "2 -6.980969 -7.661314  ... -19.715011 -22.088109 -25.362928 -28.219417   \n",
       "3 -6.961915 -7.632599  ... -19.751362 -22.129094 -25.409836 -28.271155   \n",
       "4 -6.941227 -7.601231  ... -19.786945 -22.169203 -25.455727 -28.321760   \n",
       "\n",
       "      73_2.0     77_2.0     82_2.0     86_2.0     91_2.0     95_2.0  \n",
       "0 -31.952534 -35.240710 -39.608559 -43.300212 -48.150422 -52.211376  \n",
       "1 -32.013139 -35.306559 -39.681050 -43.378082 -48.235089 -52.301534  \n",
       "2 -32.072350 -35.370881 -39.751845 -43.454117 -48.317744 -52.389537  \n",
       "3 -32.130227 -35.433740 -39.821015 -43.528395 -48.398473 -52.475475  \n",
       "4 -32.186822 -35.495197 -39.888626 -43.600986 -48.477353 -52.559433  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data1 = create_ratio(data, True)\n",
    "# data2 = create_spatial_intensity(data)\n",
    "# sim_params = ['Maternal Wall Thickness', \"Maternal Hb Concentration\", \"Fetal Hb Concentration\", \"Fetal Saturation\", \"Maternal Saturation\"]\n",
    "# data = pd.merge(data1, data2, how='inner', on=sim_params)\n",
    "\n",
    "# data = create_ratio(data, True)\n",
    "\n",
    "data = create_spatial_intensity(data)\n",
    "\n",
    "data.head() \n",
    "# NOTE: Have only 1 on at the same time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Maternal Hb Concentration</th>\n",
       "      <th>Maternal Saturation</th>\n",
       "      <th>Fetal Hb Concentration</th>\n",
       "      <th>Fetal Saturation</th>\n",
       "      <th>10_1.0</th>\n",
       "      <th>14_1.0</th>\n",
       "      <th>19_1.0</th>\n",
       "      <th>23_1.0</th>\n",
       "      <th>28_1.0</th>\n",
       "      <th>...</th>\n",
       "      <th>55_2.0</th>\n",
       "      <th>59_2.0</th>\n",
       "      <th>64_2.0</th>\n",
       "      <th>68_2.0</th>\n",
       "      <th>73_2.0</th>\n",
       "      <th>77_2.0</th>\n",
       "      <th>82_2.0</th>\n",
       "      <th>86_2.0</th>\n",
       "      <th>91_2.0</th>\n",
       "      <th>95_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-4.784362</td>\n",
       "      <td>-5.887022</td>\n",
       "      <td>-6.560915</td>\n",
       "      <td>-7.015157</td>\n",
       "      <td>-7.712442</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.639869</td>\n",
       "      <td>-22.003357</td>\n",
       "      <td>-25.265887</td>\n",
       "      <td>-28.112349</td>\n",
       "      <td>-31.952534</td>\n",
       "      <td>-35.240710</td>\n",
       "      <td>-39.608559</td>\n",
       "      <td>-43.300212</td>\n",
       "      <td>-48.150422</td>\n",
       "      <td>-52.211376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.225</td>\n",
       "      <td>-4.783804</td>\n",
       "      <td>-5.882596</td>\n",
       "      <td>-6.550246</td>\n",
       "      <td>-6.998650</td>\n",
       "      <td>-7.687817</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.677858</td>\n",
       "      <td>-22.046210</td>\n",
       "      <td>-25.314961</td>\n",
       "      <td>-28.166499</td>\n",
       "      <td>-32.013139</td>\n",
       "      <td>-35.306559</td>\n",
       "      <td>-39.681050</td>\n",
       "      <td>-43.378082</td>\n",
       "      <td>-48.235089</td>\n",
       "      <td>-52.301534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-4.783210</td>\n",
       "      <td>-5.877882</td>\n",
       "      <td>-6.538860</td>\n",
       "      <td>-6.980969</td>\n",
       "      <td>-7.661314</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.715011</td>\n",
       "      <td>-22.088109</td>\n",
       "      <td>-25.362928</td>\n",
       "      <td>-28.219417</td>\n",
       "      <td>-32.072350</td>\n",
       "      <td>-35.370881</td>\n",
       "      <td>-39.751845</td>\n",
       "      <td>-43.454117</td>\n",
       "      <td>-48.317744</td>\n",
       "      <td>-52.389537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.475</td>\n",
       "      <td>-4.782576</td>\n",
       "      <td>-5.872834</td>\n",
       "      <td>-6.526638</td>\n",
       "      <td>-6.961915</td>\n",
       "      <td>-7.632599</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.751362</td>\n",
       "      <td>-22.129094</td>\n",
       "      <td>-25.409836</td>\n",
       "      <td>-28.271155</td>\n",
       "      <td>-32.130227</td>\n",
       "      <td>-35.433740</td>\n",
       "      <td>-39.821015</td>\n",
       "      <td>-43.528395</td>\n",
       "      <td>-48.398473</td>\n",
       "      <td>-52.475475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-4.781896</td>\n",
       "      <td>-5.867394</td>\n",
       "      <td>-6.513429</td>\n",
       "      <td>-6.941227</td>\n",
       "      <td>-7.601231</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.786945</td>\n",
       "      <td>-22.169203</td>\n",
       "      <td>-25.455727</td>\n",
       "      <td>-28.321760</td>\n",
       "      <td>-32.186822</td>\n",
       "      <td>-35.495197</td>\n",
       "      <td>-39.888626</td>\n",
       "      <td>-43.600986</td>\n",
       "      <td>-48.477353</td>\n",
       "      <td>-52.559433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Maternal Wall Thickness  Maternal Hb Concentration  Maternal Saturation  \\\n",
       "0                      2.0                       12.0                  0.9   \n",
       "1                      2.0                       12.0                  0.9   \n",
       "2                      2.0                       12.0                  0.9   \n",
       "3                      2.0                       12.0                  0.9   \n",
       "4                      2.0                       12.0                  0.9   \n",
       "\n",
       "   Fetal Hb Concentration  Fetal Saturation    10_1.0    14_1.0    19_1.0  \\\n",
       "0                    0.11             0.100 -4.784362 -5.887022 -6.560915   \n",
       "1                    0.11             0.225 -4.783804 -5.882596 -6.550246   \n",
       "2                    0.11             0.350 -4.783210 -5.877882 -6.538860   \n",
       "3                    0.11             0.475 -4.782576 -5.872834 -6.526638   \n",
       "4                    0.11             0.600 -4.781896 -5.867394 -6.513429   \n",
       "\n",
       "     23_1.0    28_1.0  ...     55_2.0     59_2.0     64_2.0     68_2.0  \\\n",
       "0 -7.015157 -7.712442  ... -19.639869 -22.003357 -25.265887 -28.112349   \n",
       "1 -6.998650 -7.687817  ... -19.677858 -22.046210 -25.314961 -28.166499   \n",
       "2 -6.980969 -7.661314  ... -19.715011 -22.088109 -25.362928 -28.219417   \n",
       "3 -6.961915 -7.632599  ... -19.751362 -22.129094 -25.409836 -28.271155   \n",
       "4 -6.941227 -7.601231  ... -19.786945 -22.169203 -25.455727 -28.321760   \n",
       "\n",
       "      73_2.0     77_2.0     82_2.0     86_2.0     91_2.0     95_2.0  \n",
       "0 -31.952534 -35.240710 -39.608559 -43.300212 -48.150422 -52.211376  \n",
       "1 -32.013139 -35.306559 -39.681050 -43.378082 -48.235089 -52.301534  \n",
       "2 -32.072350 -35.370881 -39.751845 -43.454117 -48.317744 -52.389537  \n",
       "3 -32.130227 -35.433740 -39.821015 -43.528395 -48.398473 -52.475475  \n",
       "4 -32.186822 -35.495197 -39.888626 -43.600986 -48.477353 -52.559433  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup\n",
    "data.dropna(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Features\n",
    "x_columns will be the input features and y_columns are the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Y -> Target\n",
    "# y_columns = ['Maternal Wall Thickness', \"Maternal Hb Concentration\", \"Maternal Saturation\", \"Fetal Hb Concentration\", \"Fetal Saturation\"]\n",
    "# y_columns = ['Maternal Saturation']\n",
    "# y_columns = ['Maternal Hb Concentration']\n",
    "y_column = 'Fetal Saturation'\n",
    "fixed_columns = ['Maternal Wall Thickness', \"Fetal Saturation\", \"Maternal Saturation\"]\n",
    "# y_columns = ['Fetal Hb Concentration']\n",
    "\n",
    "## X -> Predictors\n",
    "# x_columns = list(filter(lambda X: '_' in X, data.columns))\n",
    "# x_columns = list(filter(lambda X: X.isdigit(), data.columns))\n",
    "x_columns = list(filter(lambda X: X.isdigit(), data.columns)) + list(filter(lambda X: '_' in X, data.columns))\n",
    "\n",
    "\n",
    "\n",
    "## Pass in maternal info\n",
    "# x_columns += [\"Maternal Hb Concentration\", \"Maternal Saturation\"]\n",
    "\n",
    "## Scale y\n",
    "y_scaler = preprocessing.StandardScaler()\n",
    "data[y_column] = y_scaler.fit_transform(data[y_column].to_numpy().reshape(-1, 1))\n",
    "\n",
    "## Scale x\n",
    "x_scaler = preprocessing.StandardScaler()\n",
    "data[x_columns] = x_scaler.fit_transform(data[x_columns])\n",
    "## Manual scale - if needed (With maternal info.)\n",
    "# data[x_columns[:-2]] /= 100.0    # stddev.   (Actual value is higher but let's keep it here for now)\n",
    "# data[x_columns[:-2]] += 0.5  # unit var, 0 mean\n",
    "\n",
    "## Scale non-intensity x columns (Maternal Hb Conc. , Maternal Saturation)\n",
    "# data[\"Maternal Saturation\"] -= 0.5 \n",
    "# data[\"Maternal Hb Concentration\"] /= 20\n",
    "# data[\"Maternal Hb Concentration\"] -= 0.5 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y scale mean [0.35]\n",
      "Y scale var [0.03125]\n"
     ]
    }
   ],
   "source": [
    "# Print Out Scaler values\n",
    "print(f'Y scale mean {y_scaler.mean_}')\n",
    "print(f'Y scale var {y_scaler.var_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.414214    375\n",
       "-0.707107    375\n",
       " 0.000000    375\n",
       " 0.707107    375\n",
       " 1.414214    375\n",
       "Name: Fetal Saturation, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[y_column].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_FEATURES = len(x_columns) * 2\n",
    "OUT_FEATURES = 1\n",
    "model_config = {\n",
    "    # 'model_class' : SplitChannelCNN,  # Class name\n",
    "    'model_class' : PerceptronReLU,  # Class name\n",
    "    # 'model_params' :  [2, IN_FEATURES, 4, 5, [2, OUT_FEATURES]],    # Input params as an array\n",
    "    # 'model_params' :  [3, IN_FEATURES, 6, 5, [6, 3, OUT_FEATURES]],    # Input params as an array\n",
    "    # 'model_params' :  [3, IN_FEATURES, 6, 7, [3, OUT_FEATURES]],    # Input params as an array\n",
    "    'model_params' :  [[IN_FEATURES, 20, 8, OUT_FEATURES]],    # Input params as an array\n",
    "    'train_split' : 0.8,\n",
    "    'epochs' : 40,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Train Function \n",
    "def train_model2(iteration_config, epoch=60):\n",
    "    np.random.seed(70)  # Set seed for consistentcy\n",
    "    params = {\n",
    "        'batch_size': iteration_config['batch_size'], 'shuffle': True, 'num_workers': 2\n",
    "    }\n",
    "    # train, val = generate_data_loaders(data, params, x_columns, y_columns, model_config['train_split'])\n",
    "    train, val = generate_differential_data_loaders(data, params, fixed_columns, x_columns, y_column, 20000, model_config['train_split'])\n",
    "    # model = create_perceptron_model(config['model'])\n",
    "    # model = create_perceptron_model([42, 8, 1])\n",
    "    # model = TwoChannelCNN(40, 4, 5, [4, 1])\n",
    "    model = model_config['model_class'](*model_config['model_params'])\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = SGD(model.parameters(), lr=iteration_config[\"lr\"], momentum=iteration_config[\"momentum\"])\n",
    "    # optimizer = Adam(model.parameters(), lr=config[\"lr\"], betas=[config[\"b1\"], config[\"b2\"]])\n",
    "    train_loss, val_loss = train_model_wtih_reporting(model, optimizer=optimizer, criterion=criterion, train_loader=train, validation_loader=val, epochs=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 11:56:27,287\tINFO worker.py:1625 -- Started a local Ray instance.\n",
      "2023-07-14 11:56:28,068\tINFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-14 11:56:28 (running for 00:00:00.30)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 4.0/64 CPUs, 0.05/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-14_11-56-28\n",
      "Number of trials: 70/80 (69 PENDING, 1 RUNNING)\n",
      "+--------------------------+----------+-----------------------+--------------+-------------+------------+\n",
      "| Trial name               | status   | loc                   |   batch_size |          lr |   momentum |\n",
      "|--------------------------+----------+-----------------------+--------------+-------------+------------|\n",
      "| train_model2_236c8_00000 | RUNNING  | 169.237.32.34:2294822 |           16 | 5.38552e-05 |       0.97 |\n",
      "| train_model2_236c8_00001 | PENDING  |                       |           16 | 4.2002e-05  |       0.93 |\n",
      "| train_model2_236c8_00002 | PENDING  |                       |           16 | 0.00038797  |       0.95 |\n",
      "| train_model2_236c8_00003 | PENDING  |                       |           16 | 3.79099e-05 |       0.97 |\n",
      "| train_model2_236c8_00004 | PENDING  |                       |            8 | 0.000170764 |       0.93 |\n",
      "| train_model2_236c8_00005 | PENDING  |                       |           16 | 4.80181e-05 |       0.93 |\n",
      "| train_model2_236c8_00006 | PENDING  |                       |            8 | 0.000421554 |       0.93 |\n",
      "| train_model2_236c8_00007 | PENDING  |                       |           16 | 2.53468e-05 |       0.93 |\n",
      "| train_model2_236c8_00008 | PENDING  |                       |           16 | 0.000297076 |       0.95 |\n",
      "| train_model2_236c8_00009 | PENDING  |                       |           16 | 1.63529e-05 |       0.93 |\n",
      "| train_model2_236c8_00010 | PENDING  |                       |           16 | 1.39453e-05 |       0.95 |\n",
      "| train_model2_236c8_00011 | PENDING  |                       |           16 | 2.7799e-05  |       0.95 |\n",
      "| train_model2_236c8_00012 | PENDING  |                       |            8 | 7.71615e-05 |       0.97 |\n",
      "| train_model2_236c8_00013 | PENDING  |                       |            8 | 5.24558e-05 |       0.93 |\n",
      "| train_model2_236c8_00014 | PENDING  |                       |           32 | 0.000136756 |       0.93 |\n",
      "| train_model2_236c8_00015 | PENDING  |                       |           32 | 1.31479e-05 |       0.93 |\n",
      "| train_model2_236c8_00016 | PENDING  |                       |           32 | 3.99445e-05 |       0.95 |\n",
      "| train_model2_236c8_00017 | PENDING  |                       |            8 | 1.07888e-05 |       0.93 |\n",
      "| train_model2_236c8_00018 | PENDING  |                       |           32 | 0.000433894 |       0.93 |\n",
      "| train_model2_236c8_00019 | PENDING  |                       |           16 | 0.000137812 |       0.95 |\n",
      "+--------------------------+----------+-----------------------+--------------+-------------+------------+\n",
      "... 50 more trials not shown (50 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([16, 1, 1])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m   return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th style=\"text-align: right;\">  combined_loss</th><th>date               </th><th>done  </th><th>hostname  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip      </th><th style=\"text-align: right;\">    pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">   val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model2_236c8_00000</td><td style=\"text-align: right;\">    1.82813e-07</td><td>2023-07-14_11-56-41</td><td>False </td><td>blueberry </td><td style=\"text-align: right;\">                         2</td><td>169.237.32.34</td><td style=\"text-align: right;\">2294822</td><td style=\"text-align: right;\">             11.9793</td><td style=\"text-align: right;\">           7.00752</td><td style=\"text-align: right;\">       11.9793</td><td style=\"text-align: right;\"> 1689361001</td><td style=\"text-align: right;\"> 0.000467599</td><td style=\"text-align: right;\">                   2</td><td>236c8_00000</td><td style=\"text-align: right;\">0.000390961</td></tr>\n",
       "<tr><td>train_model2_236c8_00001</td><td style=\"text-align: right;\">    5.26228e-05</td><td>2023-07-14_11-56-42</td><td>False </td><td>blueberry </td><td style=\"text-align: right;\">                         1</td><td>169.237.32.34</td><td style=\"text-align: right;\">2294907</td><td style=\"text-align: right;\">             10.611 </td><td style=\"text-align: right;\">          10.611  </td><td style=\"text-align: right;\">       10.611 </td><td style=\"text-align: right;\"> 1689361002</td><td style=\"text-align: right;\"> 0.0140353  </td><td style=\"text-align: right;\">                   1</td><td>236c8_00001</td><td style=\"text-align: right;\">0.00374931 </td></tr>\n",
       "<tr><td>train_model2_236c8_00002</td><td style=\"text-align: right;\">    2.14976e-07</td><td>2023-07-14_11-56-41</td><td>False </td><td>blueberry </td><td style=\"text-align: right;\">                         1</td><td>169.237.32.34</td><td style=\"text-align: right;\">2294909</td><td style=\"text-align: right;\">             10.5529</td><td style=\"text-align: right;\">          10.5529 </td><td style=\"text-align: right;\">       10.5529</td><td style=\"text-align: right;\"> 1689361001</td><td style=\"text-align: right;\"> 0.00150712 </td><td style=\"text-align: right;\">                   1</td><td>236c8_00002</td><td style=\"text-align: right;\">0.00014264 </td></tr>\n",
       "<tr><td>train_model2_236c8_00003</td><td style=\"text-align: right;\">    1.04725e-05</td><td>2023-07-14_11-56-41</td><td>False </td><td>blueberry </td><td style=\"text-align: right;\">                         1</td><td>169.237.32.34</td><td style=\"text-align: right;\">2294911</td><td style=\"text-align: right;\">             10.2696</td><td style=\"text-align: right;\">          10.2696 </td><td style=\"text-align: right;\">       10.2696</td><td style=\"text-align: right;\"> 1689361001</td><td style=\"text-align: right;\"> 0.0165637  </td><td style=\"text-align: right;\">                   1</td><td>236c8_00003</td><td style=\"text-align: right;\">0.00063226 </td></tr>\n",
       "<tr><td>train_model2_236c8_00005</td><td style=\"text-align: right;\">    1.34673e-06</td><td>2023-07-14_11-56-42</td><td>False </td><td>blueberry </td><td style=\"text-align: right;\">                         1</td><td>169.237.32.34</td><td style=\"text-align: right;\">2294915</td><td style=\"text-align: right;\">             10.7782</td><td style=\"text-align: right;\">          10.7782 </td><td style=\"text-align: right;\">       10.7782</td><td style=\"text-align: right;\"> 1689361002</td><td style=\"text-align: right;\"> 0.00297804 </td><td style=\"text-align: right;\">                   1</td><td>236c8_00005</td><td style=\"text-align: right;\">0.000452221</td></tr>\n",
       "<tr><td>train_model2_236c8_00007</td><td style=\"text-align: right;\">    0.000159237</td><td>2023-07-14_11-56-42</td><td>False </td><td>blueberry </td><td style=\"text-align: right;\">                         1</td><td>169.237.32.34</td><td style=\"text-align: right;\">2294928</td><td style=\"text-align: right;\">             10.6873</td><td style=\"text-align: right;\">          10.6873 </td><td style=\"text-align: right;\">       10.6873</td><td style=\"text-align: right;\"> 1689361002</td><td style=\"text-align: right;\"> 0.0212728  </td><td style=\"text-align: right;\">                   1</td><td>236c8_00007</td><td style=\"text-align: right;\">0.00748546 </td></tr>\n",
       "<tr><td>train_model2_236c8_00008</td><td style=\"text-align: right;\">    1.74612e-07</td><td>2023-07-14_11-56-42</td><td>False </td><td>blueberry </td><td style=\"text-align: right;\">                         1</td><td>169.237.32.34</td><td style=\"text-align: right;\">2294931</td><td style=\"text-align: right;\">             10.6031</td><td style=\"text-align: right;\">          10.6031 </td><td style=\"text-align: right;\">       10.6031</td><td style=\"text-align: right;\"> 1689361002</td><td style=\"text-align: right;\"> 0.00147027 </td><td style=\"text-align: right;\">                   1</td><td>236c8_00008</td><td style=\"text-align: right;\">0.000118762</td></tr>\n",
       "<tr><td>train_model2_236c8_00009</td><td style=\"text-align: right;\">    4.21791e-05</td><td>2023-07-14_11-56-42</td><td>False </td><td>blueberry </td><td style=\"text-align: right;\">                         1</td><td>169.237.32.34</td><td style=\"text-align: right;\">2294934</td><td style=\"text-align: right;\">             10.8249</td><td style=\"text-align: right;\">          10.8249 </td><td style=\"text-align: right;\">       10.8249</td><td style=\"text-align: right;\"> 1689361002</td><td style=\"text-align: right;\"> 0.0112048  </td><td style=\"text-align: right;\">                   1</td><td>236c8_00009</td><td style=\"text-align: right;\">0.00376437 </td></tr>\n",
       "<tr><td>train_model2_236c8_00010</td><td style=\"text-align: right;\">    0.000241077</td><td>2023-07-14_11-56-42</td><td>False </td><td>blueberry </td><td style=\"text-align: right;\">                         1</td><td>169.237.32.34</td><td style=\"text-align: right;\">2294937</td><td style=\"text-align: right;\">             10.7665</td><td style=\"text-align: right;\">          10.7665 </td><td style=\"text-align: right;\">       10.7665</td><td style=\"text-align: right;\"> 1689361002</td><td style=\"text-align: right;\"> 0.0344442  </td><td style=\"text-align: right;\">                   1</td><td>236c8_00010</td><td style=\"text-align: right;\">0.00699906 </td></tr>\n",
       "<tr><td>train_model2_236c8_00011</td><td style=\"text-align: right;\">    3.76281e-08</td><td>2023-07-14_11-56-42</td><td>False </td><td>blueberry </td><td style=\"text-align: right;\">                         1</td><td>169.237.32.34</td><td style=\"text-align: right;\">2294939</td><td style=\"text-align: right;\">             10.8216</td><td style=\"text-align: right;\">          10.8216 </td><td style=\"text-align: right;\">       10.8216</td><td style=\"text-align: right;\"> 1689361002</td><td style=\"text-align: right;\"> 0.000356645</td><td style=\"text-align: right;\">                   1</td><td>236c8_00011</td><td style=\"text-align: right;\">0.000105506</td></tr>\n",
       "<tr><td>train_model2_236c8_00014</td><td style=\"text-align: right;\">    1.44679e-06</td><td>2023-07-14_11-56-46</td><td>False </td><td>blueberry </td><td style=\"text-align: right;\">                         3</td><td>169.237.32.34</td><td style=\"text-align: right;\">2294946</td><td style=\"text-align: right;\">             14.6309</td><td style=\"text-align: right;\">           3.88569</td><td style=\"text-align: right;\">       14.6309</td><td style=\"text-align: right;\"> 1689361006</td><td style=\"text-align: right;\"> 0.00126344 </td><td style=\"text-align: right;\">                   3</td><td>236c8_00014</td><td style=\"text-align: right;\">0.00114512 </td></tr>\n",
       "<tr><td>train_model2_236c8_00015</td><td style=\"text-align: right;\">    0.00363884 </td><td>2023-07-14_11-56-38</td><td>False </td><td>blueberry </td><td style=\"text-align: right;\">                         1</td><td>169.237.32.34</td><td style=\"text-align: right;\">2294950</td><td style=\"text-align: right;\">              7.3185</td><td style=\"text-align: right;\">           7.3185 </td><td style=\"text-align: right;\">        7.3185</td><td style=\"text-align: right;\"> 1689360998</td><td style=\"text-align: right;\"> 0.0747485  </td><td style=\"text-align: right;\">                   1</td><td>236c8_00015</td><td style=\"text-align: right;\">0.0486811  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-14 11:56:34 (running for 00:00:06.63)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-14_11-56-28\n",
      "Number of trials: 80/80 (64 PENDING, 16 RUNNING)\n",
      "+--------------------------+----------+-----------------------+--------------+-------------+------------+--------------+-------------+-----------------+----------------------+\n",
      "| Trial name               | status   | loc                   |   batch_size |          lr |   momentum |   train_loss |    val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+----------+-----------------------+--------------+-------------+------------+--------------+-------------+-----------------+----------------------|\n",
      "| train_model2_236c8_00000 | RUNNING  | 169.237.32.34:2294822 |           16 | 5.38552e-05 |       0.97 |    0.0159726 | 0.000515132 |       8.228e-06 |                    1 |\n",
      "| train_model2_236c8_00001 | RUNNING  | 169.237.32.34:2294907 |           16 | 4.2002e-05  |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00002 | RUNNING  | 169.237.32.34:2294909 |           16 | 0.00038797  |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00003 | RUNNING  | 169.237.32.34:2294911 |           16 | 3.79099e-05 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00004 | RUNNING  | 169.237.32.34:2294913 |            8 | 0.000170764 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00005 | RUNNING  | 169.237.32.34:2294915 |           16 | 4.80181e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00006 | RUNNING  | 169.237.32.34:2294926 |            8 | 0.000421554 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00007 | RUNNING  | 169.237.32.34:2294928 |           16 | 2.53468e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00008 | RUNNING  | 169.237.32.34:2294931 |           16 | 0.000297076 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00009 | RUNNING  | 169.237.32.34:2294934 |           16 | 1.63529e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00016 | PENDING  |                       |           32 | 3.99445e-05 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00017 | PENDING  |                       |            8 | 1.07888e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00018 | PENDING  |                       |           32 | 0.000433894 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00019 | PENDING  |                       |           16 | 0.000137812 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00020 | PENDING  |                       |            8 | 1.73417e-05 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00021 | PENDING  |                       |           32 | 0.000218227 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00022 | PENDING  |                       |           16 | 0.000919178 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00023 | PENDING  |                       |           16 | 3.90786e-05 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00024 | PENDING  |                       |           32 | 0.000129077 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00025 | PENDING  |                       |           32 | 1.29666e-05 |       0.95 |              |             |                 |                      |\n",
      "+--------------------------+----------+-----------------------+--------------+-------------+------------+--------------+-------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (6 RUNNING, 54 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([31, 1, 1])) that is different to the input size (torch.Size([31, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\u001b[32m [repeated 17x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m   return F.mse_loss(input, target, reduction=self.reduction)\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-14 11:56:41 (running for 00:00:13.59)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-14_11-56-28\n",
      "Number of trials: 80/80 (64 PENDING, 16 RUNNING)\n",
      "+--------------------------+----------+-----------------------+--------------+-------------+------------+--------------+-------------+-----------------+----------------------+\n",
      "| Trial name               | status   | loc                   |   batch_size |          lr |   momentum |   train_loss |    val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+----------+-----------------------+--------------+-------------+------------+--------------+-------------+-----------------+----------------------|\n",
      "| train_model2_236c8_00000 | RUNNING  | 169.237.32.34:2294822 |           16 | 5.38552e-05 |       0.97 |    0.0159726 | 0.000515132 |     8.228e-06   |                    1 |\n",
      "| train_model2_236c8_00001 | RUNNING  | 169.237.32.34:2294907 |           16 | 4.2002e-05  |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00002 | RUNNING  | 169.237.32.34:2294909 |           16 | 0.00038797  |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00003 | RUNNING  | 169.237.32.34:2294911 |           16 | 3.79099e-05 |       0.97 |    0.0165637 | 0.00063226  |     1.04725e-05 |                    1 |\n",
      "| train_model2_236c8_00004 | RUNNING  | 169.237.32.34:2294913 |            8 | 0.000170764 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00005 | RUNNING  | 169.237.32.34:2294915 |           16 | 4.80181e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00006 | RUNNING  | 169.237.32.34:2294926 |            8 | 0.000421554 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00007 | RUNNING  | 169.237.32.34:2294928 |           16 | 2.53468e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00008 | RUNNING  | 169.237.32.34:2294931 |           16 | 0.000297076 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00009 | RUNNING  | 169.237.32.34:2294934 |           16 | 1.63529e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00016 | PENDING  |                       |           32 | 3.99445e-05 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00017 | PENDING  |                       |            8 | 1.07888e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00018 | PENDING  |                       |           32 | 0.000433894 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00019 | PENDING  |                       |           16 | 0.000137812 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00020 | PENDING  |                       |            8 | 1.73417e-05 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00021 | PENDING  |                       |           32 | 0.000218227 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00022 | PENDING  |                       |           16 | 0.000919178 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00023 | PENDING  |                       |           16 | 3.90786e-05 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00024 | PENDING  |                       |           32 | 0.000129077 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00025 | PENDING  |                       |           32 | 1.29666e-05 |       0.95 |              |             |                 |                      |\n",
      "+--------------------------+----------+-----------------------+--------------+-------------+------------+--------------+-------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (6 RUNNING, 54 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 11:56:45,391\tWARNING tune.py:184 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2023-07-14 11:56:46,151\tERROR tune.py:941 -- Trials did not complete: [train_model2_236c8_00000, train_model2_236c8_00001, train_model2_236c8_00002, train_model2_236c8_00003, train_model2_236c8_00004, train_model2_236c8_00005, train_model2_236c8_00006, train_model2_236c8_00007, train_model2_236c8_00008, train_model2_236c8_00009, train_model2_236c8_00010, train_model2_236c8_00011, train_model2_236c8_00012, train_model2_236c8_00013, train_model2_236c8_00014, train_model2_236c8_00015, train_model2_236c8_00016, train_model2_236c8_00017, train_model2_236c8_00018, train_model2_236c8_00019, train_model2_236c8_00020, train_model2_236c8_00021, train_model2_236c8_00022, train_model2_236c8_00023, train_model2_236c8_00024, train_model2_236c8_00025, train_model2_236c8_00026, train_model2_236c8_00027, train_model2_236c8_00028, train_model2_236c8_00029, train_model2_236c8_00030, train_model2_236c8_00031, train_model2_236c8_00032, train_model2_236c8_00033, train_model2_236c8_00034, train_model2_236c8_00035, train_model2_236c8_00036, train_model2_236c8_00037, train_model2_236c8_00038, train_model2_236c8_00039, train_model2_236c8_00040, train_model2_236c8_00041, train_model2_236c8_00042, train_model2_236c8_00043, train_model2_236c8_00044, train_model2_236c8_00045, train_model2_236c8_00046, train_model2_236c8_00047, train_model2_236c8_00048, train_model2_236c8_00049, train_model2_236c8_00050, train_model2_236c8_00051, train_model2_236c8_00052, train_model2_236c8_00053, train_model2_236c8_00054, train_model2_236c8_00055, train_model2_236c8_00056, train_model2_236c8_00057, train_model2_236c8_00058, train_model2_236c8_00059, train_model2_236c8_00060, train_model2_236c8_00061, train_model2_236c8_00062, train_model2_236c8_00063, train_model2_236c8_00064, train_model2_236c8_00065, train_model2_236c8_00066, train_model2_236c8_00067, train_model2_236c8_00068, train_model2_236c8_00069, train_model2_236c8_00070, train_model2_236c8_00071, train_model2_236c8_00072, train_model2_236c8_00073, train_model2_236c8_00074, train_model2_236c8_00075, train_model2_236c8_00076, train_model2_236c8_00077, train_model2_236c8_00078, train_model2_236c8_00079]\n",
      "2023-07-14 11:56:46,152\tINFO tune.py:945 -- Total run time: 18.08 seconds (18.01 seconds for the tuning loop).\n",
      "2023-07-14 11:56:46,152\tWARNING tune.py:954 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Continue running this experiment with: tune.run(..., resume=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-14 11:56:46 (running for 00:00:18.03)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-14_11-56-28\n",
      "Number of trials: 80/80 (64 PENDING, 16 RUNNING)\n",
      "+--------------------------+----------+-----------------------+--------------+-------------+------------+--------------+-------------+-----------------+----------------------+\n",
      "| Trial name               | status   | loc                   |   batch_size |          lr |   momentum |   train_loss |    val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+----------+-----------------------+--------------+-------------+------------+--------------+-------------+-----------------+----------------------|\n",
      "| train_model2_236c8_00000 | RUNNING  | 169.237.32.34:2294822 |           16 | 5.38552e-05 |       0.97 |  0.000467599 | 0.000390961 |     1.82813e-07 |                    2 |\n",
      "| train_model2_236c8_00001 | RUNNING  | 169.237.32.34:2294907 |           16 | 4.2002e-05  |       0.93 |  0.0140353   | 0.00374931  |     5.26228e-05 |                    1 |\n",
      "| train_model2_236c8_00002 | RUNNING  | 169.237.32.34:2294909 |           16 | 0.00038797  |       0.95 |  0.00150712  | 0.00014264  |     2.14976e-07 |                    1 |\n",
      "| train_model2_236c8_00003 | RUNNING  | 169.237.32.34:2294911 |           16 | 3.79099e-05 |       0.97 |  0.0165637   | 0.00063226  |     1.04725e-05 |                    1 |\n",
      "| train_model2_236c8_00004 | RUNNING  | 169.237.32.34:2294913 |            8 | 0.000170764 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00005 | RUNNING  | 169.237.32.34:2294915 |           16 | 4.80181e-05 |       0.93 |  0.00297804  | 0.000452221 |     1.34673e-06 |                    1 |\n",
      "| train_model2_236c8_00006 | RUNNING  | 169.237.32.34:2294926 |            8 | 0.000421554 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00007 | RUNNING  | 169.237.32.34:2294928 |           16 | 2.53468e-05 |       0.93 |  0.0212728   | 0.00748546  |     0.000159237 |                    1 |\n",
      "| train_model2_236c8_00008 | RUNNING  | 169.237.32.34:2294931 |           16 | 0.000297076 |       0.95 |  0.00147027  | 0.000118762 |     1.74612e-07 |                    1 |\n",
      "| train_model2_236c8_00009 | RUNNING  | 169.237.32.34:2294934 |           16 | 1.63529e-05 |       0.93 |  0.0112048   | 0.00376437  |     4.21791e-05 |                    1 |\n",
      "| train_model2_236c8_00010 | RUNNING  | 169.237.32.34:2294937 |           16 | 1.39453e-05 |       0.95 |  0.0344442   | 0.00699906  |     0.000241077 |                    1 |\n",
      "| train_model2_236c8_00011 | RUNNING  | 169.237.32.34:2294939 |           16 | 2.7799e-05  |       0.95 |  0.000356645 | 0.000105506 |     3.76281e-08 |                    1 |\n",
      "| train_model2_236c8_00012 | RUNNING  | 169.237.32.34:2294942 |            8 | 7.71615e-05 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00013 | RUNNING  | 169.237.32.34:2294944 |            8 | 5.24558e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00014 | RUNNING  | 169.237.32.34:2294946 |           32 | 0.000136756 |       0.93 |  0.00126344  | 0.00114512  |     1.44679e-06 |                    3 |\n",
      "| train_model2_236c8_00015 | RUNNING  | 169.237.32.34:2294950 |           32 | 1.31479e-05 |       0.93 |  0.0345816   | 0.0230476   |     0.000797023 |                    2 |\n",
      "| train_model2_236c8_00016 | PENDING  |                       |           32 | 3.99445e-05 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00017 | PENDING  |                       |            8 | 1.07888e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00018 | PENDING  |                       |           32 | 0.000433894 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00019 | PENDING  |                       |           16 | 0.000137812 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00020 | PENDING  |                       |            8 | 1.73417e-05 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00021 | PENDING  |                       |           32 | 0.000218227 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00022 | PENDING  |                       |           16 | 0.000919178 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00023 | PENDING  |                       |           16 | 3.90786e-05 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00024 | PENDING  |                       |           32 | 0.000129077 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00025 | PENDING  |                       |           32 | 1.29666e-05 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00026 | PENDING  |                       |           32 | 0.000232484 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00027 | PENDING  |                       |           32 | 1.14495e-05 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00028 | PENDING  |                       |            8 | 5.43727e-05 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00029 | PENDING  |                       |            8 | 4.36253e-05 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00030 | PENDING  |                       |           32 | 8.94438e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00031 | PENDING  |                       |           32 | 0.000421226 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00032 | PENDING  |                       |           32 | 0.000100331 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00033 | PENDING  |                       |            8 | 4.23334e-05 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00034 | PENDING  |                       |            8 | 1.26516e-05 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00035 | PENDING  |                       |            8 | 5.80813e-05 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00036 | PENDING  |                       |           16 | 0.000220095 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00037 | PENDING  |                       |           16 | 1.37421e-05 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00038 | PENDING  |                       |           16 | 0.000243492 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00039 | PENDING  |                       |           32 | 7.75458e-05 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00040 | PENDING  |                       |            8 | 0.000109591 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00041 | PENDING  |                       |            8 | 1.05223e-05 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00042 | PENDING  |                       |           16 | 1.98371e-05 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00043 | PENDING  |                       |            8 | 1.99295e-05 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00044 | PENDING  |                       |            8 | 2.05962e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00045 | PENDING  |                       |           32 | 9.95206e-05 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00046 | PENDING  |                       |            8 | 6.76318e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00047 | PENDING  |                       |           16 | 0.00033183  |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00048 | PENDING  |                       |           16 | 1.431e-05   |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00049 | PENDING  |                       |           32 | 1.83012e-05 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00050 | PENDING  |                       |           16 | 0.000795047 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00051 | PENDING  |                       |           16 | 0.000344103 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00052 | PENDING  |                       |            8 | 1.46115e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00053 | PENDING  |                       |           16 | 1.27174e-05 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00054 | PENDING  |                       |           32 | 2.73137e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00055 | PENDING  |                       |           16 | 0.000282529 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00056 | PENDING  |                       |           32 | 5.56163e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00057 | PENDING  |                       |            8 | 0.000151657 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00058 | PENDING  |                       |           32 | 1.07533e-05 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00059 | PENDING  |                       |           16 | 0.000372601 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00060 | PENDING  |                       |           16 | 0.000831442 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00061 | PENDING  |                       |           32 | 2.17519e-05 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00062 | PENDING  |                       |           16 | 1.12493e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00063 | PENDING  |                       |           32 | 5.13124e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00064 | PENDING  |                       |           32 | 2.57537e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00065 | PENDING  |                       |            8 | 0.000155944 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00066 | PENDING  |                       |           32 | 8.11505e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00067 | PENDING  |                       |           32 | 8.40942e-05 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00068 | PENDING  |                       |           32 | 1.12207e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00069 | PENDING  |                       |           16 | 1.03254e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00070 | PENDING  |                       |            8 | 0.00073587  |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00071 | PENDING  |                       |           32 | 0.00018835  |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00072 | PENDING  |                       |           16 | 7.05289e-05 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00073 | PENDING  |                       |           32 | 0.000487316 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00074 | PENDING  |                       |           16 | 0.000579608 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00075 | PENDING  |                       |            8 | 0.000747215 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00076 | PENDING  |                       |           16 | 1.53737e-05 |       0.97 |              |             |                 |                      |\n",
      "| train_model2_236c8_00077 | PENDING  |                       |            8 | 2.16904e-05 |       0.93 |              |             |                 |                      |\n",
      "| train_model2_236c8_00078 | PENDING  |                       |           32 | 1.11918e-05 |       0.95 |              |             |                 |                      |\n",
      "| train_model2_236c8_00079 | PENDING  |                       |           16 | 1.20897e-05 |       0.97 |              |             |                 |                      |\n",
      "+--------------------------+----------+-----------------------+--------------+-------------+------------+--------------+-------------+-----------------+----------------------+\n",
      "\n",
      "\n",
      "Best trial config: {'lr': 2.779901693106406e-05, 'batch_size': 16, 'momentum': 0.95}\n",
      "Best trial final validation loss: 0.00010550578308175318\n",
      "Best trial final train loss: 0.00035664461403212043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m 2023-07-14 11:56:46,148\tERROR worker.py:844 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1197, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1100, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m   File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m   File \"python/ray/_raylet.pyx\", line 870, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m   File \"python/ray/_raylet.pyx\", line 877, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m   File \"python/ray/_raylet.pyx\", line 881, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m   File \"python/ray/_raylet.pyx\", line 821, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m   File \"/home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 670, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m   File \"/home/rraiyan/cybercat/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 460, in _resume_span\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m   File \"/home/rraiyan/cybercat/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 381, in train\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m     result = self.step()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m   File \"/home/rraiyan/cybercat/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 460, in _resume_span\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m   File \"/home/rraiyan/cybercat/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 376, in step\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m     result = self._results_queue.get(\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m   File \"/usr/lib/python3.8/queue.py\", line 179, in get\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m     self.not_empty.wait(remaining)\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 306, in wait\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m     gotit = waiter.acquire(True, timeout)\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m   File \"/home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_private/worker.py\", line 841, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294822)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294934)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([15, 1, 1])) that is different to the input size (torch.Size([15, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294934)\u001b[0m   return F.mse_loss(input, target, reduction=self.reduction)\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m [2023-07-14 11:56:46,249 C 2294946 2294946] core_worker.cc:767:  Check failed: _s.ok() Bad status: IOError: Broken pipe\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(+0xd7dcaa) [0x7f5b8f3fbcaa] ray::operator<<()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(+0xd7f792) [0x7f5b8f3fd792] ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray6RayLogD1Ev+0x37) [0x7f5b8f3fdaa7] ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core10CoreWorker4ExitENS_3rpc14WorkerExitTypeERKSsRKSt10shared_ptrINS_17LocalMemoryBufferEE+0x1ab) [0x7f5b8ecebf3b] ray::core::CoreWorker::Exit()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core10CoreWorker11ExecuteTaskERKNS_17TaskSpecificationERKSt10shared_ptrISt13unordered_mapISsSt6vectorISt4pairIldESaIS9_EESt4hashISsESt8equal_toISsESaIS8_IKSsSB_EEEEPS7_IS8_INS_8ObjectIDES5_INS_9RayObjectEEESaISQ_EEST_PN6google8protobuf16RepeatedPtrFieldINS_3rpc20ObjectReferenceCountEEEPbPSs+0x1d10) [0x7f5b8ecfcb90] ray::core::CoreWorker::ExecuteTask()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(_ZNSt17_Function_handlerIFN3ray6StatusERKNS0_17TaskSpecificationESt10shared_ptrISt13unordered_mapISsSt6vectorISt4pairIldESaIS9_EESt4hashISsESt8equal_toISsESaIS8_IKSsSB_EEEEPS7_IS8_INS0_8ObjectIDES5_INS0_9RayObjectEEESaISO_EESR_PN6google8protobuf16RepeatedPtrFieldINS0_3rpc20ObjectReferenceCountEEEPbPSsESt5_BindIFMNS0_4core10CoreWorkerEFS1_S4_RKSK_SR_SR_SY_SZ_S10_EPS14_St12_PlaceholderILi1EES1A_ILi2EES1A_ILi3EES1A_ILi4EES1A_ILi5EES1A_ILi6EES1A_ILi7EEEEE9_M_invokeERKSt9_Any_dataS4_OSK_OSR_S1P_OSY_OSZ_OS10_+0x54) [0x7f5b8ec41b74] std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(+0x6a7cfa) [0x7f5b8ed25cfa] std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(+0x6ba7fe) [0x7f5b8ed387fe] ray::core::InboundRequest::Accept()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(+0x6beff8) [0x7f5b8ed3cff8] ray::core::ActorSchedulingQueue::ScheduleRequests()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core20ActorSchedulingQueue3AddEllSt8functionIFvS2_IFvNS_6StatusES2_IFvvEES5_EEEES9_S7_RKSsRKSt10shared_ptrINS_27FunctionDescriptorInterfaceEENS_6TaskIDERKSt6vectorINS_3rpc15ObjectReferenceESaISK_EE+0x596) [0x7f5b8ed3edb6] ray::core::ActorSchedulingQueue::Add()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core28CoreWorkerDirectTaskReceiver10HandleTaskENS_3rpc15PushTaskRequestEPNS2_13PushTaskReplyESt8functionIFvNS_6StatusES6_IFvvEES9_EE+0x1209) [0x7f5b8ed245f9] ray::core::CoreWorkerDirectTaskReceiver::HandleTask()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(+0x65c5aa) [0x7f5b8ecda5aa] std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(+0x938406) [0x7f5b8efb6406] EventTracker::RecordExecution()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(+0x8d61de) [0x7f5b8ef541de] std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(+0x8d6736) [0x7f5b8ef54736] boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(+0xd8f7fb) [0x7f5b8f40d7fb] boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(+0xd912c9) [0x7f5b8f40f2c9] boost::asio::detail::scheduler::run()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(+0xd91782) [0x7f5b8f40f782] boost::asio::io_context::run()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core10CoreWorker20RunTaskExecutionLoopEv+0x1c) [0x7f5b8ecc9b9c] ray::core::CoreWorker::RunTaskExecutionLoop()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core21CoreWorkerProcessImpl26RunWorkerTaskExecutionLoopEv+0x8c) [0x7f5b8ed0769c] ray::core::CoreWorkerProcessImpl::RunWorkerTaskExecutionLoop()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /home/rraiyan/cybercat/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core17CoreWorkerProcess20RunTaskExecutionLoopEv+0x1d) [0x7f5b8ed0784d] ray::core::CoreWorkerProcess::RunTaskExecutionLoop()\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m ray::ImplicitFunc() [0x504a2b]\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m ray::ImplicitFunc(_PyEval_EvalFrameDefault+0x859) [0x56b619] _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m ray::ImplicitFunc(_PyFunction_Vectorcall+0x1b6) [0x5f6ce6] _PyFunction_Vectorcall\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m ray::ImplicitFunc(_PyEval_EvalFrameDefault+0x859) [0x56b619] _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m ray::ImplicitFunc(_PyEval_EvalCodeWithName+0x26a) [0x5697da] _PyEval_EvalCodeWithName\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m ray::ImplicitFunc(PyEval_EvalCode+0x27) [0x68e547] PyEval_EvalCode\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m ray::ImplicitFunc() [0x67dbf1]\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m ray::ImplicitFunc() [0x67dc6f]\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m ray::ImplicitFunc() [0x67dd11]\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m ray::ImplicitFunc(PyRun_SimpleFileExFlags+0x197) [0x67fe37] PyRun_SimpleFileExFlags\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m ray::ImplicitFunc(Py_RunMain+0x212) [0x6b7c82] Py_RunMain\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m ray::ImplicitFunc(Py_BytesMain+0x2d) [0x6b800d] Py_BytesMain\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x7f5b9000e083] __libc_start_main\n",
      "\u001b[2m\u001b[36m(train_model2 pid=2294946)\u001b[0m ray::ImplicitFunc(_start+0x2e) [0x5fb85e] _start\n"
     ]
    }
   ],
   "source": [
    "# Hyper Parameter Search \n",
    "iteration_config = {\n",
    "    \"lr\" : tune.loguniform(1e-5, 1e-3),\n",
    "    # \"b1\" : tune.uniform(0.3, 1.0),\n",
    "    # \"b2\" : tune.uniform(0.3, 1.0),\n",
    "    \"batch_size\": tune.choice([32, 16, 8]),\n",
    "    # \"model\": tune.choice([[40, 5, 1], [40, 10, 1], [40, 5, 2, 1]]),\n",
    "    \"momentum\": tune.choice([0.93, 0.95, 0.97]),\n",
    "}\n",
    "scheduler = ASHAScheduler(metric=\"combined_loss\", mode=\"min\", max_t=40, grace_period=5, reduction_factor=2)\n",
    "reporter = CLIReporter(metric_columns=[\"train_loss\", \"val_loss\", \"combined_loss\", \"training_iteration\"])\n",
    "result = tune.run(train_model2, config=iteration_config, scheduler=scheduler, progress_reporter=reporter,\n",
    "                  num_samples=80, resources_per_trial={\"cpu\": 4, \"gpu\": 0.05},)\n",
    "\n",
    "best_trial = result.get_best_trial(\"combined_loss\", \"min\", \"last\")\n",
    "print(\"Best trial config: {}\".format(best_trial.config))\n",
    "print(\"Best trial final validation loss: {}\".format(\n",
    "    best_trial.last_result[\"val_loss\"]))\n",
    "print(\"Best trial final train loss: {}\".format(\n",
    "    best_trial.last_result[\"train_loss\"]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Best trial config: {'lr': 0.0010630834634709364, 'b1': 0.4282116859842134, 'b2': 0.3089991262211405, 'batch_size': 8, 'model': [20, 16, 8, 4, 2, 1]}\n",
    "Best trial final validation loss: 0.09234625198878348\n",
    "Best trial final train loss: 0.22368373312056064 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model with the given params.\n",
    "np.random.seed(70)  # Set seed for consistentcy\n",
    "params = {\n",
    "    'batch_size': 8, 'shuffle': True, 'num_workers': 2\n",
    "}\n",
    "# params['batch_size'] = best_trial.config['batch_size']\n",
    "train, val = generate_differential_data_loaders(data, params, fixed_columns, x_columns, y_column, 20000, model_config['train_split'])\n",
    "model = model_config['model_class'](*model_config['model_params'])\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.HuberLoss()\n",
    "# optimizer = Adam(model.parameters(), lr=0.0009, betas=[0.935, 0.701])\n",
    "optimizer = SGD(model.parameters(), lr=0.0004, momentum=0.9)\n",
    "# optimizer = SGD(model.parameters(), lr=best_trial.config['lr'], momentum=best_trial.config['momentum'])\n",
    "# CUDA_VISIBLE is already set to only see one GPU\n",
    "# train_loss, validation_loss = train_model(model, optimizer, criterion, train, val, epochs=150, gpu_to_use=0)\n",
    "train_loss, validation_loss = train_model(model, optimizer, criterion, train, val, epochs=model_config['epochs'], gpu_to_use=0)\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label='Training Loss', marker='x')\n",
    "plt.plot(validation_loss, label='Validation Loss', marker='x')\n",
    "# plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train MSE : {train_loss[-1]}, Val MSE : {validation_loss[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    x_data = torch.tensor(data[x_columns].values, dtype=torch.float).cuda()\n",
    "    predictions = model(x_data)\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    predictions = y_scaler.inverse_transform(predictions).flatten()\n",
    "    y_data = data[y_column].to_numpy()\n",
    "    y_data = y_scaler.inverse_transform(y_data).flatten()\n",
    "    absolute_error = np.abs(y_data - predictions)\n",
    "    # error_df = pd.DataFrame({'Truth': y_data, \"Predicted\": predictions, \"Absolute Error\": absolute_error, \"%tage\": absolute_error/y_data * 100})\n",
    "    error_df = pd.DataFrame({'Truth': y_data, \"Predicted\": predictions, \"Absolute Error\": absolute_error, \"%tage\": absolute_error})\n",
    "plt.figure()\n",
    "error_df['%tage'].plot.hist(bins=100)\n",
    "# plt.xlabel('(%) Error')\n",
    "plt.xlabel('Abs. Sat. Error')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Bad Samples\n",
    "VIEW_TOP_N = 50\n",
    "worst_errors = error_df['Absolute Error'].argsort()[::-1][:VIEW_TOP_N]\n",
    "combined_table = data.join(error_df)\n",
    "with pd.option_context(\"display.max_rows\", None):\n",
    "    display(combined_table[['Maternal Wall Thickness', \"Maternal Hb Concentration\", \"Maternal Saturation\", \"Fetal Hb Concentration\", \"Fetal Saturation\", 'Truth', 'Predicted', 'Absolute Error', '%tage']].iloc[worst_errors, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rough MSE's in percentage\n",
    "print(f'Train Error(non-normalized): {train_loss[-1] * y_scaler.var_ }')\n",
    "print(f'Validation Error(non-normalized): {validation_loss[-1] * y_scaler.var_ }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Info\n",
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybercat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
