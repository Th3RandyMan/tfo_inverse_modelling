{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Saturation-based Simulation Data\n",
    "In this notebook, we try to fit intensity data generated using a saturation based method. The mu_a for each of the maternal and fetal layer are based on a set oxygen saturation and HB concentration. The impact of all other pigments on mu_a are ignored. The goal for this experiment is to see if we can train a model to determine these hidden variables - the Hb conc. and the saturation just by looking at the intensity values!\n",
    "\n",
    "# Instructions\n",
    "I have the parameter search in one of the cells. Run eveerything above it to be able to run that cell.\n",
    "If you don't want to search, ignore that cell and run everything above and below. \n",
    "\n",
    "# Issues\n",
    "1. Only the mu_a's are changed, not any of the other properties! \n",
    "2. Fetal performance is not nearly as good as maternal. This could be due to the noise in the far ends of the plots. Maybe interpolation would help?\n",
    "3. Fetal errors: Sat: ~3% Sat., Conc: ~1.9\n",
    "\n",
    "\n",
    "# Notes\n",
    "1. Using interpolated values seems to make the fitting more stable. Not better however.\n",
    "2. Maternal is very good.\n",
    "3. Fetal just estimates a mean!\n",
    "\n",
    "# Things to Try\n",
    "1. Fetal | Maternal = known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from inverse_modelling_tfo.models import train_model, train_model_wtih_reporting\n",
    "from inverse_modelling_tfo.data import generate_data_loaders, equidistance_detector_normalization, constant_detector_count_normalization\n",
    "from inverse_modelling_tfo.data.intensity_interpolation import get_interpolate_fit_params_custom, interpolate_exp\n",
    "from inverse_modelling_tfo.data.interpolation_function_zoo import *\n",
    "from inverse_modelling_tfo.models.custom_models import SplitChannelCNN, PerceptronReLU\n",
    "from inverse_modelling_tfo.features.build_features import create_ratio, create_spatial_intensity\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import torchinfo\n",
    "# Set my GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SDD</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>Wave Int</th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Maternal Hb Concentration</th>\n",
       "      <th>Maternal Saturation</th>\n",
       "      <th>Fetal Hb Concentration</th>\n",
       "      <th>Fetal Saturation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>-4.999507</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>-7.171885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>-9.277114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>-10.143018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>-10.149250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SDD  Intensity  Wave Int  Maternal Wall Thickness  \\\n",
       "0   10  -4.999507       1.0                      6.0   \n",
       "1   14  -7.171885       1.0                      6.0   \n",
       "2   19  -9.277114       1.0                      6.0   \n",
       "3   23 -10.143018       1.0                      6.0   \n",
       "4   28 -10.149250       1.0                      6.0   \n",
       "\n",
       "   Maternal Hb Concentration  Maternal Saturation  Fetal Hb Concentration  \\\n",
       "0                       12.0                  0.9                    0.11   \n",
       "1                       12.0                  0.9                    0.11   \n",
       "2                       12.0                  0.9                    0.11   \n",
       "3                       12.0                  0.9                    0.11   \n",
       "4                       12.0                  0.9                    0.11   \n",
       "\n",
       "   Fetal Saturation  \n",
       "0               0.1  \n",
       "1               0.1  \n",
       "2               0.1  \n",
       "3               0.1  \n",
       "4               0.1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.read_pickle(r'/home/rraiyan/personal_projects/tfo_inverse_modelling/data/intensity/s_based_intensity.pkl')\n",
    "# data = pd.read_pickle(r'/home/rraiyan/personal_projects/tfo_inverse_modelling/data/intensity/s_based_intensity_low_conc.pkl')\n",
    "data = pd.read_pickle(r'/home/rraiyan/personal_projects/tfo_inverse_modelling/data/intensity/s_based_intensity_low_conc2.pkl')\n",
    "equidistance_detector_normalization(data)\n",
    "\n",
    "# Drop Uterus Thickness for now\n",
    "data = data.drop(columns='Uterus Thickness')\n",
    "\n",
    "# Interpolate intensity to remove noise\n",
    "data = interpolate_exp(data, weights=[1, -1])\n",
    "data['Intensity'] = data['Interpolated Intensity']\n",
    "data = data.drop(columns='Interpolated Intensity')\n",
    "\n",
    "# Manual log(intensity) normalization\n",
    "data['Intensity'] = np.log10(data['Intensity'])        # Far values wayy to small to affect anything. Take log\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Maternal Hb Concentration</th>\n",
       "      <th>Maternal Saturation</th>\n",
       "      <th>Fetal Hb Concentration</th>\n",
       "      <th>Fetal Saturation</th>\n",
       "      <th>10</th>\n",
       "      <th>14</th>\n",
       "      <th>19</th>\n",
       "      <th>23</th>\n",
       "      <th>28</th>\n",
       "      <th>...</th>\n",
       "      <th>55_2.0</th>\n",
       "      <th>59_2.0</th>\n",
       "      <th>64_2.0</th>\n",
       "      <th>68_2.0</th>\n",
       "      <th>73_2.0</th>\n",
       "      <th>77_2.0</th>\n",
       "      <th>82_2.0</th>\n",
       "      <th>86_2.0</th>\n",
       "      <th>91_2.0</th>\n",
       "      <th>95_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.598920</td>\n",
       "      <td>-2.158779</td>\n",
       "      <td>-4.764065</td>\n",
       "      <td>-6.542704</td>\n",
       "      <td>-8.031928</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.639869</td>\n",
       "      <td>-22.003357</td>\n",
       "      <td>-25.265887</td>\n",
       "      <td>-28.112349</td>\n",
       "      <td>-31.952534</td>\n",
       "      <td>-35.240710</td>\n",
       "      <td>-39.608559</td>\n",
       "      <td>-43.300212</td>\n",
       "      <td>-48.150422</td>\n",
       "      <td>-52.211376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.225</td>\n",
       "      <td>-0.599478</td>\n",
       "      <td>-2.163204</td>\n",
       "      <td>-4.774771</td>\n",
       "      <td>-6.562659</td>\n",
       "      <td>-8.069640</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.677858</td>\n",
       "      <td>-22.046210</td>\n",
       "      <td>-25.314961</td>\n",
       "      <td>-28.166499</td>\n",
       "      <td>-32.013139</td>\n",
       "      <td>-35.306559</td>\n",
       "      <td>-39.681050</td>\n",
       "      <td>-43.378082</td>\n",
       "      <td>-48.235089</td>\n",
       "      <td>-52.301534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.600072</td>\n",
       "      <td>-2.167919</td>\n",
       "      <td>-4.786194</td>\n",
       "      <td>-6.583712</td>\n",
       "      <td>-8.108948</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.715011</td>\n",
       "      <td>-22.088109</td>\n",
       "      <td>-25.362928</td>\n",
       "      <td>-28.219417</td>\n",
       "      <td>-32.072350</td>\n",
       "      <td>-35.370881</td>\n",
       "      <td>-39.751845</td>\n",
       "      <td>-43.454117</td>\n",
       "      <td>-48.317744</td>\n",
       "      <td>-52.389537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.475</td>\n",
       "      <td>-0.600706</td>\n",
       "      <td>-2.172967</td>\n",
       "      <td>-4.798451</td>\n",
       "      <td>-6.606068</td>\n",
       "      <td>-8.150199</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.751362</td>\n",
       "      <td>-22.129094</td>\n",
       "      <td>-25.409836</td>\n",
       "      <td>-28.271155</td>\n",
       "      <td>-32.130227</td>\n",
       "      <td>-35.433740</td>\n",
       "      <td>-39.821015</td>\n",
       "      <td>-43.528395</td>\n",
       "      <td>-48.398473</td>\n",
       "      <td>-52.475475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-0.601386</td>\n",
       "      <td>-2.178407</td>\n",
       "      <td>-4.811696</td>\n",
       "      <td>-6.629989</td>\n",
       "      <td>-8.193841</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.786945</td>\n",
       "      <td>-22.169203</td>\n",
       "      <td>-25.455727</td>\n",
       "      <td>-28.321760</td>\n",
       "      <td>-32.186822</td>\n",
       "      <td>-35.495197</td>\n",
       "      <td>-39.888626</td>\n",
       "      <td>-43.600986</td>\n",
       "      <td>-48.477353</td>\n",
       "      <td>-52.559433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Maternal Wall Thickness  Maternal Hb Concentration  Maternal Saturation  \\\n",
       "0                      2.0                       12.0                  0.9   \n",
       "1                      2.0                       12.0                  0.9   \n",
       "2                      2.0                       12.0                  0.9   \n",
       "3                      2.0                       12.0                  0.9   \n",
       "4                      2.0                       12.0                  0.9   \n",
       "\n",
       "   Fetal Hb Concentration  Fetal Saturation        10        14        19  \\\n",
       "0                    0.11             0.100 -0.598920 -2.158779 -4.764065   \n",
       "1                    0.11             0.225 -0.599478 -2.163204 -4.774771   \n",
       "2                    0.11             0.350 -0.600072 -2.167919 -4.786194   \n",
       "3                    0.11             0.475 -0.600706 -2.172967 -4.798451   \n",
       "4                    0.11             0.600 -0.601386 -2.178407 -4.811696   \n",
       "\n",
       "         23        28  ...     55_2.0     59_2.0     64_2.0     68_2.0  \\\n",
       "0 -6.542704 -8.031928  ... -19.639869 -22.003357 -25.265887 -28.112349   \n",
       "1 -6.562659 -8.069640  ... -19.677858 -22.046210 -25.314961 -28.166499   \n",
       "2 -6.583712 -8.108948  ... -19.715011 -22.088109 -25.362928 -28.219417   \n",
       "3 -6.606068 -8.150199  ... -19.751362 -22.129094 -25.409836 -28.271155   \n",
       "4 -6.629989 -8.193841  ... -19.786945 -22.169203 -25.455727 -28.321760   \n",
       "\n",
       "      73_2.0     77_2.0     82_2.0     86_2.0     91_2.0     95_2.0  \n",
       "0 -31.952534 -35.240710 -39.608559 -43.300212 -48.150422 -52.211376  \n",
       "1 -32.013139 -35.306559 -39.681050 -43.378082 -48.235089 -52.301534  \n",
       "2 -32.072350 -35.370881 -39.751845 -43.454117 -48.317744 -52.389537  \n",
       "3 -32.130227 -35.433740 -39.821015 -43.528395 -48.398473 -52.475475  \n",
       "4 -32.186822 -35.495197 -39.888626 -43.600986 -48.477353 -52.559433  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = create_ratio(data, True)\n",
    "data2 = create_spatial_intensity(data)\n",
    "sim_params = ['Maternal Wall Thickness', \"Maternal Hb Concentration\", \"Fetal Hb Concentration\", \"Fetal Saturation\", \"Maternal Saturation\"]\n",
    "data = pd.merge(data1, data2, how='inner', on=sim_params)\n",
    "data.head() \n",
    "# data = create_ratio(data, True)\n",
    "# data = create_spatial_intensity(data)\n",
    "# NOTE: Have only 1 on at the same time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Maternal Hb Concentration</th>\n",
       "      <th>Maternal Saturation</th>\n",
       "      <th>Fetal Hb Concentration</th>\n",
       "      <th>Fetal Saturation</th>\n",
       "      <th>10</th>\n",
       "      <th>14</th>\n",
       "      <th>19</th>\n",
       "      <th>23</th>\n",
       "      <th>28</th>\n",
       "      <th>...</th>\n",
       "      <th>55_2.0</th>\n",
       "      <th>59_2.0</th>\n",
       "      <th>64_2.0</th>\n",
       "      <th>68_2.0</th>\n",
       "      <th>73_2.0</th>\n",
       "      <th>77_2.0</th>\n",
       "      <th>82_2.0</th>\n",
       "      <th>86_2.0</th>\n",
       "      <th>91_2.0</th>\n",
       "      <th>95_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.598920</td>\n",
       "      <td>-2.158779</td>\n",
       "      <td>-4.764065</td>\n",
       "      <td>-6.542704</td>\n",
       "      <td>-8.031928</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.639869</td>\n",
       "      <td>-22.003357</td>\n",
       "      <td>-25.265887</td>\n",
       "      <td>-28.112349</td>\n",
       "      <td>-31.952534</td>\n",
       "      <td>-35.240710</td>\n",
       "      <td>-39.608559</td>\n",
       "      <td>-43.300212</td>\n",
       "      <td>-48.150422</td>\n",
       "      <td>-52.211376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.225</td>\n",
       "      <td>-0.599478</td>\n",
       "      <td>-2.163204</td>\n",
       "      <td>-4.774771</td>\n",
       "      <td>-6.562659</td>\n",
       "      <td>-8.069640</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.677858</td>\n",
       "      <td>-22.046210</td>\n",
       "      <td>-25.314961</td>\n",
       "      <td>-28.166499</td>\n",
       "      <td>-32.013139</td>\n",
       "      <td>-35.306559</td>\n",
       "      <td>-39.681050</td>\n",
       "      <td>-43.378082</td>\n",
       "      <td>-48.235089</td>\n",
       "      <td>-52.301534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.600072</td>\n",
       "      <td>-2.167919</td>\n",
       "      <td>-4.786194</td>\n",
       "      <td>-6.583712</td>\n",
       "      <td>-8.108948</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.715011</td>\n",
       "      <td>-22.088109</td>\n",
       "      <td>-25.362928</td>\n",
       "      <td>-28.219417</td>\n",
       "      <td>-32.072350</td>\n",
       "      <td>-35.370881</td>\n",
       "      <td>-39.751845</td>\n",
       "      <td>-43.454117</td>\n",
       "      <td>-48.317744</td>\n",
       "      <td>-52.389537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.475</td>\n",
       "      <td>-0.600706</td>\n",
       "      <td>-2.172967</td>\n",
       "      <td>-4.798451</td>\n",
       "      <td>-6.606068</td>\n",
       "      <td>-8.150199</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.751362</td>\n",
       "      <td>-22.129094</td>\n",
       "      <td>-25.409836</td>\n",
       "      <td>-28.271155</td>\n",
       "      <td>-32.130227</td>\n",
       "      <td>-35.433740</td>\n",
       "      <td>-39.821015</td>\n",
       "      <td>-43.528395</td>\n",
       "      <td>-48.398473</td>\n",
       "      <td>-52.475475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-0.601386</td>\n",
       "      <td>-2.178407</td>\n",
       "      <td>-4.811696</td>\n",
       "      <td>-6.629989</td>\n",
       "      <td>-8.193841</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.786945</td>\n",
       "      <td>-22.169203</td>\n",
       "      <td>-25.455727</td>\n",
       "      <td>-28.321760</td>\n",
       "      <td>-32.186822</td>\n",
       "      <td>-35.495197</td>\n",
       "      <td>-39.888626</td>\n",
       "      <td>-43.600986</td>\n",
       "      <td>-48.477353</td>\n",
       "      <td>-52.559433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Maternal Wall Thickness  Maternal Hb Concentration  Maternal Saturation  \\\n",
       "0                      2.0                       12.0                  0.9   \n",
       "1                      2.0                       12.0                  0.9   \n",
       "2                      2.0                       12.0                  0.9   \n",
       "3                      2.0                       12.0                  0.9   \n",
       "4                      2.0                       12.0                  0.9   \n",
       "\n",
       "   Fetal Hb Concentration  Fetal Saturation        10        14        19  \\\n",
       "0                    0.11             0.100 -0.598920 -2.158779 -4.764065   \n",
       "1                    0.11             0.225 -0.599478 -2.163204 -4.774771   \n",
       "2                    0.11             0.350 -0.600072 -2.167919 -4.786194   \n",
       "3                    0.11             0.475 -0.600706 -2.172967 -4.798451   \n",
       "4                    0.11             0.600 -0.601386 -2.178407 -4.811696   \n",
       "\n",
       "         23        28  ...     55_2.0     59_2.0     64_2.0     68_2.0  \\\n",
       "0 -6.542704 -8.031928  ... -19.639869 -22.003357 -25.265887 -28.112349   \n",
       "1 -6.562659 -8.069640  ... -19.677858 -22.046210 -25.314961 -28.166499   \n",
       "2 -6.583712 -8.108948  ... -19.715011 -22.088109 -25.362928 -28.219417   \n",
       "3 -6.606068 -8.150199  ... -19.751362 -22.129094 -25.409836 -28.271155   \n",
       "4 -6.629989 -8.193841  ... -19.786945 -22.169203 -25.455727 -28.321760   \n",
       "\n",
       "      73_2.0     77_2.0     82_2.0     86_2.0     91_2.0     95_2.0  \n",
       "0 -31.952534 -35.240710 -39.608559 -43.300212 -48.150422 -52.211376  \n",
       "1 -32.013139 -35.306559 -39.681050 -43.378082 -48.235089 -52.301534  \n",
       "2 -32.072350 -35.370881 -39.751845 -43.454117 -48.317744 -52.389537  \n",
       "3 -32.130227 -35.433740 -39.821015 -43.528395 -48.398473 -52.475475  \n",
       "4 -32.186822 -35.495197 -39.888626 -43.600986 -48.477353 -52.559433  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup\n",
    "data.dropna(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Features\n",
    "x_columns will be the input features and y_columns are the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Y -> Target\n",
    "# y_columns = ['Maternal Wall Thickness', \"Maternal Hb Concentration\", \"Maternal Saturation\", \"Fetal Hb Concentration\", \"Fetal Saturation\"]\n",
    "# y_columns = ['Maternal Saturation']\n",
    "y_columns = ['Maternal Hb Concentration']\n",
    "# y_columns = ['Fetal Saturation']\n",
    "# y_columns = ['Fetal Hb Concentration']\n",
    "\n",
    "## X -> Predictors\n",
    "# x_columns = list(filter(lambda X: '_' in X, data.columns))\n",
    "# x_columns = list(filter(lambda X: X.isdigit(), data.columns))\n",
    "x_columns = list(filter(lambda X: X.isdigit(), data.columns)) + list(filter(lambda X: '_' in X, data.columns))\n",
    "\n",
    "\n",
    "\n",
    "## Pass in maternal info\n",
    "# x_columns += [\"Maternal Hb Concentration\", \"Maternal Saturation\"]\n",
    "\n",
    "## Scale y\n",
    "y_scaler = preprocessing.StandardScaler()\n",
    "data[y_columns] = y_scaler.fit_transform(data[y_columns])\n",
    "\n",
    "## Scale x\n",
    "x_scaler = preprocessing.StandardScaler()\n",
    "data[x_columns] = x_scaler.fit_transform(data[x_columns])\n",
    "## Manual scale - if needed (With maternal info.)\n",
    "# data[x_columns[:-2]] /= 100.0    # stddev.   (Actual value is higher but let's keep it here for now)\n",
    "# data[x_columns[:-2]] += 0.5  # unit var, 0 mean\n",
    "\n",
    "## Scale non-intensity x columns (Maternal Hb Conc. , Maternal Saturation)\n",
    "# data[\"Maternal Saturation\"] -= 0.5 \n",
    "# data[\"Maternal Hb Concentration\"] /= 20\n",
    "# data[\"Maternal Hb Concentration\"] -= 0.5 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y scale mean [14.]\n",
      "Y scale var [2.]\n"
     ]
    }
   ],
   "source": [
    "# Print Out Scaler values\n",
    "print(f'Y scale mean {y_scaler.mean_}')\n",
    "print(f'Y scale var {y_scaler.var_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Maternal Hb Concentration\n",
       "-1.414214                    375\n",
       "-0.707107                    375\n",
       " 0.000000                    375\n",
       " 0.707107                    375\n",
       " 1.414214                    375\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[y_columns].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_FEATURES = len(x_columns)\n",
    "OUT_FEATURES = len(y_columns)\n",
    "model_config = {\n",
    "    'model_class' : SplitChannelCNN,  # Class name\n",
    "    # 'model_class' : PerceptronReLU,  # Class name\n",
    "    # 'model_params' :  [2, IN_FEATURES, 4, 5, [2, OUT_FEATURES]],    # Input params as an array\n",
    "    # 'model_params' :  [3, IN_FEATURES, 6, 5, [6, 3, OUT_FEATURES]],    # Input params as an array\n",
    "    'model_params' :  [3, IN_FEATURES, 6, 7, [3, OUT_FEATURES]],    # Input params as an array\n",
    "    # 'model_params' :  [[IN_FEATURES, 8, OUT_FEATURES]],    # Input params as an array\n",
    "    'train_split' : 0.8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Train Function \n",
    "def train_model2(iteration_config, epoch=60):\n",
    "    np.random.seed(70)  # Set seed for consistentcy\n",
    "    params = {\n",
    "        'batch_size': iteration_config['batch_size'], 'shuffle': True, 'num_workers': 2\n",
    "    }\n",
    "    train, val = generate_data_loaders(data, params, x_columns, y_columns, model_config['train_split'])\n",
    "    # model = create_perceptron_model(config['model'])\n",
    "    # model = create_perceptron_model([42, 8, 1])\n",
    "    # model = TwoChannelCNN(40, 4, 5, [4, 1])\n",
    "    model = model_config['model_class'](*model_config['model_params'])\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = SGD(model.parameters(), lr=iteration_config[\"lr\"], momentum=iteration_config[\"momentum\"])\n",
    "    # optimizer = Adam(model.parameters(), lr=config[\"lr\"], betas=[config[\"b1\"], config[\"b2\"]])\n",
    "    train_loss, val_loss = train_model_wtih_reporting(model, optimizer=optimizer, criterion=criterion, train_loader=train, validation_loader=val, epochs=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-09 14:29:03,442\tINFO worker.py:1625 -- Started a local Ray instance.\n",
      "2023-07-09 14:29:04,137\tINFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-09 14:29:04 (running for 00:00:00.33)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 4.0/64 CPUs, 0.05/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 70/80 (69 PENDING, 1 RUNNING)\n",
      "+--------------------------+----------+-----------------------+--------------+-------------+------------+\n",
      "| Trial name               | status   | loc                   |   batch_size |          lr |   momentum |\n",
      "|--------------------------+----------+-----------------------+--------------+-------------+------------|\n",
      "| train_model2_a0ce0_00000 | RUNNING  | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |\n",
      "| train_model2_a0ce0_00001 | PENDING  |                       |            8 | 1.77635e-05 |       0.95 |\n",
      "| train_model2_a0ce0_00002 | PENDING  |                       |           16 | 0.000520092 |       0.93 |\n",
      "| train_model2_a0ce0_00003 | PENDING  |                       |           16 | 3.47276e-05 |       0.93 |\n",
      "| train_model2_a0ce0_00004 | PENDING  |                       |           32 | 1.99195e-05 |       0.97 |\n",
      "| train_model2_a0ce0_00005 | PENDING  |                       |           32 | 4.30683e-05 |       0.97 |\n",
      "| train_model2_a0ce0_00006 | PENDING  |                       |           32 | 9.64281e-05 |       0.95 |\n",
      "| train_model2_a0ce0_00007 | PENDING  |                       |            8 | 6.57914e-05 |       0.93 |\n",
      "| train_model2_a0ce0_00008 | PENDING  |                       |           32 | 5.07391e-05 |       0.95 |\n",
      "| train_model2_a0ce0_00009 | PENDING  |                       |            8 | 2.37206e-05 |       0.93 |\n",
      "| train_model2_a0ce0_00010 | PENDING  |                       |           32 | 0.000434028 |       0.95 |\n",
      "| train_model2_a0ce0_00011 | PENDING  |                       |           16 | 7.77073e-05 |       0.95 |\n",
      "| train_model2_a0ce0_00012 | PENDING  |                       |           32 | 0.000299947 |       0.95 |\n",
      "| train_model2_a0ce0_00013 | PENDING  |                       |           32 | 0.000453723 |       0.97 |\n",
      "| train_model2_a0ce0_00014 | PENDING  |                       |            8 | 8.31202e-05 |       0.97 |\n",
      "| train_model2_a0ce0_00015 | PENDING  |                       |           16 | 2.54844e-05 |       0.95 |\n",
      "| train_model2_a0ce0_00016 | PENDING  |                       |            8 | 1.27965e-05 |       0.95 |\n",
      "| train_model2_a0ce0_00017 | PENDING  |                       |           32 | 0.000583307 |       0.93 |\n",
      "| train_model2_a0ce0_00018 | PENDING  |                       |           32 | 1.72815e-05 |       0.95 |\n",
      "| train_model2_a0ce0_00019 | PENDING  |                       |           32 | 3.48382e-05 |       0.97 |\n",
      "+--------------------------+----------+-----------------------+--------------+-------------+------------+\n",
      "... 50 more trials not shown (50 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th style=\"text-align: right;\">  combined_loss</th><th>date               </th><th>done  </th><th>hostname  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip      </th><th style=\"text-align: right;\">    pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model2_a0ce0_00000</td><td style=\"text-align: right;\">    4.97331e-05</td><td>2023-07-09_14-29-49</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        40</td><td>169.237.32.34</td><td style=\"text-align: right;\">1924780</td><td style=\"text-align: right;\">            44.0948 </td><td style=\"text-align: right;\">          1.08839 </td><td style=\"text-align: right;\">      44.0948 </td><td style=\"text-align: right;\"> 1688938189</td><td style=\"text-align: right;\">  0.0116887 </td><td style=\"text-align: right;\">                  40</td><td>a0ce0_00000</td><td style=\"text-align: right;\">0.0042548 </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00001</td><td style=\"text-align: right;\">    0.556714   </td><td>2023-07-09_14-29-24</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        10</td><td>169.237.32.34</td><td style=\"text-align: right;\">1924860</td><td style=\"text-align: right;\">            17.2984 </td><td style=\"text-align: right;\">          1.64491 </td><td style=\"text-align: right;\">      17.2984 </td><td style=\"text-align: right;\"> 1688938164</td><td style=\"text-align: right;\">  0.974314  </td><td style=\"text-align: right;\">                  10</td><td>a0ce0_00001</td><td style=\"text-align: right;\">0.57139   </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00002</td><td style=\"text-align: right;\">    0.000657993</td><td>2023-07-09_14-29-32</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        20</td><td>169.237.32.34</td><td style=\"text-align: right;\">1924862</td><td style=\"text-align: right;\">            24.6768 </td><td style=\"text-align: right;\">          0.916306</td><td style=\"text-align: right;\">      24.6768 </td><td style=\"text-align: right;\"> 1688938172</td><td style=\"text-align: right;\">  0.0321841 </td><td style=\"text-align: right;\">                  20</td><td>a0ce0_00002</td><td style=\"text-align: right;\">0.0204447 </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00003</td><td style=\"text-align: right;\">    1.17177    </td><td>2023-07-09_14-29-16</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1924866</td><td style=\"text-align: right;\">             9.29297</td><td style=\"text-align: right;\">          1.09908 </td><td style=\"text-align: right;\">       9.29297</td><td style=\"text-align: right;\"> 1688938156</td><td style=\"text-align: right;\">  1.04177   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00003</td><td style=\"text-align: right;\">1.12478   </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00004</td><td style=\"text-align: right;\">    0.516864   </td><td>2023-07-09_14-29-20</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        10</td><td>169.237.32.34</td><td style=\"text-align: right;\">1924871</td><td style=\"text-align: right;\">            12.6577 </td><td style=\"text-align: right;\">          0.860402</td><td style=\"text-align: right;\">      12.6577 </td><td style=\"text-align: right;\"> 1688938160</td><td style=\"text-align: right;\">  0.900003  </td><td style=\"text-align: right;\">                  10</td><td>a0ce0_00004</td><td style=\"text-align: right;\">0.574291  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00005</td><td style=\"text-align: right;\">    0.386466   </td><td>2023-07-09_14-29-29</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        20</td><td>169.237.32.34</td><td style=\"text-align: right;\">1924873</td><td style=\"text-align: right;\">            21.8831 </td><td style=\"text-align: right;\">          0.896438</td><td style=\"text-align: right;\">      21.8831 </td><td style=\"text-align: right;\"> 1688938169</td><td style=\"text-align: right;\">  0.844946  </td><td style=\"text-align: right;\">                  20</td><td>a0ce0_00005</td><td style=\"text-align: right;\">0.457386  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00006</td><td style=\"text-align: right;\">    0.702224   </td><td>2023-07-09_14-29-16</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1924880</td><td style=\"text-align: right;\">             8.49503</td><td style=\"text-align: right;\">          1.02691 </td><td style=\"text-align: right;\">       8.49503</td><td style=\"text-align: right;\"> 1688938156</td><td style=\"text-align: right;\">  0.932132  </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00006</td><td style=\"text-align: right;\">0.753353  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00007</td><td style=\"text-align: right;\">    0.70626    </td><td>2023-07-09_14-29-18</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1924882</td><td style=\"text-align: right;\">            11.0529 </td><td style=\"text-align: right;\">          1.3386  </td><td style=\"text-align: right;\">      11.0529 </td><td style=\"text-align: right;\"> 1688938158</td><td style=\"text-align: right;\">  1.00283   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00007</td><td style=\"text-align: right;\">0.704264  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00008</td><td style=\"text-align: right;\">    1.3686     </td><td>2023-07-09_14-29-15</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1924884</td><td style=\"text-align: right;\">             8.31195</td><td style=\"text-align: right;\">          1.21284 </td><td style=\"text-align: right;\">       8.31195</td><td style=\"text-align: right;\"> 1688938155</td><td style=\"text-align: right;\">  1.20425   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00008</td><td style=\"text-align: right;\">1.13648   </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00009</td><td style=\"text-align: right;\">    0.608483   </td><td>2023-07-09_14-29-18</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1924886</td><td style=\"text-align: right;\">            10.8563 </td><td style=\"text-align: right;\">          1.29193 </td><td style=\"text-align: right;\">      10.8563 </td><td style=\"text-align: right;\"> 1688938158</td><td style=\"text-align: right;\">  0.901644  </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00009</td><td style=\"text-align: right;\">0.674859  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00010</td><td style=\"text-align: right;\">    1.08262e-05</td><td>2023-07-09_14-29-47</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        40</td><td>169.237.32.34</td><td style=\"text-align: right;\">1924890</td><td style=\"text-align: right;\">            40.1067 </td><td style=\"text-align: right;\">          0.858469</td><td style=\"text-align: right;\">      40.1067 </td><td style=\"text-align: right;\"> 1688938187</td><td style=\"text-align: right;\">  0.00480079</td><td style=\"text-align: right;\">                  40</td><td>a0ce0_00010</td><td style=\"text-align: right;\">0.00225509</td></tr>\n",
       "<tr><td>train_model2_a0ce0_00011</td><td style=\"text-align: right;\">    0.432141   </td><td>2023-07-09_14-29-21</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        10</td><td>169.237.32.34</td><td style=\"text-align: right;\">1924892</td><td style=\"text-align: right;\">            14.065  </td><td style=\"text-align: right;\">          0.877147</td><td style=\"text-align: right;\">      14.065  </td><td style=\"text-align: right;\"> 1688938161</td><td style=\"text-align: right;\">  0.843855  </td><td style=\"text-align: right;\">                  10</td><td>a0ce0_00011</td><td style=\"text-align: right;\">0.512103  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00012</td><td style=\"text-align: right;\">    0.604422   </td><td>2023-07-09_14-29-16</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1924895</td><td style=\"text-align: right;\">             8.36967</td><td style=\"text-align: right;\">          1.10531 </td><td style=\"text-align: right;\">       8.36967</td><td style=\"text-align: right;\"> 1688938156</td><td style=\"text-align: right;\">  0.991092  </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00012</td><td style=\"text-align: right;\">0.609855  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00013</td><td style=\"text-align: right;\">    2.38696e-05</td><td>2023-07-09_14-29-47</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        40</td><td>169.237.32.34</td><td style=\"text-align: right;\">1924898</td><td style=\"text-align: right;\">            39.6684 </td><td style=\"text-align: right;\">          0.87631 </td><td style=\"text-align: right;\">      39.6684 </td><td style=\"text-align: right;\"> 1688938187</td><td style=\"text-align: right;\">  0.0114256 </td><td style=\"text-align: right;\">                  40</td><td>a0ce0_00013</td><td style=\"text-align: right;\">0.00208913</td></tr>\n",
       "<tr><td>train_model2_a0ce0_00014</td><td style=\"text-align: right;\">    0.62361    </td><td>2023-07-09_14-29-18</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1924901</td><td style=\"text-align: right;\">            10.9428 </td><td style=\"text-align: right;\">          1.30063 </td><td style=\"text-align: right;\">      10.9428 </td><td style=\"text-align: right;\"> 1688938158</td><td style=\"text-align: right;\">  1.00937   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00014</td><td style=\"text-align: right;\">0.61782   </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00015</td><td style=\"text-align: right;\">    1.08483    </td><td>2023-07-09_14-29-16</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1924903</td><td style=\"text-align: right;\">             9.00192</td><td style=\"text-align: right;\">          1.13158 </td><td style=\"text-align: right;\">       9.00192</td><td style=\"text-align: right;\"> 1688938156</td><td style=\"text-align: right;\">  1.0993    </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00015</td><td style=\"text-align: right;\">0.98684   </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00016</td><td style=\"text-align: right;\">    0.393685   </td><td>2023-07-09_14-29-52</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        20</td><td>169.237.32.34</td><td style=\"text-align: right;\">1949271</td><td style=\"text-align: right;\">            33.5095 </td><td style=\"text-align: right;\">          1.62428 </td><td style=\"text-align: right;\">      33.5095 </td><td style=\"text-align: right;\"> 1688938192</td><td style=\"text-align: right;\">  0.874972  </td><td style=\"text-align: right;\">                  20</td><td>a0ce0_00016</td><td style=\"text-align: right;\">0.449941  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00017</td><td style=\"text-align: right;\">    0.617758   </td><td>2023-07-09_14-29-26</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1949274</td><td style=\"text-align: right;\">             8.20612</td><td style=\"text-align: right;\">          1.17866 </td><td style=\"text-align: right;\">       8.20612</td><td style=\"text-align: right;\"> 1688938166</td><td style=\"text-align: right;\">  0.84881   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00017</td><td style=\"text-align: right;\">0.727793  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00018</td><td style=\"text-align: right;\">    0.666223   </td><td>2023-07-09_14-29-27</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1949277</td><td style=\"text-align: right;\">             8.33913</td><td style=\"text-align: right;\">          1.1273  </td><td style=\"text-align: right;\">       8.33913</td><td style=\"text-align: right;\"> 1688938167</td><td style=\"text-align: right;\">  1.02091   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00018</td><td style=\"text-align: right;\">0.652579  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00019</td><td style=\"text-align: right;\">    0.542079   </td><td>2023-07-09_14-29-33</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        10</td><td>169.237.32.34</td><td style=\"text-align: right;\">1955179</td><td style=\"text-align: right;\">            12.4423 </td><td style=\"text-align: right;\">          0.83136 </td><td style=\"text-align: right;\">      12.4423 </td><td style=\"text-align: right;\"> 1688938173</td><td style=\"text-align: right;\">  0.801757  </td><td style=\"text-align: right;\">                  10</td><td>a0ce0_00019</td><td style=\"text-align: right;\">0.676114  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00020</td><td style=\"text-align: right;\">    0.0271618  </td><td>2023-07-09_14-29-46</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        20</td><td>169.237.32.34</td><td style=\"text-align: right;\">1955192</td><td style=\"text-align: right;\">            25.475  </td><td style=\"text-align: right;\">          1.11792 </td><td style=\"text-align: right;\">      25.475  </td><td style=\"text-align: right;\"> 1688938186</td><td style=\"text-align: right;\">  0.124043  </td><td style=\"text-align: right;\">                  20</td><td>a0ce0_00020</td><td style=\"text-align: right;\">0.218971  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00021</td><td style=\"text-align: right;\">    1.19822    </td><td>2023-07-09_14-29-28</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1955195</td><td style=\"text-align: right;\">             7.98623</td><td style=\"text-align: right;\">          1.02332 </td><td style=\"text-align: right;\">       7.98623</td><td style=\"text-align: right;\"> 1688938168</td><td style=\"text-align: right;\">  1.10053   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00021</td><td style=\"text-align: right;\">1.08877   </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00022</td><td style=\"text-align: right;\">    0.68494    </td><td>2023-07-09_14-29-28</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1955198</td><td style=\"text-align: right;\">             8.04674</td><td style=\"text-align: right;\">          1.07781 </td><td style=\"text-align: right;\">       8.04674</td><td style=\"text-align: right;\"> 1688938168</td><td style=\"text-align: right;\">  0.992874  </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00022</td><td style=\"text-align: right;\">0.689856  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00023</td><td style=\"text-align: right;\">    0.869332   </td><td>2023-07-09_14-29-29</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1955264</td><td style=\"text-align: right;\">             8.66103</td><td style=\"text-align: right;\">          1.07147 </td><td style=\"text-align: right;\">       8.66103</td><td style=\"text-align: right;\"> 1688938169</td><td style=\"text-align: right;\">  1.13389   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00023</td><td style=\"text-align: right;\">0.766681  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00024</td><td style=\"text-align: right;\">    0.768419   </td><td>2023-07-09_14-29-32</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1960222</td><td style=\"text-align: right;\">             9.42347</td><td style=\"text-align: right;\">          1.31648 </td><td style=\"text-align: right;\">       9.42347</td><td style=\"text-align: right;\"> 1688938172</td><td style=\"text-align: right;\">  1.03064   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00024</td><td style=\"text-align: right;\">0.745576  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00025</td><td style=\"text-align: right;\">    0.409734   </td><td>2023-07-09_14-29-46</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        20</td><td>169.237.32.34</td><td style=\"text-align: right;\">1965380</td><td style=\"text-align: right;\">            21.885  </td><td style=\"text-align: right;\">          0.989304</td><td style=\"text-align: right;\">      21.885  </td><td style=\"text-align: right;\"> 1688938186</td><td style=\"text-align: right;\">  1.03792   </td><td style=\"text-align: right;\">                  20</td><td>a0ce0_00025</td><td style=\"text-align: right;\">0.394764  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00026</td><td style=\"text-align: right;\">    1.14579    </td><td>2023-07-09_14-29-34</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1974363</td><td style=\"text-align: right;\">             7.11871</td><td style=\"text-align: right;\">          0.87096 </td><td style=\"text-align: right;\">       7.11871</td><td style=\"text-align: right;\"> 1688938174</td><td style=\"text-align: right;\">  1.0997    </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00026</td><td style=\"text-align: right;\">1.04191   </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00027</td><td style=\"text-align: right;\">    0.93585    </td><td>2023-07-09_14-29-38</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1980681</td><td style=\"text-align: right;\">             8.52545</td><td style=\"text-align: right;\">          1.20384 </td><td style=\"text-align: right;\">       8.52545</td><td style=\"text-align: right;\"> 1688938178</td><td style=\"text-align: right;\">  1.0658    </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00027</td><td style=\"text-align: right;\">0.878075  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00028</td><td style=\"text-align: right;\">    0.488747   </td><td>2023-07-09_14-29-43</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        10</td><td>169.237.32.34</td><td style=\"text-align: right;\">1980685</td><td style=\"text-align: right;\">            13.1958 </td><td style=\"text-align: right;\">          1.08737 </td><td style=\"text-align: right;\">      13.1958 </td><td style=\"text-align: right;\"> 1688938183</td><td style=\"text-align: right;\">  0.799586  </td><td style=\"text-align: right;\">                  10</td><td>a0ce0_00028</td><td style=\"text-align: right;\">0.61125   </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00029</td><td style=\"text-align: right;\">    1.1306     </td><td>2023-07-09_14-29-40</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1987067</td><td style=\"text-align: right;\">             8.98677</td><td style=\"text-align: right;\">          1.34103 </td><td style=\"text-align: right;\">       8.98677</td><td style=\"text-align: right;\"> 1688938180</td><td style=\"text-align: right;\">  1.09669   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00029</td><td style=\"text-align: right;\">1.03092   </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00030</td><td style=\"text-align: right;\">    0.975704   </td><td>2023-07-09_14-29-40</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1987070</td><td style=\"text-align: right;\">             9.02527</td><td style=\"text-align: right;\">          1.33843 </td><td style=\"text-align: right;\">       9.02527</td><td style=\"text-align: right;\"> 1688938180</td><td style=\"text-align: right;\">  1.09285   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00030</td><td style=\"text-align: right;\">0.892804  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00031</td><td style=\"text-align: right;\">    0.261186   </td><td>2023-07-09_14-29-54</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        20</td><td>169.237.32.34</td><td style=\"text-align: right;\">1987144</td><td style=\"text-align: right;\">            22.8178 </td><td style=\"text-align: right;\">          1.03819 </td><td style=\"text-align: right;\">      22.8178 </td><td style=\"text-align: right;\"> 1688938194</td><td style=\"text-align: right;\">  0.667431  </td><td style=\"text-align: right;\">                  20</td><td>a0ce0_00031</td><td style=\"text-align: right;\">0.39133   </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00032</td><td style=\"text-align: right;\">    0.644284   </td><td>2023-07-09_14-29-42</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1987147</td><td style=\"text-align: right;\">            10.7356 </td><td style=\"text-align: right;\">          1.71868 </td><td style=\"text-align: right;\">      10.7356 </td><td style=\"text-align: right;\"> 1688938182</td><td style=\"text-align: right;\">  0.940753  </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00032</td><td style=\"text-align: right;\">0.684859  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00033</td><td style=\"text-align: right;\">    0.703199   </td><td>2023-07-09_14-29-42</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">1995217</td><td style=\"text-align: right;\">             7.52867</td><td style=\"text-align: right;\">          1.02967 </td><td style=\"text-align: right;\">       7.52867</td><td style=\"text-align: right;\"> 1688938182</td><td style=\"text-align: right;\">  1.03688   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00033</td><td style=\"text-align: right;\">0.678188  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00034</td><td style=\"text-align: right;\">    0.261114   </td><td>2023-07-09_14-29-58</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        20</td><td>169.237.32.34</td><td style=\"text-align: right;\">1995219</td><td style=\"text-align: right;\">            23.5729 </td><td style=\"text-align: right;\">          1.13773 </td><td style=\"text-align: right;\">      23.5729 </td><td style=\"text-align: right;\"> 1688938198</td><td style=\"text-align: right;\">  0.658871  </td><td style=\"text-align: right;\">                  20</td><td>a0ce0_00034</td><td style=\"text-align: right;\">0.396305  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00035</td><td style=\"text-align: right;\">    0.502237   </td><td>2023-07-09_14-29-48</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        10</td><td>169.237.32.34</td><td style=\"text-align: right;\">2000701</td><td style=\"text-align: right;\">            11.9767 </td><td style=\"text-align: right;\">          0.919276</td><td style=\"text-align: right;\">      11.9767 </td><td style=\"text-align: right;\"> 1688938188</td><td style=\"text-align: right;\">  0.964956  </td><td style=\"text-align: right;\">                  10</td><td>a0ce0_00035</td><td style=\"text-align: right;\">0.520476  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00036</td><td style=\"text-align: right;\">    0.479844   </td><td>2023-07-09_14-29-54</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        10</td><td>169.237.32.34</td><td style=\"text-align: right;\">2006620</td><td style=\"text-align: right;\">            16.0926 </td><td style=\"text-align: right;\">          1.3947  </td><td style=\"text-align: right;\">      16.0926 </td><td style=\"text-align: right;\"> 1688938194</td><td style=\"text-align: right;\">  0.964114  </td><td style=\"text-align: right;\">                  10</td><td>a0ce0_00036</td><td style=\"text-align: right;\">0.497705  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00037</td><td style=\"text-align: right;\">    5.22781e-06</td><td>2023-07-09_14-30-45</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        40</td><td>169.237.32.34</td><td style=\"text-align: right;\">2012982</td><td style=\"text-align: right;\">            64.3231 </td><td style=\"text-align: right;\">          1.36781 </td><td style=\"text-align: right;\">      64.3231 </td><td style=\"text-align: right;\"> 1688938245</td><td style=\"text-align: right;\">  0.00263733</td><td style=\"text-align: right;\">                  40</td><td>a0ce0_00037</td><td style=\"text-align: right;\">0.00198224</td></tr>\n",
       "<tr><td>train_model2_a0ce0_00038</td><td style=\"text-align: right;\">    0.58059    </td><td>2023-07-09_14-29-57</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        10</td><td>169.237.32.34</td><td style=\"text-align: right;\">2022672</td><td style=\"text-align: right;\">            14.1162 </td><td style=\"text-align: right;\">          1.18424 </td><td style=\"text-align: right;\">      14.1162 </td><td style=\"text-align: right;\"> 1688938197</td><td style=\"text-align: right;\">  0.887285  </td><td style=\"text-align: right;\">                  10</td><td>a0ce0_00038</td><td style=\"text-align: right;\">0.654344  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00039</td><td style=\"text-align: right;\">    0.63263    </td><td>2023-07-09_14-29-54</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">2022674</td><td style=\"text-align: right;\">            10.2891 </td><td style=\"text-align: right;\">          1.47776 </td><td style=\"text-align: right;\">      10.2891 </td><td style=\"text-align: right;\"> 1688938194</td><td style=\"text-align: right;\">  1.01275   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00039</td><td style=\"text-align: right;\">0.624664  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00040</td><td style=\"text-align: right;\">    0.68336    </td><td>2023-07-09_14-29-54</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">2028468</td><td style=\"text-align: right;\">             8.68056</td><td style=\"text-align: right;\">          1.23706 </td><td style=\"text-align: right;\">       8.68056</td><td style=\"text-align: right;\"> 1688938194</td><td style=\"text-align: right;\">  1.00019   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00040</td><td style=\"text-align: right;\">0.683234  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00041</td><td style=\"text-align: right;\">    0.40205    </td><td>2023-07-09_14-30-12</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        20</td><td>169.237.32.34</td><td style=\"text-align: right;\">2028471</td><td style=\"text-align: right;\">            26.5793 </td><td style=\"text-align: right;\">          1.13586 </td><td style=\"text-align: right;\">      26.5793 </td><td style=\"text-align: right;\"> 1688938212</td><td style=\"text-align: right;\">  0.898803  </td><td style=\"text-align: right;\">                  20</td><td>a0ce0_00041</td><td style=\"text-align: right;\">0.447317  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00042</td><td style=\"text-align: right;\">    0.514506   </td><td>2023-07-09_14-30-00</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        10</td><td>169.237.32.34</td><td style=\"text-align: right;\">2028473</td><td style=\"text-align: right;\">            14.153  </td><td style=\"text-align: right;\">          1.07649 </td><td style=\"text-align: right;\">      14.153  </td><td style=\"text-align: right;\"> 1688938200</td><td style=\"text-align: right;\">  0.710659  </td><td style=\"text-align: right;\">                  10</td><td>a0ce0_00042</td><td style=\"text-align: right;\">0.723985  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00043</td><td style=\"text-align: right;\">    0.000134829</td><td>2023-07-09_14-30-37</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        40</td><td>169.237.32.34</td><td style=\"text-align: right;\">2037183</td><td style=\"text-align: right;\">            48.7975 </td><td style=\"text-align: right;\">          1.30774 </td><td style=\"text-align: right;\">      48.7975 </td><td style=\"text-align: right;\"> 1688938237</td><td style=\"text-align: right;\">  0.0177542 </td><td style=\"text-align: right;\">                  40</td><td>a0ce0_00043</td><td style=\"text-align: right;\">0.00759419</td></tr>\n",
       "<tr><td>train_model2_a0ce0_00044</td><td style=\"text-align: right;\">    0.772577   </td><td>2023-07-09_14-29-57</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">2042087</td><td style=\"text-align: right;\">             7.2451 </td><td style=\"text-align: right;\">          0.862971</td><td style=\"text-align: right;\">       7.2451 </td><td style=\"text-align: right;\"> 1688938197</td><td style=\"text-align: right;\">  0.971957  </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00044</td><td style=\"text-align: right;\">0.794867  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00045</td><td style=\"text-align: right;\">    1.00667e-05</td><td>2023-07-09_14-30-38</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        40</td><td>169.237.32.34</td><td style=\"text-align: right;\">2042089</td><td style=\"text-align: right;\">            48.041  </td><td style=\"text-align: right;\">          1.1548  </td><td style=\"text-align: right;\">      48.041  </td><td style=\"text-align: right;\"> 1688938238</td><td style=\"text-align: right;\">  0.0032418 </td><td style=\"text-align: right;\">                  40</td><td>a0ce0_00045</td><td style=\"text-align: right;\">0.00310528</td></tr>\n",
       "<tr><td>train_model2_a0ce0_00046</td><td style=\"text-align: right;\">    7.00942e-06</td><td>2023-07-09_14-30-55</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        40</td><td>169.237.32.34</td><td style=\"text-align: right;\">2042091</td><td style=\"text-align: right;\">            64.5758 </td><td style=\"text-align: right;\">          1.50043 </td><td style=\"text-align: right;\">      64.5758 </td><td style=\"text-align: right;\"> 1688938255</td><td style=\"text-align: right;\">  0.00248237</td><td style=\"text-align: right;\">                  40</td><td>a0ce0_00046</td><td style=\"text-align: right;\">0.00282368</td></tr>\n",
       "<tr><td>train_model2_a0ce0_00047</td><td style=\"text-align: right;\">    1.37844    </td><td>2023-07-09_14-30-00</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">2047196</td><td style=\"text-align: right;\">             7.53276</td><td style=\"text-align: right;\">          0.944317</td><td style=\"text-align: right;\">       7.53276</td><td style=\"text-align: right;\"> 1688938200</td><td style=\"text-align: right;\">  1.12562   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00047</td><td style=\"text-align: right;\">1.2246    </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00048</td><td style=\"text-align: right;\">    0.508876   </td><td>2023-07-09_14-30-07</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        10</td><td>169.237.32.34</td><td style=\"text-align: right;\">2047198</td><td style=\"text-align: right;\">            14.4293 </td><td style=\"text-align: right;\">          1.3394  </td><td style=\"text-align: right;\">      14.4293 </td><td style=\"text-align: right;\"> 1688938207</td><td style=\"text-align: right;\">  1.00053   </td><td style=\"text-align: right;\">                  10</td><td>a0ce0_00048</td><td style=\"text-align: right;\">0.508605  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00049</td><td style=\"text-align: right;\">    0.629117   </td><td>2023-07-09_14-30-02</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">2052086</td><td style=\"text-align: right;\">             7.32018</td><td style=\"text-align: right;\">          0.932741</td><td style=\"text-align: right;\">       7.32018</td><td style=\"text-align: right;\"> 1688938202</td><td style=\"text-align: right;\">  0.849354  </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00049</td><td style=\"text-align: right;\">0.7407    </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00050</td><td style=\"text-align: right;\">    1.49409e-06</td><td>2023-07-09_14-31-02</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        40</td><td>169.237.32.34</td><td style=\"text-align: right;\">2057655</td><td style=\"text-align: right;\">            65.7067 </td><td style=\"text-align: right;\">          1.25522 </td><td style=\"text-align: right;\">      65.7067 </td><td style=\"text-align: right;\"> 1688938262</td><td style=\"text-align: right;\">  0.0012155 </td><td style=\"text-align: right;\">                  40</td><td>a0ce0_00050</td><td style=\"text-align: right;\">0.0012292 </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00051</td><td style=\"text-align: right;\">    0.0745969  </td><td>2023-07-09_14-30-23</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        20</td><td>169.237.32.34</td><td style=\"text-align: right;\">2057659</td><td style=\"text-align: right;\">            26.5111 </td><td style=\"text-align: right;\">          1.32917 </td><td style=\"text-align: right;\">      26.5111 </td><td style=\"text-align: right;\"> 1688938223</td><td style=\"text-align: right;\">  0.316162  </td><td style=\"text-align: right;\">                  20</td><td>a0ce0_00051</td><td style=\"text-align: right;\">0.235945  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00052</td><td style=\"text-align: right;\">    0.616776   </td><td>2023-07-09_14-30-07</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">2057661</td><td style=\"text-align: right;\">            10.4087 </td><td style=\"text-align: right;\">          1.82331 </td><td style=\"text-align: right;\">      10.4087 </td><td style=\"text-align: right;\"> 1688938207</td><td style=\"text-align: right;\">  0.838393  </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00052</td><td style=\"text-align: right;\">0.735664  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00053</td><td style=\"text-align: right;\">    0.662989   </td><td>2023-07-09_14-30-10</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">2062845</td><td style=\"text-align: right;\">            11.4083 </td><td style=\"text-align: right;\">          1.79162 </td><td style=\"text-align: right;\">      11.4083 </td><td style=\"text-align: right;\"> 1688938210</td><td style=\"text-align: right;\">  0.930118  </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00053</td><td style=\"text-align: right;\">0.712801  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00054</td><td style=\"text-align: right;\">    2.75805e-05</td><td>2023-07-09_14-30-44</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        40</td><td>169.237.32.34</td><td style=\"text-align: right;\">2068218</td><td style=\"text-align: right;\">            44.2874 </td><td style=\"text-align: right;\">          1.08033 </td><td style=\"text-align: right;\">      44.2874 </td><td style=\"text-align: right;\"> 1688938244</td><td style=\"text-align: right;\">  0.00693613</td><td style=\"text-align: right;\">                  40</td><td>a0ce0_00054</td><td style=\"text-align: right;\">0.00397635</td></tr>\n",
       "<tr><td>train_model2_a0ce0_00055</td><td style=\"text-align: right;\">    0.851094   </td><td>2023-07-09_14-30-09</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">2068221</td><td style=\"text-align: right;\">             8.72711</td><td style=\"text-align: right;\">          1.30758 </td><td style=\"text-align: right;\">       8.72711</td><td style=\"text-align: right;\"> 1688938209</td><td style=\"text-align: right;\">  1.04705   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00055</td><td style=\"text-align: right;\">0.812853  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00056</td><td style=\"text-align: right;\">    2.90889e-06</td><td>2023-07-09_14-30-44</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        40</td><td>169.237.32.34</td><td style=\"text-align: right;\">2068240</td><td style=\"text-align: right;\">            43.5824 </td><td style=\"text-align: right;\">          0.973434</td><td style=\"text-align: right;\">      43.5824 </td><td style=\"text-align: right;\"> 1688938244</td><td style=\"text-align: right;\">  0.00204512</td><td style=\"text-align: right;\">                  40</td><td>a0ce0_00056</td><td style=\"text-align: right;\">0.00142235</td></tr>\n",
       "<tr><td>train_model2_a0ce0_00057</td><td style=\"text-align: right;\">    0.45902    </td><td>2023-07-09_14-30-14</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        10</td><td>169.237.32.34</td><td style=\"text-align: right;\">2072995</td><td style=\"text-align: right;\">            12.0012 </td><td style=\"text-align: right;\">          0.943748</td><td style=\"text-align: right;\">      12.0012 </td><td style=\"text-align: right;\"> 1688938214</td><td style=\"text-align: right;\">  0.7194    </td><td style=\"text-align: right;\">                  10</td><td>a0ce0_00057</td><td style=\"text-align: right;\">0.63806   </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00058</td><td style=\"text-align: right;\">    0.809104   </td><td>2023-07-09_14-30-10</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">2073060</td><td style=\"text-align: right;\">             7.67616</td><td style=\"text-align: right;\">          0.96889 </td><td style=\"text-align: right;\">       7.67616</td><td style=\"text-align: right;\"> 1688938210</td><td style=\"text-align: right;\">  1.02823   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00058</td><td style=\"text-align: right;\">0.786892  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00059</td><td style=\"text-align: right;\">    0.625045   </td><td>2023-07-09_14-30-12</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">2078362</td><td style=\"text-align: right;\">             7.32996</td><td style=\"text-align: right;\">          0.946593</td><td style=\"text-align: right;\">       7.32996</td><td style=\"text-align: right;\"> 1688938212</td><td style=\"text-align: right;\">  0.995958  </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00059</td><td style=\"text-align: right;\">0.627582  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00060</td><td style=\"text-align: right;\">    7.19261e-06</td><td>2023-07-09_14-31-12</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        40</td><td>169.237.32.34</td><td style=\"text-align: right;\">2092503</td><td style=\"text-align: right;\">            62.448  </td><td style=\"text-align: right;\">          0.848898</td><td style=\"text-align: right;\">      62.448  </td><td style=\"text-align: right;\"> 1688938272</td><td style=\"text-align: right;\">  0.00281034</td><td style=\"text-align: right;\">                  40</td><td>a0ce0_00060</td><td style=\"text-align: right;\">0.00255934</td></tr>\n",
       "<tr><td>train_model2_a0ce0_00061</td><td style=\"text-align: right;\">    0.614389   </td><td>2023-07-09_14-30-17</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">2092506</td><td style=\"text-align: right;\">             7.91447</td><td style=\"text-align: right;\">          1.03842 </td><td style=\"text-align: right;\">       7.91447</td><td style=\"text-align: right;\"> 1688938217</td><td style=\"text-align: right;\">  0.831321  </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00061</td><td style=\"text-align: right;\">0.739051  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00062</td><td style=\"text-align: right;\">    0.000376095</td><td>2023-07-09_14-31-06</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        40</td><td>169.237.32.34</td><td style=\"text-align: right;\">2098484</td><td style=\"text-align: right;\">            54.3531 </td><td style=\"text-align: right;\">          0.995558</td><td style=\"text-align: right;\">      54.3531 </td><td style=\"text-align: right;\"> 1688938266</td><td style=\"text-align: right;\">  0.0326895 </td><td style=\"text-align: right;\">                  40</td><td>a0ce0_00062</td><td style=\"text-align: right;\">0.0115051 </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00063</td><td style=\"text-align: right;\">    0.00109234 </td><td>2023-07-09_14-30-38</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        20</td><td>169.237.32.34</td><td style=\"text-align: right;\">2104550</td><td style=\"text-align: right;\">            24.4293 </td><td style=\"text-align: right;\">          1.13794 </td><td style=\"text-align: right;\">      24.4293 </td><td style=\"text-align: right;\"> 1688938238</td><td style=\"text-align: right;\">  0.0408073 </td><td style=\"text-align: right;\">                  20</td><td>a0ce0_00063</td><td style=\"text-align: right;\">0.0267683 </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00064</td><td style=\"text-align: right;\">    0.697127   </td><td>2023-07-09_14-30-22</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">2104552</td><td style=\"text-align: right;\">             8.81311</td><td style=\"text-align: right;\">          1.28006 </td><td style=\"text-align: right;\">       8.81311</td><td style=\"text-align: right;\"> 1688938222</td><td style=\"text-align: right;\">  1.00791   </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00064</td><td style=\"text-align: right;\">0.691658  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00065</td><td style=\"text-align: right;\">    0.650302   </td><td>2023-07-09_14-30-28</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        10</td><td>169.237.32.34</td><td style=\"text-align: right;\">2109962</td><td style=\"text-align: right;\">            13.0698 </td><td style=\"text-align: right;\">          1.15464 </td><td style=\"text-align: right;\">      13.0698 </td><td style=\"text-align: right;\"> 1688938228</td><td style=\"text-align: right;\">  0.908868  </td><td style=\"text-align: right;\">                  10</td><td>a0ce0_00065</td><td style=\"text-align: right;\">0.715507  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00066</td><td style=\"text-align: right;\">    0.256061   </td><td>2023-07-09_14-30-42</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        20</td><td>169.237.32.34</td><td style=\"text-align: right;\">2110107</td><td style=\"text-align: right;\">            26.5799 </td><td style=\"text-align: right;\">          1.10719 </td><td style=\"text-align: right;\">      26.5799 </td><td style=\"text-align: right;\"> 1688938242</td><td style=\"text-align: right;\">  0.668255  </td><td style=\"text-align: right;\">                  20</td><td>a0ce0_00066</td><td style=\"text-align: right;\">0.383179  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00067</td><td style=\"text-align: right;\">    2.54043e-05</td><td>2023-07-09_14-31-03</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        40</td><td>169.237.32.34</td><td style=\"text-align: right;\">2115457</td><td style=\"text-align: right;\">            45.7412 </td><td style=\"text-align: right;\">          0.919903</td><td style=\"text-align: right;\">      45.7412 </td><td style=\"text-align: right;\"> 1688938263</td><td style=\"text-align: right;\">  0.0122965 </td><td style=\"text-align: right;\">                  40</td><td>a0ce0_00067</td><td style=\"text-align: right;\">0.00206598</td></tr>\n",
       "<tr><td>train_model2_a0ce0_00068</td><td style=\"text-align: right;\">    1.30695    </td><td>2023-07-09_14-30-29</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">2123919</td><td style=\"text-align: right;\">             8.11279</td><td style=\"text-align: right;\">          1.12491 </td><td style=\"text-align: right;\">       8.11279</td><td style=\"text-align: right;\"> 1688938229</td><td style=\"text-align: right;\">  1.1132    </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00068</td><td style=\"text-align: right;\">1.17405   </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00069</td><td style=\"text-align: right;\">    2.18059e-05</td><td>2023-07-09_14-31-11</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        40</td><td>169.237.32.34</td><td style=\"text-align: right;\">2136264</td><td style=\"text-align: right;\">            46.2553 </td><td style=\"text-align: right;\">          0.787787</td><td style=\"text-align: right;\">      46.2553 </td><td style=\"text-align: right;\"> 1688938271</td><td style=\"text-align: right;\">  0.00517252</td><td style=\"text-align: right;\">                  40</td><td>a0ce0_00069</td><td style=\"text-align: right;\">0.00421572</td></tr>\n",
       "<tr><td>train_model2_a0ce0_00070</td><td style=\"text-align: right;\">    0.00390273 </td><td>2023-07-09_14-30-55</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        20</td><td>169.237.32.34</td><td style=\"text-align: right;\">2142547</td><td style=\"text-align: right;\">            28.376  </td><td style=\"text-align: right;\">          1.14584 </td><td style=\"text-align: right;\">      28.376  </td><td style=\"text-align: right;\"> 1688938255</td><td style=\"text-align: right;\">  0.191699  </td><td style=\"text-align: right;\">                  20</td><td>a0ce0_00070</td><td style=\"text-align: right;\">0.0203586 </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00071</td><td style=\"text-align: right;\">    7.17759e-06</td><td>2023-07-09_14-31-12</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        40</td><td>169.237.32.34</td><td style=\"text-align: right;\">2158022</td><td style=\"text-align: right;\">            41.0378 </td><td style=\"text-align: right;\">          0.657349</td><td style=\"text-align: right;\">      41.0378 </td><td style=\"text-align: right;\"> 1688938272</td><td style=\"text-align: right;\">  0.00397503</td><td style=\"text-align: right;\">                  40</td><td>a0ce0_00071</td><td style=\"text-align: right;\">0.00180567</td></tr>\n",
       "<tr><td>train_model2_a0ce0_00072</td><td style=\"text-align: right;\">    8.16811e-05</td><td>2023-07-09_14-31-12</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        40</td><td>169.237.32.34</td><td style=\"text-align: right;\">2158025</td><td style=\"text-align: right;\">            41.1366 </td><td style=\"text-align: right;\">          0.612508</td><td style=\"text-align: right;\">      41.1366 </td><td style=\"text-align: right;\"> 1688938272</td><td style=\"text-align: right;\">  0.0250874 </td><td style=\"text-align: right;\">                  40</td><td>a0ce0_00072</td><td style=\"text-align: right;\">0.00325586</td></tr>\n",
       "<tr><td>train_model2_a0ce0_00073</td><td style=\"text-align: right;\">    0.466116   </td><td>2023-07-09_14-30-53</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        10</td><td>169.237.32.34</td><td style=\"text-align: right;\">2183313</td><td style=\"text-align: right;\">            13.5911 </td><td style=\"text-align: right;\">          1.0942  </td><td style=\"text-align: right;\">      13.5911 </td><td style=\"text-align: right;\"> 1688938253</td><td style=\"text-align: right;\">  1.01137   </td><td style=\"text-align: right;\">                  10</td><td>a0ce0_00073</td><td style=\"text-align: right;\">0.460878  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00074</td><td style=\"text-align: right;\">    0.596455   </td><td>2023-07-09_14-30-52</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">2189075</td><td style=\"text-align: right;\">            10.4583 </td><td style=\"text-align: right;\">          1.66653 </td><td style=\"text-align: right;\">      10.4583 </td><td style=\"text-align: right;\"> 1688938252</td><td style=\"text-align: right;\">  0.912186  </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00074</td><td style=\"text-align: right;\">0.653875  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00075</td><td style=\"text-align: right;\">    0.00104174 </td><td>2023-07-09_14-31-11</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        20</td><td>169.237.32.34</td><td style=\"text-align: right;\">2189123</td><td style=\"text-align: right;\">            29.0213 </td><td style=\"text-align: right;\">          1.00695 </td><td style=\"text-align: right;\">      29.0213 </td><td style=\"text-align: right;\"> 1688938271</td><td style=\"text-align: right;\">  0.417619  </td><td style=\"text-align: right;\">                  20</td><td>a0ce0_00075</td><td style=\"text-align: right;\">0.00249448</td></tr>\n",
       "<tr><td>train_model2_a0ce0_00076</td><td style=\"text-align: right;\">    0.000589921</td><td>2023-07-09_14-31-11</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        20</td><td>169.237.32.34</td><td style=\"text-align: right;\">2198212</td><td style=\"text-align: right;\">            26.9715 </td><td style=\"text-align: right;\">          0.785968</td><td style=\"text-align: right;\">      26.9715 </td><td style=\"text-align: right;\"> 1688938271</td><td style=\"text-align: right;\">  0.0347582 </td><td style=\"text-align: right;\">                  20</td><td>a0ce0_00076</td><td style=\"text-align: right;\">0.0169721 </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00077</td><td style=\"text-align: right;\">    0.832048   </td><td>2023-07-09_14-30-54</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                         5</td><td>169.237.32.34</td><td style=\"text-align: right;\">2204241</td><td style=\"text-align: right;\">             7.25037</td><td style=\"text-align: right;\">          0.997556</td><td style=\"text-align: right;\">       7.25037</td><td style=\"text-align: right;\"> 1688938254</td><td style=\"text-align: right;\">  1.0091    </td><td style=\"text-align: right;\">                   5</td><td>a0ce0_00077</td><td style=\"text-align: right;\">0.824545  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00078</td><td style=\"text-align: right;\">    0.559538   </td><td>2023-07-09_14-31-00</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        10</td><td>169.237.32.34</td><td style=\"text-align: right;\">2209342</td><td style=\"text-align: right;\">            11.528  </td><td style=\"text-align: right;\">          0.846962</td><td style=\"text-align: right;\">      11.528  </td><td style=\"text-align: right;\"> 1688938260</td><td style=\"text-align: right;\">  0.87394   </td><td style=\"text-align: right;\">                  10</td><td>a0ce0_00078</td><td style=\"text-align: right;\">0.640248  </td></tr>\n",
       "<tr><td>train_model2_a0ce0_00079</td><td style=\"text-align: right;\">    0.262724   </td><td>2023-07-09_14-31-09</td><td>True  </td><td>blueberry </td><td style=\"text-align: right;\">                        20</td><td>169.237.32.34</td><td style=\"text-align: right;\">2209344</td><td style=\"text-align: right;\">            20.3271 </td><td style=\"text-align: right;\">          0.791286</td><td style=\"text-align: right;\">      20.3271 </td><td style=\"text-align: right;\"> 1688938269</td><td style=\"text-align: right;\">  0.672553  </td><td style=\"text-align: right;\">                  20</td><td>a0ce0_00079</td><td style=\"text-align: right;\">0.390636  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-09 14:29:10 (running for 00:00:05.93)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (64 PENDING, 16 RUNNING)\n",
      "+--------------------------+----------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status   | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+----------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00000 | RUNNING  | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |     0.986828 |   0.609259 |        0.601234 |                    3 |\n",
      "| train_model2_a0ce0_00001 | RUNNING  | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00002 | RUNNING  | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00003 | RUNNING  | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00004 | RUNNING  | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00005 | RUNNING  | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00006 | RUNNING  | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00007 | RUNNING  | 169.237.32.34:1924882 |            8 | 6.57914e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00008 | RUNNING  | 169.237.32.34:1924884 |           32 | 5.07391e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00009 | RUNNING  | 169.237.32.34:1924886 |            8 | 2.37206e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00016 | PENDING  |                       |            8 | 1.27965e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00017 | PENDING  |                       |           32 | 0.000583307 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00018 | PENDING  |                       |           32 | 1.72815e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00019 | PENDING  |                       |           32 | 3.48382e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00020 | PENDING  |                       |           16 | 0.000170954 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00021 | PENDING  |                       |           32 | 6.04538e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00022 | PENDING  |                       |           32 | 0.000426472 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00023 | PENDING  |                       |           16 | 2.30102e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00024 | PENDING  |                       |            8 | 7.11999e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00025 | PENDING  |                       |           32 | 1.10936e-05 |       0.95 |              |            |                 |                      |\n",
      "+--------------------------+----------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (6 RUNNING, 54 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:29:15 (running for 00:00:11.12)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -0.6270213723506055\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (64 PENDING, 16 RUNNING)\n",
      "+--------------------------+----------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status   | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+----------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00000 | RUNNING  | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |     0.897686 |   0.657705 |        0.590413 |                    7 |\n",
      "| train_model2_a0ce0_00001 | RUNNING  | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |     1.00214  |   0.526804 |        0.527929 |                    3 |\n",
      "| train_model2_a0ce0_00002 | RUNNING  | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |     0.693113 |   0.637116 |        0.441593 |                    4 |\n",
      "| train_model2_a0ce0_00003 | RUNNING  | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |     1.13494  |   1.26826  |        1.4394   |                    3 |\n",
      "| train_model2_a0ce0_00004 | RUNNING  | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |     0.991114 |   0.643593 |        0.637874 |                    4 |\n",
      "| train_model2_a0ce0_00005 | RUNNING  | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |     0.950886 |   0.499003 |        0.474495 |                    4 |\n",
      "| train_model2_a0ce0_00006 | RUNNING  | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |     0.977331 |   0.80288  |        0.784679 |                    4 |\n",
      "| train_model2_a0ce0_00007 | RUNNING  | 169.237.32.34:1924882 |            8 | 6.57914e-05 |       0.93 |     1.03716  |   0.800307 |        0.830048 |                    2 |\n",
      "| train_model2_a0ce0_00008 | RUNNING  | 169.237.32.34:1924884 |           32 | 5.07391e-05 |       0.95 |     1.2561   |   1.23835  |        1.55549  |                    4 |\n",
      "| train_model2_a0ce0_00009 | RUNNING  | 169.237.32.34:1924886 |            8 | 2.37206e-05 |       0.93 |     0.94837  |   0.716397 |        0.679409 |                    2 |\n",
      "| train_model2_a0ce0_00016 | PENDING  |                       |            8 | 1.27965e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00017 | PENDING  |                       |           32 | 0.000583307 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00018 | PENDING  |                       |           32 | 1.72815e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00019 | PENDING  |                       |           32 | 3.48382e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00020 | PENDING  |                       |           16 | 0.000170954 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00021 | PENDING  |                       |           32 | 6.04538e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00022 | PENDING  |                       |           32 | 0.000426472 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00023 | PENDING  |                       |           16 | 2.30102e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00024 | PENDING  |                       |            8 | 7.11999e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00025 | PENDING  |                       |           32 | 1.10936e-05 |       0.95 |              |            |                 |                      |\n",
      "+--------------------------+----------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (6 RUNNING, 54 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:29:20 (running for 00:00:16.15)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.44339604640195274 | Iter 5.000: -0.6064526626157695\n",
      "Logical resource usage: 60.0/64 CPUs, 0.7500000000000001/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (56 PENDING, 15 RUNNING, 9 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00000 | RUNNING    | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |    0.545648  | 0.350462   |     0.191229    |                   12 |\n",
      "| train_model2_a0ce0_00001 | RUNNING    | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |    0.988388  | 0.551445   |     0.545042    |                    6 |\n",
      "| train_model2_a0ce0_00002 | RUNNING    | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |    0.0822267 | 0.063019   |     0.00518184  |                    8 |\n",
      "| train_model2_a0ce0_00005 | RUNNING    | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |    0.900172  | 0.489965   |     0.441053    |                   10 |\n",
      "| train_model2_a0ce0_00010 | RUNNING    | 169.237.32.34:1924890 |           32 | 0.000434028 |       0.95 |    0.382659  | 0.161901   |     0.0619529   |                    9 |\n",
      "| train_model2_a0ce0_00011 | RUNNING    | 169.237.32.34:1924892 |           16 | 7.77073e-05 |       0.95 |    0.909131  | 0.544008   |     0.494574    |                    8 |\n",
      "| train_model2_a0ce0_00013 | RUNNING    | 169.237.32.34:1924898 |           32 | 0.000453723 |       0.97 |    0.0209198 | 0.00709285 |     0.000148381 |                   10 |\n",
      "| train_model2_a0ce0_00024 | PENDING    |                       |            8 | 7.11999e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00025 | PENDING    |                       |           32 | 1.10936e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00026 | PENDING    |                       |           32 | 1.26883e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00027 | PENDING    |                       |           16 | 2.57492e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00028 | PENDING    |                       |           32 | 0.000105161 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00029 | PENDING    |                       |           16 | 2.53975e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00030 | PENDING    |                       |           16 | 2.17953e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |    1.04177   | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |    0.900003  | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |    0.932132  | 0.753353   |     0.702224    |                    5 |\n",
      "| train_model2_a0ce0_00007 | TERMINATED | 169.237.32.34:1924882 |            8 | 6.57914e-05 |       0.93 |    1.00283   | 0.704264   |     0.70626     |                    5 |\n",
      "| train_model2_a0ce0_00008 | TERMINATED | 169.237.32.34:1924884 |           32 | 5.07391e-05 |       0.95 |    1.20425   | 1.13648    |     1.3686      |                    5 |\n",
      "| train_model2_a0ce0_00009 | TERMINATED | 169.237.32.34:1924886 |            8 | 2.37206e-05 |       0.93 |    0.901644  | 0.674859   |     0.608483    |                    5 |\n",
      "| train_model2_a0ce0_00012 | TERMINATED | 169.237.32.34:1924895 |           32 | 0.000299947 |       0.95 |    0.991092  | 0.609855   |     0.604422    |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (8 RUNNING, 49 PENDING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:29:25 (running for 00:00:21.24)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.4365968468239066 | Iter 5.000: -0.6064526626157695\n",
      "Logical resource usage: 60.0/64 CPUs, 0.7500000000000001/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (54 PENDING, 15 RUNNING, 11 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00000 | RUNNING    | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |    0.112972  | 0.0084403  |     0.000953521 |                   17 |\n",
      "| train_model2_a0ce0_00002 | RUNNING    | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |    0.0445237 | 0.0356585  |     0.00158765  |                   13 |\n",
      "| train_model2_a0ce0_00005 | RUNNING    | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |    0.873528  | 0.47275    |     0.41296     |                   15 |\n",
      "| train_model2_a0ce0_00010 | RUNNING    | 169.237.32.34:1924890 |           32 | 0.000434028 |       0.95 |    0.0122829 | 0.00455475 |     5.59454e-05 |                   15 |\n",
      "| train_model2_a0ce0_00013 | RUNNING    | 169.237.32.34:1924898 |           32 | 0.000453723 |       0.97 |    0.015773  | 0.00324035 |     5.11102e-05 |                   16 |\n",
      "| train_model2_a0ce0_00016 | RUNNING    | 169.237.32.34:1949271 |            8 | 1.27965e-05 |       0.95 |    1.0912    | 0.405241   |     0.442198    |                    2 |\n",
      "| train_model2_a0ce0_00017 | RUNNING    | 169.237.32.34:1949274 |           32 | 0.000583307 |       0.93 |    0.86328   | 0.763383   |     0.659013    |                    3 |\n",
      "| train_model2_a0ce0_00026 | PENDING    |                       |           32 | 1.26883e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00027 | PENDING    |                       |           16 | 2.57492e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00028 | PENDING    |                       |           32 | 0.000105161 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00029 | PENDING    |                       |           16 | 2.53975e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00030 | PENDING    |                       |           16 | 2.17953e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00031 | PENDING    |                       |           32 | 0.000376035 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00032 | PENDING    |                       |            8 | 1.48815e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |    0.974314  | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |    1.04177   | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |    0.900003  | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |    0.932132  | 0.753353   |     0.702224    |                    5 |\n",
      "| train_model2_a0ce0_00007 | TERMINATED | 169.237.32.34:1924882 |            8 | 6.57914e-05 |       0.93 |    1.00283   | 0.704264   |     0.70626     |                    5 |\n",
      "| train_model2_a0ce0_00008 | TERMINATED | 169.237.32.34:1924884 |           32 | 5.07391e-05 |       0.95 |    1.20425   | 1.13648    |     1.3686      |                    5 |\n",
      "| train_model2_a0ce0_00009 | TERMINATED | 169.237.32.34:1924886 |            8 | 2.37206e-05 |       0.93 |    0.901644  | 0.674859   |     0.608483    |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (8 RUNNING, 47 PENDING, 4 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:29:30 (running for 00:00:26.31)\n",
      "Using AsyncHyperBand: num_stopped=17\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.00024196838883384404 | Iter 10.000: -0.4365968468239066 | Iter 5.000: -0.6131203606565847\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (47 PENDING, 16 RUNNING, 17 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00000 | RUNNING    | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |    0.0549539 | 0.00665147 |     0.000365524 |                   21 |\n",
      "| train_model2_a0ce0_00002 | RUNNING    | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |    0.0351528 | 0.0201128  |     0.00070702  |                   18 |\n",
      "| train_model2_a0ce0_00010 | RUNNING    | 169.237.32.34:1924890 |           32 | 0.000434028 |       0.95 |    0.0091857 | 0.00363439 |     3.33844e-05 |                   21 |\n",
      "| train_model2_a0ce0_00013 | RUNNING    | 169.237.32.34:1924898 |           32 | 0.000453723 |       0.97 |    0.0144814 | 0.00282304 |     4.08815e-05 |                   21 |\n",
      "| train_model2_a0ce0_00016 | RUNNING    | 169.237.32.34:1949271 |            8 | 1.27965e-05 |       0.95 |    0.984828  | 0.436768   |     0.430141    |                    5 |\n",
      "| train_model2_a0ce0_00019 | RUNNING    | 169.237.32.34:1955179 |           32 | 3.48382e-05 |       0.97 |    0.845476  | 0.620772   |     0.524847    |                    6 |\n",
      "| train_model2_a0ce0_00020 | RUNNING    | 169.237.32.34:1955192 |           16 | 0.000170954 |       0.95 |    0.79764   | 0.691724   |     0.551747    |                    6 |\n",
      "| train_model2_a0ce0_00033 | PENDING    |                       |           32 | 2.3932e-05  |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00034 | PENDING    |                       |           16 | 0.000134044 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00035 | PENDING    |                       |           32 | 1.37486e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00036 | PENDING    |                       |            8 | 1.26101e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00037 | PENDING    |                       |            8 | 0.000603897 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00038 | PENDING    |                       |           16 | 2.74947e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00039 | PENDING    |                       |            8 | 8.75715e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |    0.974314  | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |    1.04177   | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |    0.900003  | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |    0.844946  | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |    0.932132  | 0.753353   |     0.702224    |                    5 |\n",
      "| train_model2_a0ce0_00007 | TERMINATED | 169.237.32.34:1924882 |            8 | 6.57914e-05 |       0.93 |    1.00283   | 0.704264   |     0.70626     |                    5 |\n",
      "| train_model2_a0ce0_00008 | TERMINATED | 169.237.32.34:1924884 |           32 | 5.07391e-05 |       0.95 |    1.20425   | 1.13648    |     1.3686      |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (9 RUNNING, 40 PENDING, 10 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:29:35 (running for 00:00:31.36)\n",
      "Using AsyncHyperBand: num_stopped=21\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.000443249503589716 | Iter 10.000: -0.4365968468239066 | Iter 5.000: -0.6177578705568383\n",
      "Logical resource usage: 60.0/64 CPUs, 0.7500000000000001/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (44 PENDING, 15 RUNNING, 21 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00000 | RUNNING    | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0321423  | 0.00750525 |     0.000241236 |                   26 |\n",
      "| train_model2_a0ce0_00010 | RUNNING    | 169.237.32.34:1924890 |           32 | 0.000434028 |       0.95 |   0.00755776 | 0.00305024 |     2.30529e-05 |                   26 |\n",
      "| train_model2_a0ce0_00013 | RUNNING    | 169.237.32.34:1924898 |           32 | 0.000453723 |       0.97 |   0.0135462  | 0.00230111 |     3.11712e-05 |                   27 |\n",
      "| train_model2_a0ce0_00016 | RUNNING    | 169.237.32.34:1949271 |            8 | 1.27965e-05 |       0.95 |   0.919589   | 0.459842   |     0.422866    |                    9 |\n",
      "| train_model2_a0ce0_00020 | RUNNING    | 169.237.32.34:1955192 |           16 | 0.000170954 |       0.95 |   0.600518   | 0.649033   |     0.389756    |                   10 |\n",
      "| train_model2_a0ce0_00025 | RUNNING    | 169.237.32.34:1965380 |           32 | 1.10936e-05 |       0.95 |   1.09743    | 0.362817   |     0.398165    |                    8 |\n",
      "| train_model2_a0ce0_00027 | RUNNING    | 169.237.32.34:1980681 |           16 | 2.57492e-05 |       0.97 |   1.18185    | 1.14274    |     1.35055     |                    2 |\n",
      "| train_model2_a0ce0_00036 | PENDING    |                       |            8 | 1.26101e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00037 | PENDING    |                       |            8 | 0.000603897 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00038 | PENDING    |                       |           16 | 2.74947e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00039 | PENDING    |                       |            8 | 8.75715e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00040 | PENDING    |                       |           16 | 4.13506e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00041 | PENDING    |                       |           16 | 2.85459e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00042 | PENDING    |                       |           16 | 3.06588e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "| train_model2_a0ce0_00007 | TERMINATED | 169.237.32.34:1924882 |            8 | 6.57914e-05 |       0.93 |   1.00283    | 0.704264   |     0.70626     |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (8 RUNNING, 37 PENDING, 14 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:29:40 (running for 00:00:36.44)\n",
      "Using AsyncHyperBand: num_stopped=22\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.000443249503589716 | Iter 10.000: -0.4266074729233032 | Iter 5.000: -0.6131203606565847\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (42 PENDING, 16 RUNNING, 22 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00000 | RUNNING    | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0224693  | 0.00603143 |     0.000135522 |                   31 |\n",
      "| train_model2_a0ce0_00010 | RUNNING    | 169.237.32.34:1924890 |           32 | 0.000434028 |       0.95 |   0.00609548 | 0.00281355 |     1.71499e-05 |                   32 |\n",
      "| train_model2_a0ce0_00013 | RUNNING    | 169.237.32.34:1924898 |           32 | 0.000453723 |       0.97 |   0.012629   | 0.00186005 |     2.34905e-05 |                   32 |\n",
      "| train_model2_a0ce0_00016 | RUNNING    | 169.237.32.34:1949271 |            8 | 1.27965e-05 |       0.95 |   0.901008   | 0.462663   |     0.416863    |                   12 |\n",
      "| train_model2_a0ce0_00020 | RUNNING    | 169.237.32.34:1955192 |           16 | 0.000170954 |       0.95 |   0.259485   | 0.395872   |     0.102723    |                   15 |\n",
      "| train_model2_a0ce0_00025 | RUNNING    | 169.237.32.34:1965380 |           32 | 1.10936e-05 |       0.95 |   1.06775    | 0.37665    |     0.402169    |                   13 |\n",
      "| train_model2_a0ce0_00028 | RUNNING    | 169.237.32.34:1980685 |           32 | 0.000105161 |       0.97 |   0.826152   | 0.629156   |     0.519779    |                    7 |\n",
      "| train_model2_a0ce0_00038 | PENDING    |                       |           16 | 2.74947e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00039 | PENDING    |                       |            8 | 8.75715e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00040 | PENDING    |                       |           16 | 4.13506e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00041 | PENDING    |                       |           16 | 2.85459e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00042 | PENDING    |                       |           16 | 3.06588e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00043 | PENDING    |                       |           16 | 6.61162e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00044 | PENDING    |                       |           32 | 0.000775449 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "| train_model2_a0ce0_00007 | TERMINATED | 169.237.32.34:1924882 |            8 | 6.57914e-05 |       0.93 |   1.00283    | 0.704264   |     0.70626     |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (9 RUNNING, 35 PENDING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:29:45 (running for 00:00:41.46)\n",
      "Using AsyncHyperBand: num_stopped=27\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.000443249503589716 | Iter 10.000: -0.4266074729233032 | Iter 5.000: -0.6206841314656761\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (37 PENDING, 16 RUNNING, 27 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00000 | RUNNING    | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0171865  | 0.00473195 |     8.13257e-05 |                   35 |\n",
      "| train_model2_a0ce0_00010 | RUNNING    | 169.237.32.34:1924890 |           32 | 0.000434028 |       0.95 |   0.00522138 | 0.00258667 |     1.3506e-05  |                   37 |\n",
      "| train_model2_a0ce0_00013 | RUNNING    | 169.237.32.34:1924898 |           32 | 0.000453723 |       0.97 |   0.0117663  | 0.00167553 |     1.97148e-05 |                   38 |\n",
      "| train_model2_a0ce0_00016 | RUNNING    | 169.237.32.34:1949271 |            8 | 1.27965e-05 |       0.95 |   0.897442   | 0.459236   |     0.412138    |                   15 |\n",
      "| train_model2_a0ce0_00020 | RUNNING    | 169.237.32.34:1955192 |           16 | 0.000170954 |       0.95 |   0.139043   | 0.245535   |     0.03414     |                   19 |\n",
      "| train_model2_a0ce0_00025 | RUNNING    | 169.237.32.34:1965380 |           32 | 1.10936e-05 |       0.95 |   1.04524    | 0.388568   |     0.406148    |                   18 |\n",
      "| train_model2_a0ce0_00031 | RUNNING    | 169.237.32.34:1987144 |           32 | 0.000376035 |       0.97 |   0.668344   | 0.386683   |     0.258438    |                   10 |\n",
      "| train_model2_a0ce0_00043 | PENDING    |                       |           16 | 6.61162e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00044 | PENDING    |                       |           32 | 0.000775449 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00045 | PENDING    |                       |           16 | 0.000642209 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00046 | PENDING    |                       |            8 | 0.000345374 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00047 | PENDING    |                       |           32 | 1.88667e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00048 | PENDING    |                       |           16 | 1.3861e-05  |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00049 | PENDING    |                       |           16 | 9.14132e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "| train_model2_a0ce0_00007 | TERMINATED | 169.237.32.34:1924882 |            8 | 6.57914e-05 |       0.93 |   1.00283    | 0.704264   |     0.70626     |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (9 RUNNING, 30 PENDING, 20 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:29:50 (running for 00:00:46.48)\n",
      "Using AsyncHyperBand: num_stopped=33\n",
      "Bracket: Iter 40.000: -2.3869599465884567e-05 | Iter 20.000: -0.0006579931946046035 | Iter 10.000: -0.4266074729233032 | Iter 5.000: -0.6131203606565847\n",
      "Logical resource usage: 56.0/64 CPUs, 0.7000000000000001/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (33 PENDING, 14 RUNNING, 33 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00016 | RUNNING    | 169.237.32.34:1949271 |            8 | 1.27965e-05 |       0.95 |    0.888451  |  0.453489  |     0.402903    |                   18 |\n",
      "| train_model2_a0ce0_00031 | RUNNING    | 169.237.32.34:1987144 |           32 | 0.000376035 |       0.97 |    0.667213  |  0.384693  |     0.256672    |                   15 |\n",
      "| train_model2_a0ce0_00034 | RUNNING    | 169.237.32.34:1995219 |           16 | 0.000134044 |       0.97 |    0.699606  |  0.400512  |     0.280201    |                   12 |\n",
      "| train_model2_a0ce0_00036 | RUNNING    | 169.237.32.34:2006620 |            8 | 1.26101e-05 |       0.97 |    0.993977  |  0.478338  |     0.475457    |                    6 |\n",
      "| train_model2_a0ce0_00037 | RUNNING    | 169.237.32.34:2012982 |            8 | 0.000603897 |       0.93 |    0.112072  |  0.147959  |     0.016582    |                    5 |\n",
      "| train_model2_a0ce0_00038 | RUNNING    | 169.237.32.34:2022672 |           16 | 2.74947e-05 |       0.95 |    0.94934   |  0.622904  |     0.591348    |                    3 |\n",
      "| train_model2_a0ce0_00039 | RUNNING    | 169.237.32.34:2022674 |            8 | 8.75715e-05 |       0.95 |    1.06295   |  0.774996  |     0.823782    |                    2 |\n",
      "| train_model2_a0ce0_00047 | PENDING    |                       |           32 | 1.88667e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00048 | PENDING    |                       |           16 | 1.3861e-05  |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00049 | PENDING    |                       |           16 | 9.14132e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00050 | PENDING    |                       |            8 | 0.000220657 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00051 | PENDING    |                       |           16 | 5.90081e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00052 | PENDING    |                       |            8 | 0.000180459 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00053 | PENDING    |                       |            8 | 0.000107708 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |    0.0116887 |  0.0042548 |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |    0.974314  |  0.57139   |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |    0.0321841 |  0.0204447 |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |    1.04177   |  1.12478   |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |    0.900003  |  0.574291  |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |    0.844946  |  0.457386  |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |    0.932132  |  0.753353  |     0.702224    |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (7 RUNNING, 26 PENDING, 26 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:29:56 (running for 00:00:51.95)\n",
      "Using AsyncHyperBand: num_stopped=38\n",
      "Bracket: Iter 40.000: -2.3869599465884567e-05 | Iter 20.000: -0.027161845902649393 | Iter 10.000: -0.43214090211800893 | Iter 5.000: -0.6084828507563311\n",
      "Logical resource usage: 60.0/64 CPUs, 0.7500000000000001/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (27 PENDING, 15 RUNNING, 38 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00034 | RUNNING    | 169.237.32.34:1995219 |           16 | 0.000134044 |       0.97 |    0.66865   |  0.391958  |     0.262083    |                   17 |\n",
      "| train_model2_a0ce0_00037 | RUNNING    | 169.237.32.34:2012982 |            8 | 0.000603897 |       0.93 |    0.0268601 |  0.0148971 |     0.000400137 |                    8 |\n",
      "| train_model2_a0ce0_00038 | RUNNING    | 169.237.32.34:2022672 |           16 | 2.74947e-05 |       0.95 |    0.901926  |  0.649166  |     0.5855      |                    8 |\n",
      "| train_model2_a0ce0_00041 | RUNNING    | 169.237.32.34:2028471 |           16 | 2.85459e-05 |       0.95 |    0.972047  |  0.432128  |     0.420049    |                    6 |\n",
      "| train_model2_a0ce0_00042 | RUNNING    | 169.237.32.34:2028473 |           16 | 3.06588e-05 |       0.97 |    0.757687  |  0.739983  |     0.560676    |                    6 |\n",
      "| train_model2_a0ce0_00043 | RUNNING    | 169.237.32.34:2037183 |           16 | 6.61162e-05 |       0.97 |    1.01306   |  0.66424   |     0.672915    |                    4 |\n",
      "| train_model2_a0ce0_00044 | RUNNING    | 169.237.32.34:2042087 |           32 | 0.000775449 |       0.93 |    1.02333   |  0.664715  |     0.680227    |                    2 |\n",
      "| train_model2_a0ce0_00053 | PENDING    |                       |            8 | 0.000107708 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00054 | PENDING    |                       |           32 | 0.000367593 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00055 | PENDING    |                       |           16 | 2.92108e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00056 | PENDING    |                       |           32 | 0.000724692 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00057 | PENDING    |                       |           32 | 0.000298038 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00058 | PENDING    |                       |           32 | 0.000130378 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00059 | PENDING    |                       |           32 | 2.82371e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |    0.0116887 |  0.0042548 |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |    0.974314  |  0.57139   |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |    0.0321841 |  0.0204447 |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |    1.04177   |  1.12478   |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |    0.900003  |  0.574291  |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |    0.844946  |  0.457386  |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |    0.932132  |  0.753353  |     0.702224    |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (8 RUNNING, 20 PENDING, 31 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:30:01 (running for 00:00:56.95)\n",
      "Using AsyncHyperBand: num_stopped=43\n",
      "Bracket: Iter 40.000: -2.3869599465884567e-05 | Iter 20.000: -0.1441379245918769 | Iter 10.000: -0.43214090211800893 | Iter 5.000: -0.6064526626157695\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (21 PENDING, 16 RUNNING, 43 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00037 | RUNNING    | 169.237.32.34:2012982 |            8 | 0.000603897 |       0.93 |   0.00889443 | 0.00493469 |     4.38913e-05 |                   12 |\n",
      "| train_model2_a0ce0_00041 | RUNNING    | 169.237.32.34:2028471 |           16 | 2.85459e-05 |       0.95 |   0.929845   | 0.45283    |     0.421062    |                   10 |\n",
      "| train_model2_a0ce0_00043 | RUNNING    | 169.237.32.34:2037183 |           16 | 6.61162e-05 |       0.97 |   0.735876   | 0.313996   |     0.231062    |                    9 |\n",
      "| train_model2_a0ce0_00045 | RUNNING    | 169.237.32.34:2042089 |           16 | 0.000642209 |       0.95 |   0.0839742  | 0.0142026  |     0.00119265  |                    7 |\n",
      "| train_model2_a0ce0_00046 | RUNNING    | 169.237.32.34:2042091 |            8 | 0.000345374 |       0.97 |   0.0201396  | 0.0141174  |     0.000284318 |                    5 |\n",
      "| train_model2_a0ce0_00048 | RUNNING    | 169.237.32.34:2047198 |           16 | 1.3861e-05  |       0.95 |   1.03339    | 0.453886   |     0.469043    |                    4 |\n",
      "| train_model2_a0ce0_00049 | RUNNING    | 169.237.32.34:2052086 |           16 | 9.14132e-05 |       0.95 |   0.8942     | 0.746565   |     0.667578    |                    3 |\n",
      "| train_model2_a0ce0_00059 | PENDING    |                       |           32 | 2.82371e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00060 | PENDING    |                       |            8 | 0.000214237 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00061 | PENDING    |                       |           32 | 0.000316222 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00062 | PENDING    |                       |           16 | 0.000258236 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00063 | PENDING    |                       |           32 | 0.000560877 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00064 | PENDING    |                       |           16 | 2.89325e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00065 | PENDING    |                       |           32 | 2.04421e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0116887  | 0.0042548  |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (9 RUNNING, 14 PENDING, 36 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:30:06 (running for 00:01:02.02)\n",
      "Using AsyncHyperBand: num_stopped=44\n",
      "Bracket: Iter 40.000: -2.3869599465884567e-05 | Iter 20.000: -0.1441379245918769 | Iter 10.000: -0.42107404372859747 | Iter 5.000: -0.6044224744752078\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (20 PENDING, 16 RUNNING, 44 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00037 | RUNNING    | 169.237.32.34:2012982 |            8 | 0.000603897 |       0.93 |   0.00699237 | 0.00788957 |     5.51668e-05 |                   15 |\n",
      "| train_model2_a0ce0_00041 | RUNNING    | 169.237.32.34:2028471 |           16 | 2.85459e-05 |       0.95 |   0.910457   | 0.454187   |     0.413517    |                   15 |\n",
      "| train_model2_a0ce0_00043 | RUNNING    | 169.237.32.34:2037183 |           16 | 6.61162e-05 |       0.97 |   0.472121   | 0.0850896  |     0.0401726   |                   13 |\n",
      "| train_model2_a0ce0_00045 | RUNNING    | 169.237.32.34:2042089 |           16 | 0.000642209 |       0.95 |   0.0124922  | 0.00830941 |     0.000103803 |                   11 |\n",
      "| train_model2_a0ce0_00046 | RUNNING    | 169.237.32.34:2042091 |            8 | 0.000345374 |       0.97 |   0.00743761 | 0.00673646 |     5.01032e-05 |                    9 |\n",
      "| train_model2_a0ce0_00048 | RUNNING    | 169.237.32.34:2047198 |           16 | 1.3861e-05  |       0.95 |   1.00304    | 0.496678   |     0.498189    |                    9 |\n",
      "| train_model2_a0ce0_00050 | RUNNING    | 169.237.32.34:2057655 |            8 | 0.000220657 |       0.97 |   0.315111   | 0.0535688  |     0.0168801   |                    4 |\n",
      "| train_model2_a0ce0_00060 | PENDING    |                       |            8 | 0.000214237 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00061 | PENDING    |                       |           32 | 0.000316222 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00062 | PENDING    |                       |           16 | 0.000258236 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00063 | PENDING    |                       |           32 | 0.000560877 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00064 | PENDING    |                       |           16 | 2.89325e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00065 | PENDING    |                       |           32 | 2.04421e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00066 | PENDING    |                       |           16 | 0.000776199 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0116887  | 0.0042548  |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (9 RUNNING, 13 PENDING, 37 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:30:11 (running for 00:01:07.03)\n",
      "Using AsyncHyperBand: num_stopped=49\n",
      "Bracket: Iter 40.000: -2.3869599465884567e-05 | Iter 20.000: -0.1441379245918769 | Iter 10.000: -0.42107404372859747 | Iter 5.000: -0.6044224744752078\n",
      "Logical resource usage: 56.0/64 CPUs, 0.7000000000000001/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (17 PENDING, 14 RUNNING, 49 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00037 | RUNNING    | 169.237.32.34:2012982 |            8 | 0.000603897 |       0.93 |   0.00670684 | 0.00511985 |     3.4338e-05  |                   18 |\n",
      "| train_model2_a0ce0_00041 | RUNNING    | 169.237.32.34:2028471 |           16 | 2.85459e-05 |       0.95 |   0.903363   | 0.456923   |     0.412767    |                   18 |\n",
      "| train_model2_a0ce0_00043 | RUNNING    | 169.237.32.34:2037183 |           16 | 6.61162e-05 |       0.97 |   0.21189    | 0.0020582  |     0.000436112 |                   17 |\n",
      "| train_model2_a0ce0_00045 | RUNNING    | 169.237.32.34:2042089 |           16 | 0.000642209 |       0.95 |   0.00584075 | 0.00531818 |     3.10622e-05 |                   16 |\n",
      "| train_model2_a0ce0_00046 | RUNNING    | 169.237.32.34:2042091 |            8 | 0.000345374 |       0.97 |   0.00535758 | 0.00475264 |     2.54626e-05 |                   12 |\n",
      "| train_model2_a0ce0_00050 | RUNNING    | 169.237.32.34:2057655 |            8 | 0.000220657 |       0.97 |   0.0300516  | 0.00201209 |     6.04663e-05 |                    7 |\n",
      "| train_model2_a0ce0_00051 | RUNNING    | 169.237.32.34:2057659 |           16 | 5.90081e-05 |       0.95 |   0.808488   | 0.494596   |     0.399875    |                    9 |\n",
      "| train_model2_a0ce0_00063 | PENDING    |                       |           32 | 0.000560877 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00064 | PENDING    |                       |           16 | 2.89325e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00065 | PENDING    |                       |           32 | 2.04421e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00066 | PENDING    |                       |           16 | 0.000776199 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00067 | PENDING    |                       |           16 | 0.000423067 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00068 | PENDING    |                       |           16 | 1.15586e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00069 | PENDING    |                       |           32 | 0.000401711 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0116887  | 0.0042548  |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (7 RUNNING, 10 PENDING, 42 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:30:16 (running for 00:01:12.18)\n",
      "Using AsyncHyperBand: num_stopped=52\n",
      "Bracket: Iter 40.000: -2.3869599465884567e-05 | Iter 20.000: -0.01406567191020597 | Iter 10.000: -0.4089717248603323 | Iter 5.000: -0.6064526626157695\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (12 PENDING, 16 RUNNING, 52 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00037 | RUNNING    | 169.237.32.34:2012982 |            8 | 0.000603897 |       0.93 |   0.00565268 | 0.00330037 |     1.86559e-05 |                   22 |\n",
      "| train_model2_a0ce0_00043 | RUNNING    | 169.237.32.34:2037183 |           16 | 6.61162e-05 |       0.97 |   0.0945781  | 0.0131165  |     0.00124053  |                   22 |\n",
      "| train_model2_a0ce0_00045 | RUNNING    | 169.237.32.34:2042089 |           16 | 0.000642209 |       0.95 |   0.00479334 | 0.00478121 |     2.29179e-05 |                   21 |\n",
      "| train_model2_a0ce0_00046 | RUNNING    | 169.237.32.34:2042091 |            8 | 0.000345374 |       0.97 |   0.00536553 | 0.00553009 |     2.96719e-05 |                   15 |\n",
      "| train_model2_a0ce0_00050 | RUNNING    | 169.237.32.34:2057655 |            8 | 0.000220657 |       0.97 |   0.0177335  | 0.00246293 |     4.36764e-05 |                   11 |\n",
      "| train_model2_a0ce0_00051 | RUNNING    | 169.237.32.34:2057659 |           16 | 5.90081e-05 |       0.95 |   0.636505   | 0.425949   |     0.271119    |                   14 |\n",
      "| train_model2_a0ce0_00054 | RUNNING    | 169.237.32.34:2068218 |           32 | 0.000367593 |       0.97 |   0.0776253  | 0.0286922  |     0.00222724  |                   12 |\n",
      "| train_model2_a0ce0_00068 | PENDING    |                       |           16 | 1.15586e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00069 | PENDING    |                       |           32 | 0.000401711 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00070 | PENDING    |                       |           16 | 0.000149719 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00071 | PENDING    |                       |           16 | 0.000379062 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00072 | PENDING    |                       |           16 | 0.000241282 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00073 | PENDING    |                       |           32 | 1.60386e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00074 | PENDING    |                       |            8 | 1.07675e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0116887  | 0.0042548  |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (9 RUNNING, 5 PENDING, 45 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:30:21 (running for 00:01:17.21)\n",
      "Using AsyncHyperBand: num_stopped=53\n",
      "Bracket: Iter 40.000: -2.3869599465884567e-05 | Iter 20.000: -0.01406567191020597 | Iter 10.000: -0.4089717248603323 | Iter 5.000: -0.6044224744752078\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (11 PENDING, 16 RUNNING, 53 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00037 | RUNNING    | 169.237.32.34:2012982 |            8 | 0.000603897 |       0.93 |   0.00472797 | 0.00357536 |     1.69042e-05 |                   25 |\n",
      "| train_model2_a0ce0_00043 | RUNNING    | 169.237.32.34:2037183 |           16 | 6.61162e-05 |       0.97 |   0.0639673  | 0.0166467  |     0.00106484  |                   26 |\n",
      "| train_model2_a0ce0_00045 | RUNNING    | 169.237.32.34:2042089 |           16 | 0.000642209 |       0.95 |   0.00479149 | 0.00531243 |     2.54545e-05 |                   25 |\n",
      "| train_model2_a0ce0_00046 | RUNNING    | 169.237.32.34:2042091 |            8 | 0.000345374 |       0.97 |   0.00467665 | 0.00439355 |     2.05471e-05 |                   18 |\n",
      "| train_model2_a0ce0_00050 | RUNNING    | 169.237.32.34:2057655 |            8 | 0.000220657 |       0.97 |   0.0162897  | 0.00198417 |     3.23216e-05 |                   14 |\n",
      "| train_model2_a0ce0_00051 | RUNNING    | 169.237.32.34:2057659 |           16 | 5.90081e-05 |       0.95 |   0.432505   | 0.333733   |     0.144341    |                   18 |\n",
      "| train_model2_a0ce0_00054 | RUNNING    | 169.237.32.34:2068218 |           32 | 0.000367593 |       0.97 |   0.024967   | 0.0131685  |     0.000328778 |                   17 |\n",
      "| train_model2_a0ce0_00069 | PENDING    |                       |           32 | 0.000401711 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00070 | PENDING    |                       |           16 | 0.000149719 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00071 | PENDING    |                       |           16 | 0.000379062 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00072 | PENDING    |                       |           16 | 0.000241282 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00073 | PENDING    |                       |           32 | 1.60386e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00074 | PENDING    |                       |            8 | 1.07675e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00075 | PENDING    |                       |            8 | 0.000155695 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0116887  | 0.0042548  |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (9 RUNNING, 4 PENDING, 46 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:30:26 (running for 00:01:22.27)\n",
      "Using AsyncHyperBand: num_stopped=55\n",
      "Bracket: Iter 40.000: -2.3869599465884567e-05 | Iter 20.000: -0.0008137455561835758 | Iter 10.000: -0.4089717248603323 | Iter 5.000: -0.6005629527803139\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (9 PENDING, 16 RUNNING, 55 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00037 | RUNNING    | 169.237.32.34:2012982 |            8 | 0.000603897 |       0.93 |   0.0037967  | 0.00425086 |     1.61392e-05 |                   28 |\n",
      "| train_model2_a0ce0_00043 | RUNNING    | 169.237.32.34:2037183 |           16 | 6.61162e-05 |       0.97 |   0.0434305  | 0.0110009  |     0.000477776 |                   30 |\n",
      "| train_model2_a0ce0_00045 | RUNNING    | 169.237.32.34:2042089 |           16 | 0.000642209 |       0.95 |   0.00392667 | 0.00484021 |     1.90059e-05 |                   29 |\n",
      "| train_model2_a0ce0_00046 | RUNNING    | 169.237.32.34:2042091 |            8 | 0.000345374 |       0.97 |   0.00434493 | 0.00371611 |     1.61462e-05 |                   21 |\n",
      "| train_model2_a0ce0_00050 | RUNNING    | 169.237.32.34:2057655 |            8 | 0.000220657 |       0.97 |   0.0135802  | 0.0018195  |     2.47091e-05 |                   17 |\n",
      "| train_model2_a0ce0_00054 | RUNNING    | 169.237.32.34:2068218 |           32 | 0.000367593 |       0.97 |   0.0143234  | 0.0100877  |     0.00014449  |                   22 |\n",
      "| train_model2_a0ce0_00056 | RUNNING    | 169.237.32.34:2068240 |           32 | 0.000724692 |       0.97 |   0.00379657 | 0.00221613 |     8.41371e-06 |                   22 |\n",
      "| train_model2_a0ce0_00071 | PENDING    |                       |           16 | 0.000379062 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00072 | PENDING    |                       |           16 | 0.000241282 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00073 | PENDING    |                       |           32 | 1.60386e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00074 | PENDING    |                       |            8 | 1.07675e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00075 | PENDING    |                       |            8 | 0.000155695 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00076 | PENDING    |                       |            8 | 0.000121325 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00077 | PENDING    |                       |           32 | 0.000101436 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0116887  | 0.0042548  |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (9 RUNNING, 2 PENDING, 48 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:30:31 (running for 00:01:27.30)\n",
      "Using AsyncHyperBand: num_stopped=57\n",
      "Bracket: Iter 40.000: -2.3869599465884567e-05 | Iter 20.000: -0.0006579931946046035 | Iter 10.000: -0.38975605868689683 | Iter 5.000: -0.6035957835309541\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (7 PENDING, 16 RUNNING, 57 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00037 | RUNNING    | 169.237.32.34:2012982 |            8 | 0.000603897 |       0.93 |   0.00363286 | 0.00251335 |     9.13066e-06 |                   31 |\n",
      "| train_model2_a0ce0_00043 | RUNNING    | 169.237.32.34:2037183 |           16 | 6.61162e-05 |       0.97 |   0.0268297  | 0.00914105 |     0.000245251 |                   35 |\n",
      "| train_model2_a0ce0_00045 | RUNNING    | 169.237.32.34:2042089 |           16 | 0.000642209 |       0.95 |   0.00342253 | 0.00334487 |     1.14479e-05 |                   33 |\n",
      "| train_model2_a0ce0_00046 | RUNNING    | 169.237.32.34:2042091 |            8 | 0.000345374 |       0.97 |   0.00375126 | 0.00350521 |     1.3149e-05  |                   25 |\n",
      "| train_model2_a0ce0_00050 | RUNNING    | 169.237.32.34:2057655 |            8 | 0.000220657 |       0.97 |   0.0126491  | 0.00138632 |     1.75356e-05 |                   20 |\n",
      "| train_model2_a0ce0_00054 | RUNNING    | 169.237.32.34:2068218 |           32 | 0.000367593 |       0.97 |   0.0101407  | 0.00725185 |     7.35392e-05 |                   27 |\n",
      "| train_model2_a0ce0_00056 | RUNNING    | 169.237.32.34:2068240 |           32 | 0.000724692 |       0.97 |   0.00302834 | 0.00209437 |     6.34247e-06 |                   27 |\n",
      "| train_model2_a0ce0_00073 | PENDING    |                       |           32 | 1.60386e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00074 | PENDING    |                       |            8 | 1.07675e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00075 | PENDING    |                       |            8 | 0.000155695 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00076 | PENDING    |                       |            8 | 0.000121325 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00077 | PENDING    |                       |           32 | 0.000101436 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00078 | PENDING    |                       |           32 | 4.13924e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00079 | PENDING    |                       |           16 | 0.000144137 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0116887  | 0.0042548  |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (9 RUNNING, 50 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:30:36 (running for 00:01:32.48)\n",
      "Using AsyncHyperBand: num_stopped=57\n",
      "Bracket: Iter 40.000: -2.3869599465884567e-05 | Iter 20.000: -0.0006579931946046035 | Iter 10.000: -0.3812345506889143 | Iter 5.000: -0.5975301220296737\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (7 PENDING, 16 RUNNING, 57 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00037 | RUNNING    | 169.237.32.34:2012982 |            8 | 0.000603897 |       0.93 |   0.00325351 | 0.00234287 |     7.62256e-06 |                   34 |\n",
      "| train_model2_a0ce0_00043 | RUNNING    | 169.237.32.34:2037183 |           16 | 6.61162e-05 |       0.97 |   0.0191528  | 0.00783401 |     0.000150043 |                   39 |\n",
      "| train_model2_a0ce0_00045 | RUNNING    | 169.237.32.34:2042089 |           16 | 0.000642209 |       0.95 |   0.00326544 | 0.00304965 |     9.95844e-06 |                   38 |\n",
      "| train_model2_a0ce0_00046 | RUNNING    | 169.237.32.34:2042091 |            8 | 0.000345374 |       0.97 |   0.00330794 | 0.00427954 |     1.41565e-05 |                   28 |\n",
      "| train_model2_a0ce0_00050 | RUNNING    | 169.237.32.34:2057655 |            8 | 0.000220657 |       0.97 |   0.00929151 | 0.00131318 |     1.22015e-05 |                   23 |\n",
      "| train_model2_a0ce0_00054 | RUNNING    | 169.237.32.34:2068218 |           32 | 0.000367593 |       0.97 |   0.00840773 | 0.00598874 |     5.03517e-05 |                   31 |\n",
      "| train_model2_a0ce0_00056 | RUNNING    | 169.237.32.34:2068240 |           32 | 0.000724692 |       0.97 |   0.00268538 | 0.00218744 |     5.87411e-06 |                   32 |\n",
      "| train_model2_a0ce0_00073 | PENDING    |                       |           32 | 1.60386e-05 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00074 | PENDING    |                       |            8 | 1.07675e-05 |       0.93 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00075 | PENDING    |                       |            8 | 0.000155695 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00076 | PENDING    |                       |            8 | 0.000121325 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00077 | PENDING    |                       |           32 | 0.000101436 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00078 | PENDING    |                       |           32 | 4.13924e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00079 | PENDING    |                       |           16 | 0.000144137 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0116887  | 0.0042548  |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (9 RUNNING, 50 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:30:41 (running for 00:01:37.52)\n",
      "Using AsyncHyperBand: num_stopped=60\n",
      "Bracket: Iter 40.000: -2.3869599465884567e-05 | Iter 20.000: -0.0006579931946046035 | Iter 10.000: -0.3727130426909318 | Iter 5.000: -0.5924433461199354\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (4 PENDING, 16 RUNNING, 60 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00037 | RUNNING    | 169.237.32.34:2012982 |            8 | 0.000603897 |       0.93 |   0.0029979  | 0.00268092 |     8.03711e-06 |                   37 |\n",
      "| train_model2_a0ce0_00046 | RUNNING    | 169.237.32.34:2042091 |            8 | 0.000345374 |       0.97 |   0.00354608 | 0.00314096 |     1.11381e-05 |                   31 |\n",
      "| train_model2_a0ce0_00050 | RUNNING    | 169.237.32.34:2057655 |            8 | 0.000220657 |       0.97 |   0.00691215 | 0.00126386 |     8.73595e-06 |                   26 |\n",
      "| train_model2_a0ce0_00054 | RUNNING    | 169.237.32.34:2068218 |           32 | 0.000367593 |       0.97 |   0.00724544 | 0.00452597 |     3.27926e-05 |                   36 |\n",
      "| train_model2_a0ce0_00056 | RUNNING    | 169.237.32.34:2068240 |           32 | 0.000724692 |       0.97 |   0.00225996 | 0.00152683 |     3.45057e-06 |                   37 |\n",
      "| train_model2_a0ce0_00060 | RUNNING    | 169.237.32.34:2092503 |            8 | 0.000214237 |       0.93 |   0.00819757 | 0.010349   |     8.48367e-05 |                   17 |\n",
      "| train_model2_a0ce0_00062 | RUNNING    | 169.237.32.34:2098484 |           16 | 0.000258236 |       0.97 |   0.0343718  | 0.0140043  |     0.000481352 |                   20 |\n",
      "| train_model2_a0ce0_00066 | RUNNING    | 169.237.32.34:2110107 |           16 | 0.000776199 |       0.93 |   0.668977   | 0.383718   |     0.256699    |                   19 |\n",
      "| train_model2_a0ce0_00076 | PENDING    |                       |            8 | 0.000121325 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00077 | PENDING    |                       |           32 | 0.000101436 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00078 | PENDING    |                       |           32 | 4.13924e-05 |       0.97 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00079 | PENDING    |                       |           16 | 0.000144137 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0116887  | 0.0042548  |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "| train_model2_a0ce0_00007 | TERMINATED | 169.237.32.34:1924882 |            8 | 6.57914e-05 |       0.93 |   1.00283    | 0.704264   |     0.70626     |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (8 RUNNING, 52 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:30:46 (running for 00:01:42.60)\n",
      "Using AsyncHyperBand: num_stopped=64\n",
      "Bracket: Iter 40.000: -1.7347894395973673e-05 | Iter 20.000: -0.0005696726276403319 | Iter 10.000: -0.30569425216123935 | Iter 5.000: -0.5924433461199354\n",
      "Logical resource usage: 60.0/64 CPUs, 0.7500000000000001/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (1 PENDING, 15 RUNNING, 64 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00046 | RUNNING    | 169.237.32.34:2042091 |            8 | 0.000345374 |       0.97 |   0.00304841 | 0.00277838 |     8.46965e-06 |                   34 |\n",
      "| train_model2_a0ce0_00050 | RUNNING    | 169.237.32.34:2057655 |            8 | 0.000220657 |       0.97 |   0.00473835 | 0.00160751 |     7.61694e-06 |                   29 |\n",
      "| train_model2_a0ce0_00060 | RUNNING    | 169.237.32.34:2092503 |            8 | 0.000214237 |       0.93 |   0.00656437 | 0.00717782 |     4.71179e-05 |                   20 |\n",
      "| train_model2_a0ce0_00062 | RUNNING    | 169.237.32.34:2098484 |           16 | 0.000258236 |       0.97 |   0.0339865  | 0.0129964  |     0.000441702 |                   23 |\n",
      "| train_model2_a0ce0_00067 | RUNNING    | 169.237.32.34:2115457 |           16 | 0.000423067 |       0.97 |   0.0169923  | 0.00621737 |     0.000105647 |                   23 |\n",
      "| train_model2_a0ce0_00069 | RUNNING    | 169.237.32.34:2136264 |           32 | 0.000401711 |       0.95 |   0.0747414  | 0.058482   |     0.00437103  |                   15 |\n",
      "| train_model2_a0ce0_00070 | RUNNING    | 169.237.32.34:2142547 |           16 | 0.000149719 |       0.93 |   0.6276     | 0.251159   |     0.157627    |                   12 |\n",
      "| train_model2_a0ce0_00071 | RUNNING    | 169.237.32.34:2158022 |           16 | 0.000379062 |       0.95 |   0.035793   | 0.00925329 |     0.000331203 |                   10 |\n",
      "| train_model2_a0ce0_00072 | RUNNING    | 169.237.32.34:2158025 |           16 | 0.000241282 |       0.97 |   0.195928   | 0.0729945  |     0.0143017   |                   10 |\n",
      "| train_model2_a0ce0_00073 | RUNNING    | 169.237.32.34:2183313 |           32 | 1.60386e-05 |       0.95 |   1.03214    | 0.449838   |     0.464295    |                    4 |\n",
      "| train_model2_a0ce0_00079 | PENDING    |                       |           16 | 0.000144137 |       0.95 |              |            |                 |                      |\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0116887  | 0.0042548  |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "| train_model2_a0ce0_00007 | TERMINATED | 169.237.32.34:1924882 |            8 | 6.57914e-05 |       0.93 |   1.00283    | 0.704264   |     0.70626     |                    5 |\n",
      "| train_model2_a0ce0_00008 | TERMINATED | 169.237.32.34:1924884 |           32 | 5.07391e-05 |       0.95 |   1.20425    | 1.13648    |     1.3686      |                    5 |\n",
      "| train_model2_a0ce0_00009 | TERMINATED | 169.237.32.34:1924886 |            8 | 2.37206e-05 |       0.93 |   0.901644   | 0.674859   |     0.608483    |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (5 RUNNING, 54 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:30:51 (running for 00:01:47.83)\n",
      "Using AsyncHyperBand: num_stopped=64\n",
      "Bracket: Iter 40.000: -1.7347894395973673e-05 | Iter 20.000: -0.0004813520606760601 | Iter 10.000: -0.30569425216123935 | Iter 5.000: -0.5906990660571876\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (16 RUNNING, 64 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00046 | RUNNING    | 169.237.32.34:2042091 |            8 | 0.000345374 |       0.97 |   0.00279759 | 0.00371099 |     1.03818e-05 |                   38 |\n",
      "| train_model2_a0ce0_00050 | RUNNING    | 169.237.32.34:2057655 |            8 | 0.000220657 |       0.97 |   0.00321761 | 0.00116099 |     3.7356e-06  |                   32 |\n",
      "| train_model2_a0ce0_00060 | RUNNING    | 169.237.32.34:2092503 |            8 | 0.000214237 |       0.93 |   0.00557828 | 0.00547653 |     3.05496e-05 |                   23 |\n",
      "| train_model2_a0ce0_00062 | RUNNING    | 169.237.32.34:2098484 |           16 | 0.000258236 |       0.97 |   0.0336216  | 0.0133664  |     0.000449401 |                   27 |\n",
      "| train_model2_a0ce0_00067 | RUNNING    | 169.237.32.34:2115457 |           16 | 0.000423067 |       0.97 |   0.0155047  | 0.00148698 |     2.30552e-05 |                   27 |\n",
      "| train_model2_a0ce0_00069 | RUNNING    | 169.237.32.34:2136264 |           32 | 0.000401711 |       0.95 |   0.0176275  | 0.0186574  |     0.000328884 |                   20 |\n",
      "| train_model2_a0ce0_00070 | RUNNING    | 169.237.32.34:2142547 |           16 | 0.000149719 |       0.93 |   0.291199   | 0.0561777  |     0.0163589   |                   17 |\n",
      "| train_model2_a0ce0_00071 | RUNNING    | 169.237.32.34:2158022 |           16 | 0.000379062 |       0.95 |   0.0175989  | 0.00419853 |     7.38896e-05 |                   15 |\n",
      "| train_model2_a0ce0_00072 | RUNNING    | 169.237.32.34:2158025 |           16 | 0.000241282 |       0.97 |   0.0633749  | 0.00521676 |     0.000330612 |                   15 |\n",
      "| train_model2_a0ce0_00073 | RUNNING    | 169.237.32.34:2183313 |           32 | 1.60386e-05 |       0.95 |   1.01828    | 0.465935   |     0.47445     |                    8 |\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0116887  | 0.0042548  |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "| train_model2_a0ce0_00007 | TERMINATED | 169.237.32.34:1924882 |            8 | 6.57914e-05 |       0.93 |   1.00283    | 0.704264   |     0.70626     |                    5 |\n",
      "| train_model2_a0ce0_00008 | TERMINATED | 169.237.32.34:1924884 |           32 | 5.07391e-05 |       0.95 |   1.20425    | 1.13648    |     1.3686      |                    5 |\n",
      "| train_model2_a0ce0_00009 | TERMINATED | 169.237.32.34:1924886 |            8 | 2.37206e-05 |       0.93 |   0.901644   | 0.674859   |     0.608483    |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (6 RUNNING, 54 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:30:57 (running for 00:01:52.91)\n",
      "Using AsyncHyperBand: num_stopped=69\n",
      "Bracket: Iter 40.000: -1.0826189326062778e-05 | Iter 20.000: -0.00046230078213288804 | Iter 10.000: -0.316471919975855 | Iter 5.000: -0.5868297248320185\n",
      "Logical resource usage: 44.0/64 CPUs, 0.5499999999999999/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (11 RUNNING, 69 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00050 | RUNNING    | 169.237.32.34:2057655 |            8 | 0.000220657 |       0.97 |   0.00180533 | 0.00132492 |     2.39192e-06 |                   36 |\n",
      "| train_model2_a0ce0_00060 | RUNNING    | 169.237.32.34:2092503 |            8 | 0.000214237 |       0.93 |   0.00480224 | 0.00476227 |     2.28695e-05 |                   26 |\n",
      "| train_model2_a0ce0_00062 | RUNNING    | 169.237.32.34:2098484 |           16 | 0.000258236 |       0.97 |   0.0332054  | 0.0123085  |     0.000408707 |                   31 |\n",
      "| train_model2_a0ce0_00067 | RUNNING    | 169.237.32.34:2115457 |           16 | 0.000423067 |       0.97 |   0.0142558  | 0.00184899 |     2.63587e-05 |                   32 |\n",
      "| train_model2_a0ce0_00069 | RUNNING    | 169.237.32.34:2136264 |           32 | 0.000401711 |       0.95 |   0.0107659  | 0.00951633 |     0.000102452 |                   25 |\n",
      "| train_model2_a0ce0_00071 | RUNNING    | 169.237.32.34:2158022 |           16 | 0.000379062 |       0.95 |   0.0121931  | 0.00440314 |     5.3688e-05  |                   20 |\n",
      "| train_model2_a0ce0_00072 | RUNNING    | 169.237.32.34:2158025 |           16 | 0.000241282 |       0.97 |   0.0393131  | 0.00302758 |     0.000119024 |                   20 |\n",
      "| train_model2_a0ce0_00075 | RUNNING    | 169.237.32.34:2189123 |            8 | 0.000155695 |       0.97 |   0.42753    | 0.00198874 |     0.000850248 |                    7 |\n",
      "| train_model2_a0ce0_00076 | RUNNING    | 169.237.32.34:2198212 |            8 | 0.000121325 |       0.95 |   0.700376   | 0.123706   |     0.0866408   |                    6 |\n",
      "| train_model2_a0ce0_00078 | RUNNING    | 169.237.32.34:2209342 |           32 | 4.13924e-05 |       0.97 |   0.919141   | 0.597988   |     0.549635    |                    5 |\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0116887  | 0.0042548  |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "| train_model2_a0ce0_00007 | TERMINATED | 169.237.32.34:1924882 |            8 | 6.57914e-05 |       0.93 |   1.00283    | 0.704264   |     0.70626     |                    5 |\n",
      "| train_model2_a0ce0_00008 | TERMINATED | 169.237.32.34:1924884 |           32 | 5.07391e-05 |       0.95 |   1.20425    | 1.13648    |     1.3686      |                    5 |\n",
      "| train_model2_a0ce0_00009 | TERMINATED | 169.237.32.34:1924886 |            8 | 2.37206e-05 |       0.93 |   0.901644   | 0.674859   |     0.608483    |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (1 RUNNING, 59 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:31:02 (running for 00:01:57.91)\n",
      "Using AsyncHyperBand: num_stopped=70\n",
      "Bracket: Iter 40.000: -1.0826189326062778e-05 | Iter 20.000: -0.00046230078213288804 | Iter 10.000: -0.29491658434662366 | Iter 5.000: -0.5868297248320185\n",
      "Logical resource usage: 40.0/64 CPUs, 0.49999999999999994/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (10 RUNNING, 70 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00050 | RUNNING    | 169.237.32.34:2057655 |            8 | 0.000220657 |       0.97 |   0.00132025 | 0.00130169 |     1.71855e-06 |                   39 |\n",
      "| train_model2_a0ce0_00060 | RUNNING    | 169.237.32.34:2092503 |            8 | 0.000214237 |       0.93 |   0.00392501 | 0.00375882 |     1.47534e-05 |                   30 |\n",
      "| train_model2_a0ce0_00062 | RUNNING    | 169.237.32.34:2098484 |           16 | 0.000258236 |       0.97 |   0.0328227  | 0.0116203  |     0.000381409 |                   36 |\n",
      "| train_model2_a0ce0_00067 | RUNNING    | 169.237.32.34:2115457 |           16 | 0.000423067 |       0.97 |   0.0127265  | 0.00224241 |     2.85379e-05 |                   38 |\n",
      "| train_model2_a0ce0_00069 | RUNNING    | 169.237.32.34:2136264 |           32 | 0.000401711 |       0.95 |   0.00859758 | 0.00702592 |     6.04059e-05 |                   29 |\n",
      "| train_model2_a0ce0_00071 | RUNNING    | 169.237.32.34:2158022 |           16 | 0.000379062 |       0.95 |   0.00871788 | 0.00187256 |     1.63247e-05 |                   25 |\n",
      "| train_model2_a0ce0_00072 | RUNNING    | 169.237.32.34:2158025 |           16 | 0.000241282 |       0.97 |   0.031101   | 0.00271229 |     8.4355e-05  |                   25 |\n",
      "| train_model2_a0ce0_00075 | RUNNING    | 169.237.32.34:2189123 |            8 | 0.000155695 |       0.97 |   0.419457   | 0.00320556 |     0.00134459  |                   11 |\n",
      "| train_model2_a0ce0_00076 | RUNNING    | 169.237.32.34:2198212 |            8 | 0.000121325 |       0.95 |   0.0658005  | 0.0357332  |     0.00235127  |                   10 |\n",
      "| train_model2_a0ce0_00079 | RUNNING    | 169.237.32.34:2209344 |           16 | 0.000144137 |       0.95 |   0.698297   | 0.416347   |     0.290734    |                   11 |\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0116887  | 0.0042548  |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "| train_model2_a0ce0_00007 | TERMINATED | 169.237.32.34:1924882 |            8 | 6.57914e-05 |       0.93 |   1.00283    | 0.704264   |     0.70626     |                    5 |\n",
      "| train_model2_a0ce0_00008 | TERMINATED | 169.237.32.34:1924884 |           32 | 5.07391e-05 |       0.95 |   1.20425    | 1.13648    |     1.3686      |                    5 |\n",
      "| train_model2_a0ce0_00009 | TERMINATED | 169.237.32.34:1924886 |            8 | 2.37206e-05 |       0.93 |   0.901644   | 0.674859   |     0.608483    |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (60 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:31:07 (running for 00:02:02.99)\n",
      "Using AsyncHyperBand: num_stopped=73\n",
      "Bracket: Iter 40.000: -1.7347894395973673e-05 | Iter 20.000: -0.00046230078213288804 | Iter 10.000: -0.29491658434662366 | Iter 5.000: -0.5868297248320185\n",
      "Logical resource usage: 28.0/64 CPUs, 0.35/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (7 RUNNING, 73 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00060 | RUNNING    | 169.237.32.34:2092503 |            8 | 0.000214237 |       0.93 |   0.00344692 | 0.00323459 |     1.11494e-05 |                   34 |\n",
      "| train_model2_a0ce0_00069 | RUNNING    | 169.237.32.34:2136264 |           32 | 0.000401711 |       0.95 |   0.00645045 | 0.00484612 |     3.12596e-05 |                   35 |\n",
      "| train_model2_a0ce0_00071 | RUNNING    | 169.237.32.34:2158022 |           16 | 0.000379062 |       0.95 |   0.00615708 | 0.00159143 |     9.79854e-06 |                   31 |\n",
      "| train_model2_a0ce0_00072 | RUNNING    | 169.237.32.34:2158025 |           16 | 0.000241282 |       0.97 |   0.0273014  | 0.003246   |     8.86205e-05 |                   32 |\n",
      "| train_model2_a0ce0_00075 | RUNNING    | 169.237.32.34:2189123 |            8 | 0.000155695 |       0.97 |   0.418735   | 0.00281054 |     0.00117687  |                   16 |\n",
      "| train_model2_a0ce0_00076 | RUNNING    | 169.237.32.34:2198212 |            8 | 0.000121325 |       0.95 |   0.0419569  | 0.0233204  |     0.000978451 |                   14 |\n",
      "| train_model2_a0ce0_00079 | RUNNING    | 169.237.32.34:2209344 |           16 | 0.000144137 |       0.95 |   0.673803   | 0.393816   |     0.265354    |                   17 |\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0116887  | 0.0042548  |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "| train_model2_a0ce0_00007 | TERMINATED | 169.237.32.34:1924882 |            8 | 6.57914e-05 |       0.93 |   1.00283    | 0.704264   |     0.70626     |                    5 |\n",
      "| train_model2_a0ce0_00008 | TERMINATED | 169.237.32.34:1924884 |           32 | 5.07391e-05 |       0.95 |   1.20425    | 1.13648    |     1.3686      |                    5 |\n",
      "| train_model2_a0ce0_00009 | TERMINATED | 169.237.32.34:1924886 |            8 | 2.37206e-05 |       0.93 |   0.901644   | 0.674859   |     0.608483    |                    5 |\n",
      "| train_model2_a0ce0_00010 | TERMINATED | 169.237.32.34:1924890 |           32 | 0.000434028 |       0.95 |   0.00480079 | 0.00225509 |     1.08262e-05 |                   40 |\n",
      "| train_model2_a0ce0_00011 | TERMINATED | 169.237.32.34:1924892 |           16 | 7.77073e-05 |       0.95 |   0.843855   | 0.512103   |     0.432141    |                   10 |\n",
      "| train_model2_a0ce0_00012 | TERMINATED | 169.237.32.34:1924895 |           32 | 0.000299947 |       0.95 |   0.991092   | 0.609855   |     0.604422    |                    5 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (60 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-09 14:31:12 (running for 00:02:08.12)\n",
      "Using AsyncHyperBand: num_stopped=77\n",
      "Bracket: Iter 40.000: -2.1805876285351426e-05 | Iter 20.000: -0.0005899211907821408 | Iter 10.000: -0.29491658434662366 | Iter 5.000: -0.5868297248320185\n",
      "Logical resource usage: 12.0/64 CPUs, 0.15000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (3 RUNNING, 77 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00060 | RUNNING    | 169.237.32.34:2092503 |            8 | 0.000214237 |       0.93 |   0.00292072 | 0.00270105 |     7.88903e-06 |                   39 |\n",
      "| train_model2_a0ce0_00071 | RUNNING    | 169.237.32.34:2158022 |           16 | 0.000379062 |       0.95 |   0.00432954 | 0.00122535 |     5.3052e-06  |                   38 |\n",
      "| train_model2_a0ce0_00072 | RUNNING    | 169.237.32.34:2158025 |           16 | 0.000241282 |       0.97 |   0.0251508  | 0.00338086 |     8.50312e-05 |                   39 |\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0116887  | 0.0042548  |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "| train_model2_a0ce0_00007 | TERMINATED | 169.237.32.34:1924882 |            8 | 6.57914e-05 |       0.93 |   1.00283    | 0.704264   |     0.70626     |                    5 |\n",
      "| train_model2_a0ce0_00008 | TERMINATED | 169.237.32.34:1924884 |           32 | 5.07391e-05 |       0.95 |   1.20425    | 1.13648    |     1.3686      |                    5 |\n",
      "| train_model2_a0ce0_00009 | TERMINATED | 169.237.32.34:1924886 |            8 | 2.37206e-05 |       0.93 |   0.901644   | 0.674859   |     0.608483    |                    5 |\n",
      "| train_model2_a0ce0_00010 | TERMINATED | 169.237.32.34:1924890 |           32 | 0.000434028 |       0.95 |   0.00480079 | 0.00225509 |     1.08262e-05 |                   40 |\n",
      "| train_model2_a0ce0_00011 | TERMINATED | 169.237.32.34:1924892 |           16 | 7.77073e-05 |       0.95 |   0.843855   | 0.512103   |     0.432141    |                   10 |\n",
      "| train_model2_a0ce0_00012 | TERMINATED | 169.237.32.34:1924895 |           32 | 0.000299947 |       0.95 |   0.991092   | 0.609855   |     0.604422    |                    5 |\n",
      "| train_model2_a0ce0_00013 | TERMINATED | 169.237.32.34:1924898 |           32 | 0.000453723 |       0.97 |   0.0114256  | 0.00208913 |     2.38696e-05 |                   40 |\n",
      "| train_model2_a0ce0_00014 | TERMINATED | 169.237.32.34:1924901 |            8 | 8.31202e-05 |       0.97 |   1.00937    | 0.61782    |     0.62361     |                    5 |\n",
      "| train_model2_a0ce0_00015 | TERMINATED | 169.237.32.34:1924903 |           16 | 2.54844e-05 |       0.95 |   1.0993     | 0.98684    |     1.08483     |                    5 |\n",
      "| train_model2_a0ce0_00016 | TERMINATED | 169.237.32.34:1949271 |            8 | 1.27965e-05 |       0.95 |   0.874972   | 0.449941   |     0.393685    |                   20 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "... 60 more trials not shown (60 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-09 14:31:12,989\tINFO tune.py:945 -- Total run time: 128.85 seconds (128.81 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-09 14:31:12 (running for 00:02:08.82)\n",
      "Using AsyncHyperBand: num_stopped=80\n",
      "Bracket: Iter 40.000: -1.6316032805707103e-05 | Iter 20.000: -0.0005899211907821408 | Iter 10.000: -0.29491658434662366 | Iter 5.000: -0.5868297248320185\n",
      "Logical resource usage: 0/64 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-09_14-29-04\n",
      "Number of trials: 80/80 (80 TERMINATED)\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                   |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_a0ce0_00000 | TERMINATED | 169.237.32.34:1924780 |           32 | 0.000217277 |       0.97 |   0.0116887  | 0.0042548  |     4.97331e-05 |                   40 |\n",
      "| train_model2_a0ce0_00001 | TERMINATED | 169.237.32.34:1924860 |            8 | 1.77635e-05 |       0.95 |   0.974314   | 0.57139    |     0.556714    |                   10 |\n",
      "| train_model2_a0ce0_00002 | TERMINATED | 169.237.32.34:1924862 |           16 | 0.000520092 |       0.93 |   0.0321841  | 0.0204447  |     0.000657993 |                   20 |\n",
      "| train_model2_a0ce0_00003 | TERMINATED | 169.237.32.34:1924866 |           16 | 3.47276e-05 |       0.93 |   1.04177    | 1.12478    |     1.17177     |                    5 |\n",
      "| train_model2_a0ce0_00004 | TERMINATED | 169.237.32.34:1924871 |           32 | 1.99195e-05 |       0.97 |   0.900003   | 0.574291   |     0.516864    |                   10 |\n",
      "| train_model2_a0ce0_00005 | TERMINATED | 169.237.32.34:1924873 |           32 | 4.30683e-05 |       0.97 |   0.844946   | 0.457386   |     0.386466    |                   20 |\n",
      "| train_model2_a0ce0_00006 | TERMINATED | 169.237.32.34:1924880 |           32 | 9.64281e-05 |       0.95 |   0.932132   | 0.753353   |     0.702224    |                    5 |\n",
      "| train_model2_a0ce0_00007 | TERMINATED | 169.237.32.34:1924882 |            8 | 6.57914e-05 |       0.93 |   1.00283    | 0.704264   |     0.70626     |                    5 |\n",
      "| train_model2_a0ce0_00008 | TERMINATED | 169.237.32.34:1924884 |           32 | 5.07391e-05 |       0.95 |   1.20425    | 1.13648    |     1.3686      |                    5 |\n",
      "| train_model2_a0ce0_00009 | TERMINATED | 169.237.32.34:1924886 |            8 | 2.37206e-05 |       0.93 |   0.901644   | 0.674859   |     0.608483    |                    5 |\n",
      "| train_model2_a0ce0_00010 | TERMINATED | 169.237.32.34:1924890 |           32 | 0.000434028 |       0.95 |   0.00480079 | 0.00225509 |     1.08262e-05 |                   40 |\n",
      "| train_model2_a0ce0_00011 | TERMINATED | 169.237.32.34:1924892 |           16 | 7.77073e-05 |       0.95 |   0.843855   | 0.512103   |     0.432141    |                   10 |\n",
      "| train_model2_a0ce0_00012 | TERMINATED | 169.237.32.34:1924895 |           32 | 0.000299947 |       0.95 |   0.991092   | 0.609855   |     0.604422    |                    5 |\n",
      "| train_model2_a0ce0_00013 | TERMINATED | 169.237.32.34:1924898 |           32 | 0.000453723 |       0.97 |   0.0114256  | 0.00208913 |     2.38696e-05 |                   40 |\n",
      "| train_model2_a0ce0_00014 | TERMINATED | 169.237.32.34:1924901 |            8 | 8.31202e-05 |       0.97 |   1.00937    | 0.61782    |     0.62361     |                    5 |\n",
      "| train_model2_a0ce0_00015 | TERMINATED | 169.237.32.34:1924903 |           16 | 2.54844e-05 |       0.95 |   1.0993     | 0.98684    |     1.08483     |                    5 |\n",
      "| train_model2_a0ce0_00016 | TERMINATED | 169.237.32.34:1949271 |            8 | 1.27965e-05 |       0.95 |   0.874972   | 0.449941   |     0.393685    |                   20 |\n",
      "| train_model2_a0ce0_00017 | TERMINATED | 169.237.32.34:1949274 |           32 | 0.000583307 |       0.93 |   0.84881    | 0.727793   |     0.617758    |                    5 |\n",
      "| train_model2_a0ce0_00018 | TERMINATED | 169.237.32.34:1949277 |           32 | 1.72815e-05 |       0.95 |   1.02091    | 0.652579   |     0.666223    |                    5 |\n",
      "| train_model2_a0ce0_00019 | TERMINATED | 169.237.32.34:1955179 |           32 | 3.48382e-05 |       0.97 |   0.801757   | 0.676114   |     0.542079    |                   10 |\n",
      "| train_model2_a0ce0_00020 | TERMINATED | 169.237.32.34:1955192 |           16 | 0.000170954 |       0.95 |   0.124043   | 0.218971   |     0.0271618   |                   20 |\n",
      "| train_model2_a0ce0_00021 | TERMINATED | 169.237.32.34:1955195 |           32 | 6.04538e-05 |       0.95 |   1.10053    | 1.08877    |     1.19822     |                    5 |\n",
      "| train_model2_a0ce0_00022 | TERMINATED | 169.237.32.34:1955198 |           32 | 0.000426472 |       0.93 |   0.992874   | 0.689856   |     0.68494     |                    5 |\n",
      "| train_model2_a0ce0_00023 | TERMINATED | 169.237.32.34:1955264 |           16 | 2.30102e-05 |       0.93 |   1.13389    | 0.766681   |     0.869332    |                    5 |\n",
      "| train_model2_a0ce0_00024 | TERMINATED | 169.237.32.34:1960222 |            8 | 7.11999e-05 |       0.93 |   1.03064    | 0.745576   |     0.768419    |                    5 |\n",
      "| train_model2_a0ce0_00025 | TERMINATED | 169.237.32.34:1965380 |           32 | 1.10936e-05 |       0.95 |   1.03792    | 0.394764   |     0.409734    |                   20 |\n",
      "| train_model2_a0ce0_00026 | TERMINATED | 169.237.32.34:1974363 |           32 | 1.26883e-05 |       0.95 |   1.0997     | 1.04191    |     1.14579     |                    5 |\n",
      "| train_model2_a0ce0_00027 | TERMINATED | 169.237.32.34:1980681 |           16 | 2.57492e-05 |       0.97 |   1.0658     | 0.878075   |     0.93585     |                    5 |\n",
      "| train_model2_a0ce0_00028 | TERMINATED | 169.237.32.34:1980685 |           32 | 0.000105161 |       0.97 |   0.799586   | 0.61125    |     0.488747    |                   10 |\n",
      "| train_model2_a0ce0_00029 | TERMINATED | 169.237.32.34:1987067 |           16 | 2.53975e-05 |       0.93 |   1.09669    | 1.03092    |     1.1306      |                    5 |\n",
      "| train_model2_a0ce0_00030 | TERMINATED | 169.237.32.34:1987070 |           16 | 2.17953e-05 |       0.97 |   1.09285    | 0.892804   |     0.975704    |                    5 |\n",
      "| train_model2_a0ce0_00031 | TERMINATED | 169.237.32.34:1987144 |           32 | 0.000376035 |       0.97 |   0.667431   | 0.39133    |     0.261186    |                   20 |\n",
      "| train_model2_a0ce0_00032 | TERMINATED | 169.237.32.34:1987147 |            8 | 1.48815e-05 |       0.95 |   0.940753   | 0.684859   |     0.644284    |                    5 |\n",
      "| train_model2_a0ce0_00033 | TERMINATED | 169.237.32.34:1995217 |           32 | 2.3932e-05  |       0.97 |   1.03688    | 0.678188   |     0.703199    |                    5 |\n",
      "| train_model2_a0ce0_00034 | TERMINATED | 169.237.32.34:1995219 |           16 | 0.000134044 |       0.97 |   0.658871   | 0.396305   |     0.261114    |                   20 |\n",
      "| train_model2_a0ce0_00035 | TERMINATED | 169.237.32.34:2000701 |           32 | 1.37486e-05 |       0.95 |   0.964956   | 0.520476   |     0.502237    |                   10 |\n",
      "| train_model2_a0ce0_00036 | TERMINATED | 169.237.32.34:2006620 |            8 | 1.26101e-05 |       0.97 |   0.964114   | 0.497705   |     0.479844    |                   10 |\n",
      "| train_model2_a0ce0_00037 | TERMINATED | 169.237.32.34:2012982 |            8 | 0.000603897 |       0.93 |   0.00263733 | 0.00198224 |     5.22781e-06 |                   40 |\n",
      "| train_model2_a0ce0_00038 | TERMINATED | 169.237.32.34:2022672 |           16 | 2.74947e-05 |       0.95 |   0.887285   | 0.654344   |     0.58059     |                   10 |\n",
      "| train_model2_a0ce0_00039 | TERMINATED | 169.237.32.34:2022674 |            8 | 8.75715e-05 |       0.95 |   1.01275    | 0.624664   |     0.63263     |                    5 |\n",
      "| train_model2_a0ce0_00040 | TERMINATED | 169.237.32.34:2028468 |           16 | 4.13506e-05 |       0.95 |   1.00019    | 0.683234   |     0.68336     |                    5 |\n",
      "| train_model2_a0ce0_00041 | TERMINATED | 169.237.32.34:2028471 |           16 | 2.85459e-05 |       0.95 |   0.898803   | 0.447317   |     0.40205     |                   20 |\n",
      "| train_model2_a0ce0_00042 | TERMINATED | 169.237.32.34:2028473 |           16 | 3.06588e-05 |       0.97 |   0.710659   | 0.723985   |     0.514506    |                   10 |\n",
      "| train_model2_a0ce0_00043 | TERMINATED | 169.237.32.34:2037183 |           16 | 6.61162e-05 |       0.97 |   0.0177542  | 0.00759419 |     0.000134829 |                   40 |\n",
      "| train_model2_a0ce0_00044 | TERMINATED | 169.237.32.34:2042087 |           32 | 0.000775449 |       0.93 |   0.971957   | 0.794867   |     0.772577    |                    5 |\n",
      "| train_model2_a0ce0_00045 | TERMINATED | 169.237.32.34:2042089 |           16 | 0.000642209 |       0.95 |   0.0032418  | 0.00310528 |     1.00667e-05 |                   40 |\n",
      "| train_model2_a0ce0_00046 | TERMINATED | 169.237.32.34:2042091 |            8 | 0.000345374 |       0.97 |   0.00248237 | 0.00282368 |     7.00942e-06 |                   40 |\n",
      "| train_model2_a0ce0_00047 | TERMINATED | 169.237.32.34:2047196 |           32 | 1.88667e-05 |       0.97 |   1.12562    | 1.2246     |     1.37844     |                    5 |\n",
      "| train_model2_a0ce0_00048 | TERMINATED | 169.237.32.34:2047198 |           16 | 1.3861e-05  |       0.95 |   1.00053    | 0.508605   |     0.508876    |                   10 |\n",
      "| train_model2_a0ce0_00049 | TERMINATED | 169.237.32.34:2052086 |           16 | 9.14132e-05 |       0.95 |   0.849354   | 0.7407     |     0.629117    |                    5 |\n",
      "| train_model2_a0ce0_00050 | TERMINATED | 169.237.32.34:2057655 |            8 | 0.000220657 |       0.97 |   0.0012155  | 0.0012292  |     1.49409e-06 |                   40 |\n",
      "| train_model2_a0ce0_00051 | TERMINATED | 169.237.32.34:2057659 |           16 | 5.90081e-05 |       0.95 |   0.316162   | 0.235945   |     0.0745969   |                   20 |\n",
      "| train_model2_a0ce0_00052 | TERMINATED | 169.237.32.34:2057661 |            8 | 0.000180459 |       0.93 |   0.838393   | 0.735664   |     0.616776    |                    5 |\n",
      "| train_model2_a0ce0_00053 | TERMINATED | 169.237.32.34:2062845 |            8 | 0.000107708 |       0.97 |   0.930118   | 0.712801   |     0.662989    |                    5 |\n",
      "| train_model2_a0ce0_00054 | TERMINATED | 169.237.32.34:2068218 |           32 | 0.000367593 |       0.97 |   0.00693613 | 0.00397635 |     2.75805e-05 |                   40 |\n",
      "| train_model2_a0ce0_00055 | TERMINATED | 169.237.32.34:2068221 |           16 | 2.92108e-05 |       0.95 |   1.04705    | 0.812853   |     0.851094    |                    5 |\n",
      "| train_model2_a0ce0_00056 | TERMINATED | 169.237.32.34:2068240 |           32 | 0.000724692 |       0.97 |   0.00204512 | 0.00142235 |     2.90889e-06 |                   40 |\n",
      "| train_model2_a0ce0_00057 | TERMINATED | 169.237.32.34:2072995 |           32 | 0.000298038 |       0.97 |   0.7194     | 0.63806    |     0.45902     |                   10 |\n",
      "| train_model2_a0ce0_00058 | TERMINATED | 169.237.32.34:2073060 |           32 | 0.000130378 |       0.93 |   1.02823    | 0.786892   |     0.809104    |                    5 |\n",
      "| train_model2_a0ce0_00059 | TERMINATED | 169.237.32.34:2078362 |           32 | 2.82371e-05 |       0.93 |   0.995958   | 0.627582   |     0.625045    |                    5 |\n",
      "| train_model2_a0ce0_00060 | TERMINATED | 169.237.32.34:2092503 |            8 | 0.000214237 |       0.93 |   0.00281034 | 0.00255934 |     7.19261e-06 |                   40 |\n",
      "| train_model2_a0ce0_00061 | TERMINATED | 169.237.32.34:2092506 |           32 | 0.000316222 |       0.95 |   0.831321   | 0.739051   |     0.614389    |                    5 |\n",
      "| train_model2_a0ce0_00062 | TERMINATED | 169.237.32.34:2098484 |           16 | 0.000258236 |       0.97 |   0.0326895  | 0.0115051  |     0.000376095 |                   40 |\n",
      "| train_model2_a0ce0_00063 | TERMINATED | 169.237.32.34:2104550 |           32 | 0.000560877 |       0.93 |   0.0408073  | 0.0267683  |     0.00109234  |                   20 |\n",
      "| train_model2_a0ce0_00064 | TERMINATED | 169.237.32.34:2104552 |           16 | 2.89325e-05 |       0.95 |   1.00791    | 0.691658   |     0.697127    |                    5 |\n",
      "| train_model2_a0ce0_00065 | TERMINATED | 169.237.32.34:2109962 |           32 | 2.04421e-05 |       0.95 |   0.908868   | 0.715507   |     0.650302    |                   10 |\n",
      "| train_model2_a0ce0_00066 | TERMINATED | 169.237.32.34:2110107 |           16 | 0.000776199 |       0.93 |   0.668255   | 0.383179   |     0.256061    |                   20 |\n",
      "| train_model2_a0ce0_00067 | TERMINATED | 169.237.32.34:2115457 |           16 | 0.000423067 |       0.97 |   0.0122965  | 0.00206598 |     2.54043e-05 |                   40 |\n",
      "| train_model2_a0ce0_00068 | TERMINATED | 169.237.32.34:2123919 |           16 | 1.15586e-05 |       0.93 |   1.1132     | 1.17405    |     1.30695     |                    5 |\n",
      "| train_model2_a0ce0_00069 | TERMINATED | 169.237.32.34:2136264 |           32 | 0.000401711 |       0.95 |   0.00517252 | 0.00421572 |     2.18059e-05 |                   40 |\n",
      "| train_model2_a0ce0_00070 | TERMINATED | 169.237.32.34:2142547 |           16 | 0.000149719 |       0.93 |   0.191699   | 0.0203586  |     0.00390273  |                   20 |\n",
      "| train_model2_a0ce0_00071 | TERMINATED | 169.237.32.34:2158022 |           16 | 0.000379062 |       0.95 |   0.00397503 | 0.00180567 |     7.17759e-06 |                   40 |\n",
      "| train_model2_a0ce0_00072 | TERMINATED | 169.237.32.34:2158025 |           16 | 0.000241282 |       0.97 |   0.0250874  | 0.00325586 |     8.16811e-05 |                   40 |\n",
      "| train_model2_a0ce0_00073 | TERMINATED | 169.237.32.34:2183313 |           32 | 1.60386e-05 |       0.95 |   1.01137    | 0.460878   |     0.466116    |                   10 |\n",
      "| train_model2_a0ce0_00074 | TERMINATED | 169.237.32.34:2189075 |            8 | 1.07675e-05 |       0.93 |   0.912186   | 0.653875   |     0.596455    |                    5 |\n",
      "| train_model2_a0ce0_00075 | TERMINATED | 169.237.32.34:2189123 |            8 | 0.000155695 |       0.97 |   0.417619   | 0.00249448 |     0.00104174  |                   20 |\n",
      "| train_model2_a0ce0_00076 | TERMINATED | 169.237.32.34:2198212 |            8 | 0.000121325 |       0.95 |   0.0347582  | 0.0169721  |     0.000589921 |                   20 |\n",
      "| train_model2_a0ce0_00077 | TERMINATED | 169.237.32.34:2204241 |           32 | 0.000101436 |       0.95 |   1.0091     | 0.824545   |     0.832048    |                    5 |\n",
      "| train_model2_a0ce0_00078 | TERMINATED | 169.237.32.34:2209342 |           32 | 4.13924e-05 |       0.97 |   0.87394    | 0.640248   |     0.559538    |                   10 |\n",
      "| train_model2_a0ce0_00079 | TERMINATED | 169.237.32.34:2209344 |           16 | 0.000144137 |       0.95 |   0.672553   | 0.390636   |     0.262724    |                   20 |\n",
      "+--------------------------+------------+-----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "\n",
      "\n",
      "Best trial config: {'lr': 0.0002206574543783307, 'batch_size': 8, 'momentum': 0.97}\n",
      "Best trial final validation loss: 0.0012292014571164357\n",
      "Best trial final train loss: 0.0012155002423628986\n"
     ]
    }
   ],
   "source": [
    "# Hyper Parameter Search \n",
    "iteration_config = {\n",
    "    \"lr\" : tune.loguniform(1e-5, 1e-3),\n",
    "    # \"b1\" : tune.uniform(0.3, 1.0),\n",
    "    # \"b2\" : tune.uniform(0.3, 1.0),\n",
    "    \"batch_size\": tune.choice([32, 16, 8]),\n",
    "    # \"model\": tune.choice([[40, 5, 1], [40, 10, 1], [40, 5, 2, 1]]),\n",
    "    \"momentum\": tune.choice([0.93, 0.95, 0.97]),\n",
    "}\n",
    "scheduler = ASHAScheduler(metric=\"combined_loss\", mode=\"min\", max_t=40, grace_period=5, reduction_factor=2)\n",
    "reporter = CLIReporter(metric_columns=[\"train_loss\", \"val_loss\", \"combined_loss\", \"training_iteration\"])\n",
    "result = tune.run(train_model2, config=iteration_config, scheduler=scheduler, progress_reporter=reporter,\n",
    "                  num_samples=80, resources_per_trial={\"cpu\": 4, \"gpu\": 0.05},)\n",
    "\n",
    "best_trial = result.get_best_trial(\"combined_loss\", \"min\", \"last\")\n",
    "print(\"Best trial config: {}\".format(best_trial.config))\n",
    "print(\"Best trial final validation loss: {}\".format(\n",
    "    best_trial.last_result[\"val_loss\"]))\n",
    "print(\"Best trial final train loss: {}\".format(\n",
    "    best_trial.last_result[\"train_loss\"]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Best trial config: {'lr': 0.0010630834634709364, 'b1': 0.4282116859842134, 'b2': 0.3089991262211405, 'batch_size': 8, 'model': [20, 16, 8, 4, 2, 1]}\n",
    "Best trial final validation loss: 0.09234625198878348\n",
    "Best trial final train loss: 0.22368373312056064 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0002206574543783307, 'batch_size': 8, 'momentum': 0.97}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6e2452da30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train Model with the given params.\n",
    "np.random.seed(70)  # Set seed for consistentcy\n",
    "params = {\n",
    "    'batch_size': 8, 'shuffle': True, 'num_workers': 2\n",
    "}\n",
    "# params['batch_size'] = best_trial.config['batch_size']\n",
    "train, val = generate_data_loaders(data, params, x_columns, y_columns, model_config['train_split'])\n",
    "model = model_config['model_class'](*model_config['model_params'])\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.HuberLoss()\n",
    "# optimizer = Adam(model.parameters(), lr=0.0009, betas=[0.935, 0.701])\n",
    "# optimizer = SGD(model.parameters(), lr=0.00030, momentum=0.95)\n",
    "optimizer = SGD(model.parameters(), lr=best_trial.config['lr'], momentum=best_trial.config['momentum'])\n",
    "# CUDA_VISIBLE is already set to only see one GPU\n",
    "train_loss, validation_loss = train_model(model, optimizer, criterion, train, val, epochs=50, gpu_to_use=0)\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label='Training Loss', marker='x')\n",
    "plt.plot(validation_loss, label='Validation Loss', marker='x')\n",
    "# plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    x_data = torch.tensor(data[x_columns].values, dtype=torch.float).cuda()\n",
    "    predictions = model(x_data)\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    predictions = y_scaler.inverse_transform(predictions).flatten()\n",
    "    y_data = data[y_columns].to_numpy()\n",
    "    y_data = y_scaler.inverse_transform(y_data).flatten()\n",
    "    absolute_error = np.abs(y_data - predictions)\n",
    "    error_df = pd.DataFrame({'Truth': y_data, \"Predicted\": predictions, \"Absolute Error\": absolute_error, \"%tage\": absolute_error/y_data * 100})\n",
    "plt.figure()\n",
    "error_df['%tage'].plot.hist(bins=20)\n",
    "plt.xlabel('(%) Error')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Maternal Hb Concentration</th>\n",
       "      <th>Maternal Saturation</th>\n",
       "      <th>Fetal Hb Concentration</th>\n",
       "      <th>Fetal Saturation</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Absolute Error</th>\n",
       "      <th>%tage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.245877</td>\n",
       "      <td>0.754123</td>\n",
       "      <td>4.713267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.225</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.263054</td>\n",
       "      <td>0.736946</td>\n",
       "      <td>4.605913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.268040</td>\n",
       "      <td>0.731960</td>\n",
       "      <td>4.574752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.350</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.270506</td>\n",
       "      <td>0.729494</td>\n",
       "      <td>4.559338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.475</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.277618</td>\n",
       "      <td>0.722382</td>\n",
       "      <td>4.514885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.600</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.281198</td>\n",
       "      <td>0.718802</td>\n",
       "      <td>4.492515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.288612</td>\n",
       "      <td>0.711388</td>\n",
       "      <td>4.446173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.225</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.290134</td>\n",
       "      <td>0.709866</td>\n",
       "      <td>4.436660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.304634</td>\n",
       "      <td>0.695366</td>\n",
       "      <td>4.346037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.350</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.310822</td>\n",
       "      <td>0.689178</td>\n",
       "      <td>4.307365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.225</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.311640</td>\n",
       "      <td>0.688360</td>\n",
       "      <td>4.302251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.475</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.318253</td>\n",
       "      <td>0.681747</td>\n",
       "      <td>4.260921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.318705</td>\n",
       "      <td>0.681295</td>\n",
       "      <td>4.258096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.325079</td>\n",
       "      <td>0.674921</td>\n",
       "      <td>4.218256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.600</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.325290</td>\n",
       "      <td>0.674710</td>\n",
       "      <td>4.216939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.225</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.331624</td>\n",
       "      <td>0.668376</td>\n",
       "      <td>4.177350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.350</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.335280</td>\n",
       "      <td>0.664720</td>\n",
       "      <td>4.154497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.344773</td>\n",
       "      <td>0.655227</td>\n",
       "      <td>4.095167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.225</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.346922</td>\n",
       "      <td>0.653078</td>\n",
       "      <td>4.081738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.225</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.347420</td>\n",
       "      <td>0.652580</td>\n",
       "      <td>4.078627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.475</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.355860</td>\n",
       "      <td>0.644140</td>\n",
       "      <td>4.025877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.350</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.356121</td>\n",
       "      <td>0.643879</td>\n",
       "      <td>4.024243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.360565</td>\n",
       "      <td>0.639435</td>\n",
       "      <td>3.996468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.600</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.363128</td>\n",
       "      <td>0.636872</td>\n",
       "      <td>3.980452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.350</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.368449</td>\n",
       "      <td>0.631551</td>\n",
       "      <td>3.947192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.225</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.370070</td>\n",
       "      <td>0.629930</td>\n",
       "      <td>3.937066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.375358</td>\n",
       "      <td>0.624642</td>\n",
       "      <td>3.904015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.350</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.375584</td>\n",
       "      <td>0.624416</td>\n",
       "      <td>3.902602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.475</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.381455</td>\n",
       "      <td>0.618545</td>\n",
       "      <td>3.865904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.225</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.388969</td>\n",
       "      <td>0.611031</td>\n",
       "      <td>3.818941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.475</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.389143</td>\n",
       "      <td>0.610857</td>\n",
       "      <td>3.817856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.390354</td>\n",
       "      <td>0.609646</td>\n",
       "      <td>3.810287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.350</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.392909</td>\n",
       "      <td>0.607091</td>\n",
       "      <td>3.794318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.393304</td>\n",
       "      <td>0.606696</td>\n",
       "      <td>3.791851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.600</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.398307</td>\n",
       "      <td>0.601693</td>\n",
       "      <td>3.760582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.600</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.400640</td>\n",
       "      <td>0.599360</td>\n",
       "      <td>3.746003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.475</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.401647</td>\n",
       "      <td>0.598353</td>\n",
       "      <td>3.739709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.225</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.404693</td>\n",
       "      <td>0.595307</td>\n",
       "      <td>3.720671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.412455</td>\n",
       "      <td>0.587545</td>\n",
       "      <td>3.672159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.350</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.415568</td>\n",
       "      <td>0.584432</td>\n",
       "      <td>3.652698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.475</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.416259</td>\n",
       "      <td>0.583741</td>\n",
       "      <td>3.648382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.225</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.417636</td>\n",
       "      <td>0.582364</td>\n",
       "      <td>3.639776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.225</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.419398</td>\n",
       "      <td>0.580602</td>\n",
       "      <td>3.628761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.600</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.428928</td>\n",
       "      <td>0.571072</td>\n",
       "      <td>3.569198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.430158</td>\n",
       "      <td>0.569842</td>\n",
       "      <td>3.561515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.350</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.435143</td>\n",
       "      <td>0.564857</td>\n",
       "      <td>3.530359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.225</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.437289</td>\n",
       "      <td>0.562711</td>\n",
       "      <td>3.516942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.600</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.437866</td>\n",
       "      <td>0.562134</td>\n",
       "      <td>3.513336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.475</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.439850</td>\n",
       "      <td>0.560150</td>\n",
       "      <td>3.500938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.350</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.440371</td>\n",
       "      <td>0.559629</td>\n",
       "      <td>3.497684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Maternal Wall Thickness  Maternal Hb Concentration  Maternal Saturation  \\\n",
       "1750                      6.0                   1.414214                0.900   \n",
       "1751                      6.0                   1.414214                0.900   \n",
       "1755                      6.0                   1.414214                0.900   \n",
       "1752                      6.0                   1.414214                0.900   \n",
       "1753                      6.0                   1.414214                0.900   \n",
       "1754                      6.0                   1.414214                0.900   \n",
       "1760                      6.0                   1.414214                0.900   \n",
       "1756                      6.0                   1.414214                0.900   \n",
       "1765                      6.0                   1.414214                0.900   \n",
       "1757                      6.0                   1.414214                0.900   \n",
       "1761                      6.0                   1.414214                0.900   \n",
       "1758                      6.0                   1.414214                0.900   \n",
       "1770                      6.0                   1.414214                0.900   \n",
       "1775                      6.0                   1.414214                0.925   \n",
       "1759                      6.0                   1.414214                0.900   \n",
       "1766                      6.0                   1.414214                0.900   \n",
       "1762                      6.0                   1.414214                0.900   \n",
       "1780                      6.0                   1.414214                0.925   \n",
       "1776                      6.0                   1.414214                0.925   \n",
       "1771                      6.0                   1.414214                0.900   \n",
       "1763                      6.0                   1.414214                0.900   \n",
       "1767                      6.0                   1.414214                0.900   \n",
       "1785                      6.0                   1.414214                0.925   \n",
       "1764                      6.0                   1.414214                0.900   \n",
       "1777                      6.0                   1.414214                0.925   \n",
       "1781                      6.0                   1.414214                0.925   \n",
       "1790                      6.0                   1.414214                0.925   \n",
       "1772                      6.0                   1.414214                0.900   \n",
       "1768                      6.0                   1.414214                0.900   \n",
       "1786                      6.0                   1.414214                0.925   \n",
       "1778                      6.0                   1.414214                0.925   \n",
       "1795                      6.0                   1.414214                0.925   \n",
       "1782                      6.0                   1.414214                0.925   \n",
       "1800                      6.0                   1.414214                0.950   \n",
       "1769                      6.0                   1.414214                0.900   \n",
       "1779                      6.0                   1.414214                0.925   \n",
       "1773                      6.0                   1.414214                0.900   \n",
       "1791                      6.0                   1.414214                0.925   \n",
       "1805                      6.0                   1.414214                0.950   \n",
       "1787                      6.0                   1.414214                0.925   \n",
       "1783                      6.0                   1.414214                0.925   \n",
       "1801                      6.0                   1.414214                0.950   \n",
       "1796                      6.0                   1.414214                0.925   \n",
       "1774                      6.0                   1.414214                0.900   \n",
       "1810                      6.0                   1.414214                0.950   \n",
       "1792                      6.0                   1.414214                0.925   \n",
       "1806                      6.0                   1.414214                0.950   \n",
       "1784                      6.0                   1.414214                0.925   \n",
       "1788                      6.0                   1.414214                0.925   \n",
       "1802                      6.0                   1.414214                0.950   \n",
       "\n",
       "      Fetal Hb Concentration  Fetal Saturation  Truth  Predicted  \\\n",
       "1750                   0.110             0.100   16.0  15.245877   \n",
       "1751                   0.110             0.225   16.0  15.263054   \n",
       "1755                   0.125             0.100   16.0  15.268040   \n",
       "1752                   0.110             0.350   16.0  15.270506   \n",
       "1753                   0.110             0.475   16.0  15.277618   \n",
       "1754                   0.110             0.600   16.0  15.281198   \n",
       "1760                   0.140             0.100   16.0  15.288612   \n",
       "1756                   0.125             0.225   16.0  15.290134   \n",
       "1765                   0.155             0.100   16.0  15.304634   \n",
       "1757                   0.125             0.350   16.0  15.310822   \n",
       "1761                   0.140             0.225   16.0  15.311640   \n",
       "1758                   0.125             0.475   16.0  15.318253   \n",
       "1770                   0.170             0.100   16.0  15.318705   \n",
       "1775                   0.110             0.100   16.0  15.325079   \n",
       "1759                   0.125             0.600   16.0  15.325290   \n",
       "1766                   0.155             0.225   16.0  15.331624   \n",
       "1762                   0.140             0.350   16.0  15.335280   \n",
       "1780                   0.125             0.100   16.0  15.344773   \n",
       "1776                   0.110             0.225   16.0  15.346922   \n",
       "1771                   0.170             0.225   16.0  15.347420   \n",
       "1763                   0.140             0.475   16.0  15.355860   \n",
       "1767                   0.155             0.350   16.0  15.356121   \n",
       "1785                   0.140             0.100   16.0  15.360565   \n",
       "1764                   0.140             0.600   16.0  15.363128   \n",
       "1777                   0.110             0.350   16.0  15.368449   \n",
       "1781                   0.125             0.225   16.0  15.370070   \n",
       "1790                   0.155             0.100   16.0  15.375358   \n",
       "1772                   0.170             0.350   16.0  15.375584   \n",
       "1768                   0.155             0.475   16.0  15.381455   \n",
       "1786                   0.140             0.225   16.0  15.388969   \n",
       "1778                   0.110             0.475   16.0  15.389143   \n",
       "1795                   0.170             0.100   16.0  15.390354   \n",
       "1782                   0.125             0.350   16.0  15.392909   \n",
       "1800                   0.110             0.100   16.0  15.393304   \n",
       "1769                   0.155             0.600   16.0  15.398307   \n",
       "1779                   0.110             0.600   16.0  15.400640   \n",
       "1773                   0.170             0.475   16.0  15.401647   \n",
       "1791                   0.155             0.225   16.0  15.404693   \n",
       "1805                   0.125             0.100   16.0  15.412455   \n",
       "1787                   0.140             0.350   16.0  15.415568   \n",
       "1783                   0.125             0.475   16.0  15.416259   \n",
       "1801                   0.110             0.225   16.0  15.417636   \n",
       "1796                   0.170             0.225   16.0  15.419398   \n",
       "1774                   0.170             0.600   16.0  15.428928   \n",
       "1810                   0.140             0.100   16.0  15.430158   \n",
       "1792                   0.155             0.350   16.0  15.435143   \n",
       "1806                   0.125             0.225   16.0  15.437289   \n",
       "1784                   0.125             0.600   16.0  15.437866   \n",
       "1788                   0.140             0.475   16.0  15.439850   \n",
       "1802                   0.110             0.350   16.0  15.440371   \n",
       "\n",
       "      Absolute Error     %tage  \n",
       "1750        0.754123  4.713267  \n",
       "1751        0.736946  4.605913  \n",
       "1755        0.731960  4.574752  \n",
       "1752        0.729494  4.559338  \n",
       "1753        0.722382  4.514885  \n",
       "1754        0.718802  4.492515  \n",
       "1760        0.711388  4.446173  \n",
       "1756        0.709866  4.436660  \n",
       "1765        0.695366  4.346037  \n",
       "1757        0.689178  4.307365  \n",
       "1761        0.688360  4.302251  \n",
       "1758        0.681747  4.260921  \n",
       "1770        0.681295  4.258096  \n",
       "1775        0.674921  4.218256  \n",
       "1759        0.674710  4.216939  \n",
       "1766        0.668376  4.177350  \n",
       "1762        0.664720  4.154497  \n",
       "1780        0.655227  4.095167  \n",
       "1776        0.653078  4.081738  \n",
       "1771        0.652580  4.078627  \n",
       "1763        0.644140  4.025877  \n",
       "1767        0.643879  4.024243  \n",
       "1785        0.639435  3.996468  \n",
       "1764        0.636872  3.980452  \n",
       "1777        0.631551  3.947192  \n",
       "1781        0.629930  3.937066  \n",
       "1790        0.624642  3.904015  \n",
       "1772        0.624416  3.902602  \n",
       "1768        0.618545  3.865904  \n",
       "1786        0.611031  3.818941  \n",
       "1778        0.610857  3.817856  \n",
       "1795        0.609646  3.810287  \n",
       "1782        0.607091  3.794318  \n",
       "1800        0.606696  3.791851  \n",
       "1769        0.601693  3.760582  \n",
       "1779        0.599360  3.746003  \n",
       "1773        0.598353  3.739709  \n",
       "1791        0.595307  3.720671  \n",
       "1805        0.587545  3.672159  \n",
       "1787        0.584432  3.652698  \n",
       "1783        0.583741  3.648382  \n",
       "1801        0.582364  3.639776  \n",
       "1796        0.580602  3.628761  \n",
       "1774        0.571072  3.569198  \n",
       "1810        0.569842  3.561515  \n",
       "1792        0.564857  3.530359  \n",
       "1806        0.562711  3.516942  \n",
       "1784        0.562134  3.513336  \n",
       "1788        0.560150  3.500938  \n",
       "1802        0.559629  3.497684  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Top Bad Samples\n",
    "VIEW_TOP_N = 50\n",
    "worst_errors = error_df['Absolute Error'].argsort()[::-1][:VIEW_TOP_N]\n",
    "combined_table = data.join(error_df)\n",
    "with pd.option_context(\"display.max_rows\", None):\n",
    "    display(combined_table[['Maternal Wall Thickness', \"Maternal Hb Concentration\", \"Maternal Saturation\", \"Fetal Hb Concentration\", \"Fetal Saturation\", 'Truth', 'Predicted', 'Absolute Error', '%tage']].iloc[worst_errors, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error(non-normalized): [0.00290239]\n",
      "Validation Error(non-normalized): [0.00352676]\n"
     ]
    }
   ],
   "source": [
    "# Rough MSE's in percentage\n",
    "print(f'Train Error(non-normalized): {train_loss[-1] * y_scaler.var_ }')\n",
    "print(f'Validation Error(non-normalized): {validation_loss[-1] * y_scaler.var_ }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "SplitChannelCNN                          --\n",
       "├─Conv1d: 1-1                            48\n",
       "├─Sequential: 1-2                        --\n",
       "│    └─Linear: 2-1                       255\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─Linear: 2-3                       4\n",
       "│    └─Flatten: 2-4                      --\n",
       "=================================================================\n",
       "Total params: 307\n",
       "Trainable params: 307\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Info\n",
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Truth', 'Predicted', 'Absolute Error', '%tage'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybercat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
