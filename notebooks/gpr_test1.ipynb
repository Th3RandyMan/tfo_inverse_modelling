{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TFO_dataset\n",
    "from math import pi\n",
    "from sklearn.gaussian_process import *\n",
    "from inverse_modelling_tfo.data.intensity_interpolation import interpolate_exp_chunk, get_interpolate_fit_params\n",
    "from inverse_modelling_tfo.data import normalize_zero_mean \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from typing import Union, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wave Int</th>\n",
       "      <th>Uterus Thickness</th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Maternal Mu_a</th>\n",
       "      <th>Fetal Mu_a</th>\n",
       "      <th>alpha0</th>\n",
       "      <th>alpha1</th>\n",
       "      <th>alpha2</th>\n",
       "      <th>alpha3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-16.959114</td>\n",
       "      <td>1.036984</td>\n",
       "      <td>-29.212411</td>\n",
       "      <td>42.008351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-18.635541</td>\n",
       "      <td>1.097803</td>\n",
       "      <td>-31.440929</td>\n",
       "      <td>45.713937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-20.161950</td>\n",
       "      <td>1.154220</td>\n",
       "      <td>-33.478903</td>\n",
       "      <td>49.096596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-16.959210</td>\n",
       "      <td>1.036986</td>\n",
       "      <td>-29.212498</td>\n",
       "      <td>42.008514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-18.635603</td>\n",
       "      <td>1.097804</td>\n",
       "      <td>-31.440986</td>\n",
       "      <td>45.714042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wave Int  Uterus Thickness  Maternal Wall Thickness  Maternal Mu_a  \\\n",
       "0       2.0               5.0                     26.0          0.005   \n",
       "1       2.0               5.0                     26.0          0.007   \n",
       "2       2.0               5.0                     26.0          0.009   \n",
       "3       2.0               5.0                     26.0          0.005   \n",
       "4       2.0               5.0                     26.0          0.007   \n",
       "\n",
       "   Fetal Mu_a     alpha0    alpha1     alpha2     alpha3  \n",
       "0        0.05 -16.959114  1.036984 -29.212411  42.008351  \n",
       "1        0.05 -18.635541  1.097803 -31.440929  45.713937  \n",
       "2        0.05 -20.161950  1.154220 -33.478903  49.096596  \n",
       "3        0.07 -16.959210  1.036986 -29.212498  42.008514  \n",
       "4        0.07 -18.635603  1.097804 -31.440986  45.714042  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data = pd.read_pickle(r'/home/rraiyan/personal_projects/tfo_inverse_modelling/data/intensity/intensity_averaged_sim_data.pkl')\n",
    "train_data = pd.read_pickle(\n",
    "    r'/home/rraiyan/personal_projects/tfo_inverse_modelling/data/intensity/intensity_summed_sim_data_equidistance_detector.pkl')\n",
    "# Only for intensity_summed_sim_data_equidistance_detector.pkl\n",
    "sdd = train_data['SDD'].to_numpy()[:20]\n",
    "detector_count = [11, 16, 22, 27, 32, 38, 43, 48, 53,\n",
    "                  59, 64, 69, 75, 80, 85, 90, 96, 101, 106, 111]\n",
    "sdd_to_detector_count_map = {\n",
    "    dist: count for dist, count in zip(sdd, detector_count)}\n",
    "train_data['Intensity'] /= train_data['SDD'].map(\n",
    "    sdd_to_detector_count_map)\n",
    "\n",
    "# For the other cases\n",
    "# train_data['Intensity'] /= 20   # Normalize by the number of detectors per ring\n",
    "\n",
    "train_data['Intensity'] /= 1e9  # Photon count/Initial intensity\n",
    "\n",
    "\n",
    "\n",
    "interpolated_training_data = get_interpolate_fit_params(\n",
    "    train_data, weights=[1, -2])\n",
    "\n",
    "interpolated_training_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wave Int</th>\n",
       "      <th>Uterus Thickness</th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Maternal Mu_a</th>\n",
       "      <th>Fetal Mu_a</th>\n",
       "      <th>alpha0</th>\n",
       "      <th>alpha1</th>\n",
       "      <th>alpha2</th>\n",
       "      <th>alpha3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>342.000000</td>\n",
       "      <td>342.0</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>342.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-21.351539</td>\n",
       "      <td>1.161318</td>\n",
       "      <td>-34.392205</td>\n",
       "      <td>50.957188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.970502</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.016354</td>\n",
       "      <td>4.335894</td>\n",
       "      <td>0.082025</td>\n",
       "      <td>4.378542</td>\n",
       "      <td>7.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-37.637443</td>\n",
       "      <td>1.023883</td>\n",
       "      <td>-50.998421</td>\n",
       "      <td>41.231932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-22.552118</td>\n",
       "      <td>1.099423</td>\n",
       "      <td>-35.704110</td>\n",
       "      <td>45.769656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-20.266092</td>\n",
       "      <td>1.154008</td>\n",
       "      <td>-33.536098</td>\n",
       "      <td>49.251434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>-18.650280</td>\n",
       "      <td>1.204571</td>\n",
       "      <td>-31.477528</td>\n",
       "      <td>52.981612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>-16.532142</td>\n",
       "      <td>1.460359</td>\n",
       "      <td>-28.776783</td>\n",
       "      <td>81.243376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Wave Int  Uterus Thickness  Maternal Wall Thickness  Maternal Mu_a  \\\n",
       "count  342.000000             342.0               342.000000     342.000000   \n",
       "mean     1.500000               5.0                20.000000       0.007000   \n",
       "std      0.500733               0.0                10.970502       0.001635   \n",
       "min      1.000000               5.0                 2.000000       0.005000   \n",
       "25%      1.000000               5.0                10.000000       0.005000   \n",
       "50%      1.500000               5.0                20.000000       0.007000   \n",
       "75%      2.000000               5.0                30.000000       0.009000   \n",
       "max      2.000000               5.0                38.000000       0.009000   \n",
       "\n",
       "       Fetal Mu_a      alpha0      alpha1      alpha2      alpha3  \n",
       "count  342.000000  342.000000  342.000000  342.000000  342.000000  \n",
       "mean     0.070000  -21.351539    1.161318  -34.392205   50.957188  \n",
       "std      0.016354    4.335894    0.082025    4.378542    7.949997  \n",
       "min      0.050000  -37.637443    1.023883  -50.998421   41.231932  \n",
       "25%      0.050000  -22.552118    1.099423  -35.704110   45.769656  \n",
       "50%      0.070000  -20.266092    1.154008  -33.536098   49.251434  \n",
       "75%      0.090000  -18.650280    1.204571  -31.477528   52.981612  \n",
       "max      0.090000  -16.532142    1.460359  -28.776783   81.243376  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolated_training_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([(       'Uterus Thickness',  ''),\n",
      "            ('Maternal Wall Thickness',  ''),\n",
      "            (          'Maternal Mu_a',  ''),\n",
      "            (             'Fetal Mu_a',  ''),\n",
      "            (                 'alpha0', 1.0),\n",
      "            (                 'alpha0', 2.0),\n",
      "            (                 'alpha1', 1.0),\n",
      "            (                 'alpha1', 2.0),\n",
      "            (                 'alpha2', 1.0),\n",
      "            (                 'alpha2', 2.0),\n",
      "            (                 'alpha3', 1.0),\n",
      "            (                 'alpha3', 2.0)],\n",
      "           names=[None, 'Wave Int'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uterus Thickness</th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Maternal Mu_a</th>\n",
       "      <th>Fetal Mu_a</th>\n",
       "      <th>alpha0_1</th>\n",
       "      <th>alpha0_2</th>\n",
       "      <th>alpha1_1</th>\n",
       "      <th>alpha1_2</th>\n",
       "      <th>alpha2_1</th>\n",
       "      <th>alpha2_2</th>\n",
       "      <th>alpha3_1</th>\n",
       "      <th>alpha3_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-18.731813</td>\n",
       "      <td>-20.444467</td>\n",
       "      <td>1.136306</td>\n",
       "      <td>1.165762</td>\n",
       "      <td>-33.474455</td>\n",
       "      <td>-38.806152</td>\n",
       "      <td>48.387194</td>\n",
       "      <td>56.459243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-19.993693</td>\n",
       "      <td>-23.640858</td>\n",
       "      <td>1.140056</td>\n",
       "      <td>1.240522</td>\n",
       "      <td>-34.389651</td>\n",
       "      <td>-41.728256</td>\n",
       "      <td>50.292328</td>\n",
       "      <td>61.884206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-21.041806</td>\n",
       "      <td>-25.905711</td>\n",
       "      <td>1.147346</td>\n",
       "      <td>1.294433</td>\n",
       "      <td>-35.192921</td>\n",
       "      <td>-43.812067</td>\n",
       "      <td>51.919289</td>\n",
       "      <td>65.743294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-18.779575</td>\n",
       "      <td>-20.207374</td>\n",
       "      <td>1.150033</td>\n",
       "      <td>1.170677</td>\n",
       "      <td>-33.723770</td>\n",
       "      <td>-38.781909</td>\n",
       "      <td>48.693747</td>\n",
       "      <td>56.276399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-20.033502</td>\n",
       "      <td>-23.426282</td>\n",
       "      <td>1.153174</td>\n",
       "      <td>1.245650</td>\n",
       "      <td>-34.626898</td>\n",
       "      <td>-41.720371</td>\n",
       "      <td>50.580324</td>\n",
       "      <td>61.734832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Uterus Thickness  Maternal Wall Thickness  Maternal Mu_a  Fetal Mu_a  \\\n",
       "0               5.0                      2.0          0.005        0.05   \n",
       "1               5.0                      2.0          0.005        0.07   \n",
       "2               5.0                      2.0          0.005        0.09   \n",
       "3               5.0                      2.0          0.007        0.05   \n",
       "4               5.0                      2.0          0.007        0.07   \n",
       "\n",
       "    alpha0_1   alpha0_2  alpha1_1  alpha1_2   alpha2_1   alpha2_2   alpha3_1  \\\n",
       "0 -18.731813 -20.444467  1.136306  1.165762 -33.474455 -38.806152  48.387194   \n",
       "1 -19.993693 -23.640858  1.140056  1.240522 -34.389651 -41.728256  50.292328   \n",
       "2 -21.041806 -25.905711  1.147346  1.294433 -35.192921 -43.812067  51.919289   \n",
       "3 -18.779575 -20.207374  1.150033  1.170677 -33.723770 -38.781909  48.693747   \n",
       "4 -20.033502 -23.426282  1.153174  1.245650 -34.626898 -41.720371  50.580324   \n",
       "\n",
       "    alpha3_2  \n",
       "0  56.459243  \n",
       "1  61.884206  \n",
       "2  65.743294  \n",
       "3  56.276399  \n",
       "4  61.734832  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Incorporate both wavelengths by moving to a Wide Format from Long Format\n",
    "interpolated_training_data = interpolated_training_data.pivot_table(\n",
    "    index=['Uterus Thickness', 'Maternal Wall Thickness', 'Maternal Mu_a', 'Fetal Mu_a'], columns='Wave Int', values=['alpha0', 'alpha1', 'alpha2', 'alpha3']).reset_index()\n",
    "\n",
    "\n",
    "print(interpolated_training_data.columns)\n",
    "\n",
    "def _renaming_func(x, y):\n",
    "    if y == '':\n",
    "        return f'{x}'\n",
    "    else:\n",
    "        return f'{x}_{int(y)}'\n",
    "\n",
    "\n",
    "interpolated_training_data.columns = [_renaming_func(\n",
    "    x, y) for x, y in interpolated_training_data.columns]\n",
    "interpolated_training_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting only on both WV\n",
    "\n",
    "# Create Features & Normalize the fitting params\n",
    "interpolated_training_data['Bias Ratio'] = interpolated_training_data['alpha0_1'] / interpolated_training_data['alpha0_2'] \n",
    "\n",
    "X = interpolated_training_data[['Bias Ratio', 'alpha1_1', 'alpha1_2', 'alpha2_1', 'alpha2_2', 'alpha3_1', 'alpha3_2']].to_numpy()\n",
    "alpha_scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = alpha_scaler.transform(X)\n",
    "\n",
    "y = interpolated_training_data[['Fetal Mu_a']].to_numpy().flatten()\n",
    "# y = interpolated_training_data[['Maternal Mu_a']].to_numpy().flatten()\n",
    "y_scaler = preprocessing.StandardScaler().fit(y.reshape(-1, 1))\n",
    "y = y_scaler.transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "random_indices = rng.choice(np.arange(y.size), size=y.size, replace=False)\n",
    "training_count = int(y.size * 1)  # 80% Training Data\n",
    "training_indices = random_indices[:training_count]\n",
    "test_indices = random_indices[training_count:]\n",
    "\n",
    "X_train, y_train = X[training_indices], y[training_indices]\n",
    "X_test, y_test = X[test_indices], y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1**2 * Matern(length_scale=8.82e-06, nu=1.5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernel = 1 * kernels.RBF(length_scale=1.0, length_scale_bounds=(1e-4, 1e1))\n",
    "kernel = 1 * kernels.Matern(length_scale=1.0, length_scale_bounds=(1e-6, 1e-2))\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "gp.fit(X_train, y_train)\n",
    "gp.kernel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PRedict on Simulation\n",
    "# X_test = X_train\n",
    "# y_test = y_train\n",
    "# mean_prediction, std_prediction = gp.predict(X_test, return_std=True)\n",
    "# mae = np.abs(mean_prediction - y_test)\n",
    "# mse = np.square(mean_prediction - y_test)\n",
    "# df = pd.DataFrame(\n",
    "#     {\n",
    "#         'True a0' : X_test[:, 0],\n",
    "#         'True a1' : X_test[:, 1],\n",
    "#         'True a2' : X_test[:, 2],\n",
    "#         'True a3' : X_test[:, 3],\n",
    "#         'True y'  : y_test,\n",
    "#         'Prediction' : mean_prediction,\n",
    "#         'Confidence' : std_prediction,\n",
    "#         'MAE(%)' : mae * 100,\n",
    "#         'MSE(%)' : mse * 100,\n",
    "#     }\n",
    "# )\n",
    "# pd.set_option('display.max_rows', 1200)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['MAE(%)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_patient_ppg(ppg_data : pd.DataFrame, sample_number : Union[int, List], SDD = [15, 30, 45, 70, 100]) -> np.ndarray:\n",
    "    \"\"\"Prepare PPG data to be used directly into the GPR prediction.\n",
    "\n",
    "    Args:\n",
    "        ppg_data (pd.DataFrame): PPG data Dataframe. You can feed data directly from the the TFO_dataset package.\n",
    "        (Note: This should ideally be the optically normalized data)\n",
    "        sample_number (int): which sample to choose. You can either pass a single integer or an array\n",
    "        SDD (_type_, optional): Detector distances in TFO device(in mm). Defaults to SDD=[15, 30, 45, 70, 100].\n",
    "    \"\"\"\n",
    "    # The code is generalized to run on any array. make necessary conversions \n",
    "    if isinstance(sample_number, int):\n",
    "        sample_number = [sample_number]\n",
    "    \n",
    "    patient_features = []\n",
    "    for sample_point in sample_number:\n",
    "        # Pick a point in time\n",
    "        spatial_intensity = ppg_data.iloc[sample_point].copy()  # at 300s with 80Hz sampling freq.\n",
    "        spatial_intensity *=  pi * 4   # from unit area -> pi r^2 area -> match simulation\n",
    "        # Reshape ppg data to fit the format\n",
    "        spatial_intensity_wv1 = pd.DataFrame(data={\n",
    "            'SDD' : SDD,\n",
    "            'Intensity' : spatial_intensity.to_numpy()[:5]\n",
    "        })\n",
    "        spatial_intensity_wv2 = pd.DataFrame(data={\n",
    "            'SDD' : SDD,\n",
    "            'Intensity' : spatial_intensity.to_numpy()[5:]\n",
    "        })\n",
    "        alpha_wv1 = interpolate_exp_chunk(spatial_intensity_wv1, weights=[1.0, -2.0], return_alpha=True).flatten()\n",
    "        alpha_wv2 = interpolate_exp_chunk(spatial_intensity_wv2, weights=[1.0, -2.0], return_alpha=True).flatten()\n",
    "        patient_features.append([alpha_wv1[0]/alpha_wv2[0], alpha_wv1[1], alpha_wv2[1], alpha_wv1[2], alpha_wv2[2], alpha_wv1[3], alpha_wv2[3]])\n",
    "        \n",
    "    return np.array(patient_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 'sp2021', 'Recovery')\n",
      "Non- normalized Features\n",
      "         f1        f2        f3          f4          f5          f6  \\\n",
      "0  0.922549 -7.762497 -8.428254  432.869728  469.762372 -918.673743   \n",
      "1  0.952050 -8.270747 -8.690338  460.292467  483.691475 -975.992748   \n",
      "2  0.913166 -7.338907 -8.055188  409.441753  449.065345 -869.434792   \n",
      "\n",
      "            f7  \n",
      "0  -996.156135  \n",
      "1 -1025.166854  \n",
      "2  -952.622172  \n"
     ]
    }
   ],
   "source": [
    "# Predict on reallife data\n",
    "sheep_id = 23\n",
    "data = TFO_dataset.SheepData('iq_demod_optical').get(sheep_id)\n",
    "print(TFO_dataset.SheepData('iq_demod_optical').get_tuple(sheep_id))\n",
    "\n",
    "features = prepare_patient_ppg(data, [1000, 2000, 3000])\n",
    "\n",
    "# Create a DF for better viz.\n",
    "print('Non- normalized Features')\n",
    "feature_names = [f'f{i + 1}' for i in range(7)]\n",
    "feature_df = pd.DataFrame(columns=feature_names, data=features)\n",
    "print(feature_df)\n",
    "features = alpha_scaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07]\n",
      " [0.07]\n",
      " [0.07]]\n",
      "[[1.00164536 0.         0.        ]\n",
      " [0.         1.00164536 0.        ]\n",
      " [0.         0.         1.00164536]]\n"
     ]
    }
   ],
   "source": [
    "estimate, confidence = gp.predict(features, return_cov=True)\n",
    "# estimate, confidence = gp.predict(X_train[0, :].reshape(1, -1), return_std=True)\n",
    "print(y_scaler.inverse_transform(np.array(estimate).reshape(-1, 1)))\n",
    "print(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha means (From training) : [  0.94523291   1.16150141   1.16113513 -33.69234246 -35.0920684\n",
      "  49.50365467  52.41072202]\n",
      "alpha variance (From training) : [1.36340464e-02 2.78140933e-03 1.06352380e-02 5.24406179e+00\n",
      " 3.20074684e+01 1.63604967e+01 1.05449276e+02]\n"
     ]
    }
   ],
   "source": [
    "print(f'alpha means (From training) : {alpha_scaler.mean_}')\n",
    "print(f'alpha variance (From training) : {alpha_scaler.var_}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybercat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
