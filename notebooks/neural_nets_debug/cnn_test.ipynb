{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test CNN-ish networks\n",
    "## Pure 1d CNN Network\n",
    "A fully CNN network with no FC layers. Each Conv layers are connected via a batch norm, dropout and relu to the next one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inverse_modelling_tfo.models.custom_models import CNN1d\n",
    "import torch\n",
    "\n",
    "test_input = torch.randn(1, 1, 50)     # Single data point, Single channel, 100 time steps\n",
    "model = CNN1d([1, 1, 1], [1, 1, 1], [20, 10, 5])\n",
    "test_output = model(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv1d(1, 1, kernel_size=(20,), stride=(1,), padding=(1,)),\n",
       " BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(),\n",
       " Conv1d(1, 1, kernel_size=(10,), stride=(1,), padding=(1,)),\n",
       " BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(),\n",
       " Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(1,)),\n",
       " Flatten(start_dim=1, end_dim=-1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.3251,  1.1289,  1.5304,  0.1552,  0.4347, -0.2044, -0.3517,\n",
      "          -2.1150, -0.3339,  0.1401, -0.6014, -2.9514, -0.0323, -2.3537,\n",
      "          -1.0753, -0.1601, -1.2115, -0.9222,  0.2483,  1.0915, -0.9255,\n",
      "           0.3184, -0.4677, -0.6106, -0.8581, -1.3273, -0.8977, -0.3342,\n",
      "           1.3749, -0.0464,  1.8428,  0.2644,  1.0038,  2.1576, -0.6278,\n",
      "          -0.1229, -0.6388, -0.1754,  1.4870,  0.6072,  1.3794, -0.9539,\n",
      "           1.2120,  0.0506, -0.8858, -0.7983, -0.5759,  1.1218,  0.5028,\n",
      "          -2.1901]]])\n"
     ]
    }
   ],
   "source": [
    "print(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0321, -0.0321, -0.0321, -0.0321, -0.0321, -0.0549, -0.0274, -0.0178,\n",
      "         -0.0718, -0.0286, -0.0034, -0.3756,  0.0301,  0.1969,  0.1245, -0.3772,\n",
      "         -0.2980,  0.1463,  0.2741, -0.1417, -1.0467, -0.0680,  0.7353,  0.5495]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FC Connected CNN\n",
    "A bunch of FC layers followed by CNNs. Each with batchnorm/dropout/ReLu between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inverse_modelling_tfo.models.custom_models import FC2CNN\n",
    "model2 = FC2CNN([5, 10, 20], [30, 40], [5, 5])\n",
    "test_input2 = torch.randn(10, 5)    # 10 data points, 5 features\n",
    "test_output2 = model2(test_input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=5, out_features=10, bias=True),\n",
       " BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(),\n",
       " Linear(in_features=10, out_features=20, bias=True),\n",
       " Flatten(start_dim=1, end_dim=-1),\n",
       " Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(7,)),\n",
       " BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(),\n",
       " Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(7,)),\n",
       " Flatten(start_dim=1, end_dim=-1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 40])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output2.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybercat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
