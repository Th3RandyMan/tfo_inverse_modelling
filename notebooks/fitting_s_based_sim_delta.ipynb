{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Saturation-based Simulation Data Changes\n",
    "In this notebook, we try to fit intensity data generated using a saturation based method. The mu_a for each of the maternal and fetal layer are based on a set oxygen saturation and HB concentration. The impact of all other pigments on mu_a are ignored. In this notebook, we try to fit the difference between 2 sets of measurements.\n",
    "\n",
    "\n",
    "# Instructions\n",
    "I have the parameter search in one of the cells. Run eveerything above it to be able to run that cell.\n",
    "If you don't want to search, ignore that cell and run everything above and below. \n",
    "\n",
    "# V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from inverse_modelling_tfo.models import train_model, train_model_wtih_reporting\n",
    "from inverse_modelling_tfo.data import generate_data_loaders, equidistance_detector_normalization, constant_detector_count_normalization, generate_differential_data_loaders, DifferentialCombinationDataset\n",
    "from inverse_modelling_tfo.data.intensity_interpolation import get_interpolate_fit_params_custom, interpolate_exp\n",
    "from inverse_modelling_tfo.data.interpolation_function_zoo import *\n",
    "from inverse_modelling_tfo.models.custom_models import SplitChannelCNN, PerceptronReLU\n",
    "from inverse_modelling_tfo.features.build_features import create_ratio, create_spatial_intensity, create_ratio_and_intensity\n",
    "from inverse_modelling_tfo.misc.misc_training import set_seed\n",
    "from inverse_modelling_tfo.models import RandomSplit, ValidationMethod\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import torchinfo\n",
    "# Set my GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SDD</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>Wave Int</th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Maternal Hb Concentration</th>\n",
       "      <th>Maternal Saturation</th>\n",
       "      <th>Fetal Hb Concentration</th>\n",
       "      <th>Fetal Saturation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>-5.003564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>-7.176319</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>-9.282155</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>-10.143438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>-10.578727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SDD  Intensity  Wave Int  Maternal Wall Thickness  \\\n",
       "0   10  -5.003564       1.0                      6.0   \n",
       "1   14  -7.176319       1.0                      6.0   \n",
       "2   19  -9.282155       1.0                      6.0   \n",
       "3   23 -10.143438       1.0                      6.0   \n",
       "4   28 -10.578727       1.0                      6.0   \n",
       "\n",
       "   Maternal Hb Concentration  Maternal Saturation  Fetal Hb Concentration  \\\n",
       "0                       12.0                  0.9                    0.11   \n",
       "1                       12.0                  0.9                    0.11   \n",
       "2                       12.0                  0.9                    0.11   \n",
       "3                       12.0                  0.9                    0.11   \n",
       "4                       12.0                  0.9                    0.11   \n",
       "\n",
       "   Fetal Saturation  \n",
       "0               0.1  \n",
       "1               0.1  \n",
       "2               0.1  \n",
       "3               0.1  \n",
       "4               0.1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(r'/home/rraiyan/personal_projects/tfo_inverse_modelling/data/intensity/s_based_intensity_low_conc2.pkl')\n",
    "equidistance_detector_normalization(data)\n",
    "\n",
    "# Drop Uterus Thickness for now\n",
    "data = data.drop(columns='Uterus Thickness')\n",
    "\n",
    "# Interpolate intensity to remove noise\n",
    "# data = interpolate_exp(data, weights=[1, 0.8])\n",
    "# data['Intensity'] = data['Interpolated Intensity']\n",
    "# data = data.drop(columns='Interpolated Intensity')\n",
    "\n",
    "# Manual log(intensity) normalization\n",
    "data['Intensity'] = np.log10(data['Intensity'])        # Far values wayy to small to affect anything. Take log\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Maternal Hb Concentration</th>\n",
       "      <th>Maternal Saturation</th>\n",
       "      <th>Fetal Hb Concentration</th>\n",
       "      <th>Fetal Saturation</th>\n",
       "      <th>10_1.0</th>\n",
       "      <th>14_1.0</th>\n",
       "      <th>19_1.0</th>\n",
       "      <th>23_1.0</th>\n",
       "      <th>28_1.0</th>\n",
       "      <th>...</th>\n",
       "      <th>55_2.0</th>\n",
       "      <th>59_2.0</th>\n",
       "      <th>64_2.0</th>\n",
       "      <th>68_2.0</th>\n",
       "      <th>73_2.0</th>\n",
       "      <th>77_2.0</th>\n",
       "      <th>82_2.0</th>\n",
       "      <th>86_2.0</th>\n",
       "      <th>91_2.0</th>\n",
       "      <th>95_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-4.788235</td>\n",
       "      <td>-5.891256</td>\n",
       "      <td>-6.565637</td>\n",
       "      <td>-7.023905</td>\n",
       "      <td>-7.415765</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.473209</td>\n",
       "      <td>-11.759999</td>\n",
       "      <td>-12.017859</td>\n",
       "      <td>-12.274537</td>\n",
       "      <td>-12.537797</td>\n",
       "      <td>-12.793837</td>\n",
       "      <td>-13.089528</td>\n",
       "      <td>-13.309907</td>\n",
       "      <td>-13.502396</td>\n",
       "      <td>-13.825513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.225</td>\n",
       "      <td>-4.787676</td>\n",
       "      <td>-5.886830</td>\n",
       "      <td>-6.554969</td>\n",
       "      <td>-7.007363</td>\n",
       "      <td>-7.393859</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.496584</td>\n",
       "      <td>-11.786246</td>\n",
       "      <td>-12.046478</td>\n",
       "      <td>-12.306739</td>\n",
       "      <td>-12.572414</td>\n",
       "      <td>-12.830995</td>\n",
       "      <td>-13.130074</td>\n",
       "      <td>-13.352649</td>\n",
       "      <td>-13.545234</td>\n",
       "      <td>-13.872506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-4.787082</td>\n",
       "      <td>-5.882115</td>\n",
       "      <td>-6.543582</td>\n",
       "      <td>-6.989645</td>\n",
       "      <td>-7.370265</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.519309</td>\n",
       "      <td>-11.811729</td>\n",
       "      <td>-12.074236</td>\n",
       "      <td>-12.338013</td>\n",
       "      <td>-12.606005</td>\n",
       "      <td>-12.866975</td>\n",
       "      <td>-13.169270</td>\n",
       "      <td>-13.394052</td>\n",
       "      <td>-13.586719</td>\n",
       "      <td>-13.918002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.475</td>\n",
       "      <td>-4.786448</td>\n",
       "      <td>-5.877066</td>\n",
       "      <td>-6.531360</td>\n",
       "      <td>-6.970551</td>\n",
       "      <td>-7.344683</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.541401</td>\n",
       "      <td>-11.836468</td>\n",
       "      <td>-12.101154</td>\n",
       "      <td>-12.368376</td>\n",
       "      <td>-12.638587</td>\n",
       "      <td>-12.901793</td>\n",
       "      <td>-13.207129</td>\n",
       "      <td>-13.434124</td>\n",
       "      <td>-13.626866</td>\n",
       "      <td>-13.962007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-4.785766</td>\n",
       "      <td>-5.871626</td>\n",
       "      <td>-6.518150</td>\n",
       "      <td>-6.949820</td>\n",
       "      <td>-7.316720</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.562880</td>\n",
       "      <td>-11.860482</td>\n",
       "      <td>-12.127251</td>\n",
       "      <td>-12.397845</td>\n",
       "      <td>-12.670178</td>\n",
       "      <td>-12.935463</td>\n",
       "      <td>-13.243663</td>\n",
       "      <td>-13.472877</td>\n",
       "      <td>-13.665692</td>\n",
       "      <td>-14.004523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Maternal Wall Thickness  Maternal Hb Concentration  Maternal Saturation  \\\n",
       "0                      2.0                       12.0                  0.9   \n",
       "1                      2.0                       12.0                  0.9   \n",
       "2                      2.0                       12.0                  0.9   \n",
       "3                      2.0                       12.0                  0.9   \n",
       "4                      2.0                       12.0                  0.9   \n",
       "\n",
       "   Fetal Hb Concentration  Fetal Saturation    10_1.0    14_1.0    19_1.0  \\\n",
       "0                    0.11             0.100 -4.788235 -5.891256 -6.565637   \n",
       "1                    0.11             0.225 -4.787676 -5.886830 -6.554969   \n",
       "2                    0.11             0.350 -4.787082 -5.882115 -6.543582   \n",
       "3                    0.11             0.475 -4.786448 -5.877066 -6.531360   \n",
       "4                    0.11             0.600 -4.785766 -5.871626 -6.518150   \n",
       "\n",
       "     23_1.0    28_1.0  ...     55_2.0     59_2.0     64_2.0     68_2.0  \\\n",
       "0 -7.023905 -7.415765  ... -11.473209 -11.759999 -12.017859 -12.274537   \n",
       "1 -7.007363 -7.393859  ... -11.496584 -11.786246 -12.046478 -12.306739   \n",
       "2 -6.989645 -7.370265  ... -11.519309 -11.811729 -12.074236 -12.338013   \n",
       "3 -6.970551 -7.344683  ... -11.541401 -11.836468 -12.101154 -12.368376   \n",
       "4 -6.949820 -7.316720  ... -11.562880 -11.860482 -12.127251 -12.397845   \n",
       "\n",
       "      73_2.0     77_2.0     82_2.0     86_2.0     91_2.0     95_2.0  \n",
       "0 -12.537797 -12.793837 -13.089528 -13.309907 -13.502396 -13.825513  \n",
       "1 -12.572414 -12.830995 -13.130074 -13.352649 -13.545234 -13.872506  \n",
       "2 -12.606005 -12.866975 -13.169270 -13.394052 -13.586719 -13.918002  \n",
       "3 -12.638587 -12.901793 -13.207129 -13.434124 -13.626866 -13.962007  \n",
       "4 -12.670178 -12.935463 -13.243663 -13.472877 -13.665692 -14.004523  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = create_ratio_and_intensity(data, True)\n",
    "# data = create_ratio(data, True)\n",
    "data = create_spatial_intensity(data)\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "data.head() \n",
    "# NOTE: Have only 1 on at the same time!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Features\n",
    "x_columns will be the input features and y_columns are the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Y -> Target\n",
    "# y_columns = ['Maternal Wall Thickness', \"Maternal Hb Concentration\", \"Maternal Saturation\", \"Fetal Hb Concentration\", \"Fetal Saturation\"]\n",
    "# y_columns = ['Maternal Saturation']\n",
    "# y_columns = ['Maternal Hb Concentration']\n",
    "y_column = 'Fetal Hb Concentration'\n",
    "fixed_columns = ['Maternal Wall Thickness', \"Fetal Saturation\", \"Maternal Saturation\"]\n",
    "# y_columns = ['Fetal Hb Concentration']\n",
    "\n",
    "## X -> Predictors\n",
    "# x_columns = list(filter(lambda X: '_' in X, data.columns))\n",
    "# x_columns = list(filter(lambda X: X.isdigit(), data.columns))\n",
    "x_columns = list(filter(lambda X: X.isdigit(), data.columns)) + list(filter(lambda X: '_' in X, data.columns))\n",
    "\n",
    "## Pass in maternal info\n",
    "# x_columns += [\"Maternal Hb Concentration\", \"Maternal Saturation\"]\n",
    "\n",
    "## Scale y\n",
    "y_scaler = preprocessing.StandardScaler()\n",
    "data[y_column] = y_scaler.fit_transform(data[y_column].to_numpy().reshape(-1, 1))\n",
    "\n",
    "## Scale x\n",
    "# I tried using the same scaling for all to preserve spatial information. Training does not work\n",
    "# With variable scale the network learns how much weight to give each \n",
    "x_scaler = preprocessing.StandardScaler()\n",
    "data[x_columns] = x_scaler.fit_transform(data[x_columns])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_FEATURES = len(x_columns) * 2\n",
    "OUT_FEATURES = 1\n",
    "model_config = {\n",
    "    'model_class' : SplitChannelCNN,  # Class name\n",
    "    # 'model_class' : PerceptronReLU,  # Class name\n",
    "    # 'model_params' :  [2, IN_FEATURES, 4, 5, [2, OUT_FEATURES]],    # Input params as an array\n",
    "    # 'model_params' :  [3, IN_FEATURES, 6, 5, [6, 3, OUT_FEATURES]],    # Input params as an array\n",
    "    # 'model_params' :  [3, IN_FEATURES, 6, 7, [3, OUT_FEATURES]],    # Input params as an array\n",
    "    'model_params' :  [4, IN_FEATURES, 8, 7, [4, 2, OUT_FEATURES]],    # Input params as an array\n",
    "    # 'model_params' :  [[IN_FEATURES, 20, 8, OUT_FEATURES]],    # Input params as an array\n",
    "    \n",
    "    'train_split' : 0.8,\n",
    "    'epochs' : 25,\n",
    "    'total_data_len': 120000,\n",
    "    'allow_zero_diff': False,\n",
    "    'hyperparam_search_count': 20,\n",
    "    'validation' : RandomSplit(0.8),\n",
    "    'hyperparam_max_epoch': 10,\n",
    "    'seed': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Train Function \n",
    "def train_model2(iteration_config, epoch=model_config['hyperparam_max_epoch']):\n",
    "    set_seed(model_config['seed'])\n",
    "    params = {\n",
    "        'batch_size': iteration_config['batch_size'], 'shuffle': True, 'num_workers': 2\n",
    "    }\n",
    "    # train, val = generate_data_loaders(data, params, x_columns, y_columns, model_config['train_split'])\n",
    "    train, val = generate_differential_data_loaders(data, params, fixed_columns, x_columns, y_column, model_config['total_data_len'], model_config[\"allow_zero_diff\"], model_config['validation'], model_config['train_split'])\n",
    "    # model = create_perceptron_model(config['model'])\n",
    "    # model = create_perceptron_model([42, 8, 1])\n",
    "    # model = TwoChannelCNN(40, 4, 5, [4, 1])\n",
    "    model = model_config['model_class'](*model_config['model_params'])\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = SGD(model.parameters(), lr=iteration_config[\"lr\"], momentum=iteration_config[\"momentum\"])\n",
    "    # optimizer = Adam(model.parameters(), lr=config[\"lr\"], betas=[config[\"b1\"], config[\"b2\"]])\n",
    "    train_loss, val_loss = train_model_wtih_reporting(model, optimizer=optimizer, criterion=criterion, train_loader=train, validation_loader=val, epochs=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 12:23:28,540\tINFO tune.py:657 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-24 12:23:30 (running for 00:00:00.31)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (20 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:23:35 (running for 00:00:05.38)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:23:40 (running for 00:00:10.42)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:23:45 (running for 00:00:15.44)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:23:50 (running for 00:00:20.47)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th style=\"text-align: right;\">  combined_loss</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model2_9253f_00000</td><td style=\"text-align: right;\">      2.17321  </td><td style=\"text-align: right;\">    1.64012 </td><td style=\"text-align: right;\"> 1.32503  </td></tr>\n",
       "<tr><td>train_model2_9253f_00001</td><td style=\"text-align: right;\">      4.38474  </td><td style=\"text-align: right;\">    2.10627 </td><td style=\"text-align: right;\"> 2.08176  </td></tr>\n",
       "<tr><td>train_model2_9253f_00002</td><td style=\"text-align: right;\">      0.265055 </td><td style=\"text-align: right;\">    0.705913</td><td style=\"text-align: right;\"> 0.375478 </td></tr>\n",
       "<tr><td>train_model2_9253f_00003</td><td style=\"text-align: right;\">      0.0424292</td><td style=\"text-align: right;\">    0.217242</td><td style=\"text-align: right;\"> 0.195308 </td></tr>\n",
       "<tr><td>train_model2_9253f_00004</td><td style=\"text-align: right;\">      4.38589  </td><td style=\"text-align: right;\">    2.08946 </td><td style=\"text-align: right;\"> 2.09906  </td></tr>\n",
       "<tr><td>train_model2_9253f_00005</td><td style=\"text-align: right;\">      0.0130987</td><td style=\"text-align: right;\">    0.147742</td><td style=\"text-align: right;\"> 0.0886593</td></tr>\n",
       "<tr><td>train_model2_9253f_00006</td><td style=\"text-align: right;\">      4.34938  </td><td style=\"text-align: right;\">    2.08503 </td><td style=\"text-align: right;\"> 2.086    </td></tr>\n",
       "<tr><td>train_model2_9253f_00007</td><td style=\"text-align: right;\">      4.36061  </td><td style=\"text-align: right;\">    2.10139 </td><td style=\"text-align: right;\"> 2.07511  </td></tr>\n",
       "<tr><td>train_model2_9253f_00008</td><td style=\"text-align: right;\">      4.3522   </td><td style=\"text-align: right;\">    2.0998  </td><td style=\"text-align: right;\"> 2.07267  </td></tr>\n",
       "<tr><td>train_model2_9253f_00009</td><td style=\"text-align: right;\">      4.28783  </td><td style=\"text-align: right;\">    2.06863 </td><td style=\"text-align: right;\"> 2.07278  </td></tr>\n",
       "<tr><td>train_model2_9253f_00010</td><td style=\"text-align: right;\">      1.00049  </td><td style=\"text-align: right;\">    0.822638</td><td style=\"text-align: right;\"> 1.2162   </td></tr>\n",
       "<tr><td>train_model2_9253f_00011</td><td style=\"text-align: right;\">      1.06535  </td><td style=\"text-align: right;\">    1.09662 </td><td style=\"text-align: right;\"> 0.971483 </td></tr>\n",
       "<tr><td>train_model2_9253f_00012</td><td style=\"text-align: right;\">      4.3859   </td><td style=\"text-align: right;\">    2.10654 </td><td style=\"text-align: right;\"> 2.08204  </td></tr>\n",
       "<tr><td>train_model2_9253f_00013</td><td style=\"text-align: right;\">      4.35161  </td><td style=\"text-align: right;\">    2.08555 </td><td style=\"text-align: right;\"> 2.08655  </td></tr>\n",
       "<tr><td>train_model2_9253f_00014</td><td style=\"text-align: right;\">      0.988351 </td><td style=\"text-align: right;\">    1.05069 </td><td style=\"text-align: right;\"> 0.940672 </td></tr>\n",
       "<tr><td>train_model2_9253f_00015</td><td style=\"text-align: right;\">      0.0151623</td><td style=\"text-align: right;\">    0.169473</td><td style=\"text-align: right;\"> 0.0894674</td></tr>\n",
       "<tr><td>train_model2_9253f_00016</td><td style=\"text-align: right;\">      4.40764  </td><td style=\"text-align: right;\">    2.11017 </td><td style=\"text-align: right;\"> 2.08875  </td></tr>\n",
       "<tr><td>train_model2_9253f_00017</td><td style=\"text-align: right;\">      4.38243  </td><td style=\"text-align: right;\">    2.10573 </td><td style=\"text-align: right;\"> 2.08119  </td></tr>\n",
       "<tr><td>train_model2_9253f_00018</td><td style=\"text-align: right;\">      0.0195633</td><td style=\"text-align: right;\">    0.184538</td><td style=\"text-align: right;\"> 0.106012 </td></tr>\n",
       "<tr><td>train_model2_9253f_00019</td><td style=\"text-align: right;\">      0.0177872</td><td style=\"text-align: right;\">    0.146771</td><td style=\"text-align: right;\"> 0.12119  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-24 12:23:55 (running for 00:00:25.51)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:24:00 (running for 00:00:30.57)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:24:05 (running for 00:00:35.59)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:24:10 (running for 00:00:40.62)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:24:15 (running for 00:00:45.69)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:24:20 (running for 00:00:50.71)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:24:25 (running for 00:00:55.73)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:24:30 (running for 00:01:00.76)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:24:35 (running for 00:01:05.83)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:24:40 (running for 00:01:10.84)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:24:45 (running for 00:01:15.86)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:24:50 (running for 00:01:20.89)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:24:56 (running for 00:01:25.95)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:25:01 (running for 00:01:30.95)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:25:06 (running for 00:01:35.98)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:25:11 (running for 00:01:41.00)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:25:16 (running for 00:01:46.03)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (4 PENDING, 16 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:25:21 (running for 00:01:51.06)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:25:26 (running for 00:01:56.09)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:25:31 (running for 00:02:01.11)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:25:36 (running for 00:02:06.12)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:25:41 (running for 00:02:11.15)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:25:46 (running for 00:02:16.18)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:25:51 (running for 00:02:21.20)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:25:56 (running for 00:02:26.23)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:26:01 (running for 00:02:31.30)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:26:06 (running for 00:02:36.36)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:26:11 (running for 00:02:41.39)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:26:16 (running for 00:02:46.40)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:26:21 (running for 00:02:51.45)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:26:26 (running for 00:02:56.48)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:26:31 (running for 00:03:01.50)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:26:36 (running for 00:03:06.53)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:26:41 (running for 00:03:11.60)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:26:46 (running for 00:03:16.62)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:26:51 (running for 00:03:21.65)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:26:56 (running for 00:03:26.73)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -4.343093055800604\n",
      "Logical resource usage: 64.0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (2 PENDING, 16 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:27:01 (running for 00:03:31.82)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.346237687084148\n",
      "Logical resource usage: 52.0/64 CPUs, 0.65/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (13 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:27:06 (running for 00:03:36.84)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.346237687084148\n",
      "Logical resource usage: 52.0/64 CPUs, 0.65/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (13 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:27:11 (running for 00:03:41.86)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.346237687084148\n",
      "Logical resource usage: 52.0/64 CPUs, 0.65/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (13 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:27:16 (running for 00:03:46.88)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.346237687084148\n",
      "Logical resource usage: 52.0/64 CPUs, 0.65/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (13 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:27:21 (running for 00:03:51.88)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.346237687084148\n",
      "Logical resource usage: 52.0/64 CPUs, 0.65/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (13 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:27:26 (running for 00:03:56.90)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.346237687084148\n",
      "Logical resource usage: 52.0/64 CPUs, 0.65/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (13 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:27:32 (running for 00:04:01.95)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.346237687084148\n",
      "Logical resource usage: 52.0/64 CPUs, 0.65/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (13 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:27:37 (running for 00:04:06.99)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.346237687084148\n",
      "Logical resource usage: 52.0/64 CPUs, 0.65/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (13 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:27:42 (running for 00:04:12.01)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.346237687084148\n",
      "Logical resource usage: 52.0/64 CPUs, 0.65/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (13 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:27:47 (running for 00:04:17.03)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.346237687084148\n",
      "Logical resource usage: 52.0/64 CPUs, 0.65/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (13 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:27:52 (running for 00:04:22.06)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.346237687084148\n",
      "Logical resource usage: 52.0/64 CPUs, 0.65/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (13 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:27:57 (running for 00:04:27.08)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.346237687084148\n",
      "Logical resource usage: 52.0/64 CPUs, 0.65/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (13 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:28:02 (running for 00:04:32.11)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.346237687084148\n",
      "Logical resource usage: 52.0/64 CPUs, 0.65/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (13 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:28:07 (running for 00:04:37.12)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.346237687084148\n",
      "Logical resource usage: 52.0/64 CPUs, 0.65/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (13 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:28:12 (running for 00:04:42.17)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.346237687084148\n",
      "Logical resource usage: 52.0/64 CPUs, 0.65/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (13 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:28:17 (running for 00:04:47.19)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.346237687084148\n",
      "Logical resource usage: 52.0/64 CPUs, 0.65/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (13 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:28:22 (running for 00:04:52.21)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.346237687084148\n",
      "Logical resource usage: 52.0/64 CPUs, 0.65/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (13 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:28:27 (running for 00:04:57.28)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 44.0/64 CPUs, 0.5499999999999999/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (11 RUNNING, 9 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:28:32 (running for 00:05:02.31)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 44.0/64 CPUs, 0.5499999999999999/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (11 RUNNING, 9 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:28:37 (running for 00:05:07.32)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 44.0/64 CPUs, 0.5499999999999999/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (11 RUNNING, 9 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:28:42 (running for 00:05:12.35)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 44.0/64 CPUs, 0.5499999999999999/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (11 RUNNING, 9 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:28:47 (running for 00:05:17.36)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 44.0/64 CPUs, 0.5499999999999999/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (11 RUNNING, 9 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:28:52 (running for 00:05:22.39)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 44.0/64 CPUs, 0.5499999999999999/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (11 RUNNING, 9 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:28:57 (running for 00:05:27.40)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 44.0/64 CPUs, 0.5499999999999999/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (11 RUNNING, 9 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:29:02 (running for 00:05:32.46)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 44.0/64 CPUs, 0.5499999999999999/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (11 RUNNING, 9 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:29:07 (running for 00:05:37.51)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 44.0/64 CPUs, 0.5499999999999999/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (11 RUNNING, 9 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:29:12 (running for 00:05:42.58)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 44.0/64 CPUs, 0.5499999999999999/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (11 RUNNING, 9 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:29:17 (running for 00:05:47.60)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 44.0/64 CPUs, 0.5499999999999999/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (11 RUNNING, 9 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:29:22 (running for 00:05:52.62)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 44.0/64 CPUs, 0.5499999999999999/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (11 RUNNING, 9 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:29:27 (running for 00:05:57.68)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -4.287833471783684 | Iter 5.000: -4.3493823183676925\n",
      "Logical resource usage: 44.0/64 CPUs, 0.5499999999999999/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (11 RUNNING, 9 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:29:32 (running for 00:06:02.77)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.994419935750223 | Iter 5.000: -4.301062340038119\n",
      "Logical resource usage: 24.0/64 CPUs, 0.3/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (6 RUNNING, 14 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:29:37 (running for 00:06:07.82)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.301062340038119\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:29:42 (running for 00:06:12.85)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.301062340038119\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:29:47 (running for 00:06:17.87)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.301062340038119\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:29:52 (running for 00:06:22.92)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.301062340038119\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:29:57 (running for 00:06:27.94)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.301062340038119\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:30:03 (running for 00:06:32.96)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.301062340038119\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:30:08 (running for 00:06:38.05)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.301062340038119\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:30:13 (running for 00:06:43.08)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.301062340038119\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:30:18 (running for 00:06:48.09)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.301062340038119\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:30:23 (running for 00:06:53.11)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.301062340038119\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:30:28 (running for 00:06:58.15)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.301062340038119\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:30:33 (running for 00:07:03.17)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.301062340038119\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:30:38 (running for 00:07:08.22)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.301062340038119\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:30:43 (running for 00:07:13.24)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.301062340038119\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:30:48 (running for 00:07:18.26)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.301062340038119\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:30:53 (running for 00:07:23.28)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.301062340038119\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:30:58 (running for 00:07:28.33)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:31:03 (running for 00:07:33.35)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:31:08 (running for 00:07:38.37)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:31:13 (running for 00:07:43.44)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:31:18 (running for 00:07:48.45)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:31:23 (running for 00:07:53.48)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:31:28 (running for 00:07:58.50)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:31:33 (running for 00:08:03.55)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:31:38 (running for 00:08:08.57)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:31:43 (running for 00:08:13.58)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:31:48 (running for 00:08:18.60)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:31:53 (running for 00:08:23.63)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:31:58 (running for 00:08:28.65)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:32:03 (running for 00:08:33.67)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:32:08 (running for 00:08:38.77)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:32:13 (running for 00:08:43.79)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 20.0/64 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (5 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:32:18 (running for 00:08:48.82)\n",
      "Using AsyncHyperBand: num_stopped=10\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 12.0/64 CPUs, 0.15000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (3 RUNNING, 17 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:32:23 (running for 00:08:53.87)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 4.0/64 CPUs, 0.05/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (1 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:32:28 (running for 00:08:58.89)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 4.0/64 CPUs, 0.05/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (1 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:32:33 (running for 00:09:03.89)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 4.0/64 CPUs, 0.05/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (1 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:32:38 (running for 00:09:08.90)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 4.0/64 CPUs, 0.05/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (1 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:32:43 (running for 00:09:13.92)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 4.0/64 CPUs, 0.05/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (1 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:32:48 (running for 00:09:18.94)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 4.0/64 CPUs, 0.05/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (1 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:32:54 (running for 00:09:24.02)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 4.0/64 CPUs, 0.05/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (1 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:32:59 (running for 00:09:29.03)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 4.0/64 CPUs, 0.05/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (1 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:33:04 (running for 00:09:34.05)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 4.0/64 CPUs, 0.05/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (1 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-24 12:33:09 (running for 00:09:39.07)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.988351424215695 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 4.0/64 CPUs, 0.05/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (1 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 12:33:10,077\tINFO tune.py:1148 -- Total run time: 581.54 seconds (580.01 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-24 12:33:10 (running for 00:09:40.01)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.6267032754316031 | Iter 5.000: -4.2885897826830375\n",
      "Logical resource usage: 4.0/64 CPUs, 0.05/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_model2_2023-07-24_12-23-30\n",
      "Number of trials: 20/20 (20 TERMINATED)\n",
      "+--------------------------+------------+----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name               | status     | loc                  |   batch_size |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|--------------------------+------------+----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_model2_9253f_00000 | TERMINATED | 169.237.32.34:650065 |            8 | 3.15237e-05 |       0.93 |     1.64012  |  1.32503   |       2.17321   |                   10 |\n",
      "| train_model2_9253f_00001 | TERMINATED | 169.237.32.34:650066 |           16 | 2.00781e-05 |       0.95 |     2.10627  |  2.08176   |       4.38474   |                    5 |\n",
      "| train_model2_9253f_00002 | TERMINATED | 169.237.32.34:650067 |            8 | 3.98258e-05 |       0.95 |     0.705913 |  0.375478  |       0.265055  |                   10 |\n",
      "| train_model2_9253f_00003 | TERMINATED | 169.237.32.34:650068 |           16 | 9.7238e-05  |       0.97 |     0.217242 |  0.195308  |       0.0424292 |                   10 |\n",
      "| train_model2_9253f_00004 | TERMINATED | 169.237.32.34:650069 |            8 | 0.000842399 |       0.95 |     2.08946  |  2.09906   |       4.38589   |                   10 |\n",
      "| train_model2_9253f_00005 | TERMINATED | 169.237.32.34:650070 |           16 | 0.000348475 |       0.95 |     0.147742 |  0.0886593 |       0.0130987 |                   10 |\n",
      "| train_model2_9253f_00006 | TERMINATED | 169.237.32.34:650071 |           32 | 0.00053645  |       0.97 |     2.08503  |  2.086     |       4.34938   |                    5 |\n",
      "| train_model2_9253f_00007 | TERMINATED | 169.237.32.34:650073 |           16 | 6.487e-05   |       0.93 |     2.10139  |  2.07511   |       4.36061   |                    5 |\n",
      "| train_model2_9253f_00008 | TERMINATED | 169.237.32.34:650072 |           16 | 6.8878e-05  |       0.93 |     2.0998   |  2.07267   |       4.3522    |                    5 |\n",
      "| train_model2_9253f_00009 | TERMINATED | 169.237.32.34:650074 |           32 | 6.42308e-05 |       0.93 |     2.06863  |  2.07278   |       4.28783   |                   10 |\n",
      "| train_model2_9253f_00010 | TERMINATED | 169.237.32.34:650075 |           16 | 6.64147e-05 |       0.97 |     0.822638 |  1.2162    |       1.00049   |                   10 |\n",
      "| train_model2_9253f_00011 | TERMINATED | 169.237.32.34:650076 |           16 | 7.05396e-05 |       0.95 |     1.09662  |  0.971483  |       1.06535   |                   10 |\n",
      "| train_model2_9253f_00012 | TERMINATED | 169.237.32.34:650077 |           16 | 1.98424e-05 |       0.93 |     2.10654  |  2.08204   |       4.3859    |                    5 |\n",
      "| train_model2_9253f_00013 | TERMINATED | 169.237.32.34:650078 |           32 | 0.000722168 |       0.97 |     2.08555  |  2.08655   |       4.35161   |                    5 |\n",
      "| train_model2_9253f_00014 | TERMINATED | 169.237.32.34:650079 |           16 | 4.32189e-05 |       0.97 |     1.05069  |  0.940672  |       0.988351  |                   10 |\n",
      "| train_model2_9253f_00015 | TERMINATED | 169.237.32.34:650081 |            8 | 8.70068e-05 |       0.95 |     0.169473 |  0.0894674 |       0.0151623 |                   10 |\n",
      "| train_model2_9253f_00016 | TERMINATED | 169.237.32.34:663094 |           16 | 0.000574795 |       0.97 |     2.11017  |  2.08875   |       4.40764   |                    5 |\n",
      "| train_model2_9253f_00017 | TERMINATED | 169.237.32.34:663111 |           16 | 1.71861e-05 |       0.97 |     2.10573  |  2.08119   |       4.38243   |                    5 |\n",
      "| train_model2_9253f_00018 | TERMINATED | 169.237.32.34:673503 |           32 | 0.000320617 |       0.97 |     0.184538 |  0.106012  |       0.0195633 |                   10 |\n",
      "| train_model2_9253f_00019 | TERMINATED | 169.237.32.34:673522 |            8 | 0.000143468 |       0.95 |     0.146771 |  0.12119   |       0.0177872 |                   10 |\n",
      "+--------------------------+------------+----------------------+--------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "\n",
      "\n",
      "Best trial config: {'lr': 0.0003484753915362265, 'batch_size': 16, 'momentum': 0.95}\n",
      "Best trial final validation loss: 0.08865928845231731\n",
      "Best trial final train loss: 0.14774166243802755\n"
     ]
    }
   ],
   "source": [
    "# Hyper Parameter Search \n",
    "iteration_config = {\n",
    "    \"lr\" : tune.loguniform(1e-5, 1e-3),\n",
    "    # \"b1\" : tune.uniform(0.3, 1.0),\n",
    "    # \"b2\" : tune.uniform(0.3, 1.0),\n",
    "    \"batch_size\": tune.choice([32, 16, 8]),\n",
    "    # \"model\": tune.choice([[40, 5, 1], [40, 10, 1], [40, 5, 2, 1]]),\n",
    "    \"momentum\": tune.choice([0.93, 0.95, 0.97]),\n",
    "}\n",
    "scheduler = ASHAScheduler(metric=\"combined_loss\", mode=\"min\", max_t=40, grace_period=5, reduction_factor=2)\n",
    "reporter = CLIReporter(metric_columns=[\"train_loss\", \"val_loss\", \"combined_loss\", \"training_iteration\"])\n",
    "result = tune.run(train_model2, config=iteration_config, scheduler=scheduler, progress_reporter=reporter,\n",
    "                  num_samples=model_config['hyperparam_search_count'], resources_per_trial={\"cpu\": 4, \"gpu\": 0.05},)\n",
    "\n",
    "best_trial = result.get_best_trial(\"combined_loss\", \"min\", \"last\")\n",
    "print(\"Best trial config: {}\".format(best_trial.config))\n",
    "print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"val_loss\"]))\n",
    "print(\"Best trial final train loss: {}\".format(best_trial.last_result[\"train_loss\"]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Best trial config: {'lr': 0.0010630834634709364, 'b1': 0.4282116859842134, 'b2': 0.3089991262211405, 'batch_size': 8, 'model': [20, 16, 8, 4, 2, 1]}\n",
    "Best trial final validation loss: 0.09234625198878348\n",
    "Best trial final train loss: 0.22368373312056064 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0003484753915362265, 'batch_size': 16, 'momentum': 0.95}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_class': inverse_modelling_tfo.models.custom_models.SplitChannelCNN,\n",
       " 'model_params': [4, 80, 8, 7, [4, 2, 1]],\n",
       " 'train_split': 0.8,\n",
       " 'epochs': 25,\n",
       " 'total_data_len': 120000,\n",
       " 'allow_zero_diff': False,\n",
       " 'hyperparam_search_count': 20,\n",
       " 'hyperparam_max_epoch': 10,\n",
       " 'seed': 42}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/rraiyan/personal_projects/tfo_inverse_modelling/notebooks/fitting_s_based_sim_delta.ipynb Cell 14\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblueberry.ece.ucdavis.edu/home/rraiyan/personal_projects/tfo_inverse_modelling/notebooks/fitting_s_based_sim_delta.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m optimizer \u001b[39m=\u001b[39m SGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.0004\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblueberry.ece.ucdavis.edu/home/rraiyan/personal_projects/tfo_inverse_modelling/notebooks/fitting_s_based_sim_delta.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# optimizer = SGD(model.parameters(), lr=best_trial.config['lr'], momentum=best_trial.config['momentum'])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblueberry.ece.ucdavis.edu/home/rraiyan/personal_projects/tfo_inverse_modelling/notebooks/fitting_s_based_sim_delta.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# CUDA_VISIBLE is already set to only see one GPU\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bblueberry.ece.ucdavis.edu/home/rraiyan/personal_projects/tfo_inverse_modelling/notebooks/fitting_s_based_sim_delta.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m train_loss, validation_loss \u001b[39m=\u001b[39m train_model(model, optimizer, criterion, train, val, epochs\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m, gpu_to_use\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblueberry.ece.ucdavis.edu/home/rraiyan/personal_projects/tfo_inverse_modelling/notebooks/fitting_s_based_sim_delta.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# train_loss, validation_loss = train_model(model, optimizer, criterion, train, val, epochs=model_config['epochs'], gpu_to_use=0)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblueberry.ece.ucdavis.edu/home/rraiyan/personal_projects/tfo_inverse_modelling/notebooks/fitting_s_based_sim_delta.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure()\n",
      "File \u001b[0;32m~/personal_projects/tfo_inverse_modelling/inverse_modelling_tfo/models/train_model.py:62\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, criterion, train_loader, validation_loader, epochs, gpu_to_use)\u001b[0m\n\u001b[1;32m     59\u001b[0m inputs, labels \u001b[39m=\u001b[39m data\n\u001b[1;32m     61\u001b[0m \u001b[39m# to CUDA\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m     63\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     65\u001b[0m \u001b[39m# zero the parameter gradients\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train Model with the given params.\n",
    "set_seed(model_config['seed'])\n",
    "params = {\n",
    "    'batch_size': 8, 'shuffle': True, 'num_workers': 2\n",
    "}\n",
    "params['batch_size'] = best_trial.config['batch_size']\n",
    "train, val = generate_differential_data_loaders(data, params, fixed_columns, x_columns, y_column, model_config['total_data_len'], model_config[\"allow_zero_diff\"], model_config['validation'], model_config['train_split'])\n",
    "# train, val = generate_differential_data_loaders(data, params, fixed_columns, x_columns, y_column, 140000, model_config[\"allow_zero_diff\"], model_config['train_split'])\n",
    "\n",
    "model = model_config['model_class'](*model_config['model_params'])\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.HuberLoss()\n",
    "# optimizer = Adam(model.parameters(), lr=0.0009, betas=[0.935, 0.701])\n",
    "optimizer = SGD(model.parameters(), lr=0.0004, momentum=0.9)\n",
    "optimizer = SGD(model.parameters(), lr=best_trial.config['lr'], momentum=best_trial.config['momentum'])\n",
    "# CUDA_VISIBLE is already set to only see one GPU\n",
    "# train_loss, validation_loss = train_model(model, optimizer, criterion, train, val, epochs=150, gpu_to_use=0)\n",
    "train_loss, validation_loss = train_model(model, optimizer, criterion, train, val, epochs=model_config['epochs'], gpu_to_use=0)\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label='Training Loss', marker='x')\n",
    "plt.plot(validation_loss, label='Validation Loss', marker='x')\n",
    "# plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE : 0.024685320429853164, Val MSE : 0.016066946913177768\n"
     ]
    }
   ],
   "source": [
    "print(f'Train MSE : {train_loss[-1]}, Val MSE : {validation_loss[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Fetal Saturation</th>\n",
       "      <th>Maternal Saturation</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Absolute Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.025472</td>\n",
       "      <td>0.003386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.040775</td>\n",
       "      <td>0.039660</td>\n",
       "      <td>0.004225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.900</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.025566</td>\n",
       "      <td>0.043696</td>\n",
       "      <td>0.004434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Maternal Wall Thickness  Fetal Saturation  Maternal Saturation  Truth  \\\n",
       "0                     16.0             0.225                0.975  0.000   \n",
       "1                      2.0             0.350                0.975  0.000   \n",
       "2                      6.0             0.350                1.000  0.000   \n",
       "3                      4.0             0.225                0.950  0.045   \n",
       "4                      6.0             0.100                0.900 -0.030   \n",
       "\n",
       "   Predicted  Train Error  Absolute Error  \n",
       "0   0.003386     0.025472        0.003386  \n",
       "1   0.000998     0.002214        0.000998  \n",
       "2   0.000809     0.001453        0.000809  \n",
       "3   0.040775     0.039660        0.004225  \n",
       "4  -0.025566     0.043696        0.004434  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = DifferentialCombinationDataset(data, fixed_columns, x_columns, y_column, model_config['total_data_len'], model_config['allow_zero_diff'])\n",
    "truth_column = []\n",
    "prediction_column = []\n",
    "loss_column = []\n",
    "tissue_fixed_params = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, current_sample in enumerate(x_data):\n",
    "        inputs, labels = current_sample\n",
    "        inputs = inputs.view(1, -1).cuda()\n",
    "        labels = labels.view(1, -1).cuda()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Bookkeeping\n",
    "        truth_column.append(labels.item())\n",
    "        prediction_column.append(outputs.item())\n",
    "        loss_column.append(loss.item())\n",
    "        tissue_fixed_params.append(x_data.split_fixed_columns[x_data.randomized_indices_list[i]])\n",
    "\n",
    "\n",
    "tissue_fixed_params = np.array(tissue_fixed_params)\n",
    "truth_column = np.array(truth_column).reshape(-1, 1)\n",
    "prediction_column = np.array(prediction_column).reshape(-1, 1)\n",
    "loss_column = np.array(loss_column).reshape(-1, 1)\n",
    "\n",
    "# un-normalize\n",
    "truth_column = y_scaler.scale_ * truth_column\n",
    "prediction_column = y_scaler.scale_ * prediction_column\n",
    "absolute_error = np.abs(truth_column - prediction_column)\n",
    "\n",
    "\n",
    "merged = np.hstack([tissue_fixed_params, truth_column, prediction_column, loss_column, absolute_error])\n",
    "merged_df = pd.DataFrame(merged, columns=fixed_columns + ['Truth', 'Predicted', \"Train Error\", \"Absolute Error\"])\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.figure('Error Distribution')\n",
    "plt.hist(merged_df['Absolute Error'], 50)\n",
    "plt.xlabel('Abs Error')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['%Error'] = np.abs((merged_df['Truth'] - merged_df['Predicted'])) / merged_df['Truth'] * 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Fetal Saturation</th>\n",
       "      <th>Maternal Saturation</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Absolute Error</th>\n",
       "      <th>%Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46328</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.017649</td>\n",
       "      <td>0.339005</td>\n",
       "      <td>0.012351</td>\n",
       "      <td>-41.170661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7687</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.032994</td>\n",
       "      <td>0.320308</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>-26.679479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71857</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.032994</td>\n",
       "      <td>0.320308</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>-26.679479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24623</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.032994</td>\n",
       "      <td>0.320308</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>-26.679479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29121</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.018112</td>\n",
       "      <td>0.314073</td>\n",
       "      <td>0.011888</td>\n",
       "      <td>-39.627858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48699</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.018160</td>\n",
       "      <td>0.311530</td>\n",
       "      <td>0.011840</td>\n",
       "      <td>-39.467060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67643</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.018160</td>\n",
       "      <td>0.311530</td>\n",
       "      <td>0.011840</td>\n",
       "      <td>-39.467060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84820</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.018160</td>\n",
       "      <td>0.311530</td>\n",
       "      <td>0.011840</td>\n",
       "      <td>-39.467060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95158</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.018160</td>\n",
       "      <td>0.311530</td>\n",
       "      <td>0.011840</td>\n",
       "      <td>-39.467060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86702</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.018318</td>\n",
       "      <td>0.303258</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>-38.939567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119336</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.018318</td>\n",
       "      <td>0.303258</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>-38.939567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94362</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.033366</td>\n",
       "      <td>0.300753</td>\n",
       "      <td>0.011634</td>\n",
       "      <td>-25.852260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52190</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.033385</td>\n",
       "      <td>0.299804</td>\n",
       "      <td>0.011615</td>\n",
       "      <td>-25.811473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61363</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.033461</td>\n",
       "      <td>0.295906</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>-25.643122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57455</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.033461</td>\n",
       "      <td>0.295906</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>-25.643122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3406</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.018479</td>\n",
       "      <td>0.294970</td>\n",
       "      <td>0.011521</td>\n",
       "      <td>-38.403804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97330</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.018479</td>\n",
       "      <td>0.294970</td>\n",
       "      <td>0.011521</td>\n",
       "      <td>-38.403804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62020</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.071394</td>\n",
       "      <td>0.288495</td>\n",
       "      <td>0.011394</td>\n",
       "      <td>18.989963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32250</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.018699</td>\n",
       "      <td>0.283787</td>\n",
       "      <td>0.011301</td>\n",
       "      <td>-37.668738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68590</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.018710</td>\n",
       "      <td>0.283242</td>\n",
       "      <td>0.011290</td>\n",
       "      <td>-37.632542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36123</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.018710</td>\n",
       "      <td>0.283242</td>\n",
       "      <td>0.011290</td>\n",
       "      <td>-37.632542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63274</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.056223</td>\n",
       "      <td>0.279922</td>\n",
       "      <td>0.011223</td>\n",
       "      <td>24.940888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.033944</td>\n",
       "      <td>0.271633</td>\n",
       "      <td>0.011056</td>\n",
       "      <td>-24.568855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59875</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.019029</td>\n",
       "      <td>0.267467</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>-36.569624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89220</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.019029</td>\n",
       "      <td>0.267467</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>-36.569624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18028</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034209</td>\n",
       "      <td>0.258785</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>-23.980782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48550</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034209</td>\n",
       "      <td>0.258785</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>-23.980782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51172</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.004226</td>\n",
       "      <td>0.257948</td>\n",
       "      <td>0.010774</td>\n",
       "      <td>-71.825877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39658</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.004226</td>\n",
       "      <td>0.257948</td>\n",
       "      <td>0.010774</td>\n",
       "      <td>-71.825877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.019251</td>\n",
       "      <td>0.256770</td>\n",
       "      <td>0.010749</td>\n",
       "      <td>-35.830840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34652</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.019251</td>\n",
       "      <td>0.256770</td>\n",
       "      <td>0.010749</td>\n",
       "      <td>-35.830840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78327</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034251</td>\n",
       "      <td>0.256749</td>\n",
       "      <td>0.010749</td>\n",
       "      <td>-23.886272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91155</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.019301</td>\n",
       "      <td>0.254362</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>-35.662481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36585</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.019301</td>\n",
       "      <td>0.254362</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>-35.662481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3150</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034312</td>\n",
       "      <td>0.253854</td>\n",
       "      <td>0.010688</td>\n",
       "      <td>-23.751223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.019403</td>\n",
       "      <td>0.249554</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>-35.323814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112670</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.900</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034481</td>\n",
       "      <td>0.245887</td>\n",
       "      <td>0.010519</td>\n",
       "      <td>-23.375514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70983</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.900</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034481</td>\n",
       "      <td>0.245887</td>\n",
       "      <td>0.010519</td>\n",
       "      <td>-23.375514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97370</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.900</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034481</td>\n",
       "      <td>0.245887</td>\n",
       "      <td>0.010519</td>\n",
       "      <td>-23.375514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66961</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.040457</td>\n",
       "      <td>0.243002</td>\n",
       "      <td>0.010457</td>\n",
       "      <td>34.856970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91714</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.040457</td>\n",
       "      <td>0.243002</td>\n",
       "      <td>0.010457</td>\n",
       "      <td>34.856970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54693</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.019595</td>\n",
       "      <td>0.240610</td>\n",
       "      <td>0.010405</td>\n",
       "      <td>-34.684977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23140</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.019595</td>\n",
       "      <td>0.240610</td>\n",
       "      <td>0.010405</td>\n",
       "      <td>-34.684977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26518</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.900</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034619</td>\n",
       "      <td>0.239461</td>\n",
       "      <td>0.010381</td>\n",
       "      <td>-23.068061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57429</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034643</td>\n",
       "      <td>0.238357</td>\n",
       "      <td>0.010357</td>\n",
       "      <td>-23.014816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13190</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.975</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034656</td>\n",
       "      <td>0.237761</td>\n",
       "      <td>0.010344</td>\n",
       "      <td>-22.986049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90452</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.975</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034656</td>\n",
       "      <td>0.237761</td>\n",
       "      <td>0.010344</td>\n",
       "      <td>-22.986049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117757</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034709</td>\n",
       "      <td>0.235342</td>\n",
       "      <td>0.010291</td>\n",
       "      <td>-22.868786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66346</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.975</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.019719</td>\n",
       "      <td>0.234875</td>\n",
       "      <td>0.010281</td>\n",
       "      <td>-34.269156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21540</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.975</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.019719</td>\n",
       "      <td>0.234875</td>\n",
       "      <td>0.010281</td>\n",
       "      <td>-34.269156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Maternal Wall Thickness  Fetal Saturation  Maternal Saturation  Truth  \\\n",
       "46328                       4.0             0.600                1.000 -0.030   \n",
       "7687                        4.0             0.600                1.000 -0.045   \n",
       "71857                       4.0             0.600                1.000 -0.045   \n",
       "24623                       4.0             0.600                1.000 -0.045   \n",
       "29121                       4.0             0.600                1.000 -0.030   \n",
       "48699                       4.0             0.475                1.000 -0.030   \n",
       "67643                       4.0             0.475                1.000 -0.030   \n",
       "84820                       4.0             0.475                1.000 -0.030   \n",
       "95158                       4.0             0.475                1.000 -0.030   \n",
       "86702                       4.0             0.600                1.000 -0.030   \n",
       "119336                      4.0             0.600                1.000 -0.030   \n",
       "94362                       4.0             0.600                1.000 -0.045   \n",
       "52190                       4.0             0.475                1.000 -0.045   \n",
       "61363                       4.0             0.600                1.000 -0.045   \n",
       "57455                       4.0             0.600                1.000 -0.045   \n",
       "3406                        4.0             0.475                1.000 -0.030   \n",
       "97330                       4.0             0.475                1.000 -0.030   \n",
       "62020                       6.0             0.475                1.000  0.060   \n",
       "32250                       4.0             0.350                1.000 -0.030   \n",
       "68590                       4.0             0.475                1.000 -0.030   \n",
       "36123                       4.0             0.475                1.000 -0.030   \n",
       "63274                       6.0             0.600                1.000  0.045   \n",
       "5949                        4.0             0.600                1.000 -0.045   \n",
       "59875                       4.0             0.350                1.000 -0.030   \n",
       "89220                       4.0             0.350                1.000 -0.030   \n",
       "18028                       4.0             0.350                1.000 -0.045   \n",
       "48550                       4.0             0.350                1.000 -0.045   \n",
       "51172                      10.0             0.600                1.000 -0.015   \n",
       "39658                      10.0             0.600                1.000 -0.015   \n",
       "2238                        4.0             0.225                1.000 -0.030   \n",
       "34652                       4.0             0.225                1.000 -0.030   \n",
       "78327                       4.0             0.475                1.000 -0.045   \n",
       "91155                       4.0             0.475                1.000 -0.030   \n",
       "36585                       4.0             0.475                1.000 -0.030   \n",
       "3150                        4.0             0.475                1.000 -0.045   \n",
       "4559                       10.0             0.475                1.000 -0.030   \n",
       "112670                      4.0             0.600                0.900 -0.045   \n",
       "70983                       4.0             0.600                0.900 -0.045   \n",
       "97370                       4.0             0.600                0.900 -0.045   \n",
       "66961                       4.0             0.225                1.000  0.030   \n",
       "91714                       4.0             0.225                1.000  0.030   \n",
       "54693                       4.0             0.225                1.000 -0.030   \n",
       "23140                       4.0             0.225                1.000 -0.030   \n",
       "26518                       6.0             0.100                0.900 -0.045   \n",
       "57429                       4.0             0.350                1.000 -0.045   \n",
       "13190                       4.0             0.600                0.975 -0.045   \n",
       "90452                       4.0             0.600                0.975 -0.045   \n",
       "117757                     10.0             0.600                1.000 -0.045   \n",
       "66346                       4.0             0.600                0.975 -0.030   \n",
       "21540                       4.0             0.600                0.975 -0.030   \n",
       "\n",
       "        Predicted  Train Error  Absolute Error     %Error  \n",
       "46328   -0.017649     0.339005        0.012351 -41.170661  \n",
       "7687    -0.032994     0.320308        0.012006 -26.679479  \n",
       "71857   -0.032994     0.320308        0.012006 -26.679479  \n",
       "24623   -0.032994     0.320308        0.012006 -26.679479  \n",
       "29121   -0.018112     0.314073        0.011888 -39.627858  \n",
       "48699   -0.018160     0.311530        0.011840 -39.467060  \n",
       "67643   -0.018160     0.311530        0.011840 -39.467060  \n",
       "84820   -0.018160     0.311530        0.011840 -39.467060  \n",
       "95158   -0.018160     0.311530        0.011840 -39.467060  \n",
       "86702   -0.018318     0.303258        0.011682 -38.939567  \n",
       "119336  -0.018318     0.303258        0.011682 -38.939567  \n",
       "94362   -0.033366     0.300753        0.011634 -25.852260  \n",
       "52190   -0.033385     0.299804        0.011615 -25.811473  \n",
       "61363   -0.033461     0.295906        0.011539 -25.643122  \n",
       "57455   -0.033461     0.295906        0.011539 -25.643122  \n",
       "3406    -0.018479     0.294970        0.011521 -38.403804  \n",
       "97330   -0.018479     0.294970        0.011521 -38.403804  \n",
       "62020    0.071394     0.288495        0.011394  18.989963  \n",
       "32250   -0.018699     0.283787        0.011301 -37.668738  \n",
       "68590   -0.018710     0.283242        0.011290 -37.632542  \n",
       "36123   -0.018710     0.283242        0.011290 -37.632542  \n",
       "63274    0.056223     0.279922        0.011223  24.940888  \n",
       "5949    -0.033944     0.271633        0.011056 -24.568855  \n",
       "59875   -0.019029     0.267467        0.010971 -36.569624  \n",
       "89220   -0.019029     0.267467        0.010971 -36.569624  \n",
       "18028   -0.034209     0.258785        0.010791 -23.980782  \n",
       "48550   -0.034209     0.258785        0.010791 -23.980782  \n",
       "51172   -0.004226     0.257948        0.010774 -71.825877  \n",
       "39658   -0.004226     0.257948        0.010774 -71.825877  \n",
       "2238    -0.019251     0.256770        0.010749 -35.830840  \n",
       "34652   -0.019251     0.256770        0.010749 -35.830840  \n",
       "78327   -0.034251     0.256749        0.010749 -23.886272  \n",
       "91155   -0.019301     0.254362        0.010699 -35.662481  \n",
       "36585   -0.019301     0.254362        0.010699 -35.662481  \n",
       "3150    -0.034312     0.253854        0.010688 -23.751223  \n",
       "4559    -0.019403     0.249554        0.010597 -35.323814  \n",
       "112670  -0.034481     0.245887        0.010519 -23.375514  \n",
       "70983   -0.034481     0.245887        0.010519 -23.375514  \n",
       "97370   -0.034481     0.245887        0.010519 -23.375514  \n",
       "66961    0.040457     0.243002        0.010457  34.856970  \n",
       "91714    0.040457     0.243002        0.010457  34.856970  \n",
       "54693   -0.019595     0.240610        0.010405 -34.684977  \n",
       "23140   -0.019595     0.240610        0.010405 -34.684977  \n",
       "26518   -0.034619     0.239461        0.010381 -23.068061  \n",
       "57429   -0.034643     0.238357        0.010357 -23.014816  \n",
       "13190   -0.034656     0.237761        0.010344 -22.986049  \n",
       "90452   -0.034656     0.237761        0.010344 -22.986049  \n",
       "117757  -0.034709     0.235342        0.010291 -22.868786  \n",
       "66346   -0.019719     0.234875        0.010281 -34.269156  \n",
       "21540   -0.019719     0.234875        0.010281 -34.269156  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Top Bad Samples\n",
    "VIEW_TOP_N = 50\n",
    "worst_errors = merged_df['Absolute Error'].argsort()[::-1][:VIEW_TOP_N]\n",
    "# worst_errors = merged_df['%Error'].argsort()[::-1][:VIEW_TOP_N]\n",
    "with pd.option_context(\"display.max_rows\", None):\n",
    "    display(merged_df.iloc[worst_errors, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error(non-normalized): [1.80640053e-05]\n",
      "Validation Error(non-normalized): [1.6354547e-05]\n"
     ]
    }
   ],
   "source": [
    "# Rough MSE's in percentage\n",
    "print(f'Train Error(non-normalized): {train_loss[-1] * y_scaler.var_ }')\n",
    "print(f'Validation Error(non-normalized): {validation_loss[-1] * y_scaler.var_ }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "SplitChannelCNN                          --\n",
       "├─Conv1d: 1-1                            64\n",
       "├─Sequential: 1-2                        --\n",
       "│    └─Linear: 2-1                       452\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─Linear: 2-3                       10\n",
       "│    └─ReLU: 2-4                         --\n",
       "│    └─Linear: 2-5                       3\n",
       "│    └─Flatten: 2-6                      --\n",
       "=================================================================\n",
       "Total params: 529\n",
       "Trainable params: 529\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Info\n",
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.000    20066\n",
       " 0.015    20040\n",
       "-0.015    19861\n",
       " 0.030    15047\n",
       "-0.030    14954\n",
       " 0.045    10044\n",
       "-0.045     9947\n",
       "-0.060     5037\n",
       " 0.060     5004\n",
       "Name: Truth, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['Truth'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybercat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
