{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from inverse_modelling_tfo.models import train_model, create_perceptron_model, train_model_wtih_reporting\n",
    "from inverse_modelling_tfo.data import generate_data_loaders, equidistance_detector_normalization, constant_detector_count_normalization\n",
    "from inverse_modelling_tfo.data.intensity_interpolation import get_interpolate_fit_params_custom, interpolate_exp\n",
    "from inverse_modelling_tfo.data.interpolation_function_zoo import *\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import os\n",
    "\n",
    "# Set my GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "data = pd.read_pickle(\n",
    "    r'/home/rraiyan/personal_projects/tfo_inverse_modelling/data/intensity/s_based_intensity.pkl')\n",
    "equidistance_detector_normalization(data)\n",
    "\n",
    "# Interpolate intensity to remove noise\n",
    "data = interpolate_exp(data, weights=[1, 1])\n",
    "data['Intensity'] = data['Interpolated Intensity']\n",
    "\n",
    "# Far values wayy to small to affect anything. Take log\n",
    "data['Intensity'] = np.log10(data['Intensity'])\n",
    "data.head()\n",
    "\n",
    "data = pd.pivot(data, index=['Maternal Wall Thickness', \"Maternal Hb Concentration\", \"Maternal Saturation\",\n",
    "                \"Fetal Hb Concentration\", \"Fetal Saturation\"], columns=[\"SDD\", \"Wave Int\"], values=\"Intensity\").reset_index()\n",
    "# Slight coding mistake, not all waveints have both wv1 and 2\n",
    "data.dropna(inplace=True)\n",
    "data.head()\n",
    "\n",
    "# Rename multi-index columns\n",
    "data.columns = ['_'.join([str(col[0]), str(col[1])])\n",
    "                if col[1] != '' else col[0] for col in data.columns]\n",
    "# y_columns = ['Maternal Wall Thickness', \"Maternal Hb Concentration\", \"Maternal Saturation\", \"Fetal Hb Concentration\", \"Fetal Saturation\"]\n",
    "y_columns = ['Fetal Saturation']\n",
    "x_columns = list(filter(lambda X: '_' in X, data.columns))\n",
    "\n",
    "# filtered_fitting_param_table = fitting_param_table[fitting_param_table['Wave Int'] == 2.0]\n",
    "# x_scaler = preprocessing.StandardScaler()\n",
    "y_scaler = preprocessing.StandardScaler()\n",
    "data[y_columns] = y_scaler.fit_transform(data[y_columns])\n",
    "\n",
    "# Manual log(intensity) normalization\n",
    "# stddev.   (Actual value is higher but let's keep it here for now)\n",
    "data[x_columns] /= 100.0\n",
    "data[x_columns] += 0.5  # unit var : mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(70)  # Set seed for consistentcy\n",
    "params = {\n",
    "    'batch_size': 32, 'shuffle': True, 'num_workers': 2\n",
    "}\n",
    "train, val = generate_data_loaders(data, params, x_columns, y_columns, 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv1d(20, 4, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 4, 5)\n",
    "        self.fc1 = nn.Linear(10, 2)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x1 = F.relu(self.conv1(x[:, :20]))\n",
    "        x2 = F.relu(self.conv2(x[:, 20:]))\n",
    "\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # flatten all dimensions except the batch dimension\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train:\n",
    "    a = i\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 20])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.view(-1, 2, 20)\n",
    "a.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv1d(2, 4, 5, groups=2)\n",
    "x = F.relu(conv(a))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nn.Flatten()(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoChannelCNN(nn.Module):\n",
    "    \"\"\"A 2 channel based CNN connected to a set of FC layers. The 2 input channels of the CNN each \n",
    "    take half of the inputs. (Say if [input_length] is 40, one channel would get the first 20 and \n",
    "    the next 20 would be fed to another channel). The CNN Outputs onto [cnn_out_channel] number of \n",
    "    output channels. (NOTE: cnn_out_channel has to be divisible by 2. The first half of out channle \n",
    "    only  see the first half of the inputs and the second half see the second half of the inputs)\n",
    "    \n",
    "    Afterwards, they are connected to a set of linear layers with activations. The output length for\n",
    "    each of these linear layers are supploed using [linear_array]\n",
    "    \"\"\"\n",
    "    def __init__(self, input_length, cnn_out_channel, kernel_size, linear_array) -> None:\n",
    "        assert cnn_out_channel % 2 == 0, \"cnn_out_channel has to be divisible by 2\"\n",
    "        super().__init__()\n",
    "        self.split_point = input_length//2\n",
    "        self.conv1 = nn.Conv1d(2, cnn_out_channel, kernel_size, groups=2)\n",
    "        self.conv_output_length = cnn_out_channel * (self.split_point + 1 - kernel_size)\n",
    "        self.linear_layers = [nn.Linear(self.conv_output_length, linear_array[0])]\n",
    "        for index, count in enumerate(linear_array[0:-1]):\n",
    "            self.linear_layers.append(nn.ReLU())\n",
    "            self.linear_layers.append(nn.Linear(count, linear_array[index + 1]))\n",
    "        self.linear_layers.append(nn.Flatten())\n",
    "        self.linear_network = nn.Sequential(*self.linear_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 2, self.split_point)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.linear_network(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoChannelCNN(40, 4, 5, [4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybercat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
