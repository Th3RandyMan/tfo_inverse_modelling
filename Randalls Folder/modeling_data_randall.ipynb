{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set my GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35929014, 47)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Fetal Radius</th>\n",
       "      <th>Fetal Displacement</th>\n",
       "      <th>Maternal Hb Concentration</th>\n",
       "      <th>Maternal Saturation</th>\n",
       "      <th>Fetal Hb Concentration</th>\n",
       "      <th>Fetal Saturation</th>\n",
       "      <th>10.0_1.0</th>\n",
       "      <th>15.0_1.0</th>\n",
       "      <th>19.0_1.0</th>\n",
       "      <th>...</th>\n",
       "      <th>55.0_2.0</th>\n",
       "      <th>59.0_2.0</th>\n",
       "      <th>64.0_2.0</th>\n",
       "      <th>68.0_2.0</th>\n",
       "      <th>72.0_2.0</th>\n",
       "      <th>77.0_2.0</th>\n",
       "      <th>81.0_2.0</th>\n",
       "      <th>86.0_2.0</th>\n",
       "      <th>90.0_2.0</th>\n",
       "      <th>94.0_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43923</th>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10.725</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>6.001589e-15</td>\n",
       "      <td>5.848743e-15</td>\n",
       "      <td>2.763929e-16</td>\n",
       "      <td>1.500358e-17</td>\n",
       "      <td>3.398607e-18</td>\n",
       "      <td>1.015295e-18</td>\n",
       "      <td>7.130597e-20</td>\n",
       "      <td>8.710054e-22</td>\n",
       "      <td>4.012456e-20</td>\n",
       "      <td>2.355748e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43924</th>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10.725</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>5.893694e-15</td>\n",
       "      <td>5.768395e-15</td>\n",
       "      <td>2.710312e-16</td>\n",
       "      <td>1.463642e-17</td>\n",
       "      <td>3.212955e-18</td>\n",
       "      <td>9.575111e-19</td>\n",
       "      <td>6.831444e-20</td>\n",
       "      <td>8.155644e-22</td>\n",
       "      <td>3.835888e-20</td>\n",
       "      <td>2.151092e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43925</th>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10.725</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>5.789363e-15</td>\n",
       "      <td>5.689761e-15</td>\n",
       "      <td>2.658178e-16</td>\n",
       "      <td>1.428727e-17</td>\n",
       "      <td>3.039417e-18</td>\n",
       "      <td>9.030257e-19</td>\n",
       "      <td>6.545149e-20</td>\n",
       "      <td>7.646231e-22</td>\n",
       "      <td>3.667090e-20</td>\n",
       "      <td>1.964215e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43926</th>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10.725</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>5.688417e-15</td>\n",
       "      <td>5.612798e-15</td>\n",
       "      <td>2.607455e-16</td>\n",
       "      <td>1.395518e-17</td>\n",
       "      <td>2.877101e-18</td>\n",
       "      <td>8.516513e-19</td>\n",
       "      <td>6.271132e-20</td>\n",
       "      <td>7.177746e-22</td>\n",
       "      <td>3.505719e-20</td>\n",
       "      <td>1.793575e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43927</th>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10.725</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>5.590720e-15</td>\n",
       "      <td>5.537444e-15</td>\n",
       "      <td>2.558081e-16</td>\n",
       "      <td>1.363931e-17</td>\n",
       "      <td>2.725183e-18</td>\n",
       "      <td>8.032090e-19</td>\n",
       "      <td>6.008842e-20</td>\n",
       "      <td>6.746510e-22</td>\n",
       "      <td>3.351450e-20</td>\n",
       "      <td>1.637759e-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Maternal Wall Thickness  Fetal Radius  Fetal Displacement  \\\n",
       "43923                      2.0          50.0                 5.0   \n",
       "43924                      2.0          50.0                 5.0   \n",
       "43925                      2.0          50.0                 5.0   \n",
       "43926                      2.0          50.0                 5.0   \n",
       "43927                      2.0          50.0                 5.0   \n",
       "\n",
       "       Maternal Hb Concentration  Maternal Saturation  Fetal Hb Concentration  \\\n",
       "43923                       11.0                  0.9                  10.725   \n",
       "43924                       11.0                  0.9                  10.725   \n",
       "43925                       11.0                  0.9                  10.725   \n",
       "43926                       11.0                  0.9                  10.725   \n",
       "43927                       11.0                  0.9                  10.725   \n",
       "\n",
       "       Fetal Saturation  10.0_1.0  15.0_1.0  19.0_1.0  ...      55.0_2.0  \\\n",
       "43923              0.10  0.000041  0.000005  0.000001  ...  6.001589e-15   \n",
       "43924              0.15  0.000041  0.000005  0.000001  ...  5.893694e-15   \n",
       "43925              0.20  0.000041  0.000005  0.000001  ...  5.789363e-15   \n",
       "43926              0.25  0.000041  0.000005  0.000001  ...  5.688417e-15   \n",
       "43927              0.30  0.000041  0.000005  0.000001  ...  5.590720e-15   \n",
       "\n",
       "           59.0_2.0      64.0_2.0      68.0_2.0      72.0_2.0      77.0_2.0  \\\n",
       "43923  5.848743e-15  2.763929e-16  1.500358e-17  3.398607e-18  1.015295e-18   \n",
       "43924  5.768395e-15  2.710312e-16  1.463642e-17  3.212955e-18  9.575111e-19   \n",
       "43925  5.689761e-15  2.658178e-16  1.428727e-17  3.039417e-18  9.030257e-19   \n",
       "43926  5.612798e-15  2.607455e-16  1.395518e-17  2.877101e-18  8.516513e-19   \n",
       "43927  5.537444e-15  2.558081e-16  1.363931e-17  2.725183e-18  8.032090e-19   \n",
       "\n",
       "           81.0_2.0      86.0_2.0      90.0_2.0      94.0_2.0  \n",
       "43923  7.130597e-20  8.710054e-22  4.012456e-20  2.355748e-22  \n",
       "43924  6.831444e-20  8.155644e-22  3.835888e-20  2.151092e-22  \n",
       "43925  6.545149e-20  7.646231e-22  3.667090e-20  1.964215e-22  \n",
       "43926  6.271132e-20  7.177746e-22  3.505719e-20  1.793575e-22  \n",
       "43927  6.008842e-20  6.746510e-22  3.351450e-20  1.637759e-22  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = r'/home/rlfowler/Documents/research/tfo_inverse_modelling/Randalls Folder/data/randall_data_intensities.pkl'\n",
    "#CONFIG_PATH = r'/home/rlfowler/Documents/research/tfo_sim/data/compiled_intensity/randall_data.json'\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_pickle(DATA_PATH)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "## Scale y\n",
    "from sklearn import preprocessing\n",
    "\n",
    "y_columns = data.columns[:7]#[\"Fetal Saturation\"]\n",
    "x_columns = data.columns[7:]\n",
    "\n",
    "y_scaler = preprocessing.StandardScaler()\n",
    "data[y_columns] = y_scaler.fit_transform(data[y_columns])\n",
    "\n",
    "x_scaler = preprocessing.StandardScaler()\n",
    "data[x_columns] = x_scaler.fit_transform(data[x_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def filter_data(data):\n",
    "    columns = ['Fetal Hb Concentration', 'Fetal Radius', 'Maternal Saturation', 'Maternal Hb Concentration']\n",
    "    to_keep = [np.unique(data['Fetal Hb Concentration'])[1::3],\\\n",
    "                    np.unique(data['Fetal Radius'])[:11],\\\n",
    "                    np.unique(data['Maternal Saturation'])[::2],\\\n",
    "                    np.unique(data['Maternal Hb Concentration'])[::2]]\n",
    "    for col, keep in zip(columns, to_keep):\n",
    "        data = data.loc[data[col].isin(keep)]\n",
    "    return data\n",
    "\n",
    "data = filter_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (1407859, 47)\n",
      "Test data shape: (351965, 47)\n",
      "x_train columns: ['10.0_1.0', '15.0_1.0', '19.0_1.0', '24.0_1.0', '28.0_1.0', '33.0_1.0', '37.0_1.0', '41.0_1.0', '46.0_1.0', '50.0_1.0', '55.0_1.0', '59.0_1.0', '64.0_1.0', '68.0_1.0', '72.0_1.0', '77.0_1.0', '81.0_1.0', '86.0_1.0', '90.0_1.0', '94.0_1.0', '10.0_2.0', '15.0_2.0', '19.0_2.0', '24.0_2.0', '28.0_2.0', '33.0_2.0', '37.0_2.0', '41.0_2.0', '46.0_2.0', '50.0_2.0', '55.0_2.0', '59.0_2.0', '64.0_2.0', '68.0_2.0', '72.0_2.0', '77.0_2.0', '81.0_2.0', '86.0_2.0', '90.0_2.0', '94.0_2.0']\n",
      "y_train columns: ['Maternal Wall Thickness', 'Fetal Radius', 'Fetal Displacement', 'Maternal Hb Concentration', 'Maternal Saturation', 'Fetal Hb Concentration', 'Fetal Saturation']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42    # Set the random seed for reproducibility\n",
    "#SAMPLE_SIZE = 0.05   # Set the sample size from the data\n",
    "TEST_SIZE = 0.2     # Set the test size for the train/test split\n",
    "\n",
    "# Split the data into training and testing sets # Might want to remove randomness for param selection\n",
    "#train_data, test_data = train_test_split(data.sample(frac=SAMPLE_SIZE, random_state=RANDOM_SEED) , test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "train_data, test_data = train_test_split(data, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "print(f\"Train data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "# Split the data into input and output\n",
    "x_train = train_data.iloc[:, 7:]\n",
    "x_test = test_data.iloc[:, 7:]\n",
    "y_train = train_data.iloc[:,:7]\n",
    "y_test = test_data.iloc[:,:7]\n",
    "print(f\"x_train columns: {x_train.columns.tolist()}\")\n",
    "print(f\"y_train columns: {y_train.columns.tolist()}\")\n",
    "\n",
    "del data, train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "BATCH_SIZE = 32 #128, 32\n",
    "\n",
    "\n",
    "# Create a dataloader\n",
    "train_dataset = TensorDataset(torch.tensor(x_train.values, dtype=torch.float32).cuda(), torch.tensor(y_train.values, dtype=torch.float32).cuda())\n",
    "test_dataset = TensorDataset(torch.tensor(x_test.values, dtype=torch.float32).cuda(), torch.tensor(y_test.values, dtype=torch.float32).cuda())\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "from typing import Optional, List\n",
    "from torch.optim import SGD, Optimizer\n",
    "\n",
    "\n",
    "# Create a neural network\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    layers: List[nn.Module] = []     # List of layers\n",
    "    model: nn.Module            # The model\n",
    "    training_loss: List[float] = []  # Training loss\n",
    "    validation_loss: List[float] = []# Validation loss\n",
    "\n",
    "    def __init__(self, node_count: List[int], dropout_rates: Optional[List[float]]):\n",
    "        super(Net, self).__init__()\n",
    "        #self.layers = []\n",
    "        for indx, n_nodes in enumerate(node_count[:-2]):\n",
    "            self.layers.append(nn.Linear(n_nodes, node_count[indx+1]))\n",
    "            self.layers.append(nn.BatchNorm1d(node_count[indx+1]))\n",
    "            if dropout_rates:\n",
    "                self.layers.append(nn.Dropout(dropout_rates[indx]))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Linear(node_count[-2], node_count[-1]))   # Output layer\n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "        self.model.cuda()\n",
    "\n",
    "    def _default_optimizer(self):\n",
    "        return SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def run(self, train_loader: DataLoader, criterion:nn.Module = nn.MSELoss(), optimizer:Optimizer = None, n_epochs:int = 1, verbose:bool = False):\n",
    "        if optimizer is None:\n",
    "            optimizer = self._default_optimizer()\n",
    "        batch_size = train_loader.batch_size\n",
    "\n",
    "        self.model.train()  # Set the model to training mode\n",
    "        print(\"Starting training...\")\n",
    "        print(f\"Length of train_loader: {len(train_loader)}\")\n",
    "        for epoch in range(n_epochs):\n",
    "            running_loss = 0.0\n",
    "            for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "                #batch_x = batch_x.cuda()    # Send the data to the GPU\n",
    "                #batch_y = batch_y.cuda()    # Send the data to the GPU\n",
    "\n",
    "                output = self.forward(batch_x)                      # Forward pass\n",
    "                loss = criterion(output, batch_y)                   # Compute the loss\n",
    "                optimizer.zero_grad()                               # Zero the gradients to prevent accumulation\n",
    "                loss.backward()                                     # Backpropagation to compute the gradients                   \n",
    "                optimizer.step()                                    # Update the weights, apply gradients        \n",
    "\n",
    "                running_loss += loss.item()                         # Add the loss to the running loss\n",
    "\n",
    "                if verbose and step % batch_size == 0:                    # Print stats every 100 steps\n",
    "                    print(f\"Epoch: {epoch}, Step: {step}, Loss: {loss.item()}\")\n",
    "                    # accuracy = torch.sum(torch.abs(output - batch_y) < 0.1).item() / len(batch_y)\n",
    "                    # print(f\"Epoch: {epoch}, Loss: {loss.item()}, Accuracy: {accuracy}\")\n",
    "            self.training_loss.append(running_loss/len(train_loader))  # Append the average loss to the training loss list\n",
    "\n",
    "    def predict(self, test_loader, criterion:nn.Module = nn.MSELoss(), verbose=False):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        accuracy = 0.0\n",
    "        print(\"Starting prediction...\")\n",
    "        for step, (batch_x, batch_y) in enumerate(test_loader):\n",
    "            # Send the data to the GPU\n",
    "            #batch_x = batch_x.cuda()\n",
    "            #batch_y = batch_y.cuda()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = self.model(batch_x)\n",
    "                loss = criterion(output, batch_y)\n",
    "\n",
    "            # acc = torch.sum(torch.abs(output - batch_y) < 0.1).item() / len(batch_y)\n",
    "            # accuracy += acc\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Loss: {loss.item()}\")#, Accuracy: {acc}\")\n",
    "\n",
    "        accuracy /= len(test_loader)\n",
    "        running_loss /= len(test_loader)\n",
    "        self.validation_loss.append(running_loss)\n",
    "        return running_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Length of train_loader: 43996\n",
      "Epoch: 0, Step: 0, Loss: 1.2953734397888184\n",
      "Epoch: 0, Step: 32, Loss: 0.9770078659057617\n",
      "Epoch: 0, Step: 64, Loss: 1.136893630027771\n",
      "Epoch: 0, Step: 96, Loss: 1.007989525794983\n",
      "Epoch: 0, Step: 128, Loss: 1.0868791341781616\n",
      "Epoch: 0, Step: 160, Loss: 1.0777969360351562\n",
      "Epoch: 0, Step: 192, Loss: 1.0202486515045166\n",
      "Epoch: 0, Step: 224, Loss: 1.0629528760910034\n",
      "Epoch: 0, Step: 256, Loss: 1.0275259017944336\n",
      "Epoch: 0, Step: 288, Loss: 0.9475487470626831\n",
      "Epoch: 0, Step: 320, Loss: 0.9933896064758301\n",
      "Epoch: 0, Step: 352, Loss: 0.9878978729248047\n",
      "Epoch: 0, Step: 384, Loss: 0.9785196185112\n",
      "Epoch: 0, Step: 416, Loss: 0.8516818881034851\n",
      "Epoch: 0, Step: 448, Loss: 0.8434614539146423\n",
      "Epoch: 0, Step: 480, Loss: 0.8524653911590576\n",
      "Epoch: 0, Step: 512, Loss: 0.8572748303413391\n",
      "Epoch: 0, Step: 544, Loss: 0.9810054302215576\n",
      "Epoch: 0, Step: 576, Loss: 0.8687493801116943\n",
      "Epoch: 0, Step: 608, Loss: 0.900434672832489\n",
      "Epoch: 0, Step: 640, Loss: 0.9553624391555786\n",
      "Epoch: 0, Step: 672, Loss: 0.8648012280464172\n",
      "Epoch: 0, Step: 704, Loss: 0.9676863551139832\n",
      "Epoch: 0, Step: 736, Loss: 0.8374016880989075\n",
      "Epoch: 0, Step: 768, Loss: 0.7498840689659119\n",
      "Epoch: 0, Step: 800, Loss: 0.8932438492774963\n",
      "Epoch: 0, Step: 832, Loss: 0.8465162515640259\n",
      "Epoch: 0, Step: 864, Loss: 0.8458613753318787\n",
      "Epoch: 0, Step: 896, Loss: 0.8253125548362732\n",
      "Epoch: 0, Step: 928, Loss: 0.8771913647651672\n",
      "Epoch: 0, Step: 960, Loss: 0.8446162939071655\n",
      "Epoch: 0, Step: 992, Loss: 0.7924763560295105\n",
      "Epoch: 0, Step: 1024, Loss: 0.7214521765708923\n",
      "Epoch: 0, Step: 1056, Loss: 0.7774228453636169\n",
      "Epoch: 0, Step: 1088, Loss: 0.8635329008102417\n",
      "Epoch: 0, Step: 1120, Loss: 0.8007732033729553\n",
      "Epoch: 0, Step: 1152, Loss: 0.9136698842048645\n",
      "Epoch: 0, Step: 1184, Loss: 0.8399817943572998\n",
      "Epoch: 0, Step: 1216, Loss: 0.883276641368866\n",
      "Epoch: 0, Step: 1248, Loss: 0.8058958649635315\n",
      "Epoch: 0, Step: 1280, Loss: 0.8721791505813599\n",
      "Epoch: 0, Step: 1312, Loss: 0.7254908680915833\n",
      "Epoch: 0, Step: 1344, Loss: 0.7635161280632019\n",
      "Epoch: 0, Step: 1376, Loss: 0.8072581887245178\n",
      "Epoch: 0, Step: 1408, Loss: 0.8498693704605103\n",
      "Epoch: 0, Step: 1440, Loss: 0.8651705384254456\n",
      "Epoch: 0, Step: 1472, Loss: 0.804834246635437\n",
      "Epoch: 0, Step: 1504, Loss: 0.7988387942314148\n",
      "Epoch: 0, Step: 1536, Loss: 0.7741883397102356\n",
      "Epoch: 0, Step: 1568, Loss: 0.8116033673286438\n",
      "Epoch: 0, Step: 1600, Loss: 0.922835648059845\n",
      "Epoch: 0, Step: 1632, Loss: 0.9238207936286926\n",
      "Epoch: 0, Step: 1664, Loss: 0.846282422542572\n",
      "Epoch: 0, Step: 1696, Loss: 0.9297815561294556\n",
      "Epoch: 0, Step: 1728, Loss: 0.8373385071754456\n",
      "Epoch: 0, Step: 1760, Loss: 0.7808915972709656\n",
      "Epoch: 0, Step: 1792, Loss: 0.8500086069107056\n",
      "Epoch: 0, Step: 1824, Loss: 0.9214874505996704\n",
      "Epoch: 0, Step: 1856, Loss: 0.7944682240486145\n",
      "Epoch: 0, Step: 1888, Loss: 0.7673167586326599\n",
      "Epoch: 0, Step: 1920, Loss: 0.8028286695480347\n",
      "Epoch: 0, Step: 1952, Loss: 0.8347416520118713\n",
      "Epoch: 0, Step: 1984, Loss: 0.9016311168670654\n",
      "Epoch: 0, Step: 2016, Loss: 0.7798071503639221\n",
      "Epoch: 0, Step: 2048, Loss: 0.8571529984474182\n",
      "Epoch: 0, Step: 2080, Loss: 0.7203744053840637\n",
      "Epoch: 0, Step: 2112, Loss: 0.8568939566612244\n",
      "Epoch: 0, Step: 2144, Loss: 0.8028390407562256\n",
      "Epoch: 0, Step: 2176, Loss: 0.9421182870864868\n",
      "Epoch: 0, Step: 2208, Loss: 0.8501031398773193\n",
      "Epoch: 0, Step: 2240, Loss: 0.7649276256561279\n",
      "Epoch: 0, Step: 2272, Loss: 0.7963036298751831\n",
      "Epoch: 0, Step: 2304, Loss: 0.7894636392593384\n",
      "Epoch: 0, Step: 2336, Loss: 0.7853678464889526\n",
      "Epoch: 0, Step: 2368, Loss: 0.8205498456954956\n",
      "Epoch: 0, Step: 2400, Loss: 0.7071235179901123\n",
      "Epoch: 0, Step: 2432, Loss: 0.8555044531822205\n",
      "Epoch: 0, Step: 2464, Loss: 0.7403680682182312\n",
      "Epoch: 0, Step: 2496, Loss: 0.8655987977981567\n",
      "Epoch: 0, Step: 2528, Loss: 0.8183189034461975\n",
      "Epoch: 0, Step: 2560, Loss: 0.7999347448348999\n",
      "Epoch: 0, Step: 2592, Loss: 0.788669764995575\n",
      "Epoch: 0, Step: 2624, Loss: 0.8303612470626831\n",
      "Epoch: 0, Step: 2656, Loss: 0.7655546069145203\n",
      "Epoch: 0, Step: 2688, Loss: 0.8644986152648926\n",
      "Epoch: 0, Step: 2720, Loss: 0.7942842245101929\n",
      "Epoch: 0, Step: 2752, Loss: 0.8547829985618591\n",
      "Epoch: 0, Step: 2784, Loss: 0.8374971747398376\n",
      "Epoch: 0, Step: 2816, Loss: 0.8185521960258484\n",
      "Epoch: 0, Step: 2848, Loss: 0.8628932237625122\n",
      "Epoch: 0, Step: 2880, Loss: 0.6675453782081604\n",
      "Epoch: 0, Step: 2912, Loss: 0.7657097578048706\n",
      "Epoch: 0, Step: 2944, Loss: 0.758095383644104\n",
      "Epoch: 0, Step: 2976, Loss: 0.7430485486984253\n",
      "Epoch: 0, Step: 3008, Loss: 0.822247326374054\n",
      "Epoch: 0, Step: 3040, Loss: 0.9755595326423645\n",
      "Epoch: 0, Step: 3072, Loss: 0.7140296697616577\n",
      "Epoch: 0, Step: 3104, Loss: 0.7245190739631653\n",
      "Epoch: 0, Step: 3136, Loss: 0.7209764122962952\n",
      "Epoch: 0, Step: 3168, Loss: 0.7508333921432495\n",
      "Epoch: 0, Step: 3200, Loss: 0.8402227759361267\n",
      "Epoch: 0, Step: 3232, Loss: 0.8172050714492798\n",
      "Epoch: 0, Step: 3264, Loss: 0.7475149035453796\n",
      "Epoch: 0, Step: 3296, Loss: 0.7191822528839111\n",
      "Epoch: 0, Step: 3328, Loss: 0.8495031595230103\n",
      "Epoch: 0, Step: 3360, Loss: 0.7530108094215393\n",
      "Epoch: 0, Step: 3392, Loss: 0.7512630820274353\n",
      "Epoch: 0, Step: 3424, Loss: 0.8594892024993896\n",
      "Epoch: 0, Step: 3456, Loss: 0.7477967739105225\n",
      "Epoch: 0, Step: 3488, Loss: 0.8080240488052368\n",
      "Epoch: 0, Step: 3520, Loss: 0.7733503580093384\n",
      "Epoch: 0, Step: 3552, Loss: 0.8488260507583618\n",
      "Epoch: 0, Step: 3584, Loss: 0.8403635621070862\n",
      "Epoch: 0, Step: 3616, Loss: 0.7450516819953918\n",
      "Epoch: 0, Step: 3648, Loss: 0.836480438709259\n",
      "Epoch: 0, Step: 3680, Loss: 0.8277719020843506\n",
      "Epoch: 0, Step: 3712, Loss: 0.8519647717475891\n",
      "Epoch: 0, Step: 3744, Loss: 0.8387308716773987\n",
      "Epoch: 0, Step: 3776, Loss: 0.7639580368995667\n",
      "Epoch: 0, Step: 3808, Loss: 0.8281367421150208\n",
      "Epoch: 0, Step: 3840, Loss: 0.7378150820732117\n",
      "Epoch: 0, Step: 3872, Loss: 0.7199382185935974\n",
      "Epoch: 0, Step: 3904, Loss: 0.8053604364395142\n",
      "Epoch: 0, Step: 3936, Loss: 0.8444129228591919\n",
      "Epoch: 0, Step: 3968, Loss: 0.7306881546974182\n",
      "Epoch: 0, Step: 4000, Loss: 0.7847344875335693\n",
      "Epoch: 0, Step: 4032, Loss: 0.7528063058853149\n",
      "Epoch: 0, Step: 4064, Loss: 0.763990044593811\n",
      "Epoch: 0, Step: 4096, Loss: 0.7975314855575562\n",
      "Epoch: 0, Step: 4128, Loss: 0.7977033853530884\n",
      "Epoch: 0, Step: 4160, Loss: 0.6883084774017334\n",
      "Epoch: 0, Step: 4192, Loss: 0.7148807048797607\n",
      "Epoch: 0, Step: 4224, Loss: 0.7589975595474243\n",
      "Epoch: 0, Step: 4256, Loss: 0.8039852380752563\n",
      "Epoch: 0, Step: 4288, Loss: 0.7554102540016174\n",
      "Epoch: 0, Step: 4320, Loss: 0.6802027225494385\n",
      "Epoch: 0, Step: 4352, Loss: 0.704445481300354\n",
      "Epoch: 0, Step: 4384, Loss: 0.783623993396759\n",
      "Epoch: 0, Step: 4416, Loss: 0.8881701231002808\n",
      "Epoch: 0, Step: 4448, Loss: 0.719491720199585\n",
      "Epoch: 0, Step: 4480, Loss: 0.8239456415176392\n",
      "Epoch: 0, Step: 4512, Loss: 0.7945705652236938\n",
      "Epoch: 0, Step: 4544, Loss: 0.7565242648124695\n",
      "Epoch: 0, Step: 4576, Loss: 0.7780699133872986\n",
      "Epoch: 0, Step: 4608, Loss: 0.8388745188713074\n",
      "Epoch: 0, Step: 4640, Loss: 0.8085405230522156\n",
      "Epoch: 0, Step: 4672, Loss: 0.8122204542160034\n",
      "Epoch: 0, Step: 4704, Loss: 0.7566483616828918\n",
      "Epoch: 0, Step: 4736, Loss: 0.7985215783119202\n",
      "Epoch: 0, Step: 4768, Loss: 0.72072833776474\n",
      "Epoch: 0, Step: 4800, Loss: 0.7619698643684387\n",
      "Epoch: 0, Step: 4832, Loss: 0.7179518342018127\n",
      "Epoch: 0, Step: 4864, Loss: 0.8300309777259827\n",
      "Epoch: 0, Step: 4896, Loss: 0.7888229489326477\n",
      "Epoch: 0, Step: 4928, Loss: 0.838189959526062\n",
      "Epoch: 0, Step: 4960, Loss: 0.7208487391471863\n",
      "Epoch: 0, Step: 4992, Loss: 0.8019031882286072\n",
      "Epoch: 0, Step: 5024, Loss: 0.7151049375534058\n",
      "Epoch: 0, Step: 5056, Loss: 0.8029232621192932\n",
      "Epoch: 0, Step: 5088, Loss: 0.8278909921646118\n",
      "Epoch: 0, Step: 5120, Loss: 0.8296573162078857\n",
      "Epoch: 0, Step: 5152, Loss: 0.6803887486457825\n",
      "Epoch: 0, Step: 5184, Loss: 0.8754595518112183\n",
      "Epoch: 0, Step: 5216, Loss: 0.8040499091148376\n",
      "Epoch: 0, Step: 5248, Loss: 0.7597773671150208\n",
      "Epoch: 0, Step: 5280, Loss: 0.7957808375358582\n",
      "Epoch: 0, Step: 5312, Loss: 0.7830011248588562\n",
      "Epoch: 0, Step: 5344, Loss: 0.8559419512748718\n",
      "Epoch: 0, Step: 5376, Loss: 0.7794395089149475\n",
      "Epoch: 0, Step: 5408, Loss: 0.7295868992805481\n",
      "Epoch: 0, Step: 5440, Loss: 0.7547828555107117\n",
      "Epoch: 0, Step: 5472, Loss: 0.8166720867156982\n",
      "Epoch: 0, Step: 5504, Loss: 0.787357747554779\n",
      "Epoch: 0, Step: 5536, Loss: 0.7731347680091858\n",
      "Epoch: 0, Step: 5568, Loss: 0.7980936765670776\n",
      "Epoch: 0, Step: 5600, Loss: 0.6836168169975281\n",
      "Epoch: 0, Step: 5632, Loss: 0.7572847604751587\n",
      "Epoch: 0, Step: 5664, Loss: 0.772897481918335\n",
      "Epoch: 0, Step: 5696, Loss: 0.7884495258331299\n",
      "Epoch: 0, Step: 5728, Loss: 0.7759273648262024\n",
      "Epoch: 0, Step: 5760, Loss: 0.7305237650871277\n",
      "Epoch: 0, Step: 5792, Loss: 0.8230915665626526\n",
      "Epoch: 0, Step: 5824, Loss: 0.811967670917511\n",
      "Epoch: 0, Step: 5856, Loss: 0.7897854447364807\n",
      "Epoch: 0, Step: 5888, Loss: 0.8414939045906067\n",
      "Epoch: 0, Step: 5920, Loss: 0.6848236322402954\n",
      "Epoch: 0, Step: 5952, Loss: 0.7726677060127258\n",
      "Epoch: 0, Step: 5984, Loss: 0.7805608510971069\n",
      "Epoch: 0, Step: 6016, Loss: 0.8734534382820129\n",
      "Epoch: 0, Step: 6048, Loss: 0.8515406250953674\n",
      "Epoch: 0, Step: 6080, Loss: 0.7696593999862671\n",
      "Epoch: 0, Step: 6112, Loss: 0.7139982581138611\n",
      "Epoch: 0, Step: 6144, Loss: 0.9135051965713501\n",
      "Epoch: 0, Step: 6176, Loss: 0.7975826859474182\n",
      "Epoch: 0, Step: 6208, Loss: 0.7673845887184143\n",
      "Epoch: 0, Step: 6240, Loss: 0.7784974575042725\n",
      "Epoch: 0, Step: 6272, Loss: 0.7109887599945068\n",
      "Epoch: 0, Step: 6304, Loss: 0.7826737761497498\n",
      "Epoch: 0, Step: 6336, Loss: 0.6941717863082886\n",
      "Epoch: 0, Step: 6368, Loss: 0.6824457049369812\n",
      "Epoch: 0, Step: 6400, Loss: 0.7730004787445068\n",
      "Epoch: 0, Step: 6432, Loss: 0.7941919565200806\n",
      "Epoch: 0, Step: 6464, Loss: 0.7849613428115845\n",
      "Epoch: 0, Step: 6496, Loss: 0.7760072946548462\n",
      "Epoch: 0, Step: 6528, Loss: 0.7705309987068176\n",
      "Epoch: 0, Step: 6560, Loss: 0.7760511636734009\n",
      "Epoch: 0, Step: 6592, Loss: 0.7338682413101196\n",
      "Epoch: 0, Step: 6624, Loss: 0.7122923731803894\n",
      "Epoch: 0, Step: 6656, Loss: 0.7703419327735901\n",
      "Epoch: 0, Step: 6688, Loss: 0.7785388231277466\n",
      "Epoch: 0, Step: 6720, Loss: 0.9559919834136963\n",
      "Epoch: 0, Step: 6752, Loss: 0.8508173227310181\n",
      "Epoch: 0, Step: 6784, Loss: 0.7573250532150269\n",
      "Epoch: 0, Step: 6816, Loss: 0.8026702404022217\n",
      "Epoch: 0, Step: 6848, Loss: 0.749286413192749\n",
      "Epoch: 0, Step: 6880, Loss: 0.7067453265190125\n",
      "Epoch: 0, Step: 6912, Loss: 0.6962839961051941\n",
      "Epoch: 0, Step: 6944, Loss: 0.8130441904067993\n",
      "Epoch: 0, Step: 6976, Loss: 0.7860537171363831\n",
      "Epoch: 0, Step: 7008, Loss: 0.8102425336837769\n",
      "Epoch: 0, Step: 7040, Loss: 0.7332597970962524\n",
      "Epoch: 0, Step: 7072, Loss: 0.7622557282447815\n",
      "Epoch: 0, Step: 7104, Loss: 0.8540006279945374\n",
      "Epoch: 0, Step: 7136, Loss: 0.6506149172782898\n",
      "Epoch: 0, Step: 7168, Loss: 0.7270696759223938\n",
      "Epoch: 0, Step: 7200, Loss: 0.764454185962677\n",
      "Epoch: 0, Step: 7232, Loss: 0.7539746761322021\n",
      "Epoch: 0, Step: 7264, Loss: 0.7515525221824646\n",
      "Epoch: 0, Step: 7296, Loss: 0.7932075262069702\n",
      "Epoch: 0, Step: 7328, Loss: 0.7205067276954651\n",
      "Epoch: 0, Step: 7360, Loss: 0.785552442073822\n",
      "Epoch: 0, Step: 7392, Loss: 0.7870355844497681\n",
      "Epoch: 0, Step: 7424, Loss: 0.7207948565483093\n",
      "Epoch: 0, Step: 7456, Loss: 0.7118605971336365\n",
      "Epoch: 0, Step: 7488, Loss: 0.6528313755989075\n",
      "Epoch: 0, Step: 7520, Loss: 0.764009416103363\n",
      "Epoch: 0, Step: 7552, Loss: 0.8137896656990051\n",
      "Epoch: 0, Step: 7584, Loss: 0.7534323930740356\n",
      "Epoch: 0, Step: 7616, Loss: 0.960159182548523\n",
      "Epoch: 0, Step: 7648, Loss: 0.7926257252693176\n",
      "Epoch: 0, Step: 7680, Loss: 0.8079448342323303\n",
      "Epoch: 0, Step: 7712, Loss: 0.7798627614974976\n",
      "Epoch: 0, Step: 7744, Loss: 0.6603316068649292\n",
      "Epoch: 0, Step: 7776, Loss: 0.7929843068122864\n",
      "Epoch: 0, Step: 7808, Loss: 0.8070526719093323\n",
      "Epoch: 0, Step: 7840, Loss: 0.7468909621238708\n",
      "Epoch: 0, Step: 7872, Loss: 0.7898107171058655\n",
      "Epoch: 0, Step: 7904, Loss: 0.7989659905433655\n",
      "Epoch: 0, Step: 7936, Loss: 0.804294228553772\n",
      "Epoch: 0, Step: 7968, Loss: 0.914635956287384\n",
      "Epoch: 0, Step: 8000, Loss: 0.7020717859268188\n",
      "Epoch: 0, Step: 8032, Loss: 0.7401727437973022\n",
      "Epoch: 0, Step: 8064, Loss: 0.7679821848869324\n",
      "Epoch: 0, Step: 8096, Loss: 0.6993370652198792\n",
      "Epoch: 0, Step: 8128, Loss: 0.8162537217140198\n",
      "Epoch: 0, Step: 8160, Loss: 0.8233563899993896\n",
      "Epoch: 0, Step: 8192, Loss: 0.7890462279319763\n",
      "Epoch: 0, Step: 8224, Loss: 0.7486164569854736\n",
      "Epoch: 0, Step: 8256, Loss: 0.7316988110542297\n",
      "Epoch: 0, Step: 8288, Loss: 0.7564762830734253\n",
      "Epoch: 0, Step: 8320, Loss: 0.7232832312583923\n",
      "Epoch: 0, Step: 8352, Loss: 0.7962952256202698\n",
      "Epoch: 0, Step: 8384, Loss: 0.6272057294845581\n",
      "Epoch: 0, Step: 8416, Loss: 0.7104398608207703\n",
      "Epoch: 0, Step: 8448, Loss: 0.6893883347511292\n",
      "Epoch: 0, Step: 8480, Loss: 0.7510870695114136\n",
      "Epoch: 0, Step: 8512, Loss: 0.7671438455581665\n",
      "Epoch: 0, Step: 8544, Loss: 0.832787275314331\n",
      "Epoch: 0, Step: 8576, Loss: 0.8372464776039124\n",
      "Epoch: 0, Step: 8608, Loss: 0.7480920553207397\n",
      "Epoch: 0, Step: 8640, Loss: 0.8113461136817932\n",
      "Epoch: 0, Step: 8672, Loss: 0.7425669431686401\n",
      "Epoch: 0, Step: 8704, Loss: 0.740294337272644\n",
      "Epoch: 0, Step: 8736, Loss: 0.7688133120536804\n",
      "Epoch: 0, Step: 8768, Loss: 0.7477328777313232\n",
      "Epoch: 0, Step: 8800, Loss: 0.8147662281990051\n",
      "Epoch: 0, Step: 8832, Loss: 0.7261444330215454\n",
      "Epoch: 0, Step: 8864, Loss: 0.8487023711204529\n",
      "Epoch: 0, Step: 8896, Loss: 0.6665849089622498\n",
      "Epoch: 0, Step: 8928, Loss: 0.7016167044639587\n",
      "Epoch: 0, Step: 8960, Loss: 0.777565062046051\n",
      "Epoch: 0, Step: 8992, Loss: 0.7492278218269348\n",
      "Epoch: 0, Step: 9024, Loss: 0.7711536288261414\n",
      "Epoch: 0, Step: 9056, Loss: 0.8537760376930237\n",
      "Epoch: 0, Step: 9088, Loss: 0.7036579847335815\n",
      "Epoch: 0, Step: 9120, Loss: 0.8741438984870911\n",
      "Epoch: 0, Step: 9152, Loss: 0.775476336479187\n",
      "Epoch: 0, Step: 9184, Loss: 0.715137779712677\n",
      "Epoch: 0, Step: 9216, Loss: 0.8339442014694214\n",
      "Epoch: 0, Step: 9248, Loss: 0.7816258072853088\n",
      "Epoch: 0, Step: 9280, Loss: 0.6587049961090088\n",
      "Epoch: 0, Step: 9312, Loss: 0.8460659384727478\n",
      "Epoch: 0, Step: 9344, Loss: 0.726360559463501\n",
      "Epoch: 0, Step: 9376, Loss: 0.7296393513679504\n",
      "Epoch: 0, Step: 9408, Loss: 0.7277846932411194\n",
      "Epoch: 0, Step: 9440, Loss: 0.785521388053894\n",
      "Epoch: 0, Step: 9472, Loss: 0.8077610731124878\n",
      "Epoch: 0, Step: 9504, Loss: 0.794053316116333\n",
      "Epoch: 0, Step: 9536, Loss: 0.6979365944862366\n",
      "Epoch: 0, Step: 9568, Loss: 0.7604178786277771\n",
      "Epoch: 0, Step: 9600, Loss: 0.7019346952438354\n",
      "Epoch: 0, Step: 9632, Loss: 0.7768531441688538\n",
      "Epoch: 0, Step: 9664, Loss: 0.7029795050621033\n",
      "Epoch: 0, Step: 9696, Loss: 0.7284635901451111\n",
      "Epoch: 0, Step: 9728, Loss: 0.6868793368339539\n",
      "Epoch: 0, Step: 9760, Loss: 0.7133520841598511\n",
      "Epoch: 0, Step: 9792, Loss: 0.7491524815559387\n",
      "Epoch: 0, Step: 9824, Loss: 0.742972195148468\n",
      "Epoch: 0, Step: 9856, Loss: 0.6261274218559265\n",
      "Epoch: 0, Step: 9888, Loss: 0.7488738894462585\n",
      "Epoch: 0, Step: 9920, Loss: 0.7034547924995422\n",
      "Epoch: 0, Step: 9952, Loss: 0.6720467209815979\n",
      "Epoch: 0, Step: 9984, Loss: 0.8141869306564331\n",
      "Epoch: 0, Step: 10016, Loss: 0.8163732886314392\n",
      "Epoch: 0, Step: 10048, Loss: 0.7524772882461548\n",
      "Epoch: 0, Step: 10080, Loss: 0.7478557229042053\n",
      "Epoch: 0, Step: 10112, Loss: 0.8067282438278198\n",
      "Epoch: 0, Step: 10144, Loss: 0.7508719563484192\n",
      "Epoch: 0, Step: 10176, Loss: 0.7278812527656555\n",
      "Epoch: 0, Step: 10208, Loss: 0.7074676752090454\n",
      "Epoch: 0, Step: 10240, Loss: 0.7440463304519653\n",
      "Epoch: 0, Step: 10272, Loss: 0.7966684699058533\n",
      "Epoch: 0, Step: 10304, Loss: 0.7720769047737122\n",
      "Epoch: 0, Step: 10336, Loss: 0.6850007772445679\n",
      "Epoch: 0, Step: 10368, Loss: 0.7443721294403076\n",
      "Epoch: 0, Step: 10400, Loss: 0.8843234181404114\n",
      "Epoch: 0, Step: 10432, Loss: 0.8480445742607117\n",
      "Epoch: 0, Step: 10464, Loss: 0.7836647629737854\n",
      "Epoch: 0, Step: 10496, Loss: 0.7820244431495667\n",
      "Epoch: 0, Step: 10528, Loss: 0.8725958466529846\n",
      "Epoch: 0, Step: 10560, Loss: 0.7122223973274231\n",
      "Epoch: 0, Step: 10592, Loss: 0.6790415048599243\n",
      "Epoch: 0, Step: 10624, Loss: 0.7389829158782959\n",
      "Epoch: 0, Step: 10656, Loss: 0.84246426820755\n",
      "Epoch: 0, Step: 10688, Loss: 0.8145349621772766\n",
      "Epoch: 0, Step: 10720, Loss: 0.7551314830780029\n",
      "Epoch: 0, Step: 10752, Loss: 0.8833132386207581\n",
      "Epoch: 0, Step: 10784, Loss: 0.7862061262130737\n",
      "Epoch: 0, Step: 10816, Loss: 0.7760617136955261\n",
      "Epoch: 0, Step: 10848, Loss: 0.7371006608009338\n",
      "Epoch: 0, Step: 10880, Loss: 0.7766456007957458\n",
      "Epoch: 0, Step: 10912, Loss: 0.7845189571380615\n",
      "Epoch: 0, Step: 10944, Loss: 0.8095999360084534\n",
      "Epoch: 0, Step: 10976, Loss: 0.7790958881378174\n",
      "Epoch: 0, Step: 11008, Loss: 0.6866381764411926\n",
      "Epoch: 0, Step: 11040, Loss: 0.7404661774635315\n",
      "Epoch: 0, Step: 11072, Loss: 0.7772743701934814\n",
      "Epoch: 0, Step: 11104, Loss: 0.8005879521369934\n",
      "Epoch: 0, Step: 11136, Loss: 0.7926281690597534\n",
      "Epoch: 0, Step: 11168, Loss: 0.7402924299240112\n",
      "Epoch: 0, Step: 11200, Loss: 0.8009094595909119\n",
      "Epoch: 0, Step: 11232, Loss: 0.8463827967643738\n",
      "Epoch: 0, Step: 11264, Loss: 0.8218165040016174\n",
      "Epoch: 0, Step: 11296, Loss: 0.8144370913505554\n",
      "Epoch: 0, Step: 11328, Loss: 0.7220644354820251\n",
      "Epoch: 0, Step: 11360, Loss: 0.7731220126152039\n",
      "Epoch: 0, Step: 11392, Loss: 0.7499734163284302\n",
      "Epoch: 0, Step: 11424, Loss: 0.7606991529464722\n",
      "Epoch: 0, Step: 11456, Loss: 0.7607689499855042\n",
      "Epoch: 0, Step: 11488, Loss: 0.7917317748069763\n",
      "Epoch: 0, Step: 11520, Loss: 0.8677773475646973\n",
      "Epoch: 0, Step: 11552, Loss: 0.789470911026001\n",
      "Epoch: 0, Step: 11584, Loss: 0.7936661839485168\n",
      "Epoch: 0, Step: 11616, Loss: 0.8217993974685669\n",
      "Epoch: 0, Step: 11648, Loss: 0.7765705585479736\n",
      "Epoch: 0, Step: 11680, Loss: 0.7579470276832581\n",
      "Epoch: 0, Step: 11712, Loss: 0.6900823712348938\n",
      "Epoch: 0, Step: 11744, Loss: 0.6593255996704102\n",
      "Epoch: 0, Step: 11776, Loss: 0.7364507913589478\n",
      "Epoch: 0, Step: 11808, Loss: 0.7381767630577087\n",
      "Epoch: 0, Step: 11840, Loss: 0.6973040699958801\n",
      "Epoch: 0, Step: 11872, Loss: 0.7404415011405945\n",
      "Epoch: 0, Step: 11904, Loss: 0.7892530560493469\n",
      "Epoch: 0, Step: 11936, Loss: 0.8151487708091736\n",
      "Epoch: 0, Step: 11968, Loss: 0.6872260570526123\n",
      "Epoch: 0, Step: 12000, Loss: 0.8247307538986206\n",
      "Epoch: 0, Step: 12032, Loss: 0.6875749826431274\n",
      "Epoch: 0, Step: 12064, Loss: 0.7604405879974365\n",
      "Epoch: 0, Step: 12096, Loss: 0.855023980140686\n",
      "Epoch: 0, Step: 12128, Loss: 0.7557366490364075\n",
      "Epoch: 0, Step: 12160, Loss: 0.8136010766029358\n",
      "Epoch: 0, Step: 12192, Loss: 0.8056732416152954\n",
      "Epoch: 0, Step: 12224, Loss: 0.8384843468666077\n",
      "Epoch: 0, Step: 12256, Loss: 0.6929582357406616\n",
      "Epoch: 0, Step: 12288, Loss: 0.7489301562309265\n",
      "Epoch: 0, Step: 12320, Loss: 0.705991804599762\n",
      "Epoch: 0, Step: 12352, Loss: 0.8102441430091858\n",
      "Epoch: 0, Step: 12384, Loss: 0.842162013053894\n",
      "Epoch: 0, Step: 12416, Loss: 0.7553133368492126\n",
      "Epoch: 0, Step: 12448, Loss: 0.6682597994804382\n",
      "Epoch: 0, Step: 12480, Loss: 0.7723857760429382\n",
      "Epoch: 0, Step: 12512, Loss: 0.7727468609809875\n",
      "Epoch: 0, Step: 12544, Loss: 0.7533847093582153\n",
      "Epoch: 0, Step: 12576, Loss: 0.8182105422019958\n",
      "Epoch: 0, Step: 12608, Loss: 0.9378939270973206\n",
      "Epoch: 0, Step: 12640, Loss: 0.7959074378013611\n",
      "Epoch: 0, Step: 12672, Loss: 0.83006751537323\n",
      "Epoch: 0, Step: 12704, Loss: 0.6944157481193542\n",
      "Epoch: 0, Step: 12736, Loss: 0.9014585018157959\n",
      "Epoch: 0, Step: 12768, Loss: 0.8550946116447449\n",
      "Epoch: 0, Step: 12800, Loss: 0.8118458986282349\n",
      "Epoch: 0, Step: 12832, Loss: 0.8445640802383423\n",
      "Epoch: 0, Step: 12864, Loss: 0.7848794460296631\n",
      "Epoch: 0, Step: 12896, Loss: 0.7077998518943787\n",
      "Epoch: 0, Step: 12928, Loss: 0.7325860857963562\n",
      "Epoch: 0, Step: 12960, Loss: 0.844570517539978\n",
      "Epoch: 0, Step: 12992, Loss: 0.7667334079742432\n",
      "Epoch: 0, Step: 13024, Loss: 0.7239734530448914\n",
      "Epoch: 0, Step: 13056, Loss: 0.7773973345756531\n",
      "Epoch: 0, Step: 13088, Loss: 0.6900840997695923\n",
      "Epoch: 0, Step: 13120, Loss: 0.8255062699317932\n",
      "Epoch: 0, Step: 13152, Loss: 0.6573984026908875\n",
      "Epoch: 0, Step: 13184, Loss: 0.7123138308525085\n",
      "Epoch: 0, Step: 13216, Loss: 0.7427610158920288\n",
      "Epoch: 0, Step: 13248, Loss: 0.6530230641365051\n",
      "Epoch: 0, Step: 13280, Loss: 0.8368551731109619\n",
      "Epoch: 0, Step: 13312, Loss: 0.715640664100647\n",
      "Epoch: 0, Step: 13344, Loss: 0.7999421954154968\n",
      "Epoch: 0, Step: 13376, Loss: 0.6241899728775024\n",
      "Epoch: 0, Step: 13408, Loss: 0.8579303622245789\n",
      "Epoch: 0, Step: 13440, Loss: 0.7832828164100647\n",
      "Epoch: 0, Step: 13472, Loss: 0.7204566597938538\n",
      "Epoch: 0, Step: 13504, Loss: 0.7365769147872925\n",
      "Epoch: 0, Step: 13536, Loss: 0.8029611110687256\n",
      "Epoch: 0, Step: 13568, Loss: 0.7651066184043884\n",
      "Epoch: 0, Step: 13600, Loss: 0.7612484693527222\n",
      "Epoch: 0, Step: 13632, Loss: 0.7007232904434204\n",
      "Epoch: 0, Step: 13664, Loss: 0.7611764073371887\n",
      "Epoch: 0, Step: 13696, Loss: 0.7696818113327026\n",
      "Epoch: 0, Step: 13728, Loss: 0.6782206892967224\n",
      "Epoch: 0, Step: 13760, Loss: 0.7504627108573914\n",
      "Epoch: 0, Step: 13792, Loss: 0.745013952255249\n",
      "Epoch: 0, Step: 13824, Loss: 0.7657062411308289\n",
      "Epoch: 0, Step: 13856, Loss: 0.8543843030929565\n",
      "Epoch: 0, Step: 13888, Loss: 0.7722861766815186\n",
      "Epoch: 0, Step: 13920, Loss: 0.8268893361091614\n",
      "Epoch: 0, Step: 13952, Loss: 0.7553600668907166\n",
      "Epoch: 0, Step: 13984, Loss: 0.7742237448692322\n",
      "Epoch: 0, Step: 14016, Loss: 0.7730446457862854\n",
      "Epoch: 0, Step: 14048, Loss: 0.7031066417694092\n",
      "Epoch: 0, Step: 14080, Loss: 0.7544264197349548\n",
      "Epoch: 0, Step: 14112, Loss: 0.7641130685806274\n",
      "Epoch: 0, Step: 14144, Loss: 0.8430731296539307\n",
      "Epoch: 0, Step: 14176, Loss: 0.8349131941795349\n",
      "Epoch: 0, Step: 14208, Loss: 0.700634241104126\n",
      "Epoch: 0, Step: 14240, Loss: 0.8062623143196106\n",
      "Epoch: 0, Step: 14272, Loss: 0.8481478095054626\n",
      "Epoch: 0, Step: 14304, Loss: 0.7865293025970459\n",
      "Epoch: 0, Step: 14336, Loss: 0.6675132513046265\n",
      "Epoch: 0, Step: 14368, Loss: 0.7423493266105652\n",
      "Epoch: 0, Step: 14400, Loss: 0.6643322706222534\n",
      "Epoch: 0, Step: 14432, Loss: 0.8463636636734009\n",
      "Epoch: 0, Step: 14464, Loss: 0.8203501105308533\n",
      "Epoch: 0, Step: 14496, Loss: 0.9203065037727356\n",
      "Epoch: 0, Step: 14528, Loss: 0.8434211611747742\n",
      "Epoch: 0, Step: 14560, Loss: 0.7671130299568176\n",
      "Epoch: 0, Step: 14592, Loss: 0.7382400035858154\n",
      "Epoch: 0, Step: 14624, Loss: 0.740742027759552\n",
      "Epoch: 0, Step: 14656, Loss: 0.7431358098983765\n",
      "Epoch: 0, Step: 14688, Loss: 0.6712245345115662\n",
      "Epoch: 0, Step: 14720, Loss: 0.7187790274620056\n",
      "Epoch: 0, Step: 14752, Loss: 0.7724641561508179\n",
      "Epoch: 0, Step: 14784, Loss: 0.7930193543434143\n",
      "Epoch: 0, Step: 14816, Loss: 0.7863990664482117\n",
      "Epoch: 0, Step: 14848, Loss: 0.735054612159729\n",
      "Epoch: 0, Step: 14880, Loss: 0.740824818611145\n",
      "Epoch: 0, Step: 14912, Loss: 0.8827763199806213\n",
      "Epoch: 0, Step: 14944, Loss: 0.7523007988929749\n",
      "Epoch: 0, Step: 14976, Loss: 0.7724249958992004\n",
      "Epoch: 0, Step: 15008, Loss: 0.7309502363204956\n",
      "Epoch: 0, Step: 15040, Loss: 0.8278164267539978\n",
      "Epoch: 0, Step: 15072, Loss: 0.6957175731658936\n",
      "Epoch: 0, Step: 15104, Loss: 0.7441026568412781\n",
      "Epoch: 0, Step: 15136, Loss: 0.879715085029602\n",
      "Epoch: 0, Step: 15168, Loss: 0.7150957584381104\n",
      "Epoch: 0, Step: 15200, Loss: 0.8410044312477112\n",
      "Epoch: 0, Step: 15232, Loss: 0.7788439393043518\n",
      "Epoch: 0, Step: 15264, Loss: 0.7759907245635986\n",
      "Epoch: 0, Step: 15296, Loss: 0.8229225873947144\n",
      "Epoch: 0, Step: 15328, Loss: 0.7098339796066284\n",
      "Epoch: 0, Step: 15360, Loss: 0.7894116640090942\n",
      "Epoch: 0, Step: 15392, Loss: 0.7797483801841736\n",
      "Epoch: 0, Step: 15424, Loss: 0.7689493894577026\n",
      "Epoch: 0, Step: 15456, Loss: 0.6749834418296814\n",
      "Epoch: 0, Step: 15488, Loss: 0.7370907664299011\n",
      "Epoch: 0, Step: 15520, Loss: 0.745238721370697\n",
      "Epoch: 0, Step: 15552, Loss: 0.6976398229598999\n",
      "Epoch: 0, Step: 15584, Loss: 0.6996939778327942\n",
      "Epoch: 0, Step: 15616, Loss: 0.7835134863853455\n",
      "Epoch: 0, Step: 15648, Loss: 0.7710481882095337\n",
      "Epoch: 0, Step: 15680, Loss: 0.764629602432251\n",
      "Epoch: 0, Step: 15712, Loss: 0.7665514349937439\n",
      "Epoch: 0, Step: 15744, Loss: 0.7286981344223022\n",
      "Epoch: 0, Step: 15776, Loss: 0.7462469935417175\n",
      "Epoch: 0, Step: 15808, Loss: 0.7971378564834595\n",
      "Epoch: 0, Step: 15840, Loss: 0.7345228791236877\n",
      "Epoch: 0, Step: 15872, Loss: 0.7923640012741089\n",
      "Epoch: 0, Step: 15904, Loss: 0.7753074169158936\n",
      "Epoch: 0, Step: 15936, Loss: 0.7191384434700012\n",
      "Epoch: 0, Step: 15968, Loss: 0.7645360827445984\n",
      "Epoch: 0, Step: 16000, Loss: 0.699452817440033\n",
      "Epoch: 0, Step: 16032, Loss: 0.7065733671188354\n",
      "Epoch: 0, Step: 16064, Loss: 0.760226309299469\n",
      "Epoch: 0, Step: 16096, Loss: 0.8652670979499817\n",
      "Epoch: 0, Step: 16128, Loss: 0.7513896822929382\n",
      "Epoch: 0, Step: 16160, Loss: 0.7588145136833191\n",
      "Epoch: 0, Step: 16192, Loss: 0.8942334651947021\n",
      "Epoch: 0, Step: 16224, Loss: 0.7639424800872803\n",
      "Epoch: 0, Step: 16256, Loss: 0.8605116009712219\n",
      "Epoch: 0, Step: 16288, Loss: 0.8668771982192993\n",
      "Epoch: 0, Step: 16320, Loss: 0.8100529313087463\n",
      "Epoch: 0, Step: 16352, Loss: 0.7283357977867126\n",
      "Epoch: 0, Step: 16384, Loss: 0.7933635115623474\n",
      "Epoch: 0, Step: 16416, Loss: 0.6965769529342651\n",
      "Epoch: 0, Step: 16448, Loss: 0.6676238775253296\n",
      "Epoch: 0, Step: 16480, Loss: 0.7927396297454834\n",
      "Epoch: 0, Step: 16512, Loss: 0.7564870715141296\n",
      "Epoch: 0, Step: 16544, Loss: 0.7694727182388306\n",
      "Epoch: 0, Step: 16576, Loss: 0.7756708860397339\n",
      "Epoch: 0, Step: 16608, Loss: 0.6711280941963196\n",
      "Epoch: 0, Step: 16640, Loss: 0.7018184065818787\n",
      "Epoch: 0, Step: 16672, Loss: 0.750880777835846\n",
      "Epoch: 0, Step: 16704, Loss: 0.6758310198783875\n",
      "Epoch: 0, Step: 16736, Loss: 0.8084629774093628\n",
      "Epoch: 0, Step: 16768, Loss: 0.8256271481513977\n",
      "Epoch: 0, Step: 16800, Loss: 0.8150633573532104\n",
      "Epoch: 0, Step: 16832, Loss: 0.8699739575386047\n",
      "Epoch: 0, Step: 16864, Loss: 0.7527998089790344\n",
      "Epoch: 0, Step: 16896, Loss: 0.6779348850250244\n",
      "Epoch: 0, Step: 16928, Loss: 0.7363609671592712\n",
      "Epoch: 0, Step: 16960, Loss: 0.7862018942832947\n",
      "Epoch: 0, Step: 16992, Loss: 0.8437975645065308\n",
      "Epoch: 0, Step: 17024, Loss: 0.716525137424469\n",
      "Epoch: 0, Step: 17056, Loss: 0.7023106217384338\n",
      "Epoch: 0, Step: 17088, Loss: 0.8007333278656006\n",
      "Epoch: 0, Step: 17120, Loss: 0.750324010848999\n",
      "Epoch: 0, Step: 17152, Loss: 0.8243173956871033\n",
      "Epoch: 0, Step: 17184, Loss: 0.7457601428031921\n",
      "Epoch: 0, Step: 17216, Loss: 0.7280313968658447\n",
      "Epoch: 0, Step: 17248, Loss: 0.7731463313102722\n",
      "Epoch: 0, Step: 17280, Loss: 0.7392168641090393\n",
      "Epoch: 0, Step: 17312, Loss: 0.7716869711875916\n",
      "Epoch: 0, Step: 17344, Loss: 0.810526430606842\n",
      "Epoch: 0, Step: 17376, Loss: 0.7829746603965759\n",
      "Epoch: 0, Step: 17408, Loss: 0.7179422974586487\n",
      "Epoch: 0, Step: 17440, Loss: 0.7961589694023132\n",
      "Epoch: 0, Step: 17472, Loss: 0.7539060115814209\n",
      "Epoch: 0, Step: 17504, Loss: 0.7617741823196411\n",
      "Epoch: 0, Step: 17536, Loss: 0.7691599726676941\n",
      "Epoch: 0, Step: 17568, Loss: 0.7758609652519226\n",
      "Epoch: 0, Step: 17600, Loss: 0.7517616152763367\n",
      "Epoch: 0, Step: 17632, Loss: 0.7046993374824524\n",
      "Epoch: 0, Step: 17664, Loss: 0.7186997532844543\n",
      "Epoch: 0, Step: 17696, Loss: 0.7729670405387878\n",
      "Epoch: 0, Step: 17728, Loss: 0.8024256229400635\n",
      "Epoch: 0, Step: 17760, Loss: 0.7811914682388306\n",
      "Epoch: 0, Step: 17792, Loss: 0.6979957818984985\n",
      "Epoch: 0, Step: 17824, Loss: 0.8379004001617432\n",
      "Epoch: 0, Step: 17856, Loss: 0.7064518332481384\n",
      "Epoch: 0, Step: 17888, Loss: 0.7277893424034119\n",
      "Epoch: 0, Step: 17920, Loss: 0.7494918704032898\n",
      "Epoch: 0, Step: 17952, Loss: 0.7323102355003357\n",
      "Epoch: 0, Step: 17984, Loss: 0.7066224217414856\n",
      "Epoch: 0, Step: 18016, Loss: 0.7075651288032532\n",
      "Epoch: 0, Step: 18048, Loss: 0.7799232602119446\n",
      "Epoch: 0, Step: 18080, Loss: 0.794735312461853\n",
      "Epoch: 0, Step: 18112, Loss: 0.8091383576393127\n",
      "Epoch: 0, Step: 18144, Loss: 0.8254915475845337\n",
      "Epoch: 0, Step: 18176, Loss: 0.7430959343910217\n",
      "Epoch: 0, Step: 18208, Loss: 0.8392459154129028\n",
      "Epoch: 0, Step: 18240, Loss: 0.856662392616272\n",
      "Epoch: 0, Step: 18272, Loss: 0.7625535130500793\n",
      "Epoch: 0, Step: 18304, Loss: 0.8186644315719604\n",
      "Epoch: 0, Step: 18336, Loss: 0.7478329539299011\n",
      "Epoch: 0, Step: 18368, Loss: 0.7504608035087585\n",
      "Epoch: 0, Step: 18400, Loss: 0.7731632590293884\n",
      "Epoch: 0, Step: 18432, Loss: 0.7493310570716858\n",
      "Epoch: 0, Step: 18464, Loss: 0.7920613884925842\n",
      "Epoch: 0, Step: 18496, Loss: 0.755251944065094\n",
      "Epoch: 0, Step: 18528, Loss: 0.6894954442977905\n",
      "Epoch: 0, Step: 18560, Loss: 0.7795068025588989\n",
      "Epoch: 0, Step: 18592, Loss: 0.8004009127616882\n",
      "Epoch: 0, Step: 18624, Loss: 0.7615060210227966\n",
      "Epoch: 0, Step: 18656, Loss: 0.7350590229034424\n",
      "Epoch: 0, Step: 18688, Loss: 0.7584928870201111\n",
      "Epoch: 0, Step: 18720, Loss: 0.7912735342979431\n",
      "Epoch: 0, Step: 18752, Loss: 0.654815137386322\n",
      "Epoch: 0, Step: 18784, Loss: 0.7625131011009216\n",
      "Epoch: 0, Step: 18816, Loss: 0.788751482963562\n",
      "Epoch: 0, Step: 18848, Loss: 0.7400116324424744\n",
      "Epoch: 0, Step: 18880, Loss: 0.752065122127533\n",
      "Epoch: 0, Step: 18912, Loss: 0.7198368310928345\n",
      "Epoch: 0, Step: 18944, Loss: 0.7883263826370239\n",
      "Epoch: 0, Step: 18976, Loss: 0.7494663596153259\n",
      "Epoch: 0, Step: 19008, Loss: 0.7138071656227112\n",
      "Epoch: 0, Step: 19040, Loss: 0.7842274904251099\n",
      "Epoch: 0, Step: 19072, Loss: 0.8007490634918213\n",
      "Epoch: 0, Step: 19104, Loss: 0.7853664755821228\n",
      "Epoch: 0, Step: 19136, Loss: 0.6995537877082825\n",
      "Epoch: 0, Step: 19168, Loss: 0.7950754761695862\n",
      "Epoch: 0, Step: 19200, Loss: 0.886762261390686\n",
      "Epoch: 0, Step: 19232, Loss: 0.8660758137702942\n",
      "Epoch: 0, Step: 19264, Loss: 0.6756431460380554\n",
      "Epoch: 0, Step: 19296, Loss: 0.7274298071861267\n",
      "Epoch: 0, Step: 19328, Loss: 0.8146973252296448\n",
      "Epoch: 0, Step: 19360, Loss: 0.7298108339309692\n",
      "Epoch: 0, Step: 19392, Loss: 0.7718560695648193\n",
      "Epoch: 0, Step: 19424, Loss: 0.7318450212478638\n",
      "Epoch: 0, Step: 19456, Loss: 0.8162063956260681\n",
      "Epoch: 0, Step: 19488, Loss: 0.7824998497962952\n",
      "Epoch: 0, Step: 19520, Loss: 0.7752243876457214\n",
      "Epoch: 0, Step: 19552, Loss: 0.6938292980194092\n",
      "Epoch: 0, Step: 19584, Loss: 0.8112557530403137\n",
      "Epoch: 0, Step: 19616, Loss: 0.7763769030570984\n",
      "Epoch: 0, Step: 19648, Loss: 0.7708622813224792\n",
      "Epoch: 0, Step: 19680, Loss: 0.752343475818634\n",
      "Epoch: 0, Step: 19712, Loss: 0.7513778209686279\n",
      "Epoch: 0, Step: 19744, Loss: 0.7830975651741028\n",
      "Epoch: 0, Step: 19776, Loss: 0.7469761967658997\n",
      "Epoch: 0, Step: 19808, Loss: 0.8794390559196472\n",
      "Epoch: 0, Step: 19840, Loss: 0.7847322821617126\n",
      "Epoch: 0, Step: 19872, Loss: 0.7946927547454834\n",
      "Epoch: 0, Step: 19904, Loss: 0.7387092709541321\n",
      "Epoch: 0, Step: 19936, Loss: 0.8340906500816345\n",
      "Epoch: 0, Step: 19968, Loss: 0.6628518104553223\n",
      "Epoch: 0, Step: 20000, Loss: 0.6894834637641907\n",
      "Epoch: 0, Step: 20032, Loss: 0.7631921172142029\n",
      "Epoch: 0, Step: 20064, Loss: 0.8033726811408997\n",
      "Epoch: 0, Step: 20096, Loss: 0.7706260085105896\n",
      "Epoch: 0, Step: 20128, Loss: 0.7477219104766846\n",
      "Epoch: 0, Step: 20160, Loss: 0.7800570130348206\n",
      "Epoch: 0, Step: 20192, Loss: 0.7466129660606384\n",
      "Epoch: 0, Step: 20224, Loss: 0.7541072368621826\n",
      "Epoch: 0, Step: 20256, Loss: 0.7554994225502014\n",
      "Epoch: 0, Step: 20288, Loss: 0.7547222375869751\n",
      "Epoch: 0, Step: 20320, Loss: 0.8522265553474426\n",
      "Epoch: 0, Step: 20352, Loss: 0.691291093826294\n",
      "Epoch: 0, Step: 20384, Loss: 0.7527567148208618\n",
      "Epoch: 0, Step: 20416, Loss: 0.8018198609352112\n",
      "Epoch: 0, Step: 20448, Loss: 0.7233080267906189\n",
      "Epoch: 0, Step: 20480, Loss: 0.8638340830802917\n",
      "Epoch: 0, Step: 20512, Loss: 0.7982556819915771\n",
      "Epoch: 0, Step: 20544, Loss: 0.6886333227157593\n",
      "Epoch: 0, Step: 20576, Loss: 0.7241400480270386\n",
      "Epoch: 0, Step: 20608, Loss: 0.718758225440979\n",
      "Epoch: 0, Step: 20640, Loss: 0.7230126261711121\n",
      "Epoch: 0, Step: 20672, Loss: 0.8143260478973389\n",
      "Epoch: 0, Step: 20704, Loss: 0.8010308742523193\n",
      "Epoch: 0, Step: 20736, Loss: 0.7609077095985413\n",
      "Epoch: 0, Step: 20768, Loss: 0.7732370495796204\n",
      "Epoch: 0, Step: 20800, Loss: 0.8143595457077026\n",
      "Epoch: 0, Step: 20832, Loss: 0.7951835989952087\n",
      "Epoch: 0, Step: 20864, Loss: 0.8224170804023743\n",
      "Epoch: 0, Step: 20896, Loss: 0.725017249584198\n",
      "Epoch: 0, Step: 20928, Loss: 0.7180397510528564\n",
      "Epoch: 0, Step: 20960, Loss: 0.6685885190963745\n",
      "Epoch: 0, Step: 20992, Loss: 0.7711670994758606\n",
      "Epoch: 0, Step: 21024, Loss: 0.7272051572799683\n",
      "Epoch: 0, Step: 21056, Loss: 0.6963247656822205\n",
      "Epoch: 0, Step: 21088, Loss: 0.7310734391212463\n",
      "Epoch: 0, Step: 21120, Loss: 0.7447739839553833\n",
      "Epoch: 0, Step: 21152, Loss: 0.8316718935966492\n",
      "Epoch: 0, Step: 21184, Loss: 0.7070678472518921\n",
      "Epoch: 0, Step: 21216, Loss: 0.8434451222419739\n",
      "Epoch: 0, Step: 21248, Loss: 0.6852734684944153\n",
      "Epoch: 0, Step: 21280, Loss: 0.7885121703147888\n",
      "Epoch: 0, Step: 21312, Loss: 0.701074481010437\n",
      "Epoch: 0, Step: 21344, Loss: 0.8751912117004395\n",
      "Epoch: 0, Step: 21376, Loss: 0.6264731884002686\n",
      "Epoch: 0, Step: 21408, Loss: 0.8304936289787292\n",
      "Epoch: 0, Step: 21440, Loss: 0.6358965635299683\n",
      "Epoch: 0, Step: 21472, Loss: 0.7090007662773132\n",
      "Epoch: 0, Step: 21504, Loss: 0.8216810822486877\n",
      "Epoch: 0, Step: 21536, Loss: 0.8133093118667603\n",
      "Epoch: 0, Step: 21568, Loss: 0.7689070105552673\n",
      "Epoch: 0, Step: 21600, Loss: 0.8078434467315674\n",
      "Epoch: 0, Step: 21632, Loss: 0.741829514503479\n",
      "Epoch: 0, Step: 21664, Loss: 0.7838770747184753\n",
      "Epoch: 0, Step: 21696, Loss: 0.8474584221839905\n",
      "Epoch: 0, Step: 21728, Loss: 0.8228613138198853\n",
      "Epoch: 0, Step: 21760, Loss: 0.8641194105148315\n",
      "Epoch: 0, Step: 21792, Loss: 0.8732863068580627\n",
      "Epoch: 0, Step: 21824, Loss: 0.7135575413703918\n",
      "Epoch: 0, Step: 21856, Loss: 0.8433458805084229\n",
      "Epoch: 0, Step: 21888, Loss: 0.8424774408340454\n",
      "Epoch: 0, Step: 21920, Loss: 0.7516006827354431\n",
      "Epoch: 0, Step: 21952, Loss: 0.798570990562439\n",
      "Epoch: 0, Step: 21984, Loss: 0.7225197553634644\n",
      "Epoch: 0, Step: 22016, Loss: 0.7667834758758545\n",
      "Epoch: 0, Step: 22048, Loss: 0.7941151857376099\n",
      "Epoch: 0, Step: 22080, Loss: 0.6466719508171082\n",
      "Epoch: 0, Step: 22112, Loss: 0.6938382983207703\n",
      "Epoch: 0, Step: 22144, Loss: 0.8326729536056519\n",
      "Epoch: 0, Step: 22176, Loss: 0.824103593826294\n",
      "Epoch: 0, Step: 22208, Loss: 0.7904004454612732\n",
      "Epoch: 0, Step: 22240, Loss: 0.7388409376144409\n",
      "Epoch: 0, Step: 22272, Loss: 0.7436702251434326\n",
      "Epoch: 0, Step: 22304, Loss: 0.7658541798591614\n",
      "Epoch: 0, Step: 22336, Loss: 0.7402185201644897\n",
      "Epoch: 0, Step: 22368, Loss: 0.7289780378341675\n",
      "Epoch: 0, Step: 22400, Loss: 0.7906666398048401\n",
      "Epoch: 0, Step: 22432, Loss: 0.7569287419319153\n",
      "Epoch: 0, Step: 22464, Loss: 0.7069723606109619\n",
      "Epoch: 0, Step: 22496, Loss: 0.8776875734329224\n",
      "Epoch: 0, Step: 22528, Loss: 0.8489372134208679\n",
      "Epoch: 0, Step: 22560, Loss: 0.7450907826423645\n",
      "Epoch: 0, Step: 22592, Loss: 0.7609279751777649\n",
      "Epoch: 0, Step: 22624, Loss: 0.7896811366081238\n",
      "Epoch: 0, Step: 22656, Loss: 0.821032702922821\n",
      "Epoch: 0, Step: 22688, Loss: 0.6970757842063904\n",
      "Epoch: 0, Step: 22720, Loss: 0.8097909092903137\n",
      "Epoch: 0, Step: 22752, Loss: 0.7495410442352295\n",
      "Epoch: 0, Step: 22784, Loss: 0.7256092429161072\n",
      "Epoch: 0, Step: 22816, Loss: 0.7970642447471619\n",
      "Epoch: 0, Step: 22848, Loss: 0.8419325947761536\n",
      "Epoch: 0, Step: 22880, Loss: 0.7526654601097107\n",
      "Epoch: 0, Step: 22912, Loss: 0.7862295508384705\n",
      "Epoch: 0, Step: 22944, Loss: 0.8601164817810059\n",
      "Epoch: 0, Step: 22976, Loss: 0.7345936894416809\n",
      "Epoch: 0, Step: 23008, Loss: 0.7890011072158813\n",
      "Epoch: 0, Step: 23040, Loss: 0.7908139824867249\n",
      "Epoch: 0, Step: 23072, Loss: 0.8936625123023987\n",
      "Epoch: 0, Step: 23104, Loss: 0.814603865146637\n",
      "Epoch: 0, Step: 23136, Loss: 0.695617139339447\n",
      "Epoch: 0, Step: 23168, Loss: 0.7128356695175171\n",
      "Epoch: 0, Step: 23200, Loss: 0.7116873860359192\n",
      "Epoch: 0, Step: 23232, Loss: 0.712715208530426\n",
      "Epoch: 0, Step: 23264, Loss: 0.7679802775382996\n",
      "Epoch: 0, Step: 23296, Loss: 0.8040017485618591\n",
      "Epoch: 0, Step: 23328, Loss: 0.816388726234436\n",
      "Epoch: 0, Step: 23360, Loss: 0.7894852757453918\n",
      "Epoch: 0, Step: 23392, Loss: 0.8893795609474182\n",
      "Epoch: 0, Step: 23424, Loss: 0.7651119828224182\n",
      "Epoch: 0, Step: 23456, Loss: 0.768477737903595\n",
      "Epoch: 0, Step: 23488, Loss: 0.8039156794548035\n",
      "Epoch: 0, Step: 23520, Loss: 0.7882598042488098\n",
      "Epoch: 0, Step: 23552, Loss: 0.6888525485992432\n",
      "Epoch: 0, Step: 23584, Loss: 0.7401360869407654\n",
      "Epoch: 0, Step: 23616, Loss: 0.7373281717300415\n",
      "Epoch: 0, Step: 23648, Loss: 0.7319387197494507\n",
      "Epoch: 0, Step: 23680, Loss: 0.7835832238197327\n",
      "Epoch: 0, Step: 23712, Loss: 0.8684492111206055\n",
      "Epoch: 0, Step: 23744, Loss: 0.6708539128303528\n",
      "Epoch: 0, Step: 23776, Loss: 0.7824806571006775\n",
      "Epoch: 0, Step: 23808, Loss: 0.7328638434410095\n",
      "Epoch: 0, Step: 23840, Loss: 0.8936789631843567\n",
      "Epoch: 0, Step: 23872, Loss: 0.8507826328277588\n",
      "Epoch: 0, Step: 23904, Loss: 0.666545033454895\n",
      "Epoch: 0, Step: 23936, Loss: 0.8010627627372742\n",
      "Epoch: 0, Step: 23968, Loss: 0.7262160778045654\n",
      "Epoch: 0, Step: 24000, Loss: 0.7455074191093445\n",
      "Epoch: 0, Step: 24032, Loss: 0.7895798087120056\n",
      "Epoch: 0, Step: 24064, Loss: 0.804999053478241\n",
      "Epoch: 0, Step: 24096, Loss: 0.8039939403533936\n",
      "Epoch: 0, Step: 24128, Loss: 0.6534411907196045\n",
      "Epoch: 0, Step: 24160, Loss: 0.8793647885322571\n",
      "Epoch: 0, Step: 24192, Loss: 0.8128659725189209\n",
      "Epoch: 0, Step: 24224, Loss: 0.8839694857597351\n",
      "Epoch: 0, Step: 24256, Loss: 0.7570425868034363\n",
      "Epoch: 0, Step: 24288, Loss: 0.8102014064788818\n",
      "Epoch: 0, Step: 24320, Loss: 0.7861825823783875\n",
      "Epoch: 0, Step: 24352, Loss: 0.8180269002914429\n",
      "Epoch: 0, Step: 24384, Loss: 0.7743380665779114\n",
      "Epoch: 0, Step: 24416, Loss: 0.8076046109199524\n",
      "Epoch: 0, Step: 24448, Loss: 0.685588002204895\n",
      "Epoch: 0, Step: 24480, Loss: 0.7399632930755615\n",
      "Epoch: 0, Step: 24512, Loss: 0.741908848285675\n",
      "Epoch: 0, Step: 24544, Loss: 0.7023690342903137\n",
      "Epoch: 0, Step: 24576, Loss: 0.7916475534439087\n",
      "Epoch: 0, Step: 24608, Loss: 0.8342934250831604\n",
      "Epoch: 0, Step: 24640, Loss: 0.7492335438728333\n",
      "Epoch: 0, Step: 24672, Loss: 0.7386314272880554\n",
      "Epoch: 0, Step: 24704, Loss: 0.6746596097946167\n",
      "Epoch: 0, Step: 24736, Loss: 0.6776346564292908\n",
      "Epoch: 0, Step: 24768, Loss: 0.8851974010467529\n",
      "Epoch: 0, Step: 24800, Loss: 0.8003309965133667\n",
      "Epoch: 0, Step: 24832, Loss: 0.7572133541107178\n",
      "Epoch: 0, Step: 24864, Loss: 0.8459520936012268\n",
      "Epoch: 0, Step: 24896, Loss: 0.7930632829666138\n",
      "Epoch: 0, Step: 24928, Loss: 0.8114706873893738\n",
      "Epoch: 0, Step: 24960, Loss: 0.8078094720840454\n",
      "Epoch: 0, Step: 24992, Loss: 0.8042966723442078\n",
      "Epoch: 0, Step: 25024, Loss: 0.7692483067512512\n",
      "Epoch: 0, Step: 25056, Loss: 0.7909234166145325\n",
      "Epoch: 0, Step: 25088, Loss: 0.6257464289665222\n",
      "Epoch: 0, Step: 25120, Loss: 0.7438061237335205\n",
      "Epoch: 0, Step: 25152, Loss: 0.6058125495910645\n",
      "Epoch: 0, Step: 25184, Loss: 0.7480635046958923\n",
      "Epoch: 0, Step: 25216, Loss: 0.6839274764060974\n",
      "Epoch: 0, Step: 25248, Loss: 0.6985222101211548\n",
      "Epoch: 0, Step: 25280, Loss: 0.8426932096481323\n",
      "Epoch: 0, Step: 25312, Loss: 0.7182963490486145\n",
      "Epoch: 0, Step: 25344, Loss: 0.7386683225631714\n",
      "Epoch: 0, Step: 25376, Loss: 0.66836017370224\n",
      "Epoch: 0, Step: 25408, Loss: 0.7705105543136597\n",
      "Epoch: 0, Step: 25440, Loss: 0.7396894097328186\n",
      "Epoch: 0, Step: 25472, Loss: 0.7358425855636597\n",
      "Epoch: 0, Step: 25504, Loss: 0.8178775906562805\n",
      "Epoch: 0, Step: 25536, Loss: 0.7425075173377991\n",
      "Epoch: 0, Step: 25568, Loss: 0.766342043876648\n",
      "Epoch: 0, Step: 25600, Loss: 0.7060744762420654\n",
      "Epoch: 0, Step: 25632, Loss: 0.6970094442367554\n",
      "Epoch: 0, Step: 25664, Loss: 0.80596524477005\n",
      "Epoch: 0, Step: 25696, Loss: 0.7577106356620789\n",
      "Epoch: 0, Step: 25728, Loss: 0.848821222782135\n",
      "Epoch: 0, Step: 25760, Loss: 0.7913902401924133\n",
      "Epoch: 0, Step: 25792, Loss: 0.7144348621368408\n",
      "Epoch: 0, Step: 25824, Loss: 0.7361348271369934\n",
      "Epoch: 0, Step: 25856, Loss: 0.768592119216919\n",
      "Epoch: 0, Step: 25888, Loss: 0.7568144202232361\n",
      "Epoch: 0, Step: 25920, Loss: 0.8659525513648987\n",
      "Epoch: 0, Step: 25952, Loss: 0.716677725315094\n",
      "Epoch: 0, Step: 25984, Loss: 0.8148292899131775\n",
      "Epoch: 0, Step: 26016, Loss: 0.8310047388076782\n",
      "Epoch: 0, Step: 26048, Loss: 0.7468096613883972\n",
      "Epoch: 0, Step: 26080, Loss: 0.7146019339561462\n",
      "Epoch: 0, Step: 26112, Loss: 0.8265776038169861\n",
      "Epoch: 0, Step: 26144, Loss: 0.7374611496925354\n",
      "Epoch: 0, Step: 26176, Loss: 0.8238616585731506\n",
      "Epoch: 0, Step: 26208, Loss: 0.7247957587242126\n",
      "Epoch: 0, Step: 26240, Loss: 0.7723816633224487\n",
      "Epoch: 0, Step: 26272, Loss: 0.7828678488731384\n",
      "Epoch: 0, Step: 26304, Loss: 0.7854300141334534\n",
      "Epoch: 0, Step: 26336, Loss: 0.7807905077934265\n",
      "Epoch: 0, Step: 26368, Loss: 0.7721226811408997\n",
      "Epoch: 0, Step: 26400, Loss: 0.8232347369194031\n",
      "Epoch: 0, Step: 26432, Loss: 0.7166758179664612\n",
      "Epoch: 0, Step: 26464, Loss: 0.7436047196388245\n",
      "Epoch: 0, Step: 26496, Loss: 0.7113123536109924\n",
      "Epoch: 0, Step: 26528, Loss: 0.7260017991065979\n",
      "Epoch: 0, Step: 26560, Loss: 0.7280508279800415\n",
      "Epoch: 0, Step: 26592, Loss: 0.6612405776977539\n",
      "Epoch: 0, Step: 26624, Loss: 0.7598716616630554\n",
      "Epoch: 0, Step: 26656, Loss: 0.8031771779060364\n",
      "Epoch: 0, Step: 26688, Loss: 0.7162695527076721\n",
      "Epoch: 0, Step: 26720, Loss: 0.7784882187843323\n",
      "Epoch: 0, Step: 26752, Loss: 0.8235811591148376\n",
      "Epoch: 0, Step: 26784, Loss: 0.7206214070320129\n",
      "Epoch: 0, Step: 26816, Loss: 0.7139956951141357\n",
      "Epoch: 0, Step: 26848, Loss: 0.7306844592094421\n",
      "Epoch: 0, Step: 26880, Loss: 0.6542208790779114\n",
      "Epoch: 0, Step: 26912, Loss: 0.6165142059326172\n",
      "Epoch: 0, Step: 26944, Loss: 0.6912326216697693\n",
      "Epoch: 0, Step: 26976, Loss: 0.8021296262741089\n",
      "Epoch: 0, Step: 27008, Loss: 0.6970661878585815\n",
      "Epoch: 0, Step: 27040, Loss: 0.8299300670623779\n",
      "Epoch: 0, Step: 27072, Loss: 0.7648042440414429\n",
      "Epoch: 0, Step: 27104, Loss: 0.7812417149543762\n",
      "Epoch: 0, Step: 27136, Loss: 0.7567269802093506\n",
      "Epoch: 0, Step: 27168, Loss: 0.7111120820045471\n",
      "Epoch: 0, Step: 27200, Loss: 0.7531798481941223\n",
      "Epoch: 0, Step: 27232, Loss: 0.7582194805145264\n",
      "Epoch: 0, Step: 27264, Loss: 0.8115965127944946\n",
      "Epoch: 0, Step: 27296, Loss: 0.7410654425621033\n",
      "Epoch: 0, Step: 27328, Loss: 0.8164966106414795\n",
      "Epoch: 0, Step: 27360, Loss: 0.8268164396286011\n",
      "Epoch: 0, Step: 27392, Loss: 0.7016433477401733\n",
      "Epoch: 0, Step: 27424, Loss: 0.7112948894500732\n",
      "Epoch: 0, Step: 27456, Loss: 0.7450043559074402\n",
      "Epoch: 0, Step: 27488, Loss: 0.7647432684898376\n",
      "Epoch: 0, Step: 27520, Loss: 0.7561264634132385\n",
      "Epoch: 0, Step: 27552, Loss: 0.7059754729270935\n",
      "Epoch: 0, Step: 27584, Loss: 0.7760618329048157\n",
      "Epoch: 0, Step: 27616, Loss: 0.8805592656135559\n",
      "Epoch: 0, Step: 27648, Loss: 0.680580735206604\n",
      "Epoch: 0, Step: 27680, Loss: 0.7570217251777649\n",
      "Epoch: 0, Step: 27712, Loss: 0.7962934374809265\n",
      "Epoch: 0, Step: 27744, Loss: 0.735819399356842\n",
      "Epoch: 0, Step: 27776, Loss: 0.7748690843582153\n",
      "Epoch: 0, Step: 27808, Loss: 0.8081711530685425\n",
      "Epoch: 0, Step: 27840, Loss: 0.7135230898857117\n",
      "Epoch: 0, Step: 27872, Loss: 0.7471263408660889\n",
      "Epoch: 0, Step: 27904, Loss: 0.7670032382011414\n",
      "Epoch: 0, Step: 27936, Loss: 0.7880825400352478\n",
      "Epoch: 0, Step: 27968, Loss: 0.7103272080421448\n",
      "Epoch: 0, Step: 28000, Loss: 0.8936559557914734\n",
      "Epoch: 0, Step: 28032, Loss: 0.7321341037750244\n",
      "Epoch: 0, Step: 28064, Loss: 0.7834250926971436\n",
      "Epoch: 0, Step: 28096, Loss: 0.7339356541633606\n",
      "Epoch: 0, Step: 28128, Loss: 0.8173965811729431\n",
      "Epoch: 0, Step: 28160, Loss: 0.7310665249824524\n",
      "Epoch: 0, Step: 28192, Loss: 0.7363019585609436\n",
      "Epoch: 0, Step: 28224, Loss: 0.8330458998680115\n",
      "Epoch: 0, Step: 28256, Loss: 0.7294207215309143\n",
      "Epoch: 0, Step: 28288, Loss: 0.7489263415336609\n",
      "Epoch: 0, Step: 28320, Loss: 0.6365421414375305\n",
      "Epoch: 0, Step: 28352, Loss: 0.772312343120575\n",
      "Epoch: 0, Step: 28384, Loss: 0.7764206528663635\n",
      "Epoch: 0, Step: 28416, Loss: 0.765686571598053\n",
      "Epoch: 0, Step: 28448, Loss: 0.740747332572937\n",
      "Epoch: 0, Step: 28480, Loss: 0.8205977082252502\n",
      "Epoch: 0, Step: 28512, Loss: 0.7369943857192993\n",
      "Epoch: 0, Step: 28544, Loss: 0.78909832239151\n",
      "Epoch: 0, Step: 28576, Loss: 0.7289183735847473\n",
      "Epoch: 0, Step: 28608, Loss: 0.7040254473686218\n",
      "Epoch: 0, Step: 28640, Loss: 0.7244056463241577\n",
      "Epoch: 0, Step: 28672, Loss: 0.7262962460517883\n",
      "Epoch: 0, Step: 28704, Loss: 0.7716498970985413\n",
      "Epoch: 0, Step: 28736, Loss: 0.7495023608207703\n",
      "Epoch: 0, Step: 28768, Loss: 0.7137192487716675\n",
      "Epoch: 0, Step: 28800, Loss: 0.8056237697601318\n",
      "Epoch: 0, Step: 28832, Loss: 0.7880208492279053\n",
      "Epoch: 0, Step: 28864, Loss: 0.7862584590911865\n",
      "Epoch: 0, Step: 28896, Loss: 0.6721503138542175\n",
      "Epoch: 0, Step: 28928, Loss: 0.8046597242355347\n",
      "Epoch: 0, Step: 28960, Loss: 0.8396247625350952\n",
      "Epoch: 0, Step: 28992, Loss: 0.6880224347114563\n",
      "Epoch: 0, Step: 29024, Loss: 0.7577280402183533\n",
      "Epoch: 0, Step: 29056, Loss: 0.8923007845878601\n",
      "Epoch: 0, Step: 29088, Loss: 0.7677015066146851\n",
      "Epoch: 0, Step: 29120, Loss: 0.8717858195304871\n",
      "Epoch: 0, Step: 29152, Loss: 0.624210774898529\n",
      "Epoch: 0, Step: 29184, Loss: 0.695625364780426\n",
      "Epoch: 0, Step: 29216, Loss: 0.8767111897468567\n",
      "Epoch: 0, Step: 29248, Loss: 0.826150119304657\n",
      "Epoch: 0, Step: 29280, Loss: 0.91849684715271\n",
      "Epoch: 0, Step: 29312, Loss: 0.719562292098999\n",
      "Epoch: 0, Step: 29344, Loss: 0.74596107006073\n",
      "Epoch: 0, Step: 29376, Loss: 0.6889010667800903\n",
      "Epoch: 0, Step: 29408, Loss: 0.7001956701278687\n",
      "Epoch: 0, Step: 29440, Loss: 0.7156853079795837\n",
      "Epoch: 0, Step: 29472, Loss: 0.7091543078422546\n",
      "Epoch: 0, Step: 29504, Loss: 0.8050352334976196\n",
      "Epoch: 0, Step: 29536, Loss: 0.6928907632827759\n",
      "Epoch: 0, Step: 29568, Loss: 0.7315167188644409\n",
      "Epoch: 0, Step: 29600, Loss: 0.8216070532798767\n",
      "Epoch: 0, Step: 29632, Loss: 0.8546496033668518\n",
      "Epoch: 0, Step: 29664, Loss: 0.6791011691093445\n",
      "Epoch: 0, Step: 29696, Loss: 0.7732439637184143\n",
      "Epoch: 0, Step: 29728, Loss: 0.8017512559890747\n",
      "Epoch: 0, Step: 29760, Loss: 0.7160130143165588\n",
      "Epoch: 0, Step: 29792, Loss: 0.782861053943634\n",
      "Epoch: 0, Step: 29824, Loss: 0.7890099287033081\n",
      "Epoch: 0, Step: 29856, Loss: 0.6725262403488159\n",
      "Epoch: 0, Step: 29888, Loss: 0.7129965424537659\n",
      "Epoch: 0, Step: 29920, Loss: 0.796296238899231\n",
      "Epoch: 0, Step: 29952, Loss: 0.7799399495124817\n",
      "Epoch: 0, Step: 29984, Loss: 0.8658764958381653\n",
      "Epoch: 0, Step: 30016, Loss: 0.7830877900123596\n",
      "Epoch: 0, Step: 30048, Loss: 0.810924768447876\n",
      "Epoch: 0, Step: 30080, Loss: 0.7515767216682434\n",
      "Epoch: 0, Step: 30112, Loss: 0.7873648405075073\n",
      "Epoch: 0, Step: 30144, Loss: 0.6938784122467041\n",
      "Epoch: 0, Step: 30176, Loss: 0.6866758465766907\n",
      "Epoch: 0, Step: 30208, Loss: 0.8242431282997131\n",
      "Epoch: 0, Step: 30240, Loss: 0.7967318892478943\n",
      "Epoch: 0, Step: 30272, Loss: 0.660973846912384\n",
      "Epoch: 0, Step: 30304, Loss: 0.740974485874176\n",
      "Epoch: 0, Step: 30336, Loss: 0.8796877861022949\n",
      "Epoch: 0, Step: 30368, Loss: 0.8115392923355103\n",
      "Epoch: 0, Step: 30400, Loss: 0.7965911030769348\n",
      "Epoch: 0, Step: 30432, Loss: 0.6655797362327576\n",
      "Epoch: 0, Step: 30464, Loss: 0.8476076722145081\n",
      "Epoch: 0, Step: 30496, Loss: 0.7854593992233276\n",
      "Epoch: 0, Step: 30528, Loss: 0.8676904439926147\n",
      "Epoch: 0, Step: 30560, Loss: 0.6892220377922058\n",
      "Epoch: 0, Step: 30592, Loss: 0.736958384513855\n",
      "Epoch: 0, Step: 30624, Loss: 0.7459439635276794\n",
      "Epoch: 0, Step: 30656, Loss: 0.8058159947395325\n",
      "Epoch: 0, Step: 30688, Loss: 0.7529316544532776\n",
      "Epoch: 0, Step: 30720, Loss: 0.6722619533538818\n",
      "Epoch: 0, Step: 30752, Loss: 0.7112098336219788\n",
      "Epoch: 0, Step: 30784, Loss: 0.7506877779960632\n",
      "Epoch: 0, Step: 30816, Loss: 0.7858601808547974\n",
      "Epoch: 0, Step: 30848, Loss: 0.7733383774757385\n",
      "Epoch: 0, Step: 30880, Loss: 0.7246848344802856\n",
      "Epoch: 0, Step: 30912, Loss: 0.8100853562355042\n",
      "Epoch: 0, Step: 30944, Loss: 0.7030205130577087\n",
      "Epoch: 0, Step: 30976, Loss: 0.6790480017662048\n",
      "Epoch: 0, Step: 31008, Loss: 0.7194153070449829\n",
      "Epoch: 0, Step: 31040, Loss: 0.7865421175956726\n",
      "Epoch: 0, Step: 31072, Loss: 0.7626984119415283\n",
      "Epoch: 0, Step: 31104, Loss: 0.6949299573898315\n",
      "Epoch: 0, Step: 31136, Loss: 0.8416224122047424\n",
      "Epoch: 0, Step: 31168, Loss: 0.7885324358940125\n",
      "Epoch: 0, Step: 31200, Loss: 0.7617220282554626\n",
      "Epoch: 0, Step: 31232, Loss: 0.7047960162162781\n",
      "Epoch: 0, Step: 31264, Loss: 0.8091270327568054\n",
      "Epoch: 0, Step: 31296, Loss: 0.7357824444770813\n",
      "Epoch: 0, Step: 31328, Loss: 0.7975407242774963\n",
      "Epoch: 0, Step: 31360, Loss: 0.7359302639961243\n",
      "Epoch: 0, Step: 31392, Loss: 0.7992364168167114\n",
      "Epoch: 0, Step: 31424, Loss: 0.7342240810394287\n",
      "Epoch: 0, Step: 31456, Loss: 0.7792037725448608\n",
      "Epoch: 0, Step: 31488, Loss: 0.7581174373626709\n",
      "Epoch: 0, Step: 31520, Loss: 0.7696692943572998\n",
      "Epoch: 0, Step: 31552, Loss: 0.8009599447250366\n",
      "Epoch: 0, Step: 31584, Loss: 0.7616644501686096\n",
      "Epoch: 0, Step: 31616, Loss: 0.7399319410324097\n",
      "Epoch: 0, Step: 31648, Loss: 0.7149000763893127\n",
      "Epoch: 0, Step: 31680, Loss: 0.7056054472923279\n",
      "Epoch: 0, Step: 31712, Loss: 0.731248676776886\n",
      "Epoch: 0, Step: 31744, Loss: 0.793912947177887\n",
      "Epoch: 0, Step: 31776, Loss: 0.8648762702941895\n",
      "Epoch: 0, Step: 31808, Loss: 0.8322804570198059\n",
      "Epoch: 0, Step: 31840, Loss: 0.6813162565231323\n",
      "Epoch: 0, Step: 31872, Loss: 0.8259032368659973\n",
      "Epoch: 0, Step: 31904, Loss: 0.8159177303314209\n",
      "Epoch: 0, Step: 31936, Loss: 0.8129529356956482\n",
      "Epoch: 0, Step: 31968, Loss: 0.7727578282356262\n",
      "Epoch: 0, Step: 32000, Loss: 0.7363766431808472\n",
      "Epoch: 0, Step: 32032, Loss: 0.7356968522071838\n",
      "Epoch: 0, Step: 32064, Loss: 0.815291166305542\n",
      "Epoch: 0, Step: 32096, Loss: 0.8243681192398071\n",
      "Epoch: 0, Step: 32128, Loss: 0.7973655462265015\n",
      "Epoch: 0, Step: 32160, Loss: 0.7071712017059326\n",
      "Epoch: 0, Step: 32192, Loss: 0.8088566064834595\n",
      "Epoch: 0, Step: 32224, Loss: 0.7970854043960571\n",
      "Epoch: 0, Step: 32256, Loss: 0.7373597025871277\n",
      "Epoch: 0, Step: 32288, Loss: 0.771072268486023\n",
      "Epoch: 0, Step: 32320, Loss: 0.701384425163269\n",
      "Epoch: 0, Step: 32352, Loss: 0.701681911945343\n",
      "Epoch: 0, Step: 32384, Loss: 0.6329194903373718\n",
      "Epoch: 0, Step: 32416, Loss: 0.7963133454322815\n",
      "Epoch: 0, Step: 32448, Loss: 0.7684327960014343\n",
      "Epoch: 0, Step: 32480, Loss: 0.7997540235519409\n",
      "Epoch: 0, Step: 32512, Loss: 0.7834633588790894\n",
      "Epoch: 0, Step: 32544, Loss: 0.7471319437026978\n",
      "Epoch: 0, Step: 32576, Loss: 0.6333463191986084\n",
      "Epoch: 0, Step: 32608, Loss: 0.818854570388794\n",
      "Epoch: 0, Step: 32640, Loss: 0.7741962671279907\n",
      "Epoch: 0, Step: 32672, Loss: 0.8062087893486023\n",
      "Epoch: 0, Step: 32704, Loss: 0.7259696125984192\n",
      "Epoch: 0, Step: 32736, Loss: 0.6913806796073914\n",
      "Epoch: 0, Step: 32768, Loss: 0.7398390173912048\n",
      "Epoch: 0, Step: 32800, Loss: 0.6435419917106628\n",
      "Epoch: 0, Step: 32832, Loss: 0.836576521396637\n",
      "Epoch: 0, Step: 32864, Loss: 0.7310357689857483\n",
      "Epoch: 0, Step: 32896, Loss: 0.8424268960952759\n",
      "Epoch: 0, Step: 32928, Loss: 0.7198458313941956\n",
      "Epoch: 0, Step: 32960, Loss: 0.7700386643409729\n",
      "Epoch: 0, Step: 32992, Loss: 0.7552099823951721\n",
      "Epoch: 0, Step: 33024, Loss: 0.8189919590950012\n",
      "Epoch: 0, Step: 33056, Loss: 0.7848691344261169\n",
      "Epoch: 0, Step: 33088, Loss: 0.7215072512626648\n",
      "Epoch: 0, Step: 33120, Loss: 0.7439683675765991\n",
      "Epoch: 0, Step: 33152, Loss: 0.7558028101921082\n",
      "Epoch: 0, Step: 33184, Loss: 0.7294844388961792\n",
      "Epoch: 0, Step: 33216, Loss: 0.7500065565109253\n",
      "Epoch: 0, Step: 33248, Loss: 0.7827711701393127\n",
      "Epoch: 0, Step: 33280, Loss: 0.759424090385437\n",
      "Epoch: 0, Step: 33312, Loss: 0.7915986180305481\n",
      "Epoch: 0, Step: 33344, Loss: 0.7556988000869751\n",
      "Epoch: 0, Step: 33376, Loss: 0.7769216895103455\n",
      "Epoch: 0, Step: 33408, Loss: 0.7387804388999939\n",
      "Epoch: 0, Step: 33440, Loss: 0.7739854454994202\n",
      "Epoch: 0, Step: 33472, Loss: 0.6946247816085815\n",
      "Epoch: 0, Step: 33504, Loss: 0.7967145442962646\n",
      "Epoch: 0, Step: 33536, Loss: 0.7571220993995667\n",
      "Epoch: 0, Step: 33568, Loss: 0.7567713856697083\n",
      "Epoch: 0, Step: 33600, Loss: 0.7947900295257568\n",
      "Epoch: 0, Step: 33632, Loss: 0.7986541986465454\n",
      "Epoch: 0, Step: 33664, Loss: 0.7420023083686829\n",
      "Epoch: 0, Step: 33696, Loss: 0.773379921913147\n",
      "Epoch: 0, Step: 33728, Loss: 0.8450482487678528\n",
      "Epoch: 0, Step: 33760, Loss: 0.7680256962776184\n",
      "Epoch: 0, Step: 33792, Loss: 0.7106634378433228\n",
      "Epoch: 0, Step: 33824, Loss: 0.7811567187309265\n",
      "Epoch: 0, Step: 33856, Loss: 0.6509508490562439\n",
      "Epoch: 0, Step: 33888, Loss: 0.8087785840034485\n",
      "Epoch: 0, Step: 33920, Loss: 0.6577452421188354\n",
      "Epoch: 0, Step: 33952, Loss: 0.7721784114837646\n",
      "Epoch: 0, Step: 33984, Loss: 0.7309044599533081\n",
      "Epoch: 0, Step: 34016, Loss: 0.7234400510787964\n",
      "Epoch: 0, Step: 34048, Loss: 0.6958932280540466\n",
      "Epoch: 0, Step: 34080, Loss: 0.7140644788742065\n",
      "Epoch: 0, Step: 34112, Loss: 0.7080355286598206\n",
      "Epoch: 0, Step: 34144, Loss: 0.7171143293380737\n",
      "Epoch: 0, Step: 34176, Loss: 0.8123505115509033\n",
      "Epoch: 0, Step: 34208, Loss: 0.751167893409729\n",
      "Epoch: 0, Step: 34240, Loss: 0.8777925372123718\n",
      "Epoch: 0, Step: 34272, Loss: 0.7957544922828674\n",
      "Epoch: 0, Step: 34304, Loss: 0.6871415972709656\n",
      "Epoch: 0, Step: 34336, Loss: 0.773992121219635\n",
      "Epoch: 0, Step: 34368, Loss: 0.7111471891403198\n",
      "Epoch: 0, Step: 34400, Loss: 0.8103272914886475\n",
      "Epoch: 0, Step: 34432, Loss: 0.8185978531837463\n",
      "Epoch: 0, Step: 34464, Loss: 0.7358113527297974\n",
      "Epoch: 0, Step: 34496, Loss: 0.7593035101890564\n",
      "Epoch: 0, Step: 34528, Loss: 0.7627108693122864\n",
      "Epoch: 0, Step: 34560, Loss: 0.8712788820266724\n",
      "Epoch: 0, Step: 34592, Loss: 0.7474413514137268\n",
      "Epoch: 0, Step: 34624, Loss: 0.6990967392921448\n",
      "Epoch: 0, Step: 34656, Loss: 0.7189233303070068\n",
      "Epoch: 0, Step: 34688, Loss: 0.747155487537384\n",
      "Epoch: 0, Step: 34720, Loss: 0.8136820197105408\n",
      "Epoch: 0, Step: 34752, Loss: 0.7914140224456787\n",
      "Epoch: 0, Step: 34784, Loss: 0.7596171498298645\n",
      "Epoch: 0, Step: 34816, Loss: 0.7232425212860107\n",
      "Epoch: 0, Step: 34848, Loss: 0.7755154371261597\n",
      "Epoch: 0, Step: 34880, Loss: 0.8159321546554565\n",
      "Epoch: 0, Step: 34912, Loss: 0.727896511554718\n",
      "Epoch: 0, Step: 34944, Loss: 0.7906689047813416\n",
      "Epoch: 0, Step: 34976, Loss: 0.7150274515151978\n",
      "Epoch: 0, Step: 35008, Loss: 0.8425689935684204\n",
      "Epoch: 0, Step: 35040, Loss: 0.7973818182945251\n",
      "Epoch: 0, Step: 35072, Loss: 0.8374186158180237\n",
      "Epoch: 0, Step: 35104, Loss: 0.7432662844657898\n",
      "Epoch: 0, Step: 35136, Loss: 0.7258313894271851\n",
      "Epoch: 0, Step: 35168, Loss: 0.7663553357124329\n",
      "Epoch: 0, Step: 35200, Loss: 0.7044199705123901\n",
      "Epoch: 0, Step: 35232, Loss: 0.739380419254303\n",
      "Epoch: 0, Step: 35264, Loss: 0.8198431730270386\n",
      "Epoch: 0, Step: 35296, Loss: 0.7259369492530823\n",
      "Epoch: 0, Step: 35328, Loss: 0.7673847079277039\n",
      "Epoch: 0, Step: 35360, Loss: 0.8453630208969116\n",
      "Epoch: 0, Step: 35392, Loss: 0.8102538585662842\n",
      "Epoch: 0, Step: 35424, Loss: 0.7991307377815247\n",
      "Epoch: 0, Step: 35456, Loss: 0.8290277719497681\n",
      "Epoch: 0, Step: 35488, Loss: 0.7324941158294678\n",
      "Epoch: 0, Step: 35520, Loss: 0.7936532497406006\n",
      "Epoch: 0, Step: 35552, Loss: 0.8221299648284912\n",
      "Epoch: 0, Step: 35584, Loss: 0.6438191533088684\n",
      "Epoch: 0, Step: 35616, Loss: 0.7785612344741821\n",
      "Epoch: 0, Step: 35648, Loss: 0.868844747543335\n",
      "Epoch: 0, Step: 35680, Loss: 0.7154501676559448\n",
      "Epoch: 0, Step: 35712, Loss: 0.8046217560768127\n",
      "Epoch: 0, Step: 35744, Loss: 0.7187197804450989\n",
      "Epoch: 0, Step: 35776, Loss: 0.7488375902175903\n",
      "Epoch: 0, Step: 35808, Loss: 0.7972034811973572\n",
      "Epoch: 0, Step: 35840, Loss: 0.7139632701873779\n",
      "Epoch: 0, Step: 35872, Loss: 0.7991398572921753\n",
      "Epoch: 0, Step: 35904, Loss: 0.8223688006401062\n",
      "Epoch: 0, Step: 35936, Loss: 0.7530289888381958\n",
      "Epoch: 0, Step: 35968, Loss: 0.8028547763824463\n",
      "Epoch: 0, Step: 36000, Loss: 0.8156219720840454\n",
      "Epoch: 0, Step: 36032, Loss: 0.7059628963470459\n",
      "Epoch: 0, Step: 36064, Loss: 0.7109807133674622\n",
      "Epoch: 0, Step: 36096, Loss: 0.6236571669578552\n",
      "Epoch: 0, Step: 36128, Loss: 0.7242153882980347\n",
      "Epoch: 0, Step: 36160, Loss: 0.8312970995903015\n",
      "Epoch: 0, Step: 36192, Loss: 0.8162676095962524\n",
      "Epoch: 0, Step: 36224, Loss: 0.7277604937553406\n",
      "Epoch: 0, Step: 36256, Loss: 0.8450443148612976\n",
      "Epoch: 0, Step: 36288, Loss: 0.7022139430046082\n",
      "Epoch: 0, Step: 36320, Loss: 0.7943137288093567\n",
      "Epoch: 0, Step: 36352, Loss: 0.7945600748062134\n",
      "Epoch: 0, Step: 36384, Loss: 0.77875155210495\n",
      "Epoch: 0, Step: 36416, Loss: 0.7926843762397766\n",
      "Epoch: 0, Step: 36448, Loss: 0.6685250997543335\n",
      "Epoch: 0, Step: 36480, Loss: 0.6409833431243896\n",
      "Epoch: 0, Step: 36512, Loss: 0.6674215197563171\n",
      "Epoch: 0, Step: 36544, Loss: 0.7709668278694153\n",
      "Epoch: 0, Step: 36576, Loss: 0.8389560580253601\n",
      "Epoch: 0, Step: 36608, Loss: 0.7705270648002625\n",
      "Epoch: 0, Step: 36640, Loss: 0.7395966053009033\n",
      "Epoch: 0, Step: 36672, Loss: 0.7484680414199829\n",
      "Epoch: 0, Step: 36704, Loss: 0.7960168719291687\n",
      "Epoch: 0, Step: 36736, Loss: 0.8351851105690002\n",
      "Epoch: 0, Step: 36768, Loss: 0.7069016098976135\n",
      "Epoch: 0, Step: 36800, Loss: 0.8004893064498901\n",
      "Epoch: 0, Step: 36832, Loss: 0.7286191582679749\n",
      "Epoch: 0, Step: 36864, Loss: 0.7579705715179443\n",
      "Epoch: 0, Step: 36896, Loss: 0.6701257228851318\n",
      "Epoch: 0, Step: 36928, Loss: 0.6998599171638489\n",
      "Epoch: 0, Step: 36960, Loss: 0.7813271880149841\n",
      "Epoch: 0, Step: 36992, Loss: 0.7456316351890564\n",
      "Epoch: 0, Step: 37024, Loss: 0.7860586643218994\n",
      "Epoch: 0, Step: 37056, Loss: 0.8145285844802856\n",
      "Epoch: 0, Step: 37088, Loss: 0.7803652882575989\n",
      "Epoch: 0, Step: 37120, Loss: 0.7292267680168152\n",
      "Epoch: 0, Step: 37152, Loss: 0.6926213502883911\n",
      "Epoch: 0, Step: 37184, Loss: 0.71157306432724\n",
      "Epoch: 0, Step: 37216, Loss: 0.7808254361152649\n",
      "Epoch: 0, Step: 37248, Loss: 0.7406231164932251\n",
      "Epoch: 0, Step: 37280, Loss: 0.8175720572471619\n",
      "Epoch: 0, Step: 37312, Loss: 0.8218854069709778\n",
      "Epoch: 0, Step: 37344, Loss: 0.7157285809516907\n",
      "Epoch: 0, Step: 37376, Loss: 0.7422714829444885\n",
      "Epoch: 0, Step: 37408, Loss: 0.7711958289146423\n",
      "Epoch: 0, Step: 37440, Loss: 0.7324886918067932\n",
      "Epoch: 0, Step: 37472, Loss: 0.7392013072967529\n",
      "Epoch: 0, Step: 37504, Loss: 0.8020678162574768\n",
      "Epoch: 0, Step: 37536, Loss: 0.7916100025177002\n",
      "Epoch: 0, Step: 37568, Loss: 0.794577956199646\n",
      "Epoch: 0, Step: 37600, Loss: 0.6750571727752686\n",
      "Epoch: 0, Step: 37632, Loss: 0.7543068528175354\n",
      "Epoch: 0, Step: 37664, Loss: 0.8526445627212524\n",
      "Epoch: 0, Step: 37696, Loss: 0.7357499599456787\n",
      "Epoch: 0, Step: 37728, Loss: 0.8602914810180664\n",
      "Epoch: 0, Step: 37760, Loss: 0.7171195149421692\n",
      "Epoch: 0, Step: 37792, Loss: 0.8059298992156982\n",
      "Epoch: 0, Step: 37824, Loss: 0.750145673751831\n",
      "Epoch: 0, Step: 37856, Loss: 0.7737637162208557\n",
      "Epoch: 0, Step: 37888, Loss: 0.6472253799438477\n",
      "Epoch: 0, Step: 37920, Loss: 0.7333549857139587\n",
      "Epoch: 0, Step: 37952, Loss: 0.857282280921936\n",
      "Epoch: 0, Step: 37984, Loss: 0.6802088022232056\n",
      "Epoch: 0, Step: 38016, Loss: 0.8168641924858093\n",
      "Epoch: 0, Step: 38048, Loss: 0.8635282516479492\n",
      "Epoch: 0, Step: 38080, Loss: 0.6770995259284973\n",
      "Epoch: 0, Step: 38112, Loss: 0.735260546207428\n",
      "Epoch: 0, Step: 38144, Loss: 0.7645326256752014\n",
      "Epoch: 0, Step: 38176, Loss: 0.7442910671234131\n",
      "Epoch: 0, Step: 38208, Loss: 0.758883535861969\n",
      "Epoch: 0, Step: 38240, Loss: 0.8149116635322571\n",
      "Epoch: 0, Step: 38272, Loss: 0.7701441049575806\n",
      "Epoch: 0, Step: 38304, Loss: 0.7372747659683228\n",
      "Epoch: 0, Step: 38336, Loss: 0.7403736710548401\n",
      "Epoch: 0, Step: 38368, Loss: 0.7497101426124573\n",
      "Epoch: 0, Step: 38400, Loss: 0.802577793598175\n",
      "Epoch: 0, Step: 38432, Loss: 0.7488510608673096\n",
      "Epoch: 0, Step: 38464, Loss: 0.8074101209640503\n",
      "Epoch: 0, Step: 38496, Loss: 0.8640987277030945\n",
      "Epoch: 0, Step: 38528, Loss: 0.8082888722419739\n",
      "Epoch: 0, Step: 38560, Loss: 0.7369353771209717\n",
      "Epoch: 0, Step: 38592, Loss: 0.6820991039276123\n",
      "Epoch: 0, Step: 38624, Loss: 0.8297768831253052\n",
      "Epoch: 0, Step: 38656, Loss: 0.8011968731880188\n",
      "Epoch: 0, Step: 38688, Loss: 0.7413564920425415\n",
      "Epoch: 0, Step: 38720, Loss: 0.7836365103721619\n",
      "Epoch: 0, Step: 38752, Loss: 0.7439420819282532\n",
      "Epoch: 0, Step: 38784, Loss: 0.7767443060874939\n",
      "Epoch: 0, Step: 38816, Loss: 0.7246452569961548\n",
      "Epoch: 0, Step: 38848, Loss: 0.6735826730728149\n",
      "Epoch: 0, Step: 38880, Loss: 0.7536674737930298\n",
      "Epoch: 0, Step: 38912, Loss: 0.6827447414398193\n",
      "Epoch: 0, Step: 38944, Loss: 0.7245177030563354\n",
      "Epoch: 0, Step: 38976, Loss: 0.7220396399497986\n",
      "Epoch: 0, Step: 39008, Loss: 0.706110417842865\n",
      "Epoch: 0, Step: 39040, Loss: 0.6901653409004211\n",
      "Epoch: 0, Step: 39072, Loss: 0.8198868036270142\n",
      "Epoch: 0, Step: 39104, Loss: 0.8263788819313049\n",
      "Epoch: 0, Step: 39136, Loss: 0.6908532381057739\n",
      "Epoch: 0, Step: 39168, Loss: 0.7857583165168762\n",
      "Epoch: 0, Step: 39200, Loss: 0.7114438414573669\n",
      "Epoch: 0, Step: 39232, Loss: 0.7916544675827026\n",
      "Epoch: 0, Step: 39264, Loss: 0.7423571348190308\n",
      "Epoch: 0, Step: 39296, Loss: 0.8178074955940247\n",
      "Epoch: 0, Step: 39328, Loss: 0.6986998319625854\n",
      "Epoch: 0, Step: 39360, Loss: 0.7445107102394104\n",
      "Epoch: 0, Step: 39392, Loss: 0.6445936560630798\n",
      "Epoch: 0, Step: 39424, Loss: 0.843260645866394\n",
      "Epoch: 0, Step: 39456, Loss: 0.7615196108818054\n",
      "Epoch: 0, Step: 39488, Loss: 0.7731873393058777\n",
      "Epoch: 0, Step: 39520, Loss: 0.7795515656471252\n",
      "Epoch: 0, Step: 39552, Loss: 0.6379303336143494\n",
      "Epoch: 0, Step: 39584, Loss: 0.8089617490768433\n",
      "Epoch: 0, Step: 39616, Loss: 0.8243978023529053\n",
      "Epoch: 0, Step: 39648, Loss: 0.7612281441688538\n",
      "Epoch: 0, Step: 39680, Loss: 0.7656940221786499\n",
      "Epoch: 0, Step: 39712, Loss: 0.7063133716583252\n",
      "Epoch: 0, Step: 39744, Loss: 0.7588402032852173\n",
      "Epoch: 0, Step: 39776, Loss: 0.8011311292648315\n",
      "Epoch: 0, Step: 39808, Loss: 0.7375068068504333\n",
      "Epoch: 0, Step: 39840, Loss: 0.689620316028595\n",
      "Epoch: 0, Step: 39872, Loss: 0.7476758360862732\n",
      "Epoch: 0, Step: 39904, Loss: 0.7350381016731262\n",
      "Epoch: 0, Step: 39936, Loss: 0.8021326661109924\n",
      "Epoch: 0, Step: 39968, Loss: 0.7953992486000061\n",
      "Epoch: 0, Step: 40000, Loss: 0.808247447013855\n",
      "Epoch: 0, Step: 40032, Loss: 0.7875456213951111\n",
      "Epoch: 0, Step: 40064, Loss: 0.8391363024711609\n",
      "Epoch: 0, Step: 40096, Loss: 0.7700647711753845\n",
      "Epoch: 0, Step: 40128, Loss: 0.8182557821273804\n",
      "Epoch: 0, Step: 40160, Loss: 0.7401235699653625\n",
      "Epoch: 0, Step: 40192, Loss: 0.7677337527275085\n",
      "Epoch: 0, Step: 40224, Loss: 0.8037468194961548\n",
      "Epoch: 0, Step: 40256, Loss: 0.7755906581878662\n",
      "Epoch: 0, Step: 40288, Loss: 0.7997242212295532\n",
      "Epoch: 0, Step: 40320, Loss: 0.7317777276039124\n",
      "Epoch: 0, Step: 40352, Loss: 0.6862895488739014\n",
      "Epoch: 0, Step: 40384, Loss: 0.7043789625167847\n",
      "Epoch: 0, Step: 40416, Loss: 0.8555318713188171\n",
      "Epoch: 0, Step: 40448, Loss: 0.7716578245162964\n",
      "Epoch: 0, Step: 40480, Loss: 0.8911893963813782\n",
      "Epoch: 0, Step: 40512, Loss: 0.8207331299781799\n",
      "Epoch: 0, Step: 40544, Loss: 0.775429368019104\n",
      "Epoch: 0, Step: 40576, Loss: 0.8065102696418762\n",
      "Epoch: 0, Step: 40608, Loss: 0.775152862071991\n",
      "Epoch: 0, Step: 40640, Loss: 0.7478338479995728\n",
      "Epoch: 0, Step: 40672, Loss: 0.7953541874885559\n",
      "Epoch: 0, Step: 40704, Loss: 0.7210304141044617\n",
      "Epoch: 0, Step: 40736, Loss: 0.6768304705619812\n",
      "Epoch: 0, Step: 40768, Loss: 0.8111989498138428\n",
      "Epoch: 0, Step: 40800, Loss: 0.7447022199630737\n",
      "Epoch: 0, Step: 40832, Loss: 0.7205362915992737\n",
      "Epoch: 0, Step: 40864, Loss: 0.6909611225128174\n",
      "Epoch: 0, Step: 40896, Loss: 0.7095668315887451\n",
      "Epoch: 0, Step: 40928, Loss: 0.7473329901695251\n",
      "Epoch: 0, Step: 40960, Loss: 0.8423523306846619\n",
      "Epoch: 0, Step: 40992, Loss: 0.8347302079200745\n",
      "Epoch: 0, Step: 41024, Loss: 0.8588822484016418\n",
      "Epoch: 0, Step: 41056, Loss: 0.8014969229698181\n",
      "Epoch: 0, Step: 41088, Loss: 0.7830396294593811\n",
      "Epoch: 0, Step: 41120, Loss: 0.7562333345413208\n",
      "Epoch: 0, Step: 41152, Loss: 0.7273195385932922\n",
      "Epoch: 0, Step: 41184, Loss: 0.7759040594100952\n",
      "Epoch: 0, Step: 41216, Loss: 0.8059479594230652\n",
      "Epoch: 0, Step: 41248, Loss: 0.7547391653060913\n",
      "Epoch: 0, Step: 41280, Loss: 0.8463415503501892\n",
      "Epoch: 0, Step: 41312, Loss: 0.8228099346160889\n",
      "Epoch: 0, Step: 41344, Loss: 0.7153450846672058\n",
      "Epoch: 0, Step: 41376, Loss: 0.7576310634613037\n",
      "Epoch: 0, Step: 41408, Loss: 0.8881289958953857\n",
      "Epoch: 0, Step: 41440, Loss: 0.7338908314704895\n",
      "Epoch: 0, Step: 41472, Loss: 0.7568790316581726\n",
      "Epoch: 0, Step: 41504, Loss: 0.7594199776649475\n",
      "Epoch: 0, Step: 41536, Loss: 0.8253015875816345\n",
      "Epoch: 0, Step: 41568, Loss: 0.7896110415458679\n",
      "Epoch: 0, Step: 41600, Loss: 0.799799382686615\n",
      "Epoch: 0, Step: 41632, Loss: 0.8245894908905029\n",
      "Epoch: 0, Step: 41664, Loss: 0.8143581748008728\n",
      "Epoch: 0, Step: 41696, Loss: 0.7844380140304565\n",
      "Epoch: 0, Step: 41728, Loss: 0.7133916020393372\n",
      "Epoch: 0, Step: 41760, Loss: 0.6566919088363647\n",
      "Epoch: 0, Step: 41792, Loss: 0.7750776410102844\n",
      "Epoch: 0, Step: 41824, Loss: 0.7656373381614685\n",
      "Epoch: 0, Step: 41856, Loss: 0.7538133859634399\n",
      "Epoch: 0, Step: 41888, Loss: 0.7728984355926514\n",
      "Epoch: 0, Step: 41920, Loss: 0.6457223892211914\n",
      "Epoch: 0, Step: 41952, Loss: 0.7530187964439392\n",
      "Epoch: 0, Step: 41984, Loss: 0.725472629070282\n",
      "Epoch: 0, Step: 42016, Loss: 0.802839457988739\n",
      "Epoch: 0, Step: 42048, Loss: 0.7050676941871643\n",
      "Epoch: 0, Step: 42080, Loss: 0.7860885262489319\n",
      "Epoch: 0, Step: 42112, Loss: 0.7050625681877136\n",
      "Epoch: 0, Step: 42144, Loss: 0.6992722153663635\n",
      "Epoch: 0, Step: 42176, Loss: 0.8026726841926575\n",
      "Epoch: 0, Step: 42208, Loss: 0.817457914352417\n",
      "Epoch: 0, Step: 42240, Loss: 0.7199196219444275\n",
      "Epoch: 0, Step: 42272, Loss: 0.7843249440193176\n",
      "Epoch: 0, Step: 42304, Loss: 0.7593904733657837\n",
      "Epoch: 0, Step: 42336, Loss: 0.7594701051712036\n",
      "Epoch: 0, Step: 42368, Loss: 0.6834694147109985\n",
      "Epoch: 0, Step: 42400, Loss: 0.6672491431236267\n",
      "Epoch: 0, Step: 42432, Loss: 0.7623879909515381\n",
      "Epoch: 0, Step: 42464, Loss: 0.7356006503105164\n",
      "Epoch: 0, Step: 42496, Loss: 0.7644652724266052\n",
      "Epoch: 0, Step: 42528, Loss: 0.7010567784309387\n",
      "Epoch: 0, Step: 42560, Loss: 0.7332236170768738\n",
      "Epoch: 0, Step: 42592, Loss: 0.6582508087158203\n",
      "Epoch: 0, Step: 42624, Loss: 0.7606440186500549\n",
      "Epoch: 0, Step: 42656, Loss: 0.7439749836921692\n",
      "Epoch: 0, Step: 42688, Loss: 0.8499482274055481\n",
      "Epoch: 0, Step: 42720, Loss: 0.7834483981132507\n",
      "Epoch: 0, Step: 42752, Loss: 0.8684051036834717\n",
      "Epoch: 0, Step: 42784, Loss: 0.7656170129776001\n",
      "Epoch: 0, Step: 42816, Loss: 0.8379079103469849\n",
      "Epoch: 0, Step: 42848, Loss: 0.7918435335159302\n",
      "Epoch: 0, Step: 42880, Loss: 0.761637806892395\n",
      "Epoch: 0, Step: 42912, Loss: 0.7212256789207458\n",
      "Epoch: 0, Step: 42944, Loss: 0.7876166701316833\n",
      "Epoch: 0, Step: 42976, Loss: 0.7263562679290771\n",
      "Epoch: 0, Step: 43008, Loss: 0.8013066649436951\n",
      "Epoch: 0, Step: 43040, Loss: 0.7791088819503784\n",
      "Epoch: 0, Step: 43072, Loss: 0.747300922870636\n",
      "Epoch: 0, Step: 43104, Loss: 0.8468979597091675\n",
      "Epoch: 0, Step: 43136, Loss: 0.7879135012626648\n",
      "Epoch: 0, Step: 43168, Loss: 0.8538186550140381\n",
      "Epoch: 0, Step: 43200, Loss: 0.811028242111206\n",
      "Epoch: 0, Step: 43232, Loss: 0.7576956152915955\n",
      "Epoch: 0, Step: 43264, Loss: 0.8502112627029419\n",
      "Epoch: 0, Step: 43296, Loss: 0.703804075717926\n",
      "Epoch: 0, Step: 43328, Loss: 0.797370970249176\n",
      "Epoch: 0, Step: 43360, Loss: 0.767830491065979\n",
      "Epoch: 0, Step: 43392, Loss: 0.8189152479171753\n",
      "Epoch: 0, Step: 43424, Loss: 0.7378198504447937\n",
      "Epoch: 0, Step: 43456, Loss: 0.8263896107673645\n",
      "Epoch: 0, Step: 43488, Loss: 0.735914945602417\n",
      "Epoch: 0, Step: 43520, Loss: 0.6981128454208374\n",
      "Epoch: 0, Step: 43552, Loss: 0.7170346975326538\n",
      "Epoch: 0, Step: 43584, Loss: 0.7509693503379822\n",
      "Epoch: 0, Step: 43616, Loss: 0.6939958930015564\n",
      "Epoch: 0, Step: 43648, Loss: 0.7988318204879761\n",
      "Epoch: 0, Step: 43680, Loss: 0.7300998568534851\n",
      "Epoch: 0, Step: 43712, Loss: 0.764119029045105\n",
      "Epoch: 0, Step: 43744, Loss: 0.7330782413482666\n",
      "Epoch: 0, Step: 43776, Loss: 0.6730936765670776\n",
      "Epoch: 0, Step: 43808, Loss: 0.7657806277275085\n",
      "Epoch: 0, Step: 43840, Loss: 0.8029448986053467\n",
      "Epoch: 0, Step: 43872, Loss: 0.7735313773155212\n",
      "Epoch: 0, Step: 43904, Loss: 0.7609593868255615\n",
      "Epoch: 0, Step: 43936, Loss: 0.7386087775230408\n",
      "Epoch: 0, Step: 43968, Loss: 0.7768487334251404\n",
      "Epoch: 1, Step: 0, Loss: 0.8628694415092468\n",
      "Epoch: 1, Step: 32, Loss: 0.7142691016197205\n",
      "Epoch: 1, Step: 64, Loss: 0.8046889901161194\n",
      "Epoch: 1, Step: 96, Loss: 0.7575763463973999\n",
      "Epoch: 1, Step: 128, Loss: 0.7802683115005493\n",
      "Epoch: 1, Step: 160, Loss: 0.7987425327301025\n",
      "Epoch: 1, Step: 192, Loss: 0.7760986089706421\n",
      "Epoch: 1, Step: 224, Loss: 0.7336333394050598\n",
      "Epoch: 1, Step: 256, Loss: 0.7244729399681091\n",
      "Epoch: 1, Step: 288, Loss: 0.8147464394569397\n",
      "Epoch: 1, Step: 320, Loss: 0.646259069442749\n",
      "Epoch: 1, Step: 352, Loss: 0.7714348435401917\n",
      "Epoch: 1, Step: 384, Loss: 0.8769193291664124\n",
      "Epoch: 1, Step: 416, Loss: 0.6715124845504761\n",
      "Epoch: 1, Step: 448, Loss: 0.6595119833946228\n",
      "Epoch: 1, Step: 480, Loss: 0.7090378403663635\n",
      "Epoch: 1, Step: 512, Loss: 0.7759779691696167\n",
      "Epoch: 1, Step: 544, Loss: 0.7927607297897339\n",
      "Epoch: 1, Step: 576, Loss: 0.7547395825386047\n",
      "Epoch: 1, Step: 608, Loss: 0.8707442283630371\n",
      "Epoch: 1, Step: 640, Loss: 0.7854101061820984\n",
      "Epoch: 1, Step: 672, Loss: 0.7965231537818909\n",
      "Epoch: 1, Step: 704, Loss: 0.7731946110725403\n",
      "Epoch: 1, Step: 736, Loss: 0.7153550982475281\n",
      "Epoch: 1, Step: 768, Loss: 0.7265595197677612\n",
      "Epoch: 1, Step: 800, Loss: 0.7822384238243103\n",
      "Epoch: 1, Step: 832, Loss: 0.7891429662704468\n",
      "Epoch: 1, Step: 864, Loss: 0.8108778595924377\n",
      "Epoch: 1, Step: 896, Loss: 0.7217665910720825\n",
      "Epoch: 1, Step: 928, Loss: 0.7873595356941223\n",
      "Epoch: 1, Step: 960, Loss: 0.7232477068901062\n",
      "Epoch: 1, Step: 992, Loss: 0.8859891891479492\n",
      "Epoch: 1, Step: 1024, Loss: 0.8302625417709351\n",
      "Epoch: 1, Step: 1056, Loss: 0.7664843797683716\n",
      "Epoch: 1, Step: 1088, Loss: 0.8116018176078796\n",
      "Epoch: 1, Step: 1120, Loss: 0.7005031108856201\n",
      "Epoch: 1, Step: 1152, Loss: 0.7224351763725281\n",
      "Epoch: 1, Step: 1184, Loss: 0.8878939747810364\n",
      "Epoch: 1, Step: 1216, Loss: 0.7188783288002014\n",
      "Epoch: 1, Step: 1248, Loss: 0.7792985439300537\n",
      "Epoch: 1, Step: 1280, Loss: 0.8525678515434265\n",
      "Epoch: 1, Step: 1312, Loss: 0.7272331118583679\n",
      "Epoch: 1, Step: 1344, Loss: 0.6835407614707947\n",
      "Epoch: 1, Step: 1376, Loss: 0.7214659452438354\n",
      "Epoch: 1, Step: 1408, Loss: 0.8029586672782898\n",
      "Epoch: 1, Step: 1440, Loss: 0.766122579574585\n",
      "Epoch: 1, Step: 1472, Loss: 0.6376382112503052\n",
      "Epoch: 1, Step: 1504, Loss: 0.739010214805603\n",
      "Epoch: 1, Step: 1536, Loss: 0.7189859747886658\n",
      "Epoch: 1, Step: 1568, Loss: 0.7943264842033386\n",
      "Epoch: 1, Step: 1600, Loss: 0.7579707503318787\n",
      "Epoch: 1, Step: 1632, Loss: 0.7768961787223816\n",
      "Epoch: 1, Step: 1664, Loss: 0.7850996255874634\n",
      "Epoch: 1, Step: 1696, Loss: 0.7701787352561951\n",
      "Epoch: 1, Step: 1728, Loss: 0.8103834390640259\n",
      "Epoch: 1, Step: 1760, Loss: 0.8034356236457825\n",
      "Epoch: 1, Step: 1792, Loss: 0.7633089423179626\n",
      "Epoch: 1, Step: 1824, Loss: 0.6524674892425537\n",
      "Epoch: 1, Step: 1856, Loss: 0.7423717975616455\n",
      "Epoch: 1, Step: 1888, Loss: 0.8113352060317993\n",
      "Epoch: 1, Step: 1920, Loss: 0.708834707736969\n",
      "Epoch: 1, Step: 1952, Loss: 0.9283725619316101\n",
      "Epoch: 1, Step: 1984, Loss: 0.7141698598861694\n",
      "Epoch: 1, Step: 2016, Loss: 0.7040792107582092\n",
      "Epoch: 1, Step: 2048, Loss: 0.8637134432792664\n",
      "Epoch: 1, Step: 2080, Loss: 0.7785156965255737\n",
      "Epoch: 1, Step: 2112, Loss: 0.8070874810218811\n",
      "Epoch: 1, Step: 2144, Loss: 0.804768979549408\n",
      "Epoch: 1, Step: 2176, Loss: 0.8098241686820984\n",
      "Epoch: 1, Step: 2208, Loss: 0.8299881219863892\n",
      "Epoch: 1, Step: 2240, Loss: 0.7524656653404236\n",
      "Epoch: 1, Step: 2272, Loss: 0.6305273771286011\n",
      "Epoch: 1, Step: 2304, Loss: 0.8205471634864807\n",
      "Epoch: 1, Step: 2336, Loss: 0.8224689364433289\n",
      "Epoch: 1, Step: 2368, Loss: 0.801179826259613\n",
      "Epoch: 1, Step: 2400, Loss: 0.8138135075569153\n",
      "Epoch: 1, Step: 2432, Loss: 0.7949942350387573\n",
      "Epoch: 1, Step: 2464, Loss: 0.7156175971031189\n",
      "Epoch: 1, Step: 2496, Loss: 0.7177358865737915\n",
      "Epoch: 1, Step: 2528, Loss: 0.760282576084137\n",
      "Epoch: 1, Step: 2560, Loss: 0.7520830035209656\n",
      "Epoch: 1, Step: 2592, Loss: 0.7698662877082825\n",
      "Epoch: 1, Step: 2624, Loss: 0.6911715269088745\n",
      "Epoch: 1, Step: 2656, Loss: 0.7619589567184448\n",
      "Epoch: 1, Step: 2688, Loss: 0.7292505502700806\n",
      "Epoch: 1, Step: 2720, Loss: 0.7371763586997986\n",
      "Epoch: 1, Step: 2752, Loss: 0.690542459487915\n",
      "Epoch: 1, Step: 2784, Loss: 0.7366449236869812\n",
      "Epoch: 1, Step: 2816, Loss: 0.6829355359077454\n",
      "Epoch: 1, Step: 2848, Loss: 0.7125459909439087\n",
      "Epoch: 1, Step: 2880, Loss: 0.8128899931907654\n",
      "Epoch: 1, Step: 2912, Loss: 0.8091458082199097\n",
      "Epoch: 1, Step: 2944, Loss: 0.7241969704627991\n",
      "Epoch: 1, Step: 2976, Loss: 0.7839022278785706\n",
      "Epoch: 1, Step: 3008, Loss: 0.7756783962249756\n",
      "Epoch: 1, Step: 3040, Loss: 0.7731744647026062\n",
      "Epoch: 1, Step: 3072, Loss: 0.8175667524337769\n",
      "Epoch: 1, Step: 3104, Loss: 0.7634271383285522\n",
      "Epoch: 1, Step: 3136, Loss: 0.7804931998252869\n",
      "Epoch: 1, Step: 3168, Loss: 0.6963256597518921\n",
      "Epoch: 1, Step: 3200, Loss: 0.7639736533164978\n",
      "Epoch: 1, Step: 3232, Loss: 0.7470210790634155\n",
      "Epoch: 1, Step: 3264, Loss: 0.7513335347175598\n",
      "Epoch: 1, Step: 3296, Loss: 0.8247769474983215\n",
      "Epoch: 1, Step: 3328, Loss: 0.6956877112388611\n",
      "Epoch: 1, Step: 3360, Loss: 0.7797039747238159\n",
      "Epoch: 1, Step: 3392, Loss: 0.7585922479629517\n",
      "Epoch: 1, Step: 3424, Loss: 0.7659709453582764\n",
      "Epoch: 1, Step: 3456, Loss: 0.7180165648460388\n",
      "Epoch: 1, Step: 3488, Loss: 0.8971316814422607\n",
      "Epoch: 1, Step: 3520, Loss: 0.7996240258216858\n",
      "Epoch: 1, Step: 3552, Loss: 0.8020962476730347\n",
      "Epoch: 1, Step: 3584, Loss: 0.7954055666923523\n",
      "Epoch: 1, Step: 3616, Loss: 0.7489320635795593\n",
      "Epoch: 1, Step: 3648, Loss: 0.7405403852462769\n",
      "Epoch: 1, Step: 3680, Loss: 0.7769278287887573\n",
      "Epoch: 1, Step: 3712, Loss: 0.788303792476654\n",
      "Epoch: 1, Step: 3744, Loss: 0.7440937757492065\n",
      "Epoch: 1, Step: 3776, Loss: 0.8014218807220459\n",
      "Epoch: 1, Step: 3808, Loss: 0.7466203570365906\n",
      "Epoch: 1, Step: 3840, Loss: 0.7824891209602356\n",
      "Epoch: 1, Step: 3872, Loss: 0.7205630540847778\n",
      "Epoch: 1, Step: 3904, Loss: 0.7939867377281189\n",
      "Epoch: 1, Step: 3936, Loss: 0.7123960852622986\n",
      "Epoch: 1, Step: 3968, Loss: 0.6910961866378784\n",
      "Epoch: 1, Step: 4000, Loss: 0.7910314798355103\n",
      "Epoch: 1, Step: 4032, Loss: 0.8022547960281372\n",
      "Epoch: 1, Step: 4064, Loss: 0.7254666090011597\n",
      "Epoch: 1, Step: 4096, Loss: 0.7772945761680603\n",
      "Epoch: 1, Step: 4128, Loss: 0.8411560654640198\n",
      "Epoch: 1, Step: 4160, Loss: 0.7786160707473755\n",
      "Epoch: 1, Step: 4192, Loss: 0.8547917008399963\n",
      "Epoch: 1, Step: 4224, Loss: 0.7608934044837952\n",
      "Epoch: 1, Step: 4256, Loss: 0.8007296323776245\n",
      "Epoch: 1, Step: 4288, Loss: 0.7415071725845337\n",
      "Epoch: 1, Step: 4320, Loss: 0.727721631526947\n",
      "Epoch: 1, Step: 4352, Loss: 0.6836220622062683\n",
      "Epoch: 1, Step: 4384, Loss: 0.7704859972000122\n",
      "Epoch: 1, Step: 4416, Loss: 0.7282507419586182\n",
      "Epoch: 1, Step: 4448, Loss: 0.7656119465827942\n",
      "Epoch: 1, Step: 4480, Loss: 0.8132364153862\n",
      "Epoch: 1, Step: 4512, Loss: 0.785882830619812\n",
      "Epoch: 1, Step: 4544, Loss: 0.7371960282325745\n",
      "Epoch: 1, Step: 4576, Loss: 0.6845343112945557\n",
      "Epoch: 1, Step: 4608, Loss: 0.7235477566719055\n",
      "Epoch: 1, Step: 4640, Loss: 0.8272345662117004\n",
      "Epoch: 1, Step: 4672, Loss: 0.7410799264907837\n",
      "Epoch: 1, Step: 4704, Loss: 0.7732773423194885\n",
      "Epoch: 1, Step: 4736, Loss: 0.7156422734260559\n",
      "Epoch: 1, Step: 4768, Loss: 0.79849773645401\n",
      "Epoch: 1, Step: 4800, Loss: 0.725355327129364\n",
      "Epoch: 1, Step: 4832, Loss: 0.8369190096855164\n",
      "Epoch: 1, Step: 4864, Loss: 0.7344152331352234\n",
      "Epoch: 1, Step: 4896, Loss: 0.7034862041473389\n",
      "Epoch: 1, Step: 4928, Loss: 0.6980891823768616\n",
      "Epoch: 1, Step: 4960, Loss: 0.7715033292770386\n",
      "Epoch: 1, Step: 4992, Loss: 0.803745687007904\n",
      "Epoch: 1, Step: 5024, Loss: 0.8373331427574158\n",
      "Epoch: 1, Step: 5056, Loss: 0.8286036252975464\n",
      "Epoch: 1, Step: 5088, Loss: 0.7312095165252686\n",
      "Epoch: 1, Step: 5120, Loss: 0.7144091129302979\n",
      "Epoch: 1, Step: 5152, Loss: 0.7190860509872437\n",
      "Epoch: 1, Step: 5184, Loss: 0.7717582583427429\n",
      "Epoch: 1, Step: 5216, Loss: 0.7928439974784851\n",
      "Epoch: 1, Step: 5248, Loss: 0.7790740132331848\n",
      "Epoch: 1, Step: 5280, Loss: 0.7296885251998901\n",
      "Epoch: 1, Step: 5312, Loss: 0.7880197763442993\n",
      "Epoch: 1, Step: 5344, Loss: 0.7842866778373718\n",
      "Epoch: 1, Step: 5376, Loss: 0.6686503291130066\n",
      "Epoch: 1, Step: 5408, Loss: 0.7793782949447632\n",
      "Epoch: 1, Step: 5440, Loss: 0.7081965208053589\n",
      "Epoch: 1, Step: 5472, Loss: 0.7480840086936951\n",
      "Epoch: 1, Step: 5504, Loss: 0.769029974937439\n",
      "Epoch: 1, Step: 5536, Loss: 0.744651734828949\n",
      "Epoch: 1, Step: 5568, Loss: 0.7722837328910828\n",
      "Epoch: 1, Step: 5600, Loss: 0.7925387620925903\n",
      "Epoch: 1, Step: 5632, Loss: 0.7655343413352966\n",
      "Epoch: 1, Step: 5664, Loss: 0.8185283541679382\n",
      "Epoch: 1, Step: 5696, Loss: 0.7631514668464661\n",
      "Epoch: 1, Step: 5728, Loss: 0.7469356060028076\n",
      "Epoch: 1, Step: 5760, Loss: 0.8651578426361084\n",
      "Epoch: 1, Step: 5792, Loss: 0.7425249218940735\n",
      "Epoch: 1, Step: 5824, Loss: 0.7297573685646057\n",
      "Epoch: 1, Step: 5856, Loss: 0.7440155148506165\n",
      "Epoch: 1, Step: 5888, Loss: 0.6924840211868286\n",
      "Epoch: 1, Step: 5920, Loss: 0.7977359294891357\n",
      "Epoch: 1, Step: 5952, Loss: 0.7157913446426392\n",
      "Epoch: 1, Step: 5984, Loss: 0.7101722955703735\n",
      "Epoch: 1, Step: 6016, Loss: 0.6919996738433838\n",
      "Epoch: 1, Step: 6048, Loss: 0.7402225732803345\n",
      "Epoch: 1, Step: 6080, Loss: 0.7544000744819641\n",
      "Epoch: 1, Step: 6112, Loss: 0.6932848691940308\n",
      "Epoch: 1, Step: 6144, Loss: 0.7388026118278503\n",
      "Epoch: 1, Step: 6176, Loss: 0.668374240398407\n",
      "Epoch: 1, Step: 6208, Loss: 0.8254377841949463\n",
      "Epoch: 1, Step: 6240, Loss: 0.7087137699127197\n",
      "Epoch: 1, Step: 6272, Loss: 0.7459353804588318\n",
      "Epoch: 1, Step: 6304, Loss: 0.7658363580703735\n",
      "Epoch: 1, Step: 6336, Loss: 0.7871832251548767\n",
      "Epoch: 1, Step: 6368, Loss: 0.707583487033844\n",
      "Epoch: 1, Step: 6400, Loss: 0.8316841721534729\n",
      "Epoch: 1, Step: 6432, Loss: 0.650183379650116\n",
      "Epoch: 1, Step: 6464, Loss: 0.7086427807807922\n",
      "Epoch: 1, Step: 6496, Loss: 0.7008118033409119\n",
      "Epoch: 1, Step: 6528, Loss: 0.8067599534988403\n",
      "Epoch: 1, Step: 6560, Loss: 0.6480387449264526\n",
      "Epoch: 1, Step: 6592, Loss: 0.810653805732727\n",
      "Epoch: 1, Step: 6624, Loss: 0.6854175329208374\n",
      "Epoch: 1, Step: 6656, Loss: 0.7668717503547668\n",
      "Epoch: 1, Step: 6688, Loss: 0.7023950219154358\n",
      "Epoch: 1, Step: 6720, Loss: 0.7919126152992249\n",
      "Epoch: 1, Step: 6752, Loss: 0.7499657273292542\n",
      "Epoch: 1, Step: 6784, Loss: 0.8560625910758972\n",
      "Epoch: 1, Step: 6816, Loss: 0.8278013467788696\n",
      "Epoch: 1, Step: 6848, Loss: 0.741934597492218\n",
      "Epoch: 1, Step: 6880, Loss: 0.7571147680282593\n",
      "Epoch: 1, Step: 6912, Loss: 0.6545050144195557\n",
      "Epoch: 1, Step: 6944, Loss: 0.7052813172340393\n",
      "Epoch: 1, Step: 6976, Loss: 0.8411850333213806\n",
      "Epoch: 1, Step: 7008, Loss: 0.8599115014076233\n",
      "Epoch: 1, Step: 7040, Loss: 0.7618191838264465\n",
      "Epoch: 1, Step: 7072, Loss: 0.6858112215995789\n",
      "Epoch: 1, Step: 7104, Loss: 0.7660837769508362\n",
      "Epoch: 1, Step: 7136, Loss: 0.7691174149513245\n",
      "Epoch: 1, Step: 7168, Loss: 0.756482720375061\n",
      "Epoch: 1, Step: 7200, Loss: 0.8007387518882751\n",
      "Epoch: 1, Step: 7232, Loss: 0.7425574660301208\n",
      "Epoch: 1, Step: 7264, Loss: 0.7486870884895325\n",
      "Epoch: 1, Step: 7296, Loss: 0.8070921301841736\n",
      "Epoch: 1, Step: 7328, Loss: 0.7172147035598755\n",
      "Epoch: 1, Step: 7360, Loss: 0.742615282535553\n",
      "Epoch: 1, Step: 7392, Loss: 0.769542396068573\n",
      "Epoch: 1, Step: 7424, Loss: 0.7676922678947449\n",
      "Epoch: 1, Step: 7456, Loss: 0.790794312953949\n",
      "Epoch: 1, Step: 7488, Loss: 0.8069681525230408\n",
      "Epoch: 1, Step: 7520, Loss: 0.6638399362564087\n",
      "Epoch: 1, Step: 7552, Loss: 0.7588684558868408\n",
      "Epoch: 1, Step: 7584, Loss: 0.6115165948867798\n",
      "Epoch: 1, Step: 7616, Loss: 0.7983322739601135\n",
      "Epoch: 1, Step: 7648, Loss: 0.8060082793235779\n",
      "Epoch: 1, Step: 7680, Loss: 0.7046695351600647\n",
      "Epoch: 1, Step: 7712, Loss: 0.7761064171791077\n",
      "Epoch: 1, Step: 7744, Loss: 0.8302280306816101\n",
      "Epoch: 1, Step: 7776, Loss: 0.8107441663742065\n",
      "Epoch: 1, Step: 7808, Loss: 0.8575175404548645\n",
      "Epoch: 1, Step: 7840, Loss: 0.7470587491989136\n",
      "Epoch: 1, Step: 7872, Loss: 0.8245258927345276\n",
      "Epoch: 1, Step: 7904, Loss: 0.8250194787979126\n",
      "Epoch: 1, Step: 7936, Loss: 0.7117317914962769\n",
      "Epoch: 1, Step: 7968, Loss: 0.6955588459968567\n",
      "Epoch: 1, Step: 8000, Loss: 0.7442436814308167\n",
      "Epoch: 1, Step: 8032, Loss: 0.7707198858261108\n",
      "Epoch: 1, Step: 8064, Loss: 0.8043249845504761\n",
      "Epoch: 1, Step: 8096, Loss: 0.7548237442970276\n",
      "Epoch: 1, Step: 8128, Loss: 0.7970997095108032\n",
      "Epoch: 1, Step: 8160, Loss: 0.7388226985931396\n",
      "Epoch: 1, Step: 8192, Loss: 0.8080635666847229\n",
      "Epoch: 1, Step: 8224, Loss: 0.7478776574134827\n",
      "Epoch: 1, Step: 8256, Loss: 0.7266181111335754\n",
      "Epoch: 1, Step: 8288, Loss: 0.7603279948234558\n",
      "Epoch: 1, Step: 8320, Loss: 0.7218567132949829\n",
      "Epoch: 1, Step: 8352, Loss: 0.7204748392105103\n",
      "Epoch: 1, Step: 8384, Loss: 0.7401325106620789\n",
      "Epoch: 1, Step: 8416, Loss: 0.6993834972381592\n",
      "Epoch: 1, Step: 8448, Loss: 0.7829315662384033\n",
      "Epoch: 1, Step: 8480, Loss: 0.7838159799575806\n",
      "Epoch: 1, Step: 8512, Loss: 0.7576495409011841\n",
      "Epoch: 1, Step: 8544, Loss: 0.8218727707862854\n",
      "Epoch: 1, Step: 8576, Loss: 0.7879951000213623\n",
      "Epoch: 1, Step: 8608, Loss: 0.7689818143844604\n",
      "Epoch: 1, Step: 8640, Loss: 0.768330454826355\n",
      "Epoch: 1, Step: 8672, Loss: 0.7352442145347595\n",
      "Epoch: 1, Step: 8704, Loss: 0.7559252381324768\n",
      "Epoch: 1, Step: 8736, Loss: 0.7593291401863098\n",
      "Epoch: 1, Step: 8768, Loss: 0.771558940410614\n",
      "Epoch: 1, Step: 8800, Loss: 0.7180139422416687\n",
      "Epoch: 1, Step: 8832, Loss: 0.7007145285606384\n",
      "Epoch: 1, Step: 8864, Loss: 0.781996488571167\n",
      "Epoch: 1, Step: 8896, Loss: 0.6849526166915894\n",
      "Epoch: 1, Step: 8928, Loss: 0.7056898474693298\n",
      "Epoch: 1, Step: 8960, Loss: 0.6745666265487671\n",
      "Epoch: 1, Step: 8992, Loss: 0.8321377635002136\n",
      "Epoch: 1, Step: 9024, Loss: 0.7276744246482849\n",
      "Epoch: 1, Step: 9056, Loss: 0.775607705116272\n",
      "Epoch: 1, Step: 9088, Loss: 0.8250173330307007\n",
      "Epoch: 1, Step: 9120, Loss: 0.8583487272262573\n",
      "Epoch: 1, Step: 9152, Loss: 0.7873373627662659\n",
      "Epoch: 1, Step: 9184, Loss: 0.6680256128311157\n",
      "Epoch: 1, Step: 9216, Loss: 0.7345348000526428\n",
      "Epoch: 1, Step: 9248, Loss: 0.706964910030365\n",
      "Epoch: 1, Step: 9280, Loss: 0.7846581935882568\n",
      "Epoch: 1, Step: 9312, Loss: 0.8975566625595093\n",
      "Epoch: 1, Step: 9344, Loss: 0.8501660227775574\n",
      "Epoch: 1, Step: 9376, Loss: 0.6935178637504578\n",
      "Epoch: 1, Step: 9408, Loss: 0.7873302698135376\n",
      "Epoch: 1, Step: 9440, Loss: 0.8340989351272583\n",
      "Epoch: 1, Step: 9472, Loss: 0.7293814420700073\n",
      "Epoch: 1, Step: 9504, Loss: 0.8680342435836792\n",
      "Epoch: 1, Step: 9536, Loss: 0.7489528059959412\n",
      "Epoch: 1, Step: 9568, Loss: 0.8154280185699463\n",
      "Epoch: 1, Step: 9600, Loss: 0.7290676832199097\n",
      "Epoch: 1, Step: 9632, Loss: 0.731123149394989\n",
      "Epoch: 1, Step: 9664, Loss: 0.7461382150650024\n",
      "Epoch: 1, Step: 9696, Loss: 0.7996448874473572\n",
      "Epoch: 1, Step: 9728, Loss: 0.6444262266159058\n",
      "Epoch: 1, Step: 9760, Loss: 0.8310267925262451\n",
      "Epoch: 1, Step: 9792, Loss: 0.7096841335296631\n",
      "Epoch: 1, Step: 9824, Loss: 0.6896656155586243\n",
      "Epoch: 1, Step: 9856, Loss: 0.7548637986183167\n",
      "Epoch: 1, Step: 9888, Loss: 0.672117292881012\n",
      "Epoch: 1, Step: 9920, Loss: 0.7630687355995178\n",
      "Epoch: 1, Step: 9952, Loss: 0.7135921716690063\n",
      "Epoch: 1, Step: 9984, Loss: 0.8321791887283325\n",
      "Epoch: 1, Step: 10016, Loss: 0.6598222255706787\n",
      "Epoch: 1, Step: 10048, Loss: 0.6723901033401489\n",
      "Epoch: 1, Step: 10080, Loss: 0.7762230634689331\n",
      "Epoch: 1, Step: 10112, Loss: 0.7171889543533325\n",
      "Epoch: 1, Step: 10144, Loss: 0.7422505617141724\n",
      "Epoch: 1, Step: 10176, Loss: 0.7961504459381104\n",
      "Epoch: 1, Step: 10208, Loss: 0.851266086101532\n",
      "Epoch: 1, Step: 10240, Loss: 0.8309237957000732\n",
      "Epoch: 1, Step: 10272, Loss: 0.7978197336196899\n",
      "Epoch: 1, Step: 10304, Loss: 0.8447377681732178\n",
      "Epoch: 1, Step: 10336, Loss: 0.8005715012550354\n",
      "Epoch: 1, Step: 10368, Loss: 0.8107420206069946\n",
      "Epoch: 1, Step: 10400, Loss: 0.8157750964164734\n",
      "Epoch: 1, Step: 10432, Loss: 0.7780807018280029\n",
      "Epoch: 1, Step: 10464, Loss: 0.784686803817749\n",
      "Epoch: 1, Step: 10496, Loss: 0.852888286113739\n",
      "Epoch: 1, Step: 10528, Loss: 0.7417944073677063\n",
      "Epoch: 1, Step: 10560, Loss: 0.7686580419540405\n",
      "Epoch: 1, Step: 10592, Loss: 0.7122451663017273\n",
      "Epoch: 1, Step: 10624, Loss: 0.7547591328620911\n",
      "Epoch: 1, Step: 10656, Loss: 0.7401369214057922\n",
      "Epoch: 1, Step: 10688, Loss: 0.7309113144874573\n",
      "Epoch: 1, Step: 10720, Loss: 0.6247197389602661\n",
      "Epoch: 1, Step: 10752, Loss: 0.7698442339897156\n",
      "Epoch: 1, Step: 10784, Loss: 0.7698904871940613\n",
      "Epoch: 1, Step: 10816, Loss: 0.7358459830284119\n",
      "Epoch: 1, Step: 10848, Loss: 0.7842718362808228\n",
      "Epoch: 1, Step: 10880, Loss: 0.7641564011573792\n",
      "Epoch: 1, Step: 10912, Loss: 0.7861205339431763\n",
      "Epoch: 1, Step: 10944, Loss: 0.788993775844574\n",
      "Epoch: 1, Step: 10976, Loss: 0.7927299737930298\n",
      "Epoch: 1, Step: 11008, Loss: 0.8115713000297546\n",
      "Epoch: 1, Step: 11040, Loss: 0.8024454712867737\n",
      "Epoch: 1, Step: 11072, Loss: 0.7286763787269592\n",
      "Epoch: 1, Step: 11104, Loss: 0.818166196346283\n",
      "Epoch: 1, Step: 11136, Loss: 0.72902911901474\n",
      "Epoch: 1, Step: 11168, Loss: 0.7194036841392517\n",
      "Epoch: 1, Step: 11200, Loss: 0.8104101419448853\n",
      "Epoch: 1, Step: 11232, Loss: 0.8262884616851807\n",
      "Epoch: 1, Step: 11264, Loss: 0.7435690760612488\n",
      "Epoch: 1, Step: 11296, Loss: 0.7322472333908081\n",
      "Epoch: 1, Step: 11328, Loss: 0.6999809145927429\n",
      "Epoch: 1, Step: 11360, Loss: 0.7240997552871704\n",
      "Epoch: 1, Step: 11392, Loss: 0.6984606385231018\n",
      "Epoch: 1, Step: 11424, Loss: 0.7662445902824402\n",
      "Epoch: 1, Step: 11456, Loss: 0.7655155658721924\n",
      "Epoch: 1, Step: 11488, Loss: 0.7817479968070984\n",
      "Epoch: 1, Step: 11520, Loss: 0.6743614673614502\n",
      "Epoch: 1, Step: 11552, Loss: 0.7708387970924377\n",
      "Epoch: 1, Step: 11584, Loss: 0.7205114960670471\n",
      "Epoch: 1, Step: 11616, Loss: 0.6529049277305603\n",
      "Epoch: 1, Step: 11648, Loss: 0.6981847286224365\n",
      "Epoch: 1, Step: 11680, Loss: 0.7753108143806458\n",
      "Epoch: 1, Step: 11712, Loss: 0.6934491395950317\n",
      "Epoch: 1, Step: 11744, Loss: 0.73546302318573\n",
      "Epoch: 1, Step: 11776, Loss: 0.8182352781295776\n",
      "Epoch: 1, Step: 11808, Loss: 0.8086240291595459\n",
      "Epoch: 1, Step: 11840, Loss: 0.7977603673934937\n",
      "Epoch: 1, Step: 11872, Loss: 0.7532035708427429\n",
      "Epoch: 1, Step: 11904, Loss: 0.7961942553520203\n",
      "Epoch: 1, Step: 11936, Loss: 0.754945695400238\n",
      "Epoch: 1, Step: 11968, Loss: 0.716965913772583\n",
      "Epoch: 1, Step: 12000, Loss: 0.8331082463264465\n",
      "Epoch: 1, Step: 12032, Loss: 0.686935305595398\n",
      "Epoch: 1, Step: 12064, Loss: 0.7992497086524963\n",
      "Epoch: 1, Step: 12096, Loss: 0.698114275932312\n",
      "Epoch: 1, Step: 12128, Loss: 0.7555100917816162\n",
      "Epoch: 1, Step: 12160, Loss: 0.6950295567512512\n",
      "Epoch: 1, Step: 12192, Loss: 0.7332661151885986\n",
      "Epoch: 1, Step: 12224, Loss: 0.7218990921974182\n",
      "Epoch: 1, Step: 12256, Loss: 0.7798903584480286\n",
      "Epoch: 1, Step: 12288, Loss: 0.8798410296440125\n",
      "Epoch: 1, Step: 12320, Loss: 0.7214024662971497\n",
      "Epoch: 1, Step: 12352, Loss: 0.8234165906906128\n",
      "Epoch: 1, Step: 12384, Loss: 0.738942563533783\n",
      "Epoch: 1, Step: 12416, Loss: 0.8431923389434814\n",
      "Epoch: 1, Step: 12448, Loss: 0.724246084690094\n",
      "Epoch: 1, Step: 12480, Loss: 0.7256147265434265\n",
      "Epoch: 1, Step: 12512, Loss: 0.7353800535202026\n",
      "Epoch: 1, Step: 12544, Loss: 0.7407947778701782\n",
      "Epoch: 1, Step: 12576, Loss: 0.7154752016067505\n",
      "Epoch: 1, Step: 12608, Loss: 0.716741681098938\n",
      "Epoch: 1, Step: 12640, Loss: 0.8710915446281433\n",
      "Epoch: 1, Step: 12672, Loss: 0.7702210545539856\n",
      "Epoch: 1, Step: 12704, Loss: 0.7194504141807556\n",
      "Epoch: 1, Step: 12736, Loss: 0.7486191987991333\n",
      "Epoch: 1, Step: 12768, Loss: 0.8136216998100281\n",
      "Epoch: 1, Step: 12800, Loss: 0.7020571827888489\n",
      "Epoch: 1, Step: 12832, Loss: 0.7295774817466736\n",
      "Epoch: 1, Step: 12864, Loss: 0.8794411420822144\n",
      "Epoch: 1, Step: 12896, Loss: 0.6802380084991455\n",
      "Epoch: 1, Step: 12928, Loss: 0.8016074299812317\n",
      "Epoch: 1, Step: 12960, Loss: 0.6573092937469482\n",
      "Epoch: 1, Step: 12992, Loss: 0.7412808537483215\n",
      "Epoch: 1, Step: 13024, Loss: 0.8600427508354187\n",
      "Epoch: 1, Step: 13056, Loss: 0.7184616327285767\n",
      "Epoch: 1, Step: 13088, Loss: 0.8561822175979614\n",
      "Epoch: 1, Step: 13120, Loss: 0.7654029726982117\n",
      "Epoch: 1, Step: 13152, Loss: 0.7898174524307251\n",
      "Epoch: 1, Step: 13184, Loss: 0.8774397969245911\n",
      "Epoch: 1, Step: 13216, Loss: 0.6400833129882812\n",
      "Epoch: 1, Step: 13248, Loss: 0.668633222579956\n",
      "Epoch: 1, Step: 13280, Loss: 0.8931481242179871\n",
      "Epoch: 1, Step: 13312, Loss: 0.8139482736587524\n",
      "Epoch: 1, Step: 13344, Loss: 0.8591314554214478\n",
      "Epoch: 1, Step: 13376, Loss: 0.6668018698692322\n",
      "Epoch: 1, Step: 13408, Loss: 0.7446030378341675\n",
      "Epoch: 1, Step: 13440, Loss: 0.6902766823768616\n",
      "Epoch: 1, Step: 13472, Loss: 0.6849101781845093\n",
      "Epoch: 1, Step: 13504, Loss: 0.74154132604599\n",
      "Epoch: 1, Step: 13536, Loss: 0.7272621393203735\n",
      "Epoch: 1, Step: 13568, Loss: 0.7622265219688416\n",
      "Epoch: 1, Step: 13600, Loss: 0.7745105624198914\n",
      "Epoch: 1, Step: 13632, Loss: 0.7458261847496033\n",
      "Epoch: 1, Step: 13664, Loss: 0.7945371866226196\n",
      "Epoch: 1, Step: 13696, Loss: 0.8159698843955994\n",
      "Epoch: 1, Step: 13728, Loss: 0.6971201300621033\n",
      "Epoch: 1, Step: 13760, Loss: 0.7772600054740906\n",
      "Epoch: 1, Step: 13792, Loss: 0.7037355303764343\n",
      "Epoch: 1, Step: 13824, Loss: 0.7391276955604553\n",
      "Epoch: 1, Step: 13856, Loss: 0.8667486906051636\n",
      "Epoch: 1, Step: 13888, Loss: 0.7220162153244019\n",
      "Epoch: 1, Step: 13920, Loss: 0.716476321220398\n",
      "Epoch: 1, Step: 13952, Loss: 0.8067668676376343\n",
      "Epoch: 1, Step: 13984, Loss: 0.7227998375892639\n",
      "Epoch: 1, Step: 14016, Loss: 0.795825719833374\n",
      "Epoch: 1, Step: 14048, Loss: 0.6931286454200745\n",
      "Epoch: 1, Step: 14080, Loss: 0.7715364694595337\n",
      "Epoch: 1, Step: 14112, Loss: 0.7526161074638367\n",
      "Epoch: 1, Step: 14144, Loss: 0.7476829290390015\n",
      "Epoch: 1, Step: 14176, Loss: 0.6883705854415894\n",
      "Epoch: 1, Step: 14208, Loss: 0.6722273230552673\n",
      "Epoch: 1, Step: 14240, Loss: 0.7737032175064087\n",
      "Epoch: 1, Step: 14272, Loss: 0.6558344960212708\n",
      "Epoch: 1, Step: 14304, Loss: 0.71214759349823\n",
      "Epoch: 1, Step: 14336, Loss: 0.714516818523407\n",
      "Epoch: 1, Step: 14368, Loss: 0.8005787134170532\n",
      "Epoch: 1, Step: 14400, Loss: 0.797233521938324\n",
      "Epoch: 1, Step: 14432, Loss: 0.7257416844367981\n",
      "Epoch: 1, Step: 14464, Loss: 0.8094879388809204\n",
      "Epoch: 1, Step: 14496, Loss: 0.7171463370323181\n",
      "Epoch: 1, Step: 14528, Loss: 0.6927193403244019\n",
      "Epoch: 1, Step: 14560, Loss: 0.7646806240081787\n",
      "Epoch: 1, Step: 14592, Loss: 0.7395173907279968\n",
      "Epoch: 1, Step: 14624, Loss: 0.7894613146781921\n",
      "Epoch: 1, Step: 14656, Loss: 0.7603985071182251\n",
      "Epoch: 1, Step: 14688, Loss: 0.7750921845436096\n",
      "Epoch: 1, Step: 14720, Loss: 0.7667390704154968\n",
      "Epoch: 1, Step: 14752, Loss: 0.798835813999176\n",
      "Epoch: 1, Step: 14784, Loss: 0.7940222024917603\n",
      "Epoch: 1, Step: 14816, Loss: 0.6874304413795471\n",
      "Epoch: 1, Step: 14848, Loss: 0.6960734128952026\n",
      "Epoch: 1, Step: 14880, Loss: 0.7129844427108765\n",
      "Epoch: 1, Step: 14912, Loss: 0.7882639169692993\n",
      "Epoch: 1, Step: 14944, Loss: 0.7659465670585632\n",
      "Epoch: 1, Step: 14976, Loss: 0.7625132203102112\n",
      "Epoch: 1, Step: 15008, Loss: 0.7839210033416748\n",
      "Epoch: 1, Step: 15040, Loss: 0.7694265246391296\n",
      "Epoch: 1, Step: 15072, Loss: 0.812698245048523\n",
      "Epoch: 1, Step: 15104, Loss: 0.7692322134971619\n",
      "Epoch: 1, Step: 15136, Loss: 0.8056551814079285\n",
      "Epoch: 1, Step: 15168, Loss: 0.7721928358078003\n",
      "Epoch: 1, Step: 15200, Loss: 0.766631007194519\n",
      "Epoch: 1, Step: 15232, Loss: 0.7160727977752686\n",
      "Epoch: 1, Step: 15264, Loss: 0.7452405095100403\n",
      "Epoch: 1, Step: 15296, Loss: 0.6946157217025757\n",
      "Epoch: 1, Step: 15328, Loss: 0.7169840335845947\n",
      "Epoch: 1, Step: 15360, Loss: 0.7570761442184448\n",
      "Epoch: 1, Step: 15392, Loss: 0.6729483008384705\n",
      "Epoch: 1, Step: 15424, Loss: 0.7396885752677917\n",
      "Epoch: 1, Step: 15456, Loss: 0.7399296164512634\n",
      "Epoch: 1, Step: 15488, Loss: 0.8722087740898132\n",
      "Epoch: 1, Step: 15520, Loss: 0.725337564945221\n",
      "Epoch: 1, Step: 15552, Loss: 0.758324384689331\n",
      "Epoch: 1, Step: 15584, Loss: 0.7877746820449829\n",
      "Epoch: 1, Step: 15616, Loss: 0.7452666759490967\n",
      "Epoch: 1, Step: 15648, Loss: 0.8188223242759705\n",
      "Epoch: 1, Step: 15680, Loss: 0.7365749478340149\n",
      "Epoch: 1, Step: 15712, Loss: 0.7066289186477661\n",
      "Epoch: 1, Step: 15744, Loss: 0.7233036756515503\n",
      "Epoch: 1, Step: 15776, Loss: 0.767666757106781\n",
      "Epoch: 1, Step: 15808, Loss: 0.7010980248451233\n",
      "Epoch: 1, Step: 15840, Loss: 0.7707803249359131\n",
      "Epoch: 1, Step: 15872, Loss: 0.6653366088867188\n",
      "Epoch: 1, Step: 15904, Loss: 0.7869356870651245\n",
      "Epoch: 1, Step: 15936, Loss: 0.7590488791465759\n",
      "Epoch: 1, Step: 15968, Loss: 0.8379133939743042\n",
      "Epoch: 1, Step: 16000, Loss: 0.7529013752937317\n",
      "Epoch: 1, Step: 16032, Loss: 0.8389989137649536\n",
      "Epoch: 1, Step: 16064, Loss: 0.7656250596046448\n",
      "Epoch: 1, Step: 16096, Loss: 0.8039951920509338\n",
      "Epoch: 1, Step: 16128, Loss: 0.7552201151847839\n",
      "Epoch: 1, Step: 16160, Loss: 0.8028272986412048\n",
      "Epoch: 1, Step: 16192, Loss: 0.7719830274581909\n",
      "Epoch: 1, Step: 16224, Loss: 0.6457511782646179\n",
      "Epoch: 1, Step: 16256, Loss: 0.6644777059555054\n",
      "Epoch: 1, Step: 16288, Loss: 0.6992403864860535\n",
      "Epoch: 1, Step: 16320, Loss: 0.6757214069366455\n",
      "Epoch: 1, Step: 16352, Loss: 0.7592235803604126\n",
      "Epoch: 1, Step: 16384, Loss: 0.8326367735862732\n",
      "Epoch: 1, Step: 16416, Loss: 0.7510602474212646\n",
      "Epoch: 1, Step: 16448, Loss: 0.664359986782074\n",
      "Epoch: 1, Step: 16480, Loss: 0.8109451532363892\n",
      "Epoch: 1, Step: 16512, Loss: 0.680611789226532\n",
      "Epoch: 1, Step: 16544, Loss: 0.8622380495071411\n",
      "Epoch: 1, Step: 16576, Loss: 0.6736584305763245\n",
      "Epoch: 1, Step: 16608, Loss: 0.7682660222053528\n",
      "Epoch: 1, Step: 16640, Loss: 0.7016772031784058\n",
      "Epoch: 1, Step: 16672, Loss: 0.7551527619361877\n",
      "Epoch: 1, Step: 16704, Loss: 0.7428942322731018\n",
      "Epoch: 1, Step: 16736, Loss: 0.7819057703018188\n",
      "Epoch: 1, Step: 16768, Loss: 0.759768545627594\n",
      "Epoch: 1, Step: 16800, Loss: 0.7935757040977478\n",
      "Epoch: 1, Step: 16832, Loss: 0.6919180154800415\n",
      "Epoch: 1, Step: 16864, Loss: 0.8946152329444885\n",
      "Epoch: 1, Step: 16896, Loss: 0.7334644198417664\n",
      "Epoch: 1, Step: 16928, Loss: 0.7953583002090454\n",
      "Epoch: 1, Step: 16960, Loss: 0.8075619339942932\n",
      "Epoch: 1, Step: 16992, Loss: 0.7573972940444946\n",
      "Epoch: 1, Step: 17024, Loss: 0.8104493618011475\n",
      "Epoch: 1, Step: 17056, Loss: 0.7833215594291687\n",
      "Epoch: 1, Step: 17088, Loss: 0.7124260663986206\n",
      "Epoch: 1, Step: 17120, Loss: 0.7638023495674133\n",
      "Epoch: 1, Step: 17152, Loss: 0.7660006284713745\n",
      "Epoch: 1, Step: 17184, Loss: 0.7418063879013062\n",
      "Epoch: 1, Step: 17216, Loss: 0.704377293586731\n",
      "Epoch: 1, Step: 17248, Loss: 0.669126570224762\n",
      "Epoch: 1, Step: 17280, Loss: 0.7324502468109131\n",
      "Epoch: 1, Step: 17312, Loss: 0.6816909909248352\n",
      "Epoch: 1, Step: 17344, Loss: 0.7537035346031189\n",
      "Epoch: 1, Step: 17376, Loss: 0.8233092427253723\n",
      "Epoch: 1, Step: 17408, Loss: 0.8006008863449097\n",
      "Epoch: 1, Step: 17440, Loss: 0.778208315372467\n",
      "Epoch: 1, Step: 17472, Loss: 0.6966663599014282\n",
      "Epoch: 1, Step: 17504, Loss: 0.7637614011764526\n",
      "Epoch: 1, Step: 17536, Loss: 0.7339266538619995\n",
      "Epoch: 1, Step: 17568, Loss: 0.7135742902755737\n",
      "Epoch: 1, Step: 17600, Loss: 0.6921986937522888\n",
      "Epoch: 1, Step: 17632, Loss: 0.7305983304977417\n",
      "Epoch: 1, Step: 17664, Loss: 0.6853545308113098\n",
      "Epoch: 1, Step: 17696, Loss: 0.6907374858856201\n",
      "Epoch: 1, Step: 17728, Loss: 0.7961471080780029\n",
      "Epoch: 1, Step: 17760, Loss: 0.6649922132492065\n",
      "Epoch: 1, Step: 17792, Loss: 0.7528220415115356\n",
      "Epoch: 1, Step: 17824, Loss: 0.8454948663711548\n",
      "Epoch: 1, Step: 17856, Loss: 0.7070620059967041\n",
      "Epoch: 1, Step: 17888, Loss: 0.7876116633415222\n",
      "Epoch: 1, Step: 17920, Loss: 0.7492653131484985\n",
      "Epoch: 1, Step: 17952, Loss: 0.7486163973808289\n",
      "Epoch: 1, Step: 17984, Loss: 0.7256819605827332\n",
      "Epoch: 1, Step: 18016, Loss: 0.7954763770103455\n",
      "Epoch: 1, Step: 18048, Loss: 0.7683259844779968\n",
      "Epoch: 1, Step: 18080, Loss: 0.6815264225006104\n",
      "Epoch: 1, Step: 18112, Loss: 0.6838861703872681\n",
      "Epoch: 1, Step: 18144, Loss: 0.7984657883644104\n",
      "Epoch: 1, Step: 18176, Loss: 0.6794480085372925\n",
      "Epoch: 1, Step: 18208, Loss: 0.8874475359916687\n",
      "Epoch: 1, Step: 18240, Loss: 0.7648491263389587\n",
      "Epoch: 1, Step: 18272, Loss: 0.701055109500885\n",
      "Epoch: 1, Step: 18304, Loss: 0.8183196187019348\n",
      "Epoch: 1, Step: 18336, Loss: 0.8040940761566162\n",
      "Epoch: 1, Step: 18368, Loss: 0.781968891620636\n",
      "Epoch: 1, Step: 18400, Loss: 0.7526834607124329\n",
      "Epoch: 1, Step: 18432, Loss: 0.7439192533493042\n",
      "Epoch: 1, Step: 18464, Loss: 0.685850203037262\n",
      "Epoch: 1, Step: 18496, Loss: 0.8936154842376709\n",
      "Epoch: 1, Step: 18528, Loss: 0.8582515716552734\n",
      "Epoch: 1, Step: 18560, Loss: 0.7656919956207275\n",
      "Epoch: 1, Step: 18592, Loss: 0.7646210789680481\n",
      "Epoch: 1, Step: 18624, Loss: 0.8021093606948853\n",
      "Epoch: 1, Step: 18656, Loss: 0.659281849861145\n",
      "Epoch: 1, Step: 18688, Loss: 0.747526228427887\n",
      "Epoch: 1, Step: 18720, Loss: 0.6767446398735046\n",
      "Epoch: 1, Step: 18752, Loss: 0.6097352504730225\n",
      "Epoch: 1, Step: 18784, Loss: 0.7126519083976746\n",
      "Epoch: 1, Step: 18816, Loss: 0.8496320247650146\n",
      "Epoch: 1, Step: 18848, Loss: 0.7846080660820007\n",
      "Epoch: 1, Step: 18880, Loss: 0.7786161303520203\n",
      "Epoch: 1, Step: 18912, Loss: 0.7656731009483337\n",
      "Epoch: 1, Step: 18944, Loss: 0.8197115659713745\n",
      "Epoch: 1, Step: 18976, Loss: 0.7481626868247986\n",
      "Epoch: 1, Step: 19008, Loss: 0.8024457097053528\n",
      "Epoch: 1, Step: 19040, Loss: 0.7488240599632263\n",
      "Epoch: 1, Step: 19072, Loss: 0.7668984532356262\n",
      "Epoch: 1, Step: 19104, Loss: 0.7408259510993958\n",
      "Epoch: 1, Step: 19136, Loss: 0.6872934699058533\n",
      "Epoch: 1, Step: 19168, Loss: 0.8004311323165894\n",
      "Epoch: 1, Step: 19200, Loss: 0.8446478247642517\n",
      "Epoch: 1, Step: 19232, Loss: 0.8058583736419678\n",
      "Epoch: 1, Step: 19264, Loss: 0.7345598936080933\n",
      "Epoch: 1, Step: 19296, Loss: 0.7706864476203918\n",
      "Epoch: 1, Step: 19328, Loss: 0.6833289265632629\n",
      "Epoch: 1, Step: 19360, Loss: 0.7412969470024109\n",
      "Epoch: 1, Step: 19392, Loss: 0.6364201307296753\n",
      "Epoch: 1, Step: 19424, Loss: 0.7860291004180908\n",
      "Epoch: 1, Step: 19456, Loss: 0.7112804651260376\n",
      "Epoch: 1, Step: 19488, Loss: 0.7607909440994263\n",
      "Epoch: 1, Step: 19520, Loss: 0.6936824321746826\n",
      "Epoch: 1, Step: 19552, Loss: 0.8139911890029907\n",
      "Epoch: 1, Step: 19584, Loss: 0.7504854798316956\n",
      "Epoch: 1, Step: 19616, Loss: 0.7473886013031006\n",
      "Epoch: 1, Step: 19648, Loss: 0.8231924772262573\n",
      "Epoch: 1, Step: 19680, Loss: 0.7200053930282593\n",
      "Epoch: 1, Step: 19712, Loss: 0.7408654689788818\n",
      "Epoch: 1, Step: 19744, Loss: 0.8390806913375854\n",
      "Epoch: 1, Step: 19776, Loss: 0.7661585211753845\n",
      "Epoch: 1, Step: 19808, Loss: 0.7713560461997986\n",
      "Epoch: 1, Step: 19840, Loss: 0.7266086935997009\n",
      "Epoch: 1, Step: 19872, Loss: 0.6940893530845642\n",
      "Epoch: 1, Step: 19904, Loss: 0.6952307224273682\n",
      "Epoch: 1, Step: 19936, Loss: 0.7774617671966553\n",
      "Epoch: 1, Step: 19968, Loss: 0.7387188076972961\n",
      "Epoch: 1, Step: 20000, Loss: 0.843286395072937\n",
      "Epoch: 1, Step: 20032, Loss: 0.7200362682342529\n",
      "Epoch: 1, Step: 20064, Loss: 0.7919026017189026\n",
      "Epoch: 1, Step: 20096, Loss: 0.7484927773475647\n",
      "Epoch: 1, Step: 20128, Loss: 0.7679151296615601\n",
      "Epoch: 1, Step: 20160, Loss: 0.7487319111824036\n",
      "Epoch: 1, Step: 20192, Loss: 0.638625979423523\n",
      "Epoch: 1, Step: 20224, Loss: 0.6991403102874756\n",
      "Epoch: 1, Step: 20256, Loss: 0.7833824753761292\n",
      "Epoch: 1, Step: 20288, Loss: 0.7606592774391174\n",
      "Epoch: 1, Step: 20320, Loss: 0.7744673490524292\n",
      "Epoch: 1, Step: 20352, Loss: 0.7458143830299377\n",
      "Epoch: 1, Step: 20384, Loss: 0.6440715789794922\n",
      "Epoch: 1, Step: 20416, Loss: 0.7239962816238403\n",
      "Epoch: 1, Step: 20448, Loss: 0.8548405766487122\n",
      "Epoch: 1, Step: 20480, Loss: 0.7169233560562134\n",
      "Epoch: 1, Step: 20512, Loss: 0.7282884120941162\n",
      "Epoch: 1, Step: 20544, Loss: 0.7849156856536865\n",
      "Epoch: 1, Step: 20576, Loss: 0.7387616634368896\n",
      "Epoch: 1, Step: 20608, Loss: 0.7682508826255798\n",
      "Epoch: 1, Step: 20640, Loss: 0.7090526819229126\n",
      "Epoch: 1, Step: 20672, Loss: 0.7068300843238831\n",
      "Epoch: 1, Step: 20704, Loss: 0.7543479800224304\n",
      "Epoch: 1, Step: 20736, Loss: 0.7586942315101624\n",
      "Epoch: 1, Step: 20768, Loss: 0.765763521194458\n",
      "Epoch: 1, Step: 20800, Loss: 0.7215569019317627\n",
      "Epoch: 1, Step: 20832, Loss: 0.8443976044654846\n",
      "Epoch: 1, Step: 20864, Loss: 0.8179630637168884\n",
      "Epoch: 1, Step: 20896, Loss: 0.667219877243042\n",
      "Epoch: 1, Step: 20928, Loss: 0.7971935868263245\n",
      "Epoch: 1, Step: 20960, Loss: 0.7550938725471497\n",
      "Epoch: 1, Step: 20992, Loss: 0.7530918717384338\n",
      "Epoch: 1, Step: 21024, Loss: 0.6718138456344604\n",
      "Epoch: 1, Step: 21056, Loss: 0.7017618417739868\n",
      "Epoch: 1, Step: 21088, Loss: 0.8926358222961426\n",
      "Epoch: 1, Step: 21120, Loss: 0.7439433932304382\n",
      "Epoch: 1, Step: 21152, Loss: 0.7362996935844421\n",
      "Epoch: 1, Step: 21184, Loss: 0.7220011353492737\n",
      "Epoch: 1, Step: 21216, Loss: 0.7124239206314087\n",
      "Epoch: 1, Step: 21248, Loss: 0.8859183192253113\n",
      "Epoch: 1, Step: 21280, Loss: 0.8139841556549072\n",
      "Epoch: 1, Step: 21312, Loss: 0.7042795419692993\n",
      "Epoch: 1, Step: 21344, Loss: 0.7786936163902283\n",
      "Epoch: 1, Step: 21376, Loss: 0.723909318447113\n",
      "Epoch: 1, Step: 21408, Loss: 0.7325273156166077\n",
      "Epoch: 1, Step: 21440, Loss: 0.7461845874786377\n",
      "Epoch: 1, Step: 21472, Loss: 0.7926850914955139\n",
      "Epoch: 1, Step: 21504, Loss: 0.6726149916648865\n",
      "Epoch: 1, Step: 21536, Loss: 0.7022956013679504\n",
      "Epoch: 1, Step: 21568, Loss: 0.6972970366477966\n",
      "Epoch: 1, Step: 21600, Loss: 0.7247874736785889\n",
      "Epoch: 1, Step: 21632, Loss: 0.752082884311676\n",
      "Epoch: 1, Step: 21664, Loss: 0.7135568857192993\n",
      "Epoch: 1, Step: 21696, Loss: 0.7892435193061829\n",
      "Epoch: 1, Step: 21728, Loss: 0.679068386554718\n",
      "Epoch: 1, Step: 21760, Loss: 0.6605522036552429\n",
      "Epoch: 1, Step: 21792, Loss: 0.748365044593811\n",
      "Epoch: 1, Step: 21824, Loss: 0.8182520270347595\n",
      "Epoch: 1, Step: 21856, Loss: 0.787443995475769\n",
      "Epoch: 1, Step: 21888, Loss: 0.6776578426361084\n",
      "Epoch: 1, Step: 21920, Loss: 0.7997782826423645\n",
      "Epoch: 1, Step: 21952, Loss: 0.6789888739585876\n",
      "Epoch: 1, Step: 21984, Loss: 0.7534619569778442\n",
      "Epoch: 1, Step: 22016, Loss: 0.7267090082168579\n",
      "Epoch: 1, Step: 22048, Loss: 0.7652162909507751\n",
      "Epoch: 1, Step: 22080, Loss: 0.7276472449302673\n",
      "Epoch: 1, Step: 22112, Loss: 0.8300502300262451\n",
      "Epoch: 1, Step: 22144, Loss: 0.8392708897590637\n",
      "Epoch: 1, Step: 22176, Loss: 0.7678953409194946\n",
      "Epoch: 1, Step: 22208, Loss: 0.8012287020683289\n",
      "Epoch: 1, Step: 22240, Loss: 0.8556405901908875\n",
      "Epoch: 1, Step: 22272, Loss: 0.8800544738769531\n",
      "Epoch: 1, Step: 22304, Loss: 0.8052851557731628\n",
      "Epoch: 1, Step: 22336, Loss: 0.7687122225761414\n",
      "Epoch: 1, Step: 22368, Loss: 0.637471079826355\n",
      "Epoch: 1, Step: 22400, Loss: 0.8553861975669861\n",
      "Epoch: 1, Step: 22432, Loss: 0.8183907270431519\n",
      "Epoch: 1, Step: 22464, Loss: 0.722436785697937\n",
      "Epoch: 1, Step: 22496, Loss: 0.7388237714767456\n",
      "Epoch: 1, Step: 22528, Loss: 0.810335099697113\n",
      "Epoch: 1, Step: 22560, Loss: 0.7320098280906677\n",
      "Epoch: 1, Step: 22592, Loss: 0.788068950176239\n",
      "Epoch: 1, Step: 22624, Loss: 0.7253122925758362\n",
      "Epoch: 1, Step: 22656, Loss: 0.849134624004364\n",
      "Epoch: 1, Step: 22688, Loss: 0.7447677850723267\n",
      "Epoch: 1, Step: 22720, Loss: 0.7407825589179993\n",
      "Epoch: 1, Step: 22752, Loss: 0.7763439416885376\n",
      "Epoch: 1, Step: 22784, Loss: 0.8262220621109009\n",
      "Epoch: 1, Step: 22816, Loss: 0.7225130796432495\n",
      "Epoch: 1, Step: 22848, Loss: 0.66192227602005\n",
      "Epoch: 1, Step: 22880, Loss: 0.7672532796859741\n",
      "Epoch: 1, Step: 22912, Loss: 0.8366178870201111\n",
      "Epoch: 1, Step: 22944, Loss: 0.7423374056816101\n",
      "Epoch: 1, Step: 22976, Loss: 0.7160509824752808\n",
      "Epoch: 1, Step: 23008, Loss: 0.7630642056465149\n",
      "Epoch: 1, Step: 23040, Loss: 0.823805034160614\n",
      "Epoch: 1, Step: 23072, Loss: 0.6789601445198059\n",
      "Epoch: 1, Step: 23104, Loss: 0.765221893787384\n",
      "Epoch: 1, Step: 23136, Loss: 0.7223846316337585\n",
      "Epoch: 1, Step: 23168, Loss: 0.7385832071304321\n",
      "Epoch: 1, Step: 23200, Loss: 0.7782737612724304\n",
      "Epoch: 1, Step: 23232, Loss: 0.7245345711708069\n",
      "Epoch: 1, Step: 23264, Loss: 0.680474042892456\n",
      "Epoch: 1, Step: 23296, Loss: 0.8218048810958862\n",
      "Epoch: 1, Step: 23328, Loss: 0.7405241131782532\n",
      "Epoch: 1, Step: 23360, Loss: 0.704560399055481\n",
      "Epoch: 1, Step: 23392, Loss: 0.8091822266578674\n",
      "Epoch: 1, Step: 23424, Loss: 0.7063106298446655\n",
      "Epoch: 1, Step: 23456, Loss: 0.7529444098472595\n",
      "Epoch: 1, Step: 23488, Loss: 0.7509482502937317\n",
      "Epoch: 1, Step: 23520, Loss: 0.8292648196220398\n",
      "Epoch: 1, Step: 23552, Loss: 0.7823887467384338\n",
      "Epoch: 1, Step: 23584, Loss: 0.7843354344367981\n",
      "Epoch: 1, Step: 23616, Loss: 0.737079918384552\n",
      "Epoch: 1, Step: 23648, Loss: 0.7243332266807556\n",
      "Epoch: 1, Step: 23680, Loss: 0.8115226030349731\n",
      "Epoch: 1, Step: 23712, Loss: 0.6880285143852234\n",
      "Epoch: 1, Step: 23744, Loss: 0.6776450276374817\n",
      "Epoch: 1, Step: 23776, Loss: 0.6444164514541626\n",
      "Epoch: 1, Step: 23808, Loss: 0.8107185959815979\n",
      "Epoch: 1, Step: 23840, Loss: 0.8514207005500793\n",
      "Epoch: 1, Step: 23872, Loss: 0.7724769115447998\n",
      "Epoch: 1, Step: 23904, Loss: 0.693922758102417\n",
      "Epoch: 1, Step: 23936, Loss: 0.8223327994346619\n",
      "Epoch: 1, Step: 23968, Loss: 0.7841309309005737\n",
      "Epoch: 1, Step: 24000, Loss: 0.8028222322463989\n",
      "Epoch: 1, Step: 24032, Loss: 0.6911080479621887\n",
      "Epoch: 1, Step: 24064, Loss: 0.8354154825210571\n",
      "Epoch: 1, Step: 24096, Loss: 0.7210076451301575\n",
      "Epoch: 1, Step: 24128, Loss: 0.7665125131607056\n",
      "Epoch: 1, Step: 24160, Loss: 0.8003420233726501\n",
      "Epoch: 1, Step: 24192, Loss: 0.7819405198097229\n",
      "Epoch: 1, Step: 24224, Loss: 0.7256152629852295\n",
      "Epoch: 1, Step: 24256, Loss: 0.7201052308082581\n",
      "Epoch: 1, Step: 24288, Loss: 0.7648676037788391\n",
      "Epoch: 1, Step: 24320, Loss: 0.7995039224624634\n",
      "Epoch: 1, Step: 24352, Loss: 0.745237410068512\n",
      "Epoch: 1, Step: 24384, Loss: 0.771753191947937\n",
      "Epoch: 1, Step: 24416, Loss: 0.7557831406593323\n",
      "Epoch: 1, Step: 24448, Loss: 0.7659161686897278\n",
      "Epoch: 1, Step: 24480, Loss: 0.6673951745033264\n",
      "Epoch: 1, Step: 24512, Loss: 0.7748335599899292\n",
      "Epoch: 1, Step: 24544, Loss: 0.8084091544151306\n",
      "Epoch: 1, Step: 24576, Loss: 0.7156895399093628\n",
      "Epoch: 1, Step: 24608, Loss: 0.7683706879615784\n",
      "Epoch: 1, Step: 24640, Loss: 0.6437041163444519\n",
      "Epoch: 1, Step: 24672, Loss: 0.7512486577033997\n",
      "Epoch: 1, Step: 24704, Loss: 0.7774462103843689\n",
      "Epoch: 1, Step: 24736, Loss: 0.7461522817611694\n",
      "Epoch: 1, Step: 24768, Loss: 0.6364855170249939\n",
      "Epoch: 1, Step: 24800, Loss: 0.8186478018760681\n",
      "Epoch: 1, Step: 24832, Loss: 0.7577804923057556\n",
      "Epoch: 1, Step: 24864, Loss: 0.7454585433006287\n",
      "Epoch: 1, Step: 24896, Loss: 0.6704351902008057\n",
      "Epoch: 1, Step: 24928, Loss: 0.7562817931175232\n",
      "Epoch: 1, Step: 24960, Loss: 0.6632343530654907\n",
      "Epoch: 1, Step: 24992, Loss: 0.7748039960861206\n",
      "Epoch: 1, Step: 25024, Loss: 0.8630725741386414\n",
      "Epoch: 1, Step: 25056, Loss: 0.7785398364067078\n",
      "Epoch: 1, Step: 25088, Loss: 0.7162430286407471\n",
      "Epoch: 1, Step: 25120, Loss: 0.7285892367362976\n",
      "Epoch: 1, Step: 25152, Loss: 0.8013814687728882\n",
      "Epoch: 1, Step: 25184, Loss: 0.714724600315094\n",
      "Epoch: 1, Step: 25216, Loss: 0.8209945559501648\n",
      "Epoch: 1, Step: 25248, Loss: 0.7171850800514221\n",
      "Epoch: 1, Step: 25280, Loss: 0.8150742053985596\n",
      "Epoch: 1, Step: 25312, Loss: 0.7724016904830933\n",
      "Epoch: 1, Step: 25344, Loss: 0.7192023396492004\n",
      "Epoch: 1, Step: 25376, Loss: 0.8199517726898193\n",
      "Epoch: 1, Step: 25408, Loss: 0.6963828206062317\n",
      "Epoch: 1, Step: 25440, Loss: 0.6910318732261658\n",
      "Epoch: 1, Step: 25472, Loss: 0.7285999655723572\n",
      "Epoch: 1, Step: 25504, Loss: 0.7546667456626892\n",
      "Epoch: 1, Step: 25536, Loss: 0.753258466720581\n",
      "Epoch: 1, Step: 25568, Loss: 0.8179441094398499\n",
      "Epoch: 1, Step: 25600, Loss: 0.8616969585418701\n",
      "Epoch: 1, Step: 25632, Loss: 0.6976251006126404\n",
      "Epoch: 1, Step: 25664, Loss: 0.8426734805107117\n",
      "Epoch: 1, Step: 25696, Loss: 0.7461863160133362\n",
      "Epoch: 1, Step: 25728, Loss: 0.8263901472091675\n",
      "Epoch: 1, Step: 25760, Loss: 0.8140481114387512\n",
      "Epoch: 1, Step: 25792, Loss: 0.7375400066375732\n",
      "Epoch: 1, Step: 25824, Loss: 0.7516561150550842\n",
      "Epoch: 1, Step: 25856, Loss: 0.7416489124298096\n",
      "Epoch: 1, Step: 25888, Loss: 0.7647989392280579\n",
      "Epoch: 1, Step: 25920, Loss: 0.7749300599098206\n",
      "Epoch: 1, Step: 25952, Loss: 0.7535950541496277\n",
      "Epoch: 1, Step: 25984, Loss: 0.6926620006561279\n",
      "Epoch: 1, Step: 26016, Loss: 0.8073667883872986\n",
      "Epoch: 1, Step: 26048, Loss: 0.7842968702316284\n",
      "Epoch: 1, Step: 26080, Loss: 0.755828320980072\n",
      "Epoch: 1, Step: 26112, Loss: 0.7093896269798279\n",
      "Epoch: 1, Step: 26144, Loss: 0.7397035956382751\n",
      "Epoch: 1, Step: 26176, Loss: 0.8084035515785217\n",
      "Epoch: 1, Step: 26208, Loss: 0.7118574380874634\n",
      "Epoch: 1, Step: 26240, Loss: 0.6747257113456726\n",
      "Epoch: 1, Step: 26272, Loss: 0.8432167768478394\n",
      "Epoch: 1, Step: 26304, Loss: 0.6782457232475281\n",
      "Epoch: 1, Step: 26336, Loss: 0.8067581057548523\n",
      "Epoch: 1, Step: 26368, Loss: 0.764704167842865\n",
      "Epoch: 1, Step: 26400, Loss: 0.6922439932823181\n",
      "Epoch: 1, Step: 26432, Loss: 0.7899681329727173\n",
      "Epoch: 1, Step: 26464, Loss: 0.7835546731948853\n",
      "Epoch: 1, Step: 26496, Loss: 0.7205069661140442\n",
      "Epoch: 1, Step: 26528, Loss: 0.6676660180091858\n",
      "Epoch: 1, Step: 26560, Loss: 0.7637656331062317\n",
      "Epoch: 1, Step: 26592, Loss: 0.6281830668449402\n",
      "Epoch: 1, Step: 26624, Loss: 0.7580741047859192\n",
      "Epoch: 1, Step: 26656, Loss: 0.7327190637588501\n",
      "Epoch: 1, Step: 26688, Loss: 0.8072302937507629\n",
      "Epoch: 1, Step: 26720, Loss: 0.7778931856155396\n",
      "Epoch: 1, Step: 26752, Loss: 0.7756608128547668\n",
      "Epoch: 1, Step: 26784, Loss: 0.7149273753166199\n",
      "Epoch: 1, Step: 26816, Loss: 0.7234424948692322\n",
      "Epoch: 1, Step: 26848, Loss: 0.7771788239479065\n",
      "Epoch: 1, Step: 26880, Loss: 0.7517550587654114\n",
      "Epoch: 1, Step: 26912, Loss: 0.7773467898368835\n",
      "Epoch: 1, Step: 26944, Loss: 0.6615095138549805\n",
      "Epoch: 1, Step: 26976, Loss: 0.7871695160865784\n",
      "Epoch: 1, Step: 27008, Loss: 0.7844851613044739\n",
      "Epoch: 1, Step: 27040, Loss: 0.6740797758102417\n",
      "Epoch: 1, Step: 27072, Loss: 0.7031697034835815\n",
      "Epoch: 1, Step: 27104, Loss: 0.7749036550521851\n",
      "Epoch: 1, Step: 27136, Loss: 0.7435722947120667\n",
      "Epoch: 1, Step: 27168, Loss: 0.7775482535362244\n",
      "Epoch: 1, Step: 27200, Loss: 0.8203698992729187\n",
      "Epoch: 1, Step: 27232, Loss: 0.7121092081069946\n",
      "Epoch: 1, Step: 27264, Loss: 0.7267310619354248\n",
      "Epoch: 1, Step: 27296, Loss: 0.7691084146499634\n",
      "Epoch: 1, Step: 27328, Loss: 0.8327221274375916\n",
      "Epoch: 1, Step: 27360, Loss: 0.7243348956108093\n",
      "Epoch: 1, Step: 27392, Loss: 0.7503123879432678\n",
      "Epoch: 1, Step: 27424, Loss: 0.683545708656311\n",
      "Epoch: 1, Step: 27456, Loss: 0.7140820026397705\n",
      "Epoch: 1, Step: 27488, Loss: 0.8280268907546997\n",
      "Epoch: 1, Step: 27520, Loss: 0.7236796617507935\n",
      "Epoch: 1, Step: 27552, Loss: 0.6847572922706604\n",
      "Epoch: 1, Step: 27584, Loss: 0.6805223822593689\n",
      "Epoch: 1, Step: 27616, Loss: 0.8314383625984192\n",
      "Epoch: 1, Step: 27648, Loss: 0.7691094875335693\n",
      "Epoch: 1, Step: 27680, Loss: 0.7115734815597534\n",
      "Epoch: 1, Step: 27712, Loss: 0.7360531091690063\n",
      "Epoch: 1, Step: 27744, Loss: 0.6977648138999939\n",
      "Epoch: 1, Step: 27776, Loss: 0.7690666913986206\n",
      "Epoch: 1, Step: 27808, Loss: 0.6614522337913513\n",
      "Epoch: 1, Step: 27840, Loss: 0.8092455267906189\n",
      "Epoch: 1, Step: 27872, Loss: 0.7557333707809448\n",
      "Epoch: 1, Step: 27904, Loss: 0.739177942276001\n",
      "Epoch: 1, Step: 27936, Loss: 0.7416626214981079\n",
      "Epoch: 1, Step: 27968, Loss: 0.7719628810882568\n",
      "Epoch: 1, Step: 28000, Loss: 0.7412284016609192\n",
      "Epoch: 1, Step: 28032, Loss: 0.7341284155845642\n",
      "Epoch: 1, Step: 28064, Loss: 0.7224653363227844\n",
      "Epoch: 1, Step: 28096, Loss: 0.8052759766578674\n",
      "Epoch: 1, Step: 28128, Loss: 0.6868984699249268\n",
      "Epoch: 1, Step: 28160, Loss: 0.6620566844940186\n",
      "Epoch: 1, Step: 28192, Loss: 0.726449191570282\n",
      "Epoch: 1, Step: 28224, Loss: 0.8816651105880737\n",
      "Epoch: 1, Step: 28256, Loss: 0.7170736789703369\n",
      "Epoch: 1, Step: 28288, Loss: 0.6876575350761414\n",
      "Epoch: 1, Step: 28320, Loss: 0.7484661340713501\n",
      "Epoch: 1, Step: 28352, Loss: 0.7020963430404663\n",
      "Epoch: 1, Step: 28384, Loss: 0.7562547922134399\n",
      "Epoch: 1, Step: 28416, Loss: 0.6837118864059448\n",
      "Epoch: 1, Step: 28448, Loss: 0.6396486759185791\n",
      "Epoch: 1, Step: 28480, Loss: 0.7886430621147156\n",
      "Epoch: 1, Step: 28512, Loss: 0.7851267457008362\n",
      "Epoch: 1, Step: 28544, Loss: 0.6433834433555603\n",
      "Epoch: 1, Step: 28576, Loss: 0.8280070424079895\n",
      "Epoch: 1, Step: 28608, Loss: 0.7641618847846985\n",
      "Epoch: 1, Step: 28640, Loss: 0.7120897173881531\n",
      "Epoch: 1, Step: 28672, Loss: 0.8214231729507446\n",
      "Epoch: 1, Step: 28704, Loss: 0.8198496103286743\n",
      "Epoch: 1, Step: 28736, Loss: 0.696989893913269\n",
      "Epoch: 1, Step: 28768, Loss: 0.7558907270431519\n",
      "Epoch: 1, Step: 28800, Loss: 0.7387055158615112\n",
      "Epoch: 1, Step: 28832, Loss: 0.826210081577301\n",
      "Epoch: 1, Step: 28864, Loss: 0.7116774320602417\n",
      "Epoch: 1, Step: 28896, Loss: 0.7359960675239563\n",
      "Epoch: 1, Step: 28928, Loss: 0.8139703869819641\n",
      "Epoch: 1, Step: 28960, Loss: 0.739002525806427\n",
      "Epoch: 1, Step: 28992, Loss: 0.7343646287918091\n",
      "Epoch: 1, Step: 29024, Loss: 0.6257790923118591\n",
      "Epoch: 1, Step: 29056, Loss: 0.7256749272346497\n",
      "Epoch: 1, Step: 29088, Loss: 0.7693077325820923\n",
      "Epoch: 1, Step: 29120, Loss: 0.6867383122444153\n",
      "Epoch: 1, Step: 29152, Loss: 0.7346559762954712\n",
      "Epoch: 1, Step: 29184, Loss: 0.7279127836227417\n",
      "Epoch: 1, Step: 29216, Loss: 0.6685604453086853\n",
      "Epoch: 1, Step: 29248, Loss: 0.7144086360931396\n",
      "Epoch: 1, Step: 29280, Loss: 0.8028032183647156\n",
      "Epoch: 1, Step: 29312, Loss: 0.8184047937393188\n",
      "Epoch: 1, Step: 29344, Loss: 0.836942732334137\n",
      "Epoch: 1, Step: 29376, Loss: 0.7730661630630493\n",
      "Epoch: 1, Step: 29408, Loss: 0.7780563831329346\n",
      "Epoch: 1, Step: 29440, Loss: 0.7283138632774353\n",
      "Epoch: 1, Step: 29472, Loss: 0.6962874531745911\n",
      "Epoch: 1, Step: 29504, Loss: 0.7802478075027466\n",
      "Epoch: 1, Step: 29536, Loss: 0.6813711524009705\n",
      "Epoch: 1, Step: 29568, Loss: 0.7398561835289001\n",
      "Epoch: 1, Step: 29600, Loss: 0.7659826874732971\n",
      "Epoch: 1, Step: 29632, Loss: 0.8719216585159302\n",
      "Epoch: 1, Step: 29664, Loss: 0.7399924397468567\n",
      "Epoch: 1, Step: 29696, Loss: 0.7884032726287842\n",
      "Epoch: 1, Step: 29728, Loss: 0.828633189201355\n",
      "Epoch: 1, Step: 29760, Loss: 0.7358425855636597\n",
      "Epoch: 1, Step: 29792, Loss: 0.7600204348564148\n",
      "Epoch: 1, Step: 29824, Loss: 0.7501997351646423\n",
      "Epoch: 1, Step: 29856, Loss: 0.7761576771736145\n",
      "Epoch: 1, Step: 29888, Loss: 0.7768595814704895\n",
      "Epoch: 1, Step: 29920, Loss: 0.7111049294471741\n",
      "Epoch: 1, Step: 29952, Loss: 0.7695179581642151\n",
      "Epoch: 1, Step: 29984, Loss: 0.7651209235191345\n",
      "Epoch: 1, Step: 30016, Loss: 0.7570945620536804\n",
      "Epoch: 1, Step: 30048, Loss: 0.6837854981422424\n",
      "Epoch: 1, Step: 30080, Loss: 0.74305659532547\n",
      "Epoch: 1, Step: 30112, Loss: 0.6864374876022339\n",
      "Epoch: 1, Step: 30144, Loss: 0.6558107137680054\n",
      "Epoch: 1, Step: 30176, Loss: 0.938957929611206\n",
      "Epoch: 1, Step: 30208, Loss: 0.7579349875450134\n",
      "Epoch: 1, Step: 30240, Loss: 0.7083637118339539\n",
      "Epoch: 1, Step: 30272, Loss: 0.5990630388259888\n",
      "Epoch: 1, Step: 30304, Loss: 0.7474959492683411\n",
      "Epoch: 1, Step: 30336, Loss: 0.7322266697883606\n",
      "Epoch: 1, Step: 30368, Loss: 0.7283084392547607\n",
      "Epoch: 1, Step: 30400, Loss: 0.6638882756233215\n",
      "Epoch: 1, Step: 30432, Loss: 0.6300840377807617\n",
      "Epoch: 1, Step: 30464, Loss: 0.7135047316551208\n",
      "Epoch: 1, Step: 30496, Loss: 0.7405456900596619\n",
      "Epoch: 1, Step: 30528, Loss: 0.7788493633270264\n",
      "Epoch: 1, Step: 30560, Loss: 0.756669282913208\n",
      "Epoch: 1, Step: 30592, Loss: 0.8061276078224182\n",
      "Epoch: 1, Step: 30624, Loss: 0.7510131597518921\n",
      "Epoch: 1, Step: 30656, Loss: 0.8113037347793579\n",
      "Epoch: 1, Step: 30688, Loss: 0.781006395816803\n",
      "Epoch: 1, Step: 30720, Loss: 0.7665568590164185\n",
      "Epoch: 1, Step: 30752, Loss: 0.7473766803741455\n",
      "Epoch: 1, Step: 30784, Loss: 0.7077764272689819\n",
      "Epoch: 1, Step: 30816, Loss: 0.7976558208465576\n",
      "Epoch: 1, Step: 30848, Loss: 0.8032436966896057\n",
      "Epoch: 1, Step: 30880, Loss: 0.8399574160575867\n",
      "Epoch: 1, Step: 30912, Loss: 0.7575739622116089\n",
      "Epoch: 1, Step: 30944, Loss: 0.7689827680587769\n",
      "Epoch: 1, Step: 30976, Loss: 0.8193560242652893\n",
      "Epoch: 1, Step: 31008, Loss: 0.6994181871414185\n",
      "Epoch: 1, Step: 31040, Loss: 0.8425086140632629\n",
      "Epoch: 1, Step: 31072, Loss: 0.7570496201515198\n",
      "Epoch: 1, Step: 31104, Loss: 0.7603785991668701\n",
      "Epoch: 1, Step: 31136, Loss: 0.7974333167076111\n",
      "Epoch: 1, Step: 31168, Loss: 0.6562150120735168\n",
      "Epoch: 1, Step: 31200, Loss: 0.7795384526252747\n",
      "Epoch: 1, Step: 31232, Loss: 0.9054955244064331\n",
      "Epoch: 1, Step: 31264, Loss: 0.7779752016067505\n",
      "Epoch: 1, Step: 31296, Loss: 0.8299041986465454\n",
      "Epoch: 1, Step: 31328, Loss: 0.7844908237457275\n",
      "Epoch: 1, Step: 31360, Loss: 0.77364581823349\n",
      "Epoch: 1, Step: 31392, Loss: 0.8923284411430359\n",
      "Epoch: 1, Step: 31424, Loss: 0.7848636507987976\n",
      "Epoch: 1, Step: 31456, Loss: 0.683500349521637\n",
      "Epoch: 1, Step: 31488, Loss: 0.7853372693061829\n",
      "Epoch: 1, Step: 31520, Loss: 0.7918320298194885\n",
      "Epoch: 1, Step: 31552, Loss: 0.7174899578094482\n",
      "Epoch: 1, Step: 31584, Loss: 0.7880439162254333\n",
      "Epoch: 1, Step: 31616, Loss: 0.7759231328964233\n",
      "Epoch: 1, Step: 31648, Loss: 0.6402691602706909\n",
      "Epoch: 1, Step: 31680, Loss: 0.8762366771697998\n",
      "Epoch: 1, Step: 31712, Loss: 0.7332380414009094\n",
      "Epoch: 1, Step: 31744, Loss: 0.6771966814994812\n",
      "Epoch: 1, Step: 31776, Loss: 0.7487990260124207\n",
      "Epoch: 1, Step: 31808, Loss: 0.8109095692634583\n",
      "Epoch: 1, Step: 31840, Loss: 0.7366916537284851\n",
      "Epoch: 1, Step: 31872, Loss: 0.7944523096084595\n",
      "Epoch: 1, Step: 31904, Loss: 0.6930024027824402\n",
      "Epoch: 1, Step: 31936, Loss: 0.6388100385665894\n",
      "Epoch: 1, Step: 31968, Loss: 0.692780077457428\n",
      "Epoch: 1, Step: 32000, Loss: 0.6502403616905212\n",
      "Epoch: 1, Step: 32032, Loss: 0.7364736199378967\n",
      "Epoch: 1, Step: 32064, Loss: 0.8308974504470825\n",
      "Epoch: 1, Step: 32096, Loss: 0.8471133708953857\n",
      "Epoch: 1, Step: 32128, Loss: 0.7519925236701965\n",
      "Epoch: 1, Step: 32160, Loss: 0.7565125226974487\n",
      "Epoch: 1, Step: 32192, Loss: 0.7066304087638855\n",
      "Epoch: 1, Step: 32224, Loss: 0.7499471306800842\n",
      "Epoch: 1, Step: 32256, Loss: 0.7616711258888245\n",
      "Epoch: 1, Step: 32288, Loss: 0.8075527548789978\n",
      "Epoch: 1, Step: 32320, Loss: 0.8569914102554321\n",
      "Epoch: 1, Step: 32352, Loss: 0.798595666885376\n",
      "Epoch: 1, Step: 32384, Loss: 0.7252151370048523\n",
      "Epoch: 1, Step: 32416, Loss: 0.7197633981704712\n",
      "Epoch: 1, Step: 32448, Loss: 0.7314423322677612\n",
      "Epoch: 1, Step: 32480, Loss: 0.7785177826881409\n",
      "Epoch: 1, Step: 32512, Loss: 0.8510937094688416\n",
      "Epoch: 1, Step: 32544, Loss: 0.7453621625900269\n",
      "Epoch: 1, Step: 32576, Loss: 0.7559854388237\n",
      "Epoch: 1, Step: 32608, Loss: 0.7561876177787781\n",
      "Epoch: 1, Step: 32640, Loss: 0.7087239027023315\n",
      "Epoch: 1, Step: 32672, Loss: 0.7163106203079224\n",
      "Epoch: 1, Step: 32704, Loss: 0.8391224145889282\n",
      "Epoch: 1, Step: 32736, Loss: 0.8374307155609131\n",
      "Epoch: 1, Step: 32768, Loss: 0.7915923595428467\n",
      "Epoch: 1, Step: 32800, Loss: 0.8096333742141724\n",
      "Epoch: 1, Step: 32832, Loss: 0.7759192585945129\n",
      "Epoch: 1, Step: 32864, Loss: 0.7130158543586731\n",
      "Epoch: 1, Step: 32896, Loss: 0.7108619809150696\n",
      "Epoch: 1, Step: 32928, Loss: 0.7297030687332153\n",
      "Epoch: 1, Step: 32960, Loss: 0.7418109774589539\n",
      "Epoch: 1, Step: 32992, Loss: 0.7290629148483276\n",
      "Epoch: 1, Step: 33024, Loss: 0.7137143611907959\n",
      "Epoch: 1, Step: 33056, Loss: 0.6738255620002747\n",
      "Epoch: 1, Step: 33088, Loss: 0.7240543961524963\n",
      "Epoch: 1, Step: 33120, Loss: 0.794747531414032\n",
      "Epoch: 1, Step: 33152, Loss: 0.8559322953224182\n",
      "Epoch: 1, Step: 33184, Loss: 0.8403387665748596\n",
      "Epoch: 1, Step: 33216, Loss: 0.7266438007354736\n",
      "Epoch: 1, Step: 33248, Loss: 0.7456738948822021\n",
      "Epoch: 1, Step: 33280, Loss: 0.8611299395561218\n",
      "Epoch: 1, Step: 33312, Loss: 0.7308253049850464\n",
      "Epoch: 1, Step: 33344, Loss: 0.6661446690559387\n",
      "Epoch: 1, Step: 33376, Loss: 0.7201912999153137\n",
      "Epoch: 1, Step: 33408, Loss: 0.692564070224762\n",
      "Epoch: 1, Step: 33440, Loss: 0.7452734708786011\n",
      "Epoch: 1, Step: 33472, Loss: 0.8009176850318909\n",
      "Epoch: 1, Step: 33504, Loss: 0.6567972898483276\n",
      "Epoch: 1, Step: 33536, Loss: 0.8150142431259155\n",
      "Epoch: 1, Step: 33568, Loss: 0.7279922366142273\n",
      "Epoch: 1, Step: 33600, Loss: 0.8364217281341553\n",
      "Epoch: 1, Step: 33632, Loss: 0.7208842039108276\n",
      "Epoch: 1, Step: 33664, Loss: 0.8171380758285522\n",
      "Epoch: 1, Step: 33696, Loss: 0.7540308237075806\n",
      "Epoch: 1, Step: 33728, Loss: 0.6666370630264282\n",
      "Epoch: 1, Step: 33760, Loss: 0.7546407580375671\n",
      "Epoch: 1, Step: 33792, Loss: 0.8237356543540955\n",
      "Epoch: 1, Step: 33824, Loss: 0.840726912021637\n",
      "Epoch: 1, Step: 33856, Loss: 0.7316095232963562\n",
      "Epoch: 1, Step: 33888, Loss: 0.7395108342170715\n",
      "Epoch: 1, Step: 33920, Loss: 0.7425380945205688\n",
      "Epoch: 1, Step: 33952, Loss: 0.7509159445762634\n",
      "Epoch: 1, Step: 33984, Loss: 0.7327931523323059\n",
      "Epoch: 1, Step: 34016, Loss: 0.7142789363861084\n",
      "Epoch: 1, Step: 34048, Loss: 0.7179282903671265\n",
      "Epoch: 1, Step: 34080, Loss: 0.6901871562004089\n",
      "Epoch: 1, Step: 34112, Loss: 0.8083044290542603\n",
      "Epoch: 1, Step: 34144, Loss: 0.7932329773902893\n",
      "Epoch: 1, Step: 34176, Loss: 0.7747552394866943\n",
      "Epoch: 1, Step: 34208, Loss: 0.8132008910179138\n",
      "Epoch: 1, Step: 34240, Loss: 0.7501327991485596\n",
      "Epoch: 1, Step: 34272, Loss: 0.8115115761756897\n",
      "Epoch: 1, Step: 34304, Loss: 0.6877138018608093\n",
      "Epoch: 1, Step: 34336, Loss: 0.7714634537696838\n",
      "Epoch: 1, Step: 34368, Loss: 0.8051496744155884\n",
      "Epoch: 1, Step: 34400, Loss: 0.7648981213569641\n",
      "Epoch: 1, Step: 34432, Loss: 0.8064436316490173\n",
      "Epoch: 1, Step: 34464, Loss: 0.6839093565940857\n",
      "Epoch: 1, Step: 34496, Loss: 0.7696859240531921\n",
      "Epoch: 1, Step: 34528, Loss: 0.7236071228981018\n",
      "Epoch: 1, Step: 34560, Loss: 0.6823850274085999\n",
      "Epoch: 1, Step: 34592, Loss: 0.8326334357261658\n",
      "Epoch: 1, Step: 34624, Loss: 0.7643216252326965\n",
      "Epoch: 1, Step: 34656, Loss: 0.6241621375083923\n",
      "Epoch: 1, Step: 34688, Loss: 0.8565452694892883\n",
      "Epoch: 1, Step: 34720, Loss: 0.7514816522598267\n",
      "Epoch: 1, Step: 34752, Loss: 0.7811903357505798\n",
      "Epoch: 1, Step: 34784, Loss: 0.6945326924324036\n",
      "Epoch: 1, Step: 34816, Loss: 0.6295735836029053\n",
      "Epoch: 1, Step: 34848, Loss: 0.7298805117607117\n",
      "Epoch: 1, Step: 34880, Loss: 0.6982864737510681\n",
      "Epoch: 1, Step: 34912, Loss: 0.7579706907272339\n",
      "Epoch: 1, Step: 34944, Loss: 0.7413656115531921\n",
      "Epoch: 1, Step: 34976, Loss: 0.7286498546600342\n",
      "Epoch: 1, Step: 35008, Loss: 0.6985024213790894\n",
      "Epoch: 1, Step: 35040, Loss: 0.7121430039405823\n",
      "Epoch: 1, Step: 35072, Loss: 0.7899040579795837\n",
      "Epoch: 1, Step: 35104, Loss: 0.7150344252586365\n",
      "Epoch: 1, Step: 35136, Loss: 0.8007256984710693\n",
      "Epoch: 1, Step: 35168, Loss: 0.7932456135749817\n",
      "Epoch: 1, Step: 35200, Loss: 0.7727814316749573\n",
      "Epoch: 1, Step: 35232, Loss: 0.7064125537872314\n",
      "Epoch: 1, Step: 35264, Loss: 0.7826240062713623\n",
      "Epoch: 1, Step: 35296, Loss: 0.7749515175819397\n",
      "Epoch: 1, Step: 35328, Loss: 0.6806461215019226\n",
      "Epoch: 1, Step: 35360, Loss: 0.8080328702926636\n",
      "Epoch: 1, Step: 35392, Loss: 0.7378847599029541\n",
      "Epoch: 1, Step: 35424, Loss: 0.7786237597465515\n",
      "Epoch: 1, Step: 35456, Loss: 0.8075383901596069\n",
      "Epoch: 1, Step: 35488, Loss: 0.7898452877998352\n",
      "Epoch: 1, Step: 35520, Loss: 0.7757194638252258\n",
      "Epoch: 1, Step: 35552, Loss: 0.7461904883384705\n",
      "Epoch: 1, Step: 35584, Loss: 0.7950590252876282\n",
      "Epoch: 1, Step: 35616, Loss: 0.8347504734992981\n",
      "Epoch: 1, Step: 35648, Loss: 0.8429540991783142\n",
      "Epoch: 1, Step: 35680, Loss: 0.7101249098777771\n",
      "Epoch: 1, Step: 35712, Loss: 0.8144052624702454\n",
      "Epoch: 1, Step: 35744, Loss: 0.7288419604301453\n",
      "Epoch: 1, Step: 35776, Loss: 0.6858469247817993\n",
      "Epoch: 1, Step: 35808, Loss: 0.77202308177948\n",
      "Epoch: 1, Step: 35840, Loss: 0.7399361729621887\n",
      "Epoch: 1, Step: 35872, Loss: 0.8051580786705017\n",
      "Epoch: 1, Step: 35904, Loss: 0.7259685397148132\n",
      "Epoch: 1, Step: 35936, Loss: 0.7114508748054504\n",
      "Epoch: 1, Step: 35968, Loss: 0.7190815210342407\n",
      "Epoch: 1, Step: 36000, Loss: 0.6942090392112732\n",
      "Epoch: 1, Step: 36032, Loss: 0.9007463455200195\n",
      "Epoch: 1, Step: 36064, Loss: 0.7121726274490356\n",
      "Epoch: 1, Step: 36096, Loss: 0.8390324711799622\n",
      "Epoch: 1, Step: 36128, Loss: 0.7131916880607605\n",
      "Epoch: 1, Step: 36160, Loss: 0.7748053669929504\n",
      "Epoch: 1, Step: 36192, Loss: 0.8510905504226685\n",
      "Epoch: 1, Step: 36224, Loss: 0.7476359605789185\n",
      "Epoch: 1, Step: 36256, Loss: 0.6984304785728455\n",
      "Epoch: 1, Step: 36288, Loss: 0.733491063117981\n",
      "Epoch: 1, Step: 36320, Loss: 0.6698720455169678\n",
      "Epoch: 1, Step: 36352, Loss: 0.765265703201294\n",
      "Epoch: 1, Step: 36384, Loss: 0.7108940482139587\n",
      "Epoch: 1, Step: 36416, Loss: 0.7071710228919983\n",
      "Epoch: 1, Step: 36448, Loss: 0.7106756567955017\n",
      "Epoch: 1, Step: 36480, Loss: 0.7424765229225159\n",
      "Epoch: 1, Step: 36512, Loss: 0.804208517074585\n",
      "Epoch: 1, Step: 36544, Loss: 0.7420035600662231\n",
      "Epoch: 1, Step: 36576, Loss: 0.8704549074172974\n",
      "Epoch: 1, Step: 36608, Loss: 0.717022180557251\n",
      "Epoch: 1, Step: 36640, Loss: 0.6818364262580872\n",
      "Epoch: 1, Step: 36672, Loss: 0.6297001242637634\n",
      "Epoch: 1, Step: 36704, Loss: 0.7063782215118408\n",
      "Epoch: 1, Step: 36736, Loss: 0.6887823939323425\n",
      "Epoch: 1, Step: 36768, Loss: 0.7123687267303467\n",
      "Epoch: 1, Step: 36800, Loss: 0.7680178284645081\n",
      "Epoch: 1, Step: 36832, Loss: 0.7584284543991089\n",
      "Epoch: 1, Step: 36864, Loss: 0.7516751885414124\n",
      "Epoch: 1, Step: 36896, Loss: 0.7730680704116821\n",
      "Epoch: 1, Step: 36928, Loss: 0.7332488298416138\n",
      "Epoch: 1, Step: 36960, Loss: 0.7300412654876709\n",
      "Epoch: 1, Step: 36992, Loss: 0.719808042049408\n",
      "Epoch: 1, Step: 37024, Loss: 0.7719458341598511\n",
      "Epoch: 1, Step: 37056, Loss: 0.74490886926651\n",
      "Epoch: 1, Step: 37088, Loss: 0.6927616000175476\n",
      "Epoch: 1, Step: 37120, Loss: 0.7586979269981384\n",
      "Epoch: 1, Step: 37152, Loss: 0.62908935546875\n",
      "Epoch: 1, Step: 37184, Loss: 0.7858865261077881\n",
      "Epoch: 1, Step: 37216, Loss: 0.7181004285812378\n",
      "Epoch: 1, Step: 37248, Loss: 0.651722252368927\n",
      "Epoch: 1, Step: 37280, Loss: 0.7552090287208557\n",
      "Epoch: 1, Step: 37312, Loss: 0.8240611553192139\n",
      "Epoch: 1, Step: 37344, Loss: 0.7702124714851379\n",
      "Epoch: 1, Step: 37376, Loss: 0.7098726630210876\n",
      "Epoch: 1, Step: 37408, Loss: 0.8214396238327026\n",
      "Epoch: 1, Step: 37440, Loss: 0.717268168926239\n",
      "Epoch: 1, Step: 37472, Loss: 0.6913411617279053\n",
      "Epoch: 1, Step: 37504, Loss: 0.6992927193641663\n",
      "Epoch: 1, Step: 37536, Loss: 0.7500117421150208\n",
      "Epoch: 1, Step: 37568, Loss: 0.7801960110664368\n",
      "Epoch: 1, Step: 37600, Loss: 0.6177440881729126\n",
      "Epoch: 1, Step: 37632, Loss: 0.7270208597183228\n",
      "Epoch: 1, Step: 37664, Loss: 0.7294350862503052\n",
      "Epoch: 1, Step: 37696, Loss: 0.634765625\n",
      "Epoch: 1, Step: 37728, Loss: 0.7487671971321106\n",
      "Epoch: 1, Step: 37760, Loss: 0.7914469242095947\n",
      "Epoch: 1, Step: 37792, Loss: 0.7400814294815063\n",
      "Epoch: 1, Step: 37824, Loss: 0.6596425175666809\n",
      "Epoch: 1, Step: 37856, Loss: 0.7758069634437561\n",
      "Epoch: 1, Step: 37888, Loss: 0.6611493229866028\n",
      "Epoch: 1, Step: 37920, Loss: 0.7771458029747009\n",
      "Epoch: 1, Step: 37952, Loss: 0.7569959163665771\n",
      "Epoch: 1, Step: 37984, Loss: 0.7047047019004822\n",
      "Epoch: 1, Step: 38016, Loss: 0.826979398727417\n",
      "Epoch: 1, Step: 38048, Loss: 0.7593091130256653\n",
      "Epoch: 1, Step: 38080, Loss: 0.7474838495254517\n",
      "Epoch: 1, Step: 38112, Loss: 0.7397423982620239\n",
      "Epoch: 1, Step: 38144, Loss: 0.6718738079071045\n",
      "Epoch: 1, Step: 38176, Loss: 0.6565244197845459\n",
      "Epoch: 1, Step: 38208, Loss: 0.6966375708580017\n",
      "Epoch: 1, Step: 38240, Loss: 0.6574956178665161\n",
      "Epoch: 1, Step: 38272, Loss: 0.6456144452095032\n",
      "Epoch: 1, Step: 38304, Loss: 0.7653299570083618\n",
      "Epoch: 1, Step: 38336, Loss: 0.6947659254074097\n",
      "Epoch: 1, Step: 38368, Loss: 0.7167413234710693\n",
      "Epoch: 1, Step: 38400, Loss: 0.6161100268363953\n",
      "Epoch: 1, Step: 38432, Loss: 0.729397177696228\n",
      "Epoch: 1, Step: 38464, Loss: 0.7965734004974365\n",
      "Epoch: 1, Step: 38496, Loss: 0.7795255184173584\n",
      "Epoch: 1, Step: 38528, Loss: 0.7656368613243103\n",
      "Epoch: 1, Step: 38560, Loss: 0.73668372631073\n",
      "Epoch: 1, Step: 38592, Loss: 0.7436386346817017\n",
      "Epoch: 1, Step: 38624, Loss: 0.7585292458534241\n",
      "Epoch: 1, Step: 38656, Loss: 0.8573627471923828\n",
      "Epoch: 1, Step: 38688, Loss: 0.7897362112998962\n",
      "Epoch: 1, Step: 38720, Loss: 0.7593079209327698\n",
      "Epoch: 1, Step: 38752, Loss: 0.8420616984367371\n",
      "Epoch: 1, Step: 38784, Loss: 0.7177862524986267\n",
      "Epoch: 1, Step: 38816, Loss: 0.892734169960022\n",
      "Epoch: 1, Step: 38848, Loss: 0.7127150297164917\n",
      "Epoch: 1, Step: 38880, Loss: 0.800268292427063\n",
      "Epoch: 1, Step: 38912, Loss: 0.7433335185050964\n",
      "Epoch: 1, Step: 38944, Loss: 0.8109457492828369\n",
      "Epoch: 1, Step: 38976, Loss: 0.7023414373397827\n",
      "Epoch: 1, Step: 39008, Loss: 0.7274449467658997\n",
      "Epoch: 1, Step: 39040, Loss: 0.7342317700386047\n",
      "Epoch: 1, Step: 39072, Loss: 0.6815413236618042\n",
      "Epoch: 1, Step: 39104, Loss: 0.7520010471343994\n",
      "Epoch: 1, Step: 39136, Loss: 0.7059777975082397\n",
      "Epoch: 1, Step: 39168, Loss: 0.852698564529419\n",
      "Epoch: 1, Step: 39200, Loss: 0.7144553661346436\n",
      "Epoch: 1, Step: 39232, Loss: 0.7436832785606384\n",
      "Epoch: 1, Step: 39264, Loss: 0.8458677530288696\n",
      "Epoch: 1, Step: 39296, Loss: 0.7947801947593689\n",
      "Epoch: 1, Step: 39328, Loss: 0.7628333568572998\n",
      "Epoch: 1, Step: 39360, Loss: 0.7215458154678345\n",
      "Epoch: 1, Step: 39392, Loss: 0.8023545742034912\n",
      "Epoch: 1, Step: 39424, Loss: 0.7865456938743591\n",
      "Epoch: 1, Step: 39456, Loss: 0.7363365292549133\n",
      "Epoch: 1, Step: 39488, Loss: 0.7630735635757446\n",
      "Epoch: 1, Step: 39520, Loss: 0.6865714192390442\n",
      "Epoch: 1, Step: 39552, Loss: 0.7620632648468018\n",
      "Epoch: 1, Step: 39584, Loss: 0.68196040391922\n",
      "Epoch: 1, Step: 39616, Loss: 0.723861038684845\n",
      "Epoch: 1, Step: 39648, Loss: 0.7126878499984741\n",
      "Epoch: 1, Step: 39680, Loss: 0.6636574864387512\n",
      "Epoch: 1, Step: 39712, Loss: 0.7738276124000549\n",
      "Epoch: 1, Step: 39744, Loss: 0.7738228440284729\n",
      "Epoch: 1, Step: 39776, Loss: 0.782418966293335\n",
      "Epoch: 1, Step: 39808, Loss: 0.8146510720252991\n",
      "Epoch: 1, Step: 39840, Loss: 0.7143747806549072\n",
      "Epoch: 1, Step: 39872, Loss: 0.773415744304657\n",
      "Epoch: 1, Step: 39904, Loss: 0.7457722425460815\n",
      "Epoch: 1, Step: 39936, Loss: 0.6922608017921448\n",
      "Epoch: 1, Step: 39968, Loss: 0.7345125079154968\n",
      "Epoch: 1, Step: 40000, Loss: 0.6767902970314026\n",
      "Epoch: 1, Step: 40032, Loss: 0.7519568204879761\n",
      "Epoch: 1, Step: 40064, Loss: 0.7062776684761047\n",
      "Epoch: 1, Step: 40096, Loss: 0.7306801080703735\n",
      "Epoch: 1, Step: 40128, Loss: 0.7050506472587585\n",
      "Epoch: 1, Step: 40160, Loss: 0.7168956398963928\n",
      "Epoch: 1, Step: 40192, Loss: 0.7824972867965698\n",
      "Epoch: 1, Step: 40224, Loss: 0.753859281539917\n",
      "Epoch: 1, Step: 40256, Loss: 0.7496243119239807\n",
      "Epoch: 1, Step: 40288, Loss: 0.6637424230575562\n",
      "Epoch: 1, Step: 40320, Loss: 0.7759988307952881\n",
      "Epoch: 1, Step: 40352, Loss: 0.8031739592552185\n",
      "Epoch: 1, Step: 40384, Loss: 0.7577852606773376\n",
      "Epoch: 1, Step: 40416, Loss: 0.7831717133522034\n",
      "Epoch: 1, Step: 40448, Loss: 0.6804974675178528\n",
      "Epoch: 1, Step: 40480, Loss: 0.7499092817306519\n",
      "Epoch: 1, Step: 40512, Loss: 0.8612618446350098\n",
      "Epoch: 1, Step: 40544, Loss: 0.8048304319381714\n",
      "Epoch: 1, Step: 40576, Loss: 0.7116125822067261\n",
      "Epoch: 1, Step: 40608, Loss: 0.6805921196937561\n",
      "Epoch: 1, Step: 40640, Loss: 0.8824458122253418\n",
      "Epoch: 1, Step: 40672, Loss: 0.6967347264289856\n",
      "Epoch: 1, Step: 40704, Loss: 0.7609158158302307\n",
      "Epoch: 1, Step: 40736, Loss: 0.7918569445610046\n",
      "Epoch: 1, Step: 40768, Loss: 0.6846586465835571\n",
      "Epoch: 1, Step: 40800, Loss: 0.7086375951766968\n",
      "Epoch: 1, Step: 40832, Loss: 0.765929102897644\n",
      "Epoch: 1, Step: 40864, Loss: 0.6796962022781372\n",
      "Epoch: 1, Step: 40896, Loss: 0.7421308755874634\n",
      "Epoch: 1, Step: 40928, Loss: 0.7469812631607056\n",
      "Epoch: 1, Step: 40960, Loss: 0.7952272891998291\n",
      "Epoch: 1, Step: 40992, Loss: 0.6453206539154053\n",
      "Epoch: 1, Step: 41024, Loss: 0.6844114065170288\n",
      "Epoch: 1, Step: 41056, Loss: 0.6167999505996704\n",
      "Epoch: 1, Step: 41088, Loss: 0.6666073203086853\n",
      "Epoch: 1, Step: 41120, Loss: 0.7515909671783447\n",
      "Epoch: 1, Step: 41152, Loss: 0.902573823928833\n",
      "Epoch: 1, Step: 41184, Loss: 0.6805212497711182\n",
      "Epoch: 1, Step: 41216, Loss: 0.8353737592697144\n",
      "Epoch: 1, Step: 41248, Loss: 0.6738196611404419\n",
      "Epoch: 1, Step: 41280, Loss: 0.7237245440483093\n",
      "Epoch: 1, Step: 41312, Loss: 0.7329990863800049\n",
      "Epoch: 1, Step: 41344, Loss: 0.8061861395835876\n",
      "Epoch: 1, Step: 41376, Loss: 0.7163180708885193\n",
      "Epoch: 1, Step: 41408, Loss: 0.6844853162765503\n",
      "Epoch: 1, Step: 41440, Loss: 0.7583768963813782\n",
      "Epoch: 1, Step: 41472, Loss: 0.7911228537559509\n",
      "Epoch: 1, Step: 41504, Loss: 0.7679885029792786\n",
      "Epoch: 1, Step: 41536, Loss: 0.8673308491706848\n",
      "Epoch: 1, Step: 41568, Loss: 0.6753934025764465\n",
      "Epoch: 1, Step: 41600, Loss: 0.7244559526443481\n",
      "Epoch: 1, Step: 41632, Loss: 0.8100867867469788\n",
      "Epoch: 1, Step: 41664, Loss: 0.7554322481155396\n",
      "Epoch: 1, Step: 41696, Loss: 0.8115194439888\n",
      "Epoch: 1, Step: 41728, Loss: 0.7420856356620789\n",
      "Epoch: 1, Step: 41760, Loss: 0.686700165271759\n",
      "Epoch: 1, Step: 41792, Loss: 0.7435685396194458\n",
      "Epoch: 1, Step: 41824, Loss: 0.9041447639465332\n",
      "Epoch: 1, Step: 41856, Loss: 0.7329228520393372\n",
      "Epoch: 1, Step: 41888, Loss: 0.8159081935882568\n",
      "Epoch: 1, Step: 41920, Loss: 0.6858236193656921\n",
      "Epoch: 1, Step: 41952, Loss: 0.8282588124275208\n",
      "Epoch: 1, Step: 41984, Loss: 0.780160665512085\n",
      "Epoch: 1, Step: 42016, Loss: 0.7673361897468567\n",
      "Epoch: 1, Step: 42048, Loss: 0.6435033679008484\n",
      "Epoch: 1, Step: 42080, Loss: 0.6860110759735107\n",
      "Epoch: 1, Step: 42112, Loss: 0.7325127124786377\n",
      "Epoch: 1, Step: 42144, Loss: 0.797804057598114\n",
      "Epoch: 1, Step: 42176, Loss: 0.8260508179664612\n",
      "Epoch: 1, Step: 42208, Loss: 0.8342617750167847\n",
      "Epoch: 1, Step: 42240, Loss: 0.7139624357223511\n",
      "Epoch: 1, Step: 42272, Loss: 0.724091649055481\n",
      "Epoch: 1, Step: 42304, Loss: 0.7157462239265442\n",
      "Epoch: 1, Step: 42336, Loss: 0.7163122892379761\n",
      "Epoch: 1, Step: 42368, Loss: 0.70450359582901\n",
      "Epoch: 1, Step: 42400, Loss: 0.6833897233009338\n",
      "Epoch: 1, Step: 42432, Loss: 0.7341841459274292\n",
      "Epoch: 1, Step: 42464, Loss: 0.7246761918067932\n",
      "Epoch: 1, Step: 42496, Loss: 0.7816731333732605\n",
      "Epoch: 1, Step: 42528, Loss: 0.7916942834854126\n",
      "Epoch: 1, Step: 42560, Loss: 0.7843400835990906\n",
      "Epoch: 1, Step: 42592, Loss: 0.7712345719337463\n",
      "Epoch: 1, Step: 42624, Loss: 0.7132881879806519\n",
      "Epoch: 1, Step: 42656, Loss: 0.8002952337265015\n",
      "Epoch: 1, Step: 42688, Loss: 0.7684352993965149\n",
      "Epoch: 1, Step: 42720, Loss: 0.8849080204963684\n",
      "Epoch: 1, Step: 42752, Loss: 0.7002117037773132\n",
      "Epoch: 1, Step: 42784, Loss: 0.7262092232704163\n",
      "Epoch: 1, Step: 42816, Loss: 0.7203666567802429\n",
      "Epoch: 1, Step: 42848, Loss: 0.6841164231300354\n",
      "Epoch: 1, Step: 42880, Loss: 0.8024493455886841\n",
      "Epoch: 1, Step: 42912, Loss: 0.7396019697189331\n",
      "Epoch: 1, Step: 42944, Loss: 0.7050898671150208\n",
      "Epoch: 1, Step: 42976, Loss: 0.7017006278038025\n",
      "Epoch: 1, Step: 43008, Loss: 0.7596834897994995\n",
      "Epoch: 1, Step: 43040, Loss: 0.7422502636909485\n",
      "Epoch: 1, Step: 43072, Loss: 0.7632701992988586\n",
      "Epoch: 1, Step: 43104, Loss: 0.7705352306365967\n",
      "Epoch: 1, Step: 43136, Loss: 0.7728288173675537\n",
      "Epoch: 1, Step: 43168, Loss: 0.7570499777793884\n",
      "Epoch: 1, Step: 43200, Loss: 0.7627878785133362\n",
      "Epoch: 1, Step: 43232, Loss: 0.7180348038673401\n",
      "Epoch: 1, Step: 43264, Loss: 0.7045758366584778\n",
      "Epoch: 1, Step: 43296, Loss: 0.6931331157684326\n",
      "Epoch: 1, Step: 43328, Loss: 0.7422134280204773\n",
      "Epoch: 1, Step: 43360, Loss: 0.659168541431427\n",
      "Epoch: 1, Step: 43392, Loss: 0.7281790971755981\n",
      "Epoch: 1, Step: 43424, Loss: 0.5823619961738586\n",
      "Epoch: 1, Step: 43456, Loss: 0.6844492554664612\n",
      "Epoch: 1, Step: 43488, Loss: 0.8143945932388306\n",
      "Epoch: 1, Step: 43520, Loss: 0.6991227865219116\n",
      "Epoch: 1, Step: 43552, Loss: 0.7159010767936707\n",
      "Epoch: 1, Step: 43584, Loss: 0.6977146863937378\n",
      "Epoch: 1, Step: 43616, Loss: 0.7444468140602112\n",
      "Epoch: 1, Step: 43648, Loss: 0.7479141354560852\n",
      "Epoch: 1, Step: 43680, Loss: 0.7497112154960632\n",
      "Epoch: 1, Step: 43712, Loss: 0.7817344069480896\n",
      "Epoch: 1, Step: 43744, Loss: 0.6763755083084106\n",
      "Epoch: 1, Step: 43776, Loss: 0.7035186886787415\n",
      "Epoch: 1, Step: 43808, Loss: 0.7337616682052612\n",
      "Epoch: 1, Step: 43840, Loss: 0.7309287190437317\n",
      "Epoch: 1, Step: 43872, Loss: 0.7394248843193054\n",
      "Epoch: 1, Step: 43904, Loss: 0.6978884339332581\n",
      "Epoch: 1, Step: 43936, Loss: 0.789326012134552\n",
      "Epoch: 1, Step: 43968, Loss: 0.7033339142799377\n",
      "Starting prediction...\n",
      "Loss: 0.6472970843315125\n",
      "Loss: 0.6748070120811462\n",
      "Loss: 0.6225723028182983\n",
      "Loss: 0.6386877298355103\n",
      "Loss: 0.7037751078605652\n",
      "Loss: 0.6559200286865234\n",
      "Loss: 0.6629856824874878\n",
      "Loss: 0.5883535146713257\n",
      "Loss: 0.6109899282455444\n",
      "Loss: 0.6186613440513611\n",
      "Loss: 0.565934956073761\n",
      "Loss: 0.5869108438491821\n",
      "Loss: 0.679189920425415\n",
      "Loss: 0.6387376189231873\n",
      "Loss: 0.6389010548591614\n",
      "Loss: 0.5768986940383911\n",
      "Loss: 0.6545328497886658\n",
      "Loss: 0.6873224377632141\n",
      "Loss: 0.6678664684295654\n",
      "Loss: 0.6293001174926758\n",
      "Loss: 0.6254810690879822\n",
      "Loss: 0.6332010626792908\n",
      "Loss: 0.6723372936248779\n",
      "Loss: 0.6177576184272766\n",
      "Loss: 0.7022413015365601\n",
      "Loss: 0.6150091886520386\n",
      "Loss: 0.7401360869407654\n",
      "Loss: 0.7007278203964233\n",
      "Loss: 0.5774030089378357\n",
      "Loss: 0.6321195363998413\n",
      "Loss: 0.6211955547332764\n",
      "Loss: 0.7050268650054932\n",
      "Loss: 0.6241439580917358\n",
      "Loss: 0.5813650488853455\n",
      "Loss: 0.5306534171104431\n",
      "Loss: 0.6313488483428955\n",
      "Loss: 0.5836700797080994\n",
      "Loss: 0.6986389756202698\n",
      "Loss: 0.62834233045578\n",
      "Loss: 0.640990138053894\n",
      "Loss: 0.5995771288871765\n",
      "Loss: 0.6635364294052124\n",
      "Loss: 0.6605362296104431\n",
      "Loss: 0.6065571308135986\n",
      "Loss: 0.6309404373168945\n",
      "Loss: 0.6533635258674622\n",
      "Loss: 0.5352132320404053\n",
      "Loss: 0.681768536567688\n",
      "Loss: 0.6592380404472351\n",
      "Loss: 0.6726450324058533\n",
      "Loss: 0.7414233684539795\n",
      "Loss: 0.6372705698013306\n",
      "Loss: 0.5471611022949219\n",
      "Loss: 0.6990169882774353\n",
      "Loss: 0.6311290264129639\n",
      "Loss: 0.6451427340507507\n",
      "Loss: 0.6563582420349121\n",
      "Loss: 0.6173242926597595\n",
      "Loss: 0.6269077658653259\n",
      "Loss: 0.6998727917671204\n",
      "Loss: 0.7322758436203003\n",
      "Loss: 0.5729224681854248\n",
      "Loss: 0.5588152408599854\n",
      "Loss: 0.6305856704711914\n",
      "Loss: 0.6396662592887878\n",
      "Loss: 0.6656264066696167\n",
      "Loss: 0.5837721228599548\n",
      "Loss: 0.7608516216278076\n",
      "Loss: 0.6974780559539795\n",
      "Loss: 0.6273047924041748\n",
      "Loss: 0.6499364376068115\n",
      "Loss: 0.6631281971931458\n",
      "Loss: 0.6607739925384521\n",
      "Loss: 0.5816691517829895\n",
      "Loss: 0.6553937196731567\n",
      "Loss: 0.5619343519210815\n",
      "Loss: 0.6433703899383545\n",
      "Loss: 0.6930109858512878\n",
      "Loss: 0.6472737193107605\n",
      "Loss: 0.6692982316017151\n",
      "Loss: 0.5481581091880798\n",
      "Loss: 0.6853565573692322\n",
      "Loss: 0.6603306531906128\n",
      "Loss: 0.7111347913742065\n",
      "Loss: 0.6477749347686768\n",
      "Loss: 0.5622164011001587\n",
      "Loss: 0.5591675639152527\n",
      "Loss: 0.6730348467826843\n",
      "Loss: 0.645150363445282\n",
      "Loss: 0.5544205904006958\n",
      "Loss: 0.630142092704773\n",
      "Loss: 0.612409234046936\n",
      "Loss: 0.6572903394699097\n",
      "Loss: 0.5916929244995117\n",
      "Loss: 0.6486833095550537\n",
      "Loss: 0.6690294146537781\n",
      "Loss: 0.5990402698516846\n",
      "Loss: 0.7295960187911987\n",
      "Loss: 0.5894018411636353\n",
      "Loss: 0.6028159260749817\n",
      "Loss: 0.629321813583374\n",
      "Loss: 0.6111999750137329\n",
      "Loss: 0.6253739595413208\n",
      "Loss: 0.6449145078659058\n",
      "Loss: 0.6044142842292786\n",
      "Loss: 0.6286524534225464\n",
      "Loss: 0.6099270582199097\n",
      "Loss: 0.6376552581787109\n",
      "Loss: 0.7171413898468018\n",
      "Loss: 0.6289187669754028\n",
      "Loss: 0.6180557608604431\n",
      "Loss: 0.6189026236534119\n",
      "Loss: 0.6486088037490845\n",
      "Loss: 0.6368096470832825\n",
      "Loss: 0.691951334476471\n",
      "Loss: 0.7500255107879639\n",
      "Loss: 0.7046176195144653\n",
      "Loss: 0.6493498682975769\n",
      "Loss: 0.6398236751556396\n",
      "Loss: 0.6185763478279114\n",
      "Loss: 0.5824974775314331\n",
      "Loss: 0.6016309261322021\n",
      "Loss: 0.655784547328949\n",
      "Loss: 0.708722710609436\n",
      "Loss: 0.6000033617019653\n",
      "Loss: 0.672859787940979\n",
      "Loss: 0.6179550886154175\n",
      "Loss: 0.5701927542686462\n",
      "Loss: 0.6760137677192688\n",
      "Loss: 0.637741208076477\n",
      "Loss: 0.6340904235839844\n",
      "Loss: 0.6438091397285461\n",
      "Loss: 0.6846432089805603\n",
      "Loss: 0.6499338150024414\n",
      "Loss: 0.6499894857406616\n",
      "Loss: 0.6603765487670898\n",
      "Loss: 0.690876841545105\n",
      "Loss: 0.6379043459892273\n",
      "Loss: 0.5317544937133789\n",
      "Loss: 0.6767436265945435\n",
      "Loss: 0.6257821321487427\n",
      "Loss: 0.6507620215415955\n",
      "Loss: 0.5558714866638184\n",
      "Loss: 0.6804589629173279\n",
      "Loss: 0.6664646863937378\n",
      "Loss: 0.6254777908325195\n",
      "Loss: 0.6532297134399414\n",
      "Loss: 0.6837375164031982\n",
      "Loss: 0.6344068050384521\n",
      "Loss: 0.6759529709815979\n",
      "Loss: 0.6233871579170227\n",
      "Loss: 0.6254318356513977\n",
      "Loss: 0.5691766738891602\n",
      "Loss: 0.6180996894836426\n",
      "Loss: 0.6708257794380188\n",
      "Loss: 0.6859411597251892\n",
      "Loss: 0.6608666181564331\n",
      "Loss: 0.5857240557670593\n",
      "Loss: 0.6746171116828918\n",
      "Loss: 0.6953367590904236\n",
      "Loss: 0.7019254565238953\n",
      "Loss: 0.5612257122993469\n",
      "Loss: 0.6204500198364258\n",
      "Loss: 0.6869274377822876\n",
      "Loss: 0.5949842929840088\n",
      "Loss: 0.5881336331367493\n",
      "Loss: 0.7158883213996887\n",
      "Loss: 0.6610562801361084\n",
      "Loss: 0.6381834745407104\n",
      "Loss: 0.6809844374656677\n",
      "Loss: 0.6158396601676941\n",
      "Loss: 0.6408225297927856\n",
      "Loss: 0.6913737058639526\n",
      "Loss: 0.6436767578125\n",
      "Loss: 0.6144903898239136\n",
      "Loss: 0.6785084009170532\n",
      "Loss: 0.6684021353721619\n",
      "Loss: 0.7259609699249268\n",
      "Loss: 0.5940963625907898\n",
      "Loss: 0.5216633081436157\n",
      "Loss: 0.6585346460342407\n",
      "Loss: 0.6113868951797485\n",
      "Loss: 0.7087129354476929\n",
      "Loss: 0.67484050989151\n",
      "Loss: 0.6628490686416626\n",
      "Loss: 0.616733729839325\n",
      "Loss: 0.6015627980232239\n",
      "Loss: 0.6831458806991577\n",
      "Loss: 0.6245283484458923\n",
      "Loss: 0.6224468350410461\n",
      "Loss: 0.6391814947128296\n",
      "Loss: 0.6746623516082764\n",
      "Loss: 0.6526082158088684\n",
      "Loss: 0.6479935050010681\n",
      "Loss: 0.658456027507782\n",
      "Loss: 0.6088444590568542\n",
      "Loss: 0.6751521825790405\n",
      "Loss: 0.691523015499115\n",
      "Loss: 0.5976313352584839\n",
      "Loss: 0.5553597211837769\n",
      "Loss: 0.6072553992271423\n",
      "Loss: 0.6217135787010193\n",
      "Loss: 0.6536775827407837\n",
      "Loss: 0.6312274932861328\n",
      "Loss: 0.5949932932853699\n",
      "Loss: 0.6469864249229431\n",
      "Loss: 0.6558511853218079\n",
      "Loss: 0.6717506051063538\n",
      "Loss: 0.7157496213912964\n",
      "Loss: 0.7613136768341064\n",
      "Loss: 0.6329145431518555\n",
      "Loss: 0.6427544355392456\n",
      "Loss: 0.6186659336090088\n",
      "Loss: 0.6741434335708618\n",
      "Loss: 0.6179307699203491\n",
      "Loss: 0.5973262786865234\n",
      "Loss: 0.695348858833313\n",
      "Loss: 0.7160323858261108\n",
      "Loss: 0.6586332321166992\n",
      "Loss: 0.6052476763725281\n",
      "Loss: 0.6862475275993347\n",
      "Loss: 0.6013545989990234\n",
      "Loss: 0.644504964351654\n",
      "Loss: 0.5887601971626282\n",
      "Loss: 0.6456910371780396\n",
      "Loss: 0.67667156457901\n",
      "Loss: 0.6584585905075073\n",
      "Loss: 0.6793962717056274\n",
      "Loss: 0.6348370313644409\n",
      "Loss: 0.6255415081977844\n",
      "Loss: 0.6241404414176941\n",
      "Loss: 0.6580395102500916\n",
      "Loss: 0.6646392941474915\n",
      "Loss: 0.7087635397911072\n",
      "Loss: 0.5933114886283875\n",
      "Loss: 0.5962328314781189\n",
      "Loss: 0.6470605731010437\n",
      "Loss: 0.6264796257019043\n",
      "Loss: 0.6685934662818909\n",
      "Loss: 0.6461507678031921\n",
      "Loss: 0.6773746013641357\n",
      "Loss: 0.6008772850036621\n",
      "Loss: 0.6107410788536072\n",
      "Loss: 0.6762884855270386\n",
      "Loss: 0.7001025080680847\n",
      "Loss: 0.6390337347984314\n",
      "Loss: 0.5903777480125427\n",
      "Loss: 0.7156772017478943\n",
      "Loss: 0.6120336055755615\n",
      "Loss: 0.650753378868103\n",
      "Loss: 0.6258416175842285\n",
      "Loss: 0.659579873085022\n",
      "Loss: 0.6884320378303528\n",
      "Loss: 0.7012093663215637\n",
      "Loss: 0.7165117859840393\n",
      "Loss: 0.5746666789054871\n",
      "Loss: 0.6582038402557373\n",
      "Loss: 0.6551491618156433\n",
      "Loss: 0.7006004452705383\n",
      "Loss: 0.6809870600700378\n",
      "Loss: 0.638234555721283\n",
      "Loss: 0.6763594746589661\n",
      "Loss: 0.600345253944397\n",
      "Loss: 0.610198974609375\n",
      "Loss: 0.6743184924125671\n",
      "Loss: 0.5827716588973999\n",
      "Loss: 0.6618082523345947\n",
      "Loss: 0.6751701235771179\n",
      "Loss: 0.69645094871521\n",
      "Loss: 0.639925479888916\n",
      "Loss: 0.6293848752975464\n",
      "Loss: 0.6231118440628052\n",
      "Loss: 0.531964898109436\n",
      "Loss: 0.5493062734603882\n",
      "Loss: 0.7178536057472229\n",
      "Loss: 0.5715691447257996\n",
      "Loss: 0.7213291525840759\n",
      "Loss: 0.6465371251106262\n",
      "Loss: 0.4953523576259613\n",
      "Loss: 0.6788827776908875\n",
      "Loss: 0.7061718702316284\n",
      "Loss: 0.7056887745857239\n",
      "Loss: 0.6301092505455017\n",
      "Loss: 0.6491556167602539\n",
      "Loss: 0.6590094566345215\n",
      "Loss: 0.6067237854003906\n",
      "Loss: 0.6737097501754761\n",
      "Loss: 0.6634982228279114\n",
      "Loss: 0.6416999697685242\n",
      "Loss: 0.6382881999015808\n",
      "Loss: 0.7360147833824158\n",
      "Loss: 0.6993300914764404\n",
      "Loss: 0.7006591558456421\n",
      "Loss: 0.5956253409385681\n",
      "Loss: 0.5836838483810425\n",
      "Loss: 0.6552189588546753\n",
      "Loss: 0.6292532682418823\n",
      "Loss: 0.7325829267501831\n",
      "Loss: 0.5869383215904236\n",
      "Loss: 0.7171595692634583\n",
      "Loss: 0.6202617883682251\n",
      "Loss: 0.6044436693191528\n",
      "Loss: 0.6578539609909058\n",
      "Loss: 0.696340024471283\n",
      "Loss: 0.5022043585777283\n",
      "Loss: 0.6132384538650513\n",
      "Loss: 0.591796338558197\n",
      "Loss: 0.5671337842941284\n",
      "Loss: 0.5998325347900391\n",
      "Loss: 0.684813916683197\n",
      "Loss: 0.6689419150352478\n",
      "Loss: 0.6875994801521301\n",
      "Loss: 0.5910060405731201\n",
      "Loss: 0.6454509496688843\n",
      "Loss: 0.5594629049301147\n",
      "Loss: 0.6614565253257751\n",
      "Loss: 0.7011513113975525\n",
      "Loss: 0.6775327920913696\n",
      "Loss: 0.6529294848442078\n",
      "Loss: 0.6319381594657898\n",
      "Loss: 0.6572149395942688\n",
      "Loss: 0.631814181804657\n",
      "Loss: 0.6327821612358093\n",
      "Loss: 0.7162467241287231\n",
      "Loss: 0.5977403521537781\n",
      "Loss: 0.6912013292312622\n",
      "Loss: 0.5800210237503052\n",
      "Loss: 0.6234108209609985\n",
      "Loss: 0.6784525513648987\n",
      "Loss: 0.6602453589439392\n",
      "Loss: 0.6932917237281799\n",
      "Loss: 0.5787360668182373\n",
      "Loss: 0.6429672241210938\n",
      "Loss: 0.6786126494407654\n",
      "Loss: 0.7136269211769104\n",
      "Loss: 0.672260046005249\n",
      "Loss: 0.659108579158783\n",
      "Loss: 0.6420225501060486\n",
      "Loss: 0.6622664928436279\n",
      "Loss: 0.6533825993537903\n",
      "Loss: 0.6515172123908997\n",
      "Loss: 0.6213240027427673\n",
      "Loss: 0.5896719694137573\n",
      "Loss: 0.6610824465751648\n",
      "Loss: 0.7176125049591064\n",
      "Loss: 0.7124350666999817\n",
      "Loss: 0.6542179584503174\n",
      "Loss: 0.6520962119102478\n",
      "Loss: 0.6557340025901794\n",
      "Loss: 0.6680561304092407\n",
      "Loss: 0.6422759294509888\n",
      "Loss: 0.6470977663993835\n",
      "Loss: 0.6220210194587708\n",
      "Loss: 0.6063258647918701\n",
      "Loss: 0.7122529149055481\n",
      "Loss: 0.5722739696502686\n",
      "Loss: 0.622611403465271\n",
      "Loss: 0.7387929558753967\n",
      "Loss: 0.6655453443527222\n",
      "Loss: 0.6613531112670898\n",
      "Loss: 0.6323727965354919\n",
      "Loss: 0.5833184719085693\n",
      "Loss: 0.6208622455596924\n",
      "Loss: 0.7034820914268494\n",
      "Loss: 0.6032957434654236\n",
      "Loss: 0.676258385181427\n",
      "Loss: 0.620857834815979\n",
      "Loss: 0.5922162532806396\n",
      "Loss: 0.5921818017959595\n",
      "Loss: 0.7055560946464539\n",
      "Loss: 0.6800967454910278\n",
      "Loss: 0.607298731803894\n",
      "Loss: 0.6550177931785583\n",
      "Loss: 0.6073579788208008\n",
      "Loss: 0.6752727031707764\n",
      "Loss: 0.6838408708572388\n",
      "Loss: 0.6311017870903015\n",
      "Loss: 0.6247234344482422\n",
      "Loss: 0.6325505375862122\n",
      "Loss: 0.6322181224822998\n",
      "Loss: 0.6554490923881531\n",
      "Loss: 0.6328084468841553\n",
      "Loss: 0.6317828297615051\n",
      "Loss: 0.6090895533561707\n",
      "Loss: 0.5788083076477051\n",
      "Loss: 0.5496841073036194\n",
      "Loss: 0.6061695218086243\n",
      "Loss: 0.6099889278411865\n",
      "Loss: 0.6928375959396362\n",
      "Loss: 0.7079116702079773\n",
      "Loss: 0.6635783314704895\n",
      "Loss: 0.6894379258155823\n",
      "Loss: 0.6474372744560242\n",
      "Loss: 0.6255046725273132\n",
      "Loss: 0.6192977428436279\n",
      "Loss: 0.7074781656265259\n",
      "Loss: 0.6415373682975769\n",
      "Loss: 0.7031295299530029\n",
      "Loss: 0.5993671417236328\n",
      "Loss: 0.554110050201416\n",
      "Loss: 0.6129459738731384\n",
      "Loss: 0.5798971056938171\n",
      "Loss: 0.6120597720146179\n",
      "Loss: 0.6260585784912109\n",
      "Loss: 0.6003695726394653\n",
      "Loss: 0.6897632479667664\n",
      "Loss: 0.5843682289123535\n",
      "Loss: 0.6798897385597229\n",
      "Loss: 0.6367395520210266\n",
      "Loss: 0.62994384765625\n",
      "Loss: 0.6469793319702148\n",
      "Loss: 0.6340745091438293\n",
      "Loss: 0.6420888304710388\n",
      "Loss: 0.7349191904067993\n",
      "Loss: 0.6693724989891052\n",
      "Loss: 0.6037096381187439\n",
      "Loss: 0.6170394420623779\n",
      "Loss: 0.7594010233879089\n",
      "Loss: 0.6908134818077087\n",
      "Loss: 0.5787782669067383\n",
      "Loss: 0.6522831916809082\n",
      "Loss: 0.5760416388511658\n",
      "Loss: 0.6854764819145203\n",
      "Loss: 0.6792544722557068\n",
      "Loss: 0.640623927116394\n",
      "Loss: 0.6030935645103455\n",
      "Loss: 0.6640617251396179\n",
      "Loss: 0.552137553691864\n",
      "Loss: 0.6009855270385742\n",
      "Loss: 0.6873824000358582\n",
      "Loss: 0.653002142906189\n",
      "Loss: 0.6220253109931946\n",
      "Loss: 0.6563262939453125\n",
      "Loss: 0.6291009783744812\n",
      "Loss: 0.6929824352264404\n",
      "Loss: 0.672824501991272\n",
      "Loss: 0.6195266842842102\n",
      "Loss: 0.6413002014160156\n",
      "Loss: 0.6168056726455688\n",
      "Loss: 0.6298320293426514\n",
      "Loss: 0.6349581480026245\n",
      "Loss: 0.6662542819976807\n",
      "Loss: 0.6608002781867981\n",
      "Loss: 0.5942541360855103\n",
      "Loss: 0.5976364612579346\n",
      "Loss: 0.6849623918533325\n",
      "Loss: 0.626126229763031\n",
      "Loss: 0.709991991519928\n",
      "Loss: 0.7072620987892151\n",
      "Loss: 0.6588056087493896\n",
      "Loss: 0.7306836247444153\n",
      "Loss: 0.7046496272087097\n",
      "Loss: 0.6560332179069519\n",
      "Loss: 0.6985493302345276\n",
      "Loss: 0.7355508208274841\n",
      "Loss: 0.6130672693252563\n",
      "Loss: 0.5908404588699341\n",
      "Loss: 0.6769911646842957\n",
      "Loss: 0.5928769111633301\n",
      "Loss: 0.6647119522094727\n",
      "Loss: 0.642315149307251\n",
      "Loss: 0.651681661605835\n",
      "Loss: 0.659784197807312\n",
      "Loss: 0.6605628132820129\n",
      "Loss: 0.5663004517555237\n",
      "Loss: 0.5777308940887451\n",
      "Loss: 0.6485456228256226\n",
      "Loss: 0.6864811778068542\n",
      "Loss: 0.6529449820518494\n",
      "Loss: 0.6611315011978149\n",
      "Loss: 0.668583333492279\n",
      "Loss: 0.6747825741767883\n",
      "Loss: 0.6256136894226074\n",
      "Loss: 0.658797562122345\n",
      "Loss: 0.6260455846786499\n",
      "Loss: 0.716134786605835\n",
      "Loss: 0.6117938756942749\n",
      "Loss: 0.614129900932312\n",
      "Loss: 0.633087158203125\n",
      "Loss: 0.7077261209487915\n",
      "Loss: 0.6287132501602173\n",
      "Loss: 0.702809751033783\n",
      "Loss: 0.6754453778266907\n",
      "Loss: 0.6726496815681458\n",
      "Loss: 0.6662725806236267\n",
      "Loss: 0.7062860727310181\n",
      "Loss: 0.6015200018882751\n",
      "Loss: 0.6486124992370605\n",
      "Loss: 0.6834776997566223\n",
      "Loss: 0.6119191646575928\n",
      "Loss: 0.5920862555503845\n",
      "Loss: 0.5371001362800598\n",
      "Loss: 0.7065879702568054\n",
      "Loss: 0.7001828551292419\n",
      "Loss: 0.6572751998901367\n",
      "Loss: 0.6681045889854431\n",
      "Loss: 0.6140033602714539\n",
      "Loss: 0.7245222926139832\n",
      "Loss: 0.6561158895492554\n",
      "Loss: 0.6331092119216919\n",
      "Loss: 0.7135809659957886\n",
      "Loss: 0.6087156534194946\n",
      "Loss: 0.6200571060180664\n",
      "Loss: 0.6611127257347107\n",
      "Loss: 0.6260256767272949\n",
      "Loss: 0.6221253275871277\n",
      "Loss: 0.6966164112091064\n",
      "Loss: 0.6512826681137085\n",
      "Loss: 0.6240679025650024\n",
      "Loss: 0.608658492565155\n",
      "Loss: 0.6091068983078003\n",
      "Loss: 0.7199963927268982\n",
      "Loss: 0.6963382363319397\n",
      "Loss: 0.6038347482681274\n",
      "Loss: 0.6528099775314331\n",
      "Loss: 0.5684088468551636\n",
      "Loss: 0.6271731853485107\n",
      "Loss: 0.6303065419197083\n",
      "Loss: 0.6388518810272217\n",
      "Loss: 0.6331270337104797\n",
      "Loss: 0.6627675890922546\n",
      "Loss: 0.6860349178314209\n",
      "Loss: 0.6241146326065063\n",
      "Loss: 0.6784447431564331\n",
      "Loss: 0.6670905947685242\n",
      "Loss: 0.6346462965011597\n",
      "Loss: 0.5680592656135559\n",
      "Loss: 0.6692526936531067\n",
      "Loss: 0.6534490585327148\n",
      "Loss: 0.6145203113555908\n",
      "Loss: 0.6507867574691772\n",
      "Loss: 0.5904611945152283\n",
      "Loss: 0.6216184496879578\n",
      "Loss: 0.6120638251304626\n",
      "Loss: 0.689120888710022\n",
      "Loss: 0.6754378080368042\n",
      "Loss: 0.6282957792282104\n",
      "Loss: 0.6322672963142395\n",
      "Loss: 0.6584319472312927\n",
      "Loss: 0.6180521249771118\n",
      "Loss: 0.6626990437507629\n",
      "Loss: 0.6517410278320312\n",
      "Loss: 0.6682422161102295\n",
      "Loss: 0.6433326601982117\n",
      "Loss: 0.6211659908294678\n",
      "Loss: 0.7419918775558472\n",
      "Loss: 0.6323509216308594\n",
      "Loss: 0.6278843283653259\n",
      "Loss: 0.6753608584403992\n",
      "Loss: 0.6688318848609924\n",
      "Loss: 0.6677577495574951\n",
      "Loss: 0.6455931067466736\n",
      "Loss: 0.6736123561859131\n",
      "Loss: 0.6510674953460693\n",
      "Loss: 0.6085293889045715\n",
      "Loss: 0.7018190622329712\n",
      "Loss: 0.6309152841567993\n",
      "Loss: 0.7078434824943542\n",
      "Loss: 0.6822811365127563\n",
      "Loss: 0.6482707858085632\n",
      "Loss: 0.6495036482810974\n",
      "Loss: 0.6371728181838989\n",
      "Loss: 0.619001030921936\n",
      "Loss: 0.49613335728645325\n",
      "Loss: 0.670203447341919\n",
      "Loss: 0.6776078939437866\n",
      "Loss: 0.6844916939735413\n",
      "Loss: 0.6524071097373962\n",
      "Loss: 0.6270111203193665\n",
      "Loss: 0.7032860517501831\n",
      "Loss: 0.560236394405365\n",
      "Loss: 0.7219613194465637\n",
      "Loss: 0.6569828391075134\n",
      "Loss: 0.670033872127533\n",
      "Loss: 0.5993388295173645\n",
      "Loss: 0.6069198846817017\n",
      "Loss: 0.6624940037727356\n",
      "Loss: 0.629167377948761\n",
      "Loss: 0.6369787454605103\n",
      "Loss: 0.6623165011405945\n",
      "Loss: 0.5969583988189697\n",
      "Loss: 0.6319013833999634\n",
      "Loss: 0.6616983413696289\n",
      "Loss: 0.6387546062469482\n",
      "Loss: 0.762099027633667\n",
      "Loss: 0.7174599766731262\n",
      "Loss: 0.5793988704681396\n",
      "Loss: 0.6900441646575928\n",
      "Loss: 0.6698644161224365\n",
      "Loss: 0.6453025341033936\n",
      "Loss: 0.6374590992927551\n",
      "Loss: 0.6340152621269226\n",
      "Loss: 0.6351005434989929\n",
      "Loss: 0.6896188855171204\n",
      "Loss: 0.6198895573616028\n",
      "Loss: 0.635291337966919\n",
      "Loss: 0.6456331014633179\n",
      "Loss: 0.6385995745658875\n",
      "Loss: 0.6957163214683533\n",
      "Loss: 0.6662968993186951\n",
      "Loss: 0.6772987246513367\n",
      "Loss: 0.7206442952156067\n",
      "Loss: 0.6836987137794495\n",
      "Loss: 0.5977911949157715\n",
      "Loss: 0.6324871778488159\n",
      "Loss: 0.6321824193000793\n",
      "Loss: 0.6661649942398071\n",
      "Loss: 0.6645606160163879\n",
      "Loss: 0.6315634846687317\n",
      "Loss: 0.6471869945526123\n",
      "Loss: 0.6679056882858276\n",
      "Loss: 0.6443493366241455\n",
      "Loss: 0.6294893622398376\n",
      "Loss: 0.5979315638542175\n",
      "Loss: 0.6082178354263306\n",
      "Loss: 0.6794191598892212\n",
      "Loss: 0.5911505222320557\n",
      "Loss: 0.6847339868545532\n",
      "Loss: 0.6342239379882812\n",
      "Loss: 0.667665421962738\n",
      "Loss: 0.6609216928482056\n",
      "Loss: 0.6245580911636353\n",
      "Loss: 0.6224838495254517\n",
      "Loss: 0.6778479814529419\n",
      "Loss: 0.6345558166503906\n",
      "Loss: 0.6472195386886597\n",
      "Loss: 0.6178785562515259\n",
      "Loss: 0.6204191446304321\n",
      "Loss: 0.599201500415802\n",
      "Loss: 0.6471217274665833\n",
      "Loss: 0.6673396229743958\n",
      "Loss: 0.6375150680541992\n",
      "Loss: 0.6597797274589539\n",
      "Loss: 0.6168687343597412\n",
      "Loss: 0.653556227684021\n",
      "Loss: 0.6743174195289612\n",
      "Loss: 0.6152570247650146\n",
      "Loss: 0.656265377998352\n",
      "Loss: 0.6293584108352661\n",
      "Loss: 0.650634765625\n",
      "Loss: 0.7123356461524963\n",
      "Loss: 0.6887989640235901\n",
      "Loss: 0.6538184881210327\n",
      "Loss: 0.6844075918197632\n",
      "Loss: 0.6275809407234192\n",
      "Loss: 0.6056659817695618\n",
      "Loss: 0.6322399377822876\n",
      "Loss: 0.680281400680542\n",
      "Loss: 0.6227659583091736\n",
      "Loss: 0.7096375823020935\n",
      "Loss: 0.6366090774536133\n",
      "Loss: 0.6104175448417664\n",
      "Loss: 0.5905537605285645\n",
      "Loss: 0.6668040752410889\n",
      "Loss: 0.6480674743652344\n",
      "Loss: 0.6037424802780151\n",
      "Loss: 0.7284761667251587\n",
      "Loss: 0.6343033909797668\n",
      "Loss: 0.7028234004974365\n",
      "Loss: 0.6639584302902222\n",
      "Loss: 0.6678058505058289\n",
      "Loss: 0.632516086101532\n",
      "Loss: 0.5847430229187012\n",
      "Loss: 0.7007404565811157\n",
      "Loss: 0.6400750279426575\n",
      "Loss: 0.7188674807548523\n",
      "Loss: 0.6973005533218384\n",
      "Loss: 0.593531608581543\n",
      "Loss: 0.6744915246963501\n",
      "Loss: 0.6671426892280579\n",
      "Loss: 0.5712499022483826\n",
      "Loss: 0.6317243576049805\n",
      "Loss: 0.6331130266189575\n",
      "Loss: 0.6752015948295593\n",
      "Loss: 0.6282777786254883\n",
      "Loss: 0.6623119711875916\n",
      "Loss: 0.6694353818893433\n",
      "Loss: 0.6137493848800659\n",
      "Loss: 0.6304625868797302\n",
      "Loss: 0.6204309463500977\n",
      "Loss: 0.5831310749053955\n",
      "Loss: 0.6384237408638\n",
      "Loss: 0.6038004755973816\n",
      "Loss: 0.625105082988739\n",
      "Loss: 0.6093586683273315\n",
      "Loss: 0.6564912796020508\n",
      "Loss: 0.639296293258667\n",
      "Loss: 0.6072415113449097\n",
      "Loss: 0.600249707698822\n",
      "Loss: 0.6663827896118164\n",
      "Loss: 0.5677339434623718\n",
      "Loss: 0.7333958745002747\n",
      "Loss: 0.6409458518028259\n",
      "Loss: 0.6546411514282227\n",
      "Loss: 0.6467700004577637\n",
      "Loss: 0.6339471340179443\n",
      "Loss: 0.6289691925048828\n",
      "Loss: 0.7288334965705872\n",
      "Loss: 0.6774777770042419\n",
      "Loss: 0.695199728012085\n",
      "Loss: 0.6341313123703003\n",
      "Loss: 0.6418184041976929\n",
      "Loss: 0.6929953098297119\n",
      "Loss: 0.6730968356132507\n",
      "Loss: 0.6061747074127197\n",
      "Loss: 0.6147350668907166\n",
      "Loss: 0.7718509435653687\n",
      "Loss: 0.6538190245628357\n",
      "Loss: 0.6398116946220398\n",
      "Loss: 0.5864057540893555\n",
      "Loss: 0.6027863621711731\n",
      "Loss: 0.5901374816894531\n",
      "Loss: 0.6797792315483093\n",
      "Loss: 0.6131274700164795\n",
      "Loss: 0.6405993700027466\n",
      "Loss: 0.6333759427070618\n",
      "Loss: 0.6176864504814148\n",
      "Loss: 0.6762199997901917\n",
      "Loss: 0.6950560212135315\n",
      "Loss: 0.661432683467865\n",
      "Loss: 0.6460816264152527\n",
      "Loss: 0.6690580248832703\n",
      "Loss: 0.6116964817047119\n",
      "Loss: 0.6954331994056702\n",
      "Loss: 0.6314197778701782\n",
      "Loss: 0.5963391065597534\n",
      "Loss: 0.6352179646492004\n",
      "Loss: 0.7024709582328796\n",
      "Loss: 0.7408958673477173\n",
      "Loss: 0.5857189297676086\n",
      "Loss: 0.6944181323051453\n",
      "Loss: 0.6193236708641052\n",
      "Loss: 0.6159465909004211\n",
      "Loss: 0.5832206606864929\n",
      "Loss: 0.661890983581543\n",
      "Loss: 0.6907039880752563\n",
      "Loss: 0.6415833830833435\n",
      "Loss: 0.6132473945617676\n",
      "Loss: 0.670745313167572\n",
      "Loss: 0.6475871205329895\n",
      "Loss: 0.5958890914916992\n",
      "Loss: 0.6516831517219543\n",
      "Loss: 0.6188232898712158\n",
      "Loss: 0.6575888395309448\n",
      "Loss: 0.7188200354576111\n",
      "Loss: 0.668355405330658\n",
      "Loss: 0.6008586883544922\n",
      "Loss: 0.6527339816093445\n",
      "Loss: 0.6335623860359192\n",
      "Loss: 0.7074860334396362\n",
      "Loss: 0.709189772605896\n",
      "Loss: 0.6420078277587891\n",
      "Loss: 0.6352239847183228\n",
      "Loss: 0.683169424533844\n",
      "Loss: 0.6325197219848633\n",
      "Loss: 0.6260349154472351\n",
      "Loss: 0.6251890063285828\n",
      "Loss: 0.672019362449646\n",
      "Loss: 0.6670803427696228\n",
      "Loss: 0.5969106554985046\n",
      "Loss: 0.6361348628997803\n",
      "Loss: 0.6130326390266418\n",
      "Loss: 0.7734261155128479\n",
      "Loss: 0.7062361836433411\n",
      "Loss: 0.5632246732711792\n",
      "Loss: 0.6461857557296753\n",
      "Loss: 0.7205219864845276\n",
      "Loss: 0.6578084230422974\n",
      "Loss: 0.6154168248176575\n",
      "Loss: 0.6645165681838989\n",
      "Loss: 0.5751867294311523\n",
      "Loss: 0.6040018796920776\n",
      "Loss: 0.6117848753929138\n",
      "Loss: 0.671754777431488\n",
      "Loss: 0.5611511468887329\n",
      "Loss: 0.6836872696876526\n",
      "Loss: 0.6268550753593445\n",
      "Loss: 0.6834997534751892\n",
      "Loss: 0.652600884437561\n",
      "Loss: 0.6211093664169312\n",
      "Loss: 0.6516845226287842\n",
      "Loss: 0.6649444699287415\n",
      "Loss: 0.6640866994857788\n",
      "Loss: 0.6794079542160034\n",
      "Loss: 0.6455869078636169\n",
      "Loss: 0.6635247468948364\n",
      "Loss: 0.7377508878707886\n",
      "Loss: 0.6067021489143372\n",
      "Loss: 0.6200618743896484\n",
      "Loss: 0.6819866895675659\n",
      "Loss: 0.6530506014823914\n",
      "Loss: 0.5880865454673767\n",
      "Loss: 0.6368478536605835\n",
      "Loss: 0.5757741928100586\n",
      "Loss: 0.6096013784408569\n",
      "Loss: 0.6387360692024231\n",
      "Loss: 0.6343913078308105\n",
      "Loss: 0.6951491236686707\n",
      "Loss: 0.6424322128295898\n",
      "Loss: 0.7518298625946045\n",
      "Loss: 0.7144750952720642\n",
      "Loss: 0.6694964170455933\n",
      "Loss: 0.6809675693511963\n",
      "Loss: 0.636950671672821\n",
      "Loss: 0.654584527015686\n",
      "Loss: 0.596332311630249\n",
      "Loss: 0.6023430228233337\n",
      "Loss: 0.6207307577133179\n",
      "Loss: 0.6688148975372314\n",
      "Loss: 0.7011086940765381\n",
      "Loss: 0.6979760527610779\n",
      "Loss: 0.5735137462615967\n",
      "Loss: 0.6528040766716003\n",
      "Loss: 0.6072966456413269\n",
      "Loss: 0.6654367446899414\n",
      "Loss: 0.5385004878044128\n",
      "Loss: 0.6851627826690674\n",
      "Loss: 0.5860884189605713\n",
      "Loss: 0.6156250238418579\n",
      "Loss: 0.6506580710411072\n",
      "Loss: 0.6576518416404724\n",
      "Loss: 0.6405640840530396\n",
      "Loss: 0.6417064070701599\n",
      "Loss: 0.6241152286529541\n",
      "Loss: 0.5629896521568298\n",
      "Loss: 0.6493575572967529\n",
      "Loss: 0.7309582233428955\n",
      "Loss: 0.6556986570358276\n",
      "Loss: 0.6378601789474487\n",
      "Loss: 0.5648106336593628\n",
      "Loss: 0.5874037146568298\n",
      "Loss: 0.6594249606132507\n",
      "Loss: 0.6981445550918579\n",
      "Loss: 0.6629040241241455\n",
      "Loss: 0.6573222279548645\n",
      "Loss: 0.6999460458755493\n",
      "Loss: 0.6021741032600403\n",
      "Loss: 0.655800998210907\n",
      "Loss: 0.6468503475189209\n",
      "Loss: 0.7088698148727417\n",
      "Loss: 0.6921252608299255\n",
      "Loss: 0.6877987384796143\n",
      "Loss: 0.624043881893158\n",
      "Loss: 0.6912381649017334\n",
      "Loss: 0.6621899008750916\n",
      "Loss: 0.6453914642333984\n",
      "Loss: 0.7428725361824036\n",
      "Loss: 0.6761791110038757\n",
      "Loss: 0.6956982016563416\n",
      "Loss: 0.657062292098999\n",
      "Loss: 0.7014979720115662\n",
      "Loss: 0.6336224675178528\n",
      "Loss: 0.6191925406455994\n",
      "Loss: 0.635342538356781\n",
      "Loss: 0.692233145236969\n",
      "Loss: 0.638972282409668\n",
      "Loss: 0.6797168254852295\n",
      "Loss: 0.6136578917503357\n",
      "Loss: 0.5924407839775085\n",
      "Loss: 0.6490507125854492\n",
      "Loss: 0.5888798832893372\n",
      "Loss: 0.6241740584373474\n",
      "Loss: 0.6021187901496887\n",
      "Loss: 0.5435348749160767\n",
      "Loss: 0.6272825598716736\n",
      "Loss: 0.6381652355194092\n",
      "Loss: 0.6470560431480408\n",
      "Loss: 0.6893393993377686\n",
      "Loss: 0.5222595930099487\n",
      "Loss: 0.569660484790802\n",
      "Loss: 0.6739736795425415\n",
      "Loss: 0.6831998229026794\n",
      "Loss: 0.6642391681671143\n",
      "Loss: 0.6337618231773376\n",
      "Loss: 0.6823443174362183\n",
      "Loss: 0.6768968105316162\n",
      "Loss: 0.6401922106742859\n",
      "Loss: 0.6672069430351257\n",
      "Loss: 0.5489070415496826\n",
      "Loss: 0.7161203622817993\n",
      "Loss: 0.6246728897094727\n",
      "Loss: 0.6389721632003784\n",
      "Loss: 0.6217501163482666\n",
      "Loss: 0.7236282825469971\n",
      "Loss: 0.6509412527084351\n",
      "Loss: 0.6412731409072876\n",
      "Loss: 0.669838547706604\n",
      "Loss: 0.5825942158699036\n",
      "Loss: 0.6266568899154663\n",
      "Loss: 0.638976514339447\n",
      "Loss: 0.6287254691123962\n",
      "Loss: 0.6587111949920654\n",
      "Loss: 0.6999095678329468\n",
      "Loss: 0.6361544728279114\n",
      "Loss: 0.6525129079818726\n",
      "Loss: 0.6950246095657349\n",
      "Loss: 0.671203076839447\n",
      "Loss: 0.7134210467338562\n",
      "Loss: 0.6470958590507507\n",
      "Loss: 0.6282490491867065\n",
      "Loss: 0.6602106094360352\n",
      "Loss: 0.633651614189148\n",
      "Loss: 0.657551109790802\n",
      "Loss: 0.6484853625297546\n",
      "Loss: 0.6020664572715759\n",
      "Loss: 0.6958491802215576\n",
      "Loss: 0.6663950085639954\n",
      "Loss: 0.6213815808296204\n",
      "Loss: 0.6512377262115479\n",
      "Loss: 0.6275421380996704\n",
      "Loss: 0.6342513561248779\n",
      "Loss: 0.6309598088264465\n",
      "Loss: 0.6268013715744019\n",
      "Loss: 0.6966507434844971\n",
      "Loss: 0.6431964635848999\n",
      "Loss: 0.6796213388442993\n",
      "Loss: 0.6664960384368896\n",
      "Loss: 0.6785567402839661\n",
      "Loss: 0.5348250269889832\n",
      "Loss: 0.6125742197036743\n",
      "Loss: 0.6642578840255737\n",
      "Loss: 0.7824403643608093\n",
      "Loss: 0.6758300065994263\n",
      "Loss: 0.6941770911216736\n",
      "Loss: 0.6271578073501587\n",
      "Loss: 0.6416201591491699\n",
      "Loss: 0.6768661737442017\n",
      "Loss: 0.6495526432991028\n",
      "Loss: 0.5181204676628113\n",
      "Loss: 0.5883605480194092\n",
      "Loss: 0.6877971291542053\n",
      "Loss: 0.5737180709838867\n",
      "Loss: 0.6221764087677002\n",
      "Loss: 0.6140245795249939\n",
      "Loss: 0.6555105447769165\n",
      "Loss: 0.5863176584243774\n",
      "Loss: 0.7028921842575073\n",
      "Loss: 0.6119953393936157\n",
      "Loss: 0.5890744924545288\n",
      "Loss: 0.6532537341117859\n",
      "Loss: 0.6540021896362305\n",
      "Loss: 0.6644806265830994\n",
      "Loss: 0.6163617968559265\n",
      "Loss: 0.6606508493423462\n",
      "Loss: 0.6614529490470886\n",
      "Loss: 0.5870916247367859\n",
      "Loss: 0.5112649202346802\n",
      "Loss: 0.6446481943130493\n",
      "Loss: 0.6650737524032593\n",
      "Loss: 0.6444061994552612\n",
      "Loss: 0.7236306667327881\n",
      "Loss: 0.6519676446914673\n",
      "Loss: 0.7066667079925537\n",
      "Loss: 0.6039570569992065\n",
      "Loss: 0.6649853587150574\n",
      "Loss: 0.5910456776618958\n",
      "Loss: 0.6725852489471436\n",
      "Loss: 0.7215734124183655\n",
      "Loss: 0.6765949130058289\n",
      "Loss: 0.6008802652359009\n",
      "Loss: 0.525723934173584\n",
      "Loss: 0.679165244102478\n",
      "Loss: 0.5787489414215088\n",
      "Loss: 0.6427075862884521\n",
      "Loss: 0.6502396464347839\n",
      "Loss: 0.6457757353782654\n",
      "Loss: 0.5771627426147461\n",
      "Loss: 0.6547264456748962\n",
      "Loss: 0.644142746925354\n",
      "Loss: 0.6646119952201843\n",
      "Loss: 0.6202349662780762\n",
      "Loss: 0.6312040090560913\n",
      "Loss: 0.6260561943054199\n",
      "Loss: 0.651411771774292\n",
      "Loss: 0.6497289538383484\n",
      "Loss: 0.6423324942588806\n",
      "Loss: 0.6779125928878784\n",
      "Loss: 0.6316243410110474\n",
      "Loss: 0.669765293598175\n",
      "Loss: 0.54023677110672\n",
      "Loss: 0.6557430624961853\n",
      "Loss: 0.6478866934776306\n",
      "Loss: 0.6252806782722473\n",
      "Loss: 0.649365246295929\n",
      "Loss: 0.7088693380355835\n",
      "Loss: 0.632048487663269\n",
      "Loss: 0.6542297601699829\n",
      "Loss: 0.5798548460006714\n",
      "Loss: 0.665317952632904\n",
      "Loss: 0.7245161533355713\n",
      "Loss: 0.6341761350631714\n",
      "Loss: 0.6650205850601196\n",
      "Loss: 0.6752617359161377\n",
      "Loss: 0.7392650246620178\n",
      "Loss: 0.776346743106842\n",
      "Loss: 0.6209928393363953\n",
      "Loss: 0.5987292528152466\n",
      "Loss: 0.5925086736679077\n",
      "Loss: 0.6527700424194336\n",
      "Loss: 0.5558163523674011\n",
      "Loss: 0.7012278437614441\n",
      "Loss: 0.6209095120429993\n",
      "Loss: 0.6571288108825684\n",
      "Loss: 0.6313449740409851\n",
      "Loss: 0.6741539835929871\n",
      "Loss: 0.683170735836029\n",
      "Loss: 0.6453348398208618\n",
      "Loss: 0.6193134188652039\n",
      "Loss: 0.6114649176597595\n",
      "Loss: 0.5833331942558289\n",
      "Loss: 0.6915839910507202\n",
      "Loss: 0.6817223429679871\n",
      "Loss: 0.6992045044898987\n",
      "Loss: 0.627057671546936\n",
      "Loss: 0.6689927577972412\n",
      "Loss: 0.7119638323783875\n",
      "Loss: 0.5126606225967407\n",
      "Loss: 0.654651403427124\n",
      "Loss: 0.61062091588974\n",
      "Loss: 0.6550019979476929\n",
      "Loss: 0.6103909611701965\n",
      "Loss: 0.6147598028182983\n",
      "Loss: 0.662358283996582\n",
      "Loss: 0.6767292618751526\n",
      "Loss: 0.6246744394302368\n",
      "Loss: 0.6603473424911499\n",
      "Loss: 0.62005215883255\n",
      "Loss: 0.7218291759490967\n",
      "Loss: 0.5904197692871094\n",
      "Loss: 0.6803401112556458\n",
      "Loss: 0.6508700847625732\n",
      "Loss: 0.6401306390762329\n",
      "Loss: 0.7315851449966431\n",
      "Loss: 0.6860312223434448\n",
      "Loss: 0.6092948913574219\n",
      "Loss: 0.6640555262565613\n",
      "Loss: 0.6235883235931396\n",
      "Loss: 0.6335059404373169\n",
      "Loss: 0.6915352940559387\n",
      "Loss: 0.5959985256195068\n",
      "Loss: 0.6633651256561279\n",
      "Loss: 0.5863033533096313\n",
      "Loss: 0.6682924628257751\n",
      "Loss: 0.6632102727890015\n",
      "Loss: 0.6380032300949097\n",
      "Loss: 0.608575165271759\n",
      "Loss: 0.6947683691978455\n",
      "Loss: 0.6153416633605957\n",
      "Loss: 0.6047646999359131\n",
      "Loss: 0.6848280429840088\n",
      "Loss: 0.7179041504859924\n",
      "Loss: 0.5835480093955994\n",
      "Loss: 0.6704708337783813\n",
      "Loss: 0.701771080493927\n",
      "Loss: 0.6711931824684143\n",
      "Loss: 0.6097104549407959\n",
      "Loss: 0.6751822233200073\n",
      "Loss: 0.7155505418777466\n",
      "Loss: 0.663536548614502\n",
      "Loss: 0.6395253539085388\n",
      "Loss: 0.6383540630340576\n",
      "Loss: 0.6992244124412537\n",
      "Loss: 0.5994389653205872\n",
      "Loss: 0.6140119433403015\n",
      "Loss: 0.6253364086151123\n",
      "Loss: 0.6773391962051392\n",
      "Loss: 0.7130959630012512\n",
      "Loss: 0.573320746421814\n",
      "Loss: 0.6244993209838867\n",
      "Loss: 0.6957634687423706\n",
      "Loss: 0.5762444734573364\n",
      "Loss: 0.6326228976249695\n",
      "Loss: 0.7251545190811157\n",
      "Loss: 0.6111952066421509\n",
      "Loss: 0.5909954309463501\n",
      "Loss: 0.6556774377822876\n",
      "Loss: 0.6740841269493103\n",
      "Loss: 0.6923671960830688\n",
      "Loss: 0.5825116038322449\n",
      "Loss: 0.6453612446784973\n",
      "Loss: 0.5935218334197998\n",
      "Loss: 0.6042556166648865\n",
      "Loss: 0.6116499304771423\n",
      "Loss: 0.6637417078018188\n",
      "Loss: 0.6466347575187683\n",
      "Loss: 0.6019534468650818\n",
      "Loss: 0.615393877029419\n",
      "Loss: 0.6600382924079895\n",
      "Loss: 0.6253659725189209\n",
      "Loss: 0.726184606552124\n",
      "Loss: 0.7231588959693909\n",
      "Loss: 0.6386750340461731\n",
      "Loss: 0.6012258529663086\n",
      "Loss: 0.6468890309333801\n",
      "Loss: 0.687595784664154\n",
      "Loss: 0.6510944366455078\n",
      "Loss: 0.672995924949646\n",
      "Loss: 0.7118150591850281\n",
      "Loss: 0.6415249109268188\n",
      "Loss: 0.5881938338279724\n",
      "Loss: 0.6378421783447266\n",
      "Loss: 0.6160573959350586\n",
      "Loss: 0.6431921720504761\n",
      "Loss: 0.5969561338424683\n",
      "Loss: 0.6471389532089233\n",
      "Loss: 0.6751204133033752\n",
      "Loss: 0.6263651847839355\n",
      "Loss: 0.7685173749923706\n",
      "Loss: 0.6486194729804993\n",
      "Loss: 0.709787130355835\n",
      "Loss: 0.6772075891494751\n",
      "Loss: 0.6438047289848328\n",
      "Loss: 0.6931108832359314\n",
      "Loss: 0.5719083547592163\n",
      "Loss: 0.7034059762954712\n",
      "Loss: 0.5990604758262634\n",
      "Loss: 0.5566239953041077\n",
      "Loss: 0.6092422008514404\n",
      "Loss: 0.6113174557685852\n",
      "Loss: 0.5774089694023132\n",
      "Loss: 0.6717277765274048\n",
      "Loss: 0.5928665399551392\n",
      "Loss: 0.6227672100067139\n",
      "Loss: 0.642352283000946\n",
      "Loss: 0.7561134696006775\n",
      "Loss: 0.6038183569908142\n",
      "Loss: 0.6720530986785889\n",
      "Loss: 0.6669074892997742\n",
      "Loss: 0.5946243405342102\n",
      "Loss: 0.6378719210624695\n",
      "Loss: 0.6930865049362183\n",
      "Loss: 0.6924787759780884\n",
      "Loss: 0.6466333270072937\n",
      "Loss: 0.5704918503761292\n",
      "Loss: 0.6288142204284668\n",
      "Loss: 0.680792510509491\n",
      "Loss: 0.6273886561393738\n",
      "Loss: 0.6182572841644287\n",
      "Loss: 0.6314429044723511\n",
      "Loss: 0.6155062913894653\n",
      "Loss: 0.6043421626091003\n",
      "Loss: 0.6263784766197205\n",
      "Loss: 0.6538876295089722\n",
      "Loss: 0.6527727842330933\n",
      "Loss: 0.6936964392662048\n",
      "Loss: 0.6283129453659058\n",
      "Loss: 0.6561873555183411\n",
      "Loss: 0.6209583282470703\n",
      "Loss: 0.6646952629089355\n",
      "Loss: 0.6341372728347778\n",
      "Loss: 0.7205318808555603\n",
      "Loss: 0.6590279936790466\n",
      "Loss: 0.6222241520881653\n",
      "Loss: 0.6496993899345398\n",
      "Loss: 0.7285298109054565\n",
      "Loss: 0.6690998673439026\n",
      "Loss: 0.7126895189285278\n",
      "Loss: 0.532915472984314\n",
      "Loss: 0.6200249791145325\n",
      "Loss: 0.6260043978691101\n",
      "Loss: 0.5960537791252136\n",
      "Loss: 0.6337308287620544\n",
      "Loss: 0.5320771336555481\n",
      "Loss: 0.6360780000686646\n",
      "Loss: 0.6141560077667236\n",
      "Loss: 0.7042957544326782\n",
      "Loss: 0.6698499321937561\n",
      "Loss: 0.616550087928772\n",
      "Loss: 0.6854032874107361\n",
      "Loss: 0.6382717490196228\n",
      "Loss: 0.6055540442466736\n",
      "Loss: 0.608931839466095\n",
      "Loss: 0.6660322546958923\n",
      "Loss: 0.6976519227027893\n",
      "Loss: 0.69330894947052\n",
      "Loss: 0.6654537916183472\n",
      "Loss: 0.6542808413505554\n",
      "Loss: 0.6532996296882629\n",
      "Loss: 0.6468603014945984\n",
      "Loss: 0.6045186519622803\n",
      "Loss: 0.766605019569397\n",
      "Loss: 0.6557531356811523\n",
      "Loss: 0.6027157306671143\n",
      "Loss: 0.7459264993667603\n",
      "Loss: 0.6298377513885498\n",
      "Loss: 0.6320350766181946\n",
      "Loss: 0.6477514505386353\n",
      "Loss: 0.6639078259468079\n",
      "Loss: 0.6605473756790161\n",
      "Loss: 0.6442668437957764\n",
      "Loss: 0.6124435663223267\n",
      "Loss: 0.6045679450035095\n",
      "Loss: 0.6621374487876892\n",
      "Loss: 0.6624695062637329\n",
      "Loss: 0.6596450209617615\n",
      "Loss: 0.742226243019104\n",
      "Loss: 0.6950026750564575\n",
      "Loss: 0.645621657371521\n",
      "Loss: 0.7073719501495361\n",
      "Loss: 0.6291910409927368\n",
      "Loss: 0.7175081968307495\n",
      "Loss: 0.5337314605712891\n",
      "Loss: 0.6261705756187439\n",
      "Loss: 0.7057992815971375\n",
      "Loss: 0.6762323975563049\n",
      "Loss: 0.63665771484375\n",
      "Loss: 0.6368808746337891\n",
      "Loss: 0.6611230373382568\n",
      "Loss: 0.6207892298698425\n",
      "Loss: 0.6310666799545288\n",
      "Loss: 0.5887434482574463\n",
      "Loss: 0.6852949261665344\n",
      "Loss: 0.6518158316612244\n",
      "Loss: 0.655807375907898\n",
      "Loss: 0.6957178711891174\n",
      "Loss: 0.6657468676567078\n",
      "Loss: 0.6339768171310425\n",
      "Loss: 0.5655875205993652\n",
      "Loss: 0.5930637717247009\n",
      "Loss: 0.6975414752960205\n",
      "Loss: 0.6575679779052734\n",
      "Loss: 0.6285706758499146\n",
      "Loss: 0.6074752807617188\n",
      "Loss: 0.6451013684272766\n",
      "Loss: 0.5917197465896606\n",
      "Loss: 0.6276106238365173\n",
      "Loss: 0.7018812894821167\n",
      "Loss: 0.6319935917854309\n",
      "Loss: 0.6053134799003601\n",
      "Loss: 0.7168276906013489\n",
      "Loss: 0.6261180639266968\n",
      "Loss: 0.7927359342575073\n",
      "Loss: 0.6941099762916565\n",
      "Loss: 0.6475866436958313\n",
      "Loss: 0.6315646171569824\n",
      "Loss: 0.5600618720054626\n",
      "Loss: 0.570269763469696\n",
      "Loss: 0.661457359790802\n",
      "Loss: 0.681296706199646\n",
      "Loss: 0.5691630244255066\n",
      "Loss: 0.7142789959907532\n",
      "Loss: 0.6537402272224426\n",
      "Loss: 0.6139290928840637\n",
      "Loss: 0.6354078650474548\n",
      "Loss: 0.711861789226532\n",
      "Loss: 0.6483129262924194\n",
      "Loss: 0.6351844668388367\n",
      "Loss: 0.6784676313400269\n",
      "Loss: 0.5831109881401062\n",
      "Loss: 0.6480004787445068\n",
      "Loss: 0.722001314163208\n",
      "Loss: 0.5892387628555298\n",
      "Loss: 0.6058482527732849\n",
      "Loss: 0.6270295977592468\n",
      "Loss: 0.675678014755249\n",
      "Loss: 0.6148614287376404\n",
      "Loss: 0.6553478240966797\n",
      "Loss: 0.7537241578102112\n",
      "Loss: 0.6749363541603088\n",
      "Loss: 0.66819167137146\n",
      "Loss: 0.6312624216079712\n",
      "Loss: 0.6450718641281128\n",
      "Loss: 0.6552413105964661\n",
      "Loss: 0.6621502637863159\n",
      "Loss: 0.6532087326049805\n",
      "Loss: 0.682822585105896\n",
      "Loss: 0.6106914281845093\n",
      "Loss: 0.6433675289154053\n",
      "Loss: 0.6625091433525085\n",
      "Loss: 0.6318095326423645\n",
      "Loss: 0.6926471590995789\n",
      "Loss: 0.6690283417701721\n",
      "Loss: 0.6305115818977356\n",
      "Loss: 0.6279816031455994\n",
      "Loss: 0.5884544253349304\n",
      "Loss: 0.6299470663070679\n",
      "Loss: 0.6096367239952087\n",
      "Loss: 0.5867589712142944\n",
      "Loss: 0.5662459135055542\n",
      "Loss: 0.7123115062713623\n",
      "Loss: 0.5995720028877258\n",
      "Loss: 0.6080173850059509\n",
      "Loss: 0.5863459706306458\n",
      "Loss: 0.5985231399536133\n",
      "Loss: 0.6540318727493286\n",
      "Loss: 0.5688645839691162\n",
      "Loss: 0.6519324779510498\n",
      "Loss: 0.6375244855880737\n",
      "Loss: 0.713668167591095\n",
      "Loss: 0.6088345050811768\n",
      "Loss: 0.6598178744316101\n",
      "Loss: 0.6773665547370911\n",
      "Loss: 0.6505740284919739\n",
      "Loss: 0.7015703916549683\n",
      "Loss: 0.6751130223274231\n",
      "Loss: 0.6633026003837585\n",
      "Loss: 0.618545413017273\n",
      "Loss: 0.5920475721359253\n",
      "Loss: 0.6779820322990417\n",
      "Loss: 0.6112636923789978\n",
      "Loss: 0.6304759383201599\n",
      "Loss: 0.7047356367111206\n",
      "Loss: 0.6468483209609985\n",
      "Loss: 0.6005196571350098\n",
      "Loss: 0.6670816540718079\n",
      "Loss: 0.6821139454841614\n",
      "Loss: 0.7344316840171814\n",
      "Loss: 0.5580135583877563\n",
      "Loss: 0.6558908224105835\n",
      "Loss: 0.6734778881072998\n",
      "Loss: 0.5685735940933228\n",
      "Loss: 0.615206241607666\n",
      "Loss: 0.6979926824569702\n",
      "Loss: 0.6140454411506653\n",
      "Loss: 0.7744763493537903\n",
      "Loss: 0.6245071291923523\n",
      "Loss: 0.630107045173645\n",
      "Loss: 0.6181840896606445\n",
      "Loss: 0.6584685444831848\n",
      "Loss: 0.7114932537078857\n",
      "Loss: 0.6705092787742615\n",
      "Loss: 0.7036672830581665\n",
      "Loss: 0.6212248206138611\n",
      "Loss: 0.6573885679244995\n",
      "Loss: 0.6403338313102722\n",
      "Loss: 0.5812767148017883\n",
      "Loss: 0.705615222454071\n",
      "Loss: 0.6337260603904724\n",
      "Loss: 0.6902040243148804\n",
      "Loss: 0.6613986492156982\n",
      "Loss: 0.683565080165863\n",
      "Loss: 0.5986744165420532\n",
      "Loss: 0.6501574516296387\n",
      "Loss: 0.5987423062324524\n",
      "Loss: 0.5670031309127808\n",
      "Loss: 0.7722237706184387\n",
      "Loss: 0.7098580002784729\n",
      "Loss: 0.6795600056648254\n",
      "Loss: 0.6758970022201538\n",
      "Loss: 0.58683842420578\n",
      "Loss: 0.6182724237442017\n",
      "Loss: 0.6587468981742859\n",
      "Loss: 0.6440428495407104\n",
      "Loss: 0.6936156749725342\n",
      "Loss: 0.6191782355308533\n",
      "Loss: 0.7482508420944214\n",
      "Loss: 0.6635429859161377\n",
      "Loss: 0.6401610374450684\n",
      "Loss: 0.6465689539909363\n",
      "Loss: 0.6270359754562378\n",
      "Loss: 0.6914249658584595\n",
      "Loss: 0.648070752620697\n",
      "Loss: 0.5703877806663513\n",
      "Loss: 0.6863670945167542\n",
      "Loss: 0.6391913294792175\n",
      "Loss: 0.6685894727706909\n",
      "Loss: 0.6837177872657776\n",
      "Loss: 0.5810702443122864\n",
      "Loss: 0.6147608160972595\n",
      "Loss: 0.66620272397995\n",
      "Loss: 0.5725440382957458\n",
      "Loss: 0.6857820749282837\n",
      "Loss: 0.6082524061203003\n",
      "Loss: 0.5904404520988464\n",
      "Loss: 0.6675231456756592\n",
      "Loss: 0.6857605576515198\n",
      "Loss: 0.5635649561882019\n",
      "Loss: 0.6430282592773438\n",
      "Loss: 0.6304234266281128\n",
      "Loss: 0.6437975764274597\n",
      "Loss: 0.6850765347480774\n",
      "Loss: 0.6091611385345459\n",
      "Loss: 0.612166702747345\n",
      "Loss: 0.679487407207489\n",
      "Loss: 0.6143954396247864\n",
      "Loss: 0.6201745867729187\n",
      "Loss: 0.6658979654312134\n",
      "Loss: 0.5627075433731079\n",
      "Loss: 0.6839430928230286\n",
      "Loss: 0.6486485004425049\n",
      "Loss: 0.65739506483078\n",
      "Loss: 0.6459080576896667\n",
      "Loss: 0.7220306992530823\n",
      "Loss: 0.66817706823349\n",
      "Loss: 0.6073631644248962\n",
      "Loss: 0.6871290802955627\n",
      "Loss: 0.5858814120292664\n",
      "Loss: 0.5969732999801636\n",
      "Loss: 0.5971549153327942\n",
      "Loss: 0.7188324332237244\n",
      "Loss: 0.6448431015014648\n",
      "Loss: 0.6405795812606812\n",
      "Loss: 0.7021896839141846\n",
      "Loss: 0.6302728652954102\n",
      "Loss: 0.6018498539924622\n",
      "Loss: 0.6713528037071228\n",
      "Loss: 0.6457011103630066\n",
      "Loss: 0.6675780415534973\n",
      "Loss: 0.7266871929168701\n",
      "Loss: 0.6164824962615967\n",
      "Loss: 0.6685513257980347\n",
      "Loss: 0.6529260873794556\n",
      "Loss: 0.5718441009521484\n",
      "Loss: 0.6422742605209351\n",
      "Loss: 0.6354241371154785\n",
      "Loss: 0.6865856051445007\n",
      "Loss: 0.6237415671348572\n",
      "Loss: 0.6272881627082825\n",
      "Loss: 0.7052499055862427\n",
      "Loss: 0.5790503621101379\n",
      "Loss: 0.6553069949150085\n",
      "Loss: 0.6935654878616333\n",
      "Loss: 0.5868827700614929\n",
      "Loss: 0.6782385110855103\n",
      "Loss: 0.6260377168655396\n",
      "Loss: 0.6381449699401855\n",
      "Loss: 0.6920596957206726\n",
      "Loss: 0.6966408491134644\n",
      "Loss: 0.6396841406822205\n",
      "Loss: 0.6414150595664978\n",
      "Loss: 0.6943551898002625\n",
      "Loss: 0.6229896545410156\n",
      "Loss: 0.6002275347709656\n",
      "Loss: 0.6268914341926575\n",
      "Loss: 0.7102362513542175\n",
      "Loss: 0.6261869668960571\n",
      "Loss: 0.6539707183837891\n",
      "Loss: 0.5941563844680786\n",
      "Loss: 0.5958388447761536\n",
      "Loss: 0.7063332200050354\n",
      "Loss: 0.7056062817573547\n",
      "Loss: 0.6184653043746948\n",
      "Loss: 0.651823878288269\n",
      "Loss: 0.651980996131897\n",
      "Loss: 0.6261826753616333\n",
      "Loss: 0.6972810626029968\n",
      "Loss: 0.6560680270195007\n",
      "Loss: 0.7094309329986572\n",
      "Loss: 0.6563155055046082\n",
      "Loss: 0.714872419834137\n",
      "Loss: 0.6854223608970642\n",
      "Loss: 0.6585161685943604\n",
      "Loss: 0.6318420767784119\n",
      "Loss: 0.6349790096282959\n",
      "Loss: 0.6448081135749817\n",
      "Loss: 0.5899399518966675\n",
      "Loss: 0.6531041264533997\n",
      "Loss: 0.5888096690177917\n",
      "Loss: 0.5929669141769409\n",
      "Loss: 0.6830067038536072\n",
      "Loss: 0.6458037495613098\n",
      "Loss: 0.5968923568725586\n",
      "Loss: 0.6390469670295715\n",
      "Loss: 0.5992507934570312\n",
      "Loss: 0.6796301603317261\n",
      "Loss: 0.6717278361320496\n",
      "Loss: 0.6695274710655212\n",
      "Loss: 0.6588194966316223\n",
      "Loss: 0.7080385684967041\n",
      "Loss: 0.7090572714805603\n",
      "Loss: 0.6029017567634583\n",
      "Loss: 0.6822346448898315\n",
      "Loss: 0.6840780973434448\n",
      "Loss: 0.6733200550079346\n",
      "Loss: 0.702071487903595\n",
      "Loss: 0.6818082928657532\n",
      "Loss: 0.6482588052749634\n",
      "Loss: 0.647557258605957\n",
      "Loss: 0.6633733510971069\n",
      "Loss: 0.5940763354301453\n",
      "Loss: 0.5845714807510376\n",
      "Loss: 0.6466596126556396\n",
      "Loss: 0.6473839282989502\n",
      "Loss: 0.6526758670806885\n",
      "Loss: 0.6618638038635254\n",
      "Loss: 0.5759867429733276\n",
      "Loss: 0.6168727874755859\n",
      "Loss: 0.6679559946060181\n",
      "Loss: 0.7243283987045288\n",
      "Loss: 0.6081774830818176\n",
      "Loss: 0.6054075360298157\n",
      "Loss: 0.6764602065086365\n",
      "Loss: 0.6057193875312805\n",
      "Loss: 0.7079773545265198\n",
      "Loss: 0.7427421808242798\n",
      "Loss: 0.674056887626648\n",
      "Loss: 0.6567804217338562\n",
      "Loss: 0.678700864315033\n",
      "Loss: 0.6898658275604248\n",
      "Loss: 0.7335920929908752\n",
      "Loss: 0.5655009150505066\n",
      "Loss: 0.6274209022521973\n",
      "Loss: 0.6457952857017517\n",
      "Loss: 0.5442866683006287\n",
      "Loss: 0.6464093327522278\n",
      "Loss: 0.6550915837287903\n",
      "Loss: 0.6234118342399597\n",
      "Loss: 0.6737558841705322\n",
      "Loss: 0.6505012512207031\n",
      "Loss: 0.6518779993057251\n",
      "Loss: 0.7088278532028198\n",
      "Loss: 0.6316826939582825\n",
      "Loss: 0.6437000632286072\n",
      "Loss: 0.6878443360328674\n",
      "Loss: 0.6332893371582031\n",
      "Loss: 0.6467674970626831\n",
      "Loss: 0.6495578289031982\n",
      "Loss: 0.7015761137008667\n",
      "Loss: 0.590412974357605\n",
      "Loss: 0.6442877054214478\n",
      "Loss: 0.6571803092956543\n",
      "Loss: 0.6849038600921631\n",
      "Loss: 0.6901410222053528\n",
      "Loss: 0.6745145320892334\n",
      "Loss: 0.6322147250175476\n",
      "Loss: 0.7037302851676941\n",
      "Loss: 0.6090856790542603\n",
      "Loss: 0.55819171667099\n",
      "Loss: 0.6882795691490173\n",
      "Loss: 0.634471595287323\n",
      "Loss: 0.6500551700592041\n",
      "Loss: 0.6861984133720398\n",
      "Loss: 0.6412712335586548\n",
      "Loss: 0.7147749066352844\n",
      "Loss: 0.618546724319458\n",
      "Loss: 0.6767032146453857\n",
      "Loss: 0.6503329277038574\n",
      "Loss: 0.633680522441864\n",
      "Loss: 0.7180691957473755\n",
      "Loss: 0.5425158739089966\n",
      "Loss: 0.666819155216217\n",
      "Loss: 0.6576980948448181\n",
      "Loss: 0.7485129833221436\n",
      "Loss: 0.594437301158905\n",
      "Loss: 0.6964401602745056\n",
      "Loss: 0.5856354832649231\n",
      "Loss: 0.6551740765571594\n",
      "Loss: 0.6700121164321899\n",
      "Loss: 0.6398140788078308\n",
      "Loss: 0.6365241408348083\n",
      "Loss: 0.6814606785774231\n",
      "Loss: 0.5978501439094543\n",
      "Loss: 0.553364634513855\n",
      "Loss: 0.6341803669929504\n",
      "Loss: 0.5937469005584717\n",
      "Loss: 0.6338608860969543\n",
      "Loss: 0.6488050222396851\n",
      "Loss: 0.5847703814506531\n",
      "Loss: 0.6702553033828735\n",
      "Loss: 0.6876713037490845\n",
      "Loss: 0.6727518439292908\n",
      "Loss: 0.6560613512992859\n",
      "Loss: 0.6434569358825684\n",
      "Loss: 0.6991832256317139\n",
      "Loss: 0.6549659967422485\n",
      "Loss: 0.6467317938804626\n",
      "Loss: 0.6888745427131653\n",
      "Loss: 0.675031304359436\n",
      "Loss: 0.628674328327179\n",
      "Loss: 0.6383125185966492\n",
      "Loss: 0.6391154527664185\n",
      "Loss: 0.6612884402275085\n",
      "Loss: 0.6419605612754822\n",
      "Loss: 0.6596332788467407\n",
      "Loss: 0.6595618724822998\n",
      "Loss: 0.7108513712882996\n",
      "Loss: 0.662896454334259\n",
      "Loss: 0.6287453770637512\n",
      "Loss: 0.5819014310836792\n",
      "Loss: 0.5421895980834961\n",
      "Loss: 0.5980440378189087\n",
      "Loss: 0.7208291888237\n",
      "Loss: 0.673852264881134\n",
      "Loss: 0.6439567804336548\n",
      "Loss: 0.6407003402709961\n",
      "Loss: 0.6170233488082886\n",
      "Loss: 0.6819426417350769\n",
      "Loss: 0.6765649318695068\n",
      "Loss: 0.6686274409294128\n",
      "Loss: 0.6027547717094421\n",
      "Loss: 0.6913121342658997\n",
      "Loss: 0.6130325198173523\n",
      "Loss: 0.645283043384552\n",
      "Loss: 0.6081655025482178\n",
      "Loss: 0.6318031549453735\n",
      "Loss: 0.6314735412597656\n",
      "Loss: 0.5868915319442749\n",
      "Loss: 0.6087592840194702\n",
      "Loss: 0.6189477443695068\n",
      "Loss: 0.5946627855300903\n",
      "Loss: 0.6485269069671631\n",
      "Loss: 0.619424045085907\n",
      "Loss: 0.5573679208755493\n",
      "Loss: 0.6108617782592773\n",
      "Loss: 0.5790097713470459\n",
      "Loss: 0.659141480922699\n",
      "Loss: 0.637171745300293\n",
      "Loss: 0.6116608381271362\n",
      "Loss: 0.5852422714233398\n",
      "Loss: 0.6817799806594849\n",
      "Loss: 0.5994153022766113\n",
      "Loss: 0.6867544651031494\n",
      "Loss: 0.6019207835197449\n",
      "Loss: 0.6432075500488281\n",
      "Loss: 0.7442869544029236\n",
      "Loss: 0.6434771418571472\n",
      "Loss: 0.6458142399787903\n",
      "Loss: 0.7311576008796692\n",
      "Loss: 0.6936324238777161\n",
      "Loss: 0.6932379007339478\n",
      "Loss: 0.6058241128921509\n",
      "Loss: 0.687041163444519\n",
      "Loss: 0.5595096349716187\n",
      "Loss: 0.6841223835945129\n",
      "Loss: 0.7137256860733032\n",
      "Loss: 0.6641626358032227\n",
      "Loss: 0.6388029456138611\n",
      "Loss: 0.6423413753509521\n",
      "Loss: 0.6248587965965271\n",
      "Loss: 0.7228753566741943\n",
      "Loss: 0.6132890582084656\n",
      "Loss: 0.5616960525512695\n",
      "Loss: 0.5941647887229919\n",
      "Loss: 0.6360082030296326\n",
      "Loss: 0.6766940951347351\n",
      "Loss: 0.716263473033905\n",
      "Loss: 0.6392896771430969\n",
      "Loss: 0.6397663354873657\n",
      "Loss: 0.7273333668708801\n",
      "Loss: 0.5981296896934509\n",
      "Loss: 0.6700231432914734\n",
      "Loss: 0.6986063718795776\n",
      "Loss: 0.6905964016914368\n",
      "Loss: 0.6743387579917908\n",
      "Loss: 0.619402289390564\n",
      "Loss: 0.6692960262298584\n",
      "Loss: 0.6907028555870056\n",
      "Loss: 0.6836583614349365\n",
      "Loss: 0.6609342098236084\n",
      "Loss: 0.5863984823226929\n",
      "Loss: 0.6261883974075317\n",
      "Loss: 0.627109706401825\n",
      "Loss: 0.6507849097251892\n",
      "Loss: 0.6879534125328064\n",
      "Loss: 0.6497623324394226\n",
      "Loss: 0.6856362819671631\n",
      "Loss: 0.6239778995513916\n",
      "Loss: 0.6151129007339478\n",
      "Loss: 0.6601600646972656\n",
      "Loss: 0.674947202205658\n",
      "Loss: 0.5916026830673218\n",
      "Loss: 0.7270799875259399\n",
      "Loss: 0.562280535697937\n",
      "Loss: 0.6781922578811646\n",
      "Loss: 0.6218146681785583\n",
      "Loss: 0.6922692060470581\n",
      "Loss: 0.6350629329681396\n",
      "Loss: 0.6566647887229919\n",
      "Loss: 0.4947763681411743\n",
      "Loss: 0.6273130774497986\n",
      "Loss: 0.6932298541069031\n",
      "Loss: 0.6568611860275269\n",
      "Loss: 0.5887823104858398\n",
      "Loss: 0.6175548434257507\n",
      "Loss: 0.6533715724945068\n",
      "Loss: 0.707125723361969\n",
      "Loss: 0.6120495200157166\n",
      "Loss: 0.6768101453781128\n",
      "Loss: 0.6632899641990662\n",
      "Loss: 0.5723620653152466\n",
      "Loss: 0.7301900386810303\n",
      "Loss: 0.6773725152015686\n",
      "Loss: 0.647718608379364\n",
      "Loss: 0.6576564311981201\n",
      "Loss: 0.5910625457763672\n",
      "Loss: 0.7008198499679565\n",
      "Loss: 0.6413349509239197\n",
      "Loss: 0.6429069638252258\n",
      "Loss: 0.6346716284751892\n",
      "Loss: 0.6762468218803406\n",
      "Loss: 0.6670830845832825\n",
      "Loss: 0.791209876537323\n",
      "Loss: 0.6578561067581177\n",
      "Loss: 0.7132725119590759\n",
      "Loss: 0.6149538159370422\n",
      "Loss: 0.6361477375030518\n",
      "Loss: 0.6510053873062134\n",
      "Loss: 0.7172489762306213\n",
      "Loss: 0.5953397750854492\n",
      "Loss: 0.6158909201622009\n",
      "Loss: 0.6921601891517639\n",
      "Loss: 0.7436521053314209\n",
      "Loss: 0.6715220212936401\n",
      "Loss: 0.7174640893936157\n",
      "Loss: 0.6763907074928284\n",
      "Loss: 0.690327525138855\n",
      "Loss: 0.6639326810836792\n",
      "Loss: 0.57622891664505\n",
      "Loss: 0.6719871163368225\n",
      "Loss: 0.7373623251914978\n",
      "Loss: 0.6461246013641357\n",
      "Loss: 0.594761312007904\n",
      "Loss: 0.60030597448349\n",
      "Loss: 0.5984048247337341\n",
      "Loss: 0.6367747187614441\n",
      "Loss: 0.6385636329650879\n",
      "Loss: 0.6034694910049438\n",
      "Loss: 0.6743778586387634\n",
      "Loss: 0.6118849515914917\n",
      "Loss: 0.6354363560676575\n",
      "Loss: 0.5821112394332886\n",
      "Loss: 0.5786373019218445\n",
      "Loss: 0.5863395929336548\n",
      "Loss: 0.666528582572937\n",
      "Loss: 0.7419977784156799\n",
      "Loss: 0.6552011370658875\n",
      "Loss: 0.5888163447380066\n",
      "Loss: 0.628076434135437\n",
      "Loss: 0.6585988998413086\n",
      "Loss: 0.6747245192527771\n",
      "Loss: 0.7326725721359253\n",
      "Loss: 0.6310044527053833\n",
      "Loss: 0.6141828298568726\n",
      "Loss: 0.6607407927513123\n",
      "Loss: 0.7093403935432434\n",
      "Loss: 0.5776646733283997\n",
      "Loss: 0.6876341104507446\n",
      "Loss: 0.610649585723877\n",
      "Loss: 0.737348198890686\n",
      "Loss: 0.6301342844963074\n",
      "Loss: 0.6370702981948853\n",
      "Loss: 0.6929630637168884\n",
      "Loss: 0.6724601984024048\n",
      "Loss: 0.770582914352417\n",
      "Loss: 0.6259437799453735\n",
      "Loss: 0.6897011399269104\n",
      "Loss: 0.6148970723152161\n",
      "Loss: 0.7255779504776001\n",
      "Loss: 0.6899210810661316\n",
      "Loss: 0.5767788290977478\n",
      "Loss: 0.6629644632339478\n",
      "Loss: 0.5890845656394958\n",
      "Loss: 0.5740325450897217\n",
      "Loss: 0.6053589582443237\n",
      "Loss: 0.6583511829376221\n",
      "Loss: 0.693329930305481\n",
      "Loss: 0.5981736183166504\n",
      "Loss: 0.6500973105430603\n",
      "Loss: 0.6307239532470703\n",
      "Loss: 0.6197201013565063\n",
      "Loss: 0.5946944355964661\n",
      "Loss: 0.6224068403244019\n",
      "Loss: 0.6304911971092224\n",
      "Loss: 0.6097618341445923\n",
      "Loss: 0.617214560508728\n",
      "Loss: 0.6551417708396912\n",
      "Loss: 0.5532975196838379\n",
      "Loss: 0.6636030077934265\n",
      "Loss: 0.6631038188934326\n",
      "Loss: 0.5742227435112\n",
      "Loss: 0.5330926775932312\n",
      "Loss: 0.7149728536605835\n",
      "Loss: 0.6263753175735474\n",
      "Loss: 0.6916792988777161\n",
      "Loss: 0.6158214807510376\n",
      "Loss: 0.7277743816375732\n",
      "Loss: 0.6257156133651733\n",
      "Loss: 0.5670541524887085\n",
      "Loss: 0.5808665156364441\n",
      "Loss: 0.6519023776054382\n",
      "Loss: 0.6064109206199646\n",
      "Loss: 0.6121299862861633\n",
      "Loss: 0.6877433061599731\n",
      "Loss: 0.6686014533042908\n",
      "Loss: 0.6296732425689697\n",
      "Loss: 0.694108247756958\n",
      "Loss: 0.6039729118347168\n",
      "Loss: 0.7165653705596924\n",
      "Loss: 0.6392666101455688\n",
      "Loss: 0.6620115637779236\n",
      "Loss: 0.6980164051055908\n",
      "Loss: 0.6338740587234497\n",
      "Loss: 0.6816352605819702\n",
      "Loss: 0.6184569597244263\n",
      "Loss: 0.719089925289154\n",
      "Loss: 0.6304010152816772\n",
      "Loss: 0.6007134318351746\n",
      "Loss: 0.6844854950904846\n",
      "Loss: 0.6544802784919739\n",
      "Loss: 0.6647894382476807\n",
      "Loss: 0.6544182896614075\n",
      "Loss: 0.5530926585197449\n",
      "Loss: 0.6337811946868896\n",
      "Loss: 0.6622447371482849\n",
      "Loss: 0.700372576713562\n",
      "Loss: 0.638397216796875\n",
      "Loss: 0.7070673108100891\n",
      "Loss: 0.5787064433097839\n",
      "Loss: 0.6951924562454224\n",
      "Loss: 0.7184229493141174\n",
      "Loss: 0.6877211928367615\n",
      "Loss: 0.7045285701751709\n",
      "Loss: 0.6576219797134399\n",
      "Loss: 0.676547110080719\n",
      "Loss: 0.651521623134613\n",
      "Loss: 0.7092468738555908\n",
      "Loss: 0.643439769744873\n",
      "Loss: 0.602321445941925\n",
      "Loss: 0.6412307620048523\n",
      "Loss: 0.6369420886039734\n",
      "Loss: 0.6792172193527222\n",
      "Loss: 0.6369392275810242\n",
      "Loss: 0.6486846208572388\n",
      "Loss: 0.6470279693603516\n",
      "Loss: 0.6159202456474304\n",
      "Loss: 0.5898503065109253\n",
      "Loss: 0.5959488153457642\n",
      "Loss: 0.5989189147949219\n",
      "Loss: 0.6542152762413025\n",
      "Loss: 0.7467939853668213\n",
      "Loss: 0.6489021182060242\n",
      "Loss: 0.6665191650390625\n",
      "Loss: 0.6623642444610596\n",
      "Loss: 0.6515053510665894\n",
      "Loss: 0.6392237544059753\n",
      "Loss: 0.6676058173179626\n",
      "Loss: 0.6342384219169617\n",
      "Loss: 0.6881323456764221\n",
      "Loss: 0.6231838464736938\n",
      "Loss: 0.742954432964325\n",
      "Loss: 0.6623210310935974\n",
      "Loss: 0.6462655067443848\n",
      "Loss: 0.6257368922233582\n",
      "Loss: 0.6213804483413696\n",
      "Loss: 0.7109127640724182\n",
      "Loss: 0.6170625686645508\n",
      "Loss: 0.559238851070404\n",
      "Loss: 0.6098580360412598\n",
      "Loss: 0.7187536954879761\n",
      "Loss: 0.6561645865440369\n",
      "Loss: 0.6915174722671509\n",
      "Loss: 0.6420227289199829\n",
      "Loss: 0.6224415302276611\n",
      "Loss: 0.597752571105957\n",
      "Loss: 0.7073127031326294\n",
      "Loss: 0.6438067555427551\n",
      "Loss: 0.6336562633514404\n",
      "Loss: 0.5716285705566406\n",
      "Loss: 0.7287682890892029\n",
      "Loss: 0.6934219598770142\n",
      "Loss: 0.6118922233581543\n",
      "Loss: 0.6502072811126709\n",
      "Loss: 0.6887482404708862\n",
      "Loss: 0.6663264632225037\n",
      "Loss: 0.6259279251098633\n",
      "Loss: 0.5993257761001587\n",
      "Loss: 0.7233268022537231\n",
      "Loss: 0.5905396938323975\n",
      "Loss: 0.6136998534202576\n",
      "Loss: 0.6668668389320374\n",
      "Loss: 0.6148549914360046\n",
      "Loss: 0.6316211223602295\n",
      "Loss: 0.6397817134857178\n",
      "Loss: 0.6440127491950989\n",
      "Loss: 0.5348492860794067\n",
      "Loss: 0.6265703439712524\n",
      "Loss: 0.6263756155967712\n",
      "Loss: 0.6243502497673035\n",
      "Loss: 0.6775015592575073\n",
      "Loss: 0.6447604894638062\n",
      "Loss: 0.6625816822052002\n",
      "Loss: 0.5933290719985962\n",
      "Loss: 0.656843900680542\n",
      "Loss: 0.6637623906135559\n",
      "Loss: 0.6305463314056396\n",
      "Loss: 0.6848908066749573\n",
      "Loss: 0.6868825554847717\n",
      "Loss: 0.6643287539482117\n",
      "Loss: 0.6756759881973267\n",
      "Loss: 0.6298240423202515\n",
      "Loss: 0.5738310813903809\n",
      "Loss: 0.6957389712333679\n",
      "Loss: 0.6978737711906433\n",
      "Loss: 0.6853669285774231\n",
      "Loss: 0.5898447036743164\n",
      "Loss: 0.6731822490692139\n",
      "Loss: 0.5981842875480652\n",
      "Loss: 0.6975077390670776\n",
      "Loss: 0.5448771119117737\n",
      "Loss: 0.6348087191581726\n",
      "Loss: 0.5925233364105225\n",
      "Loss: 0.6683924794197083\n",
      "Loss: 0.6402653455734253\n",
      "Loss: 0.6154239773750305\n",
      "Loss: 0.6379919052124023\n",
      "Loss: 0.6358910799026489\n",
      "Loss: 0.5854206085205078\n",
      "Loss: 0.642453670501709\n",
      "Loss: 0.7114299535751343\n",
      "Loss: 0.6038625240325928\n",
      "Loss: 0.7081733345985413\n",
      "Loss: 0.6800580620765686\n",
      "Loss: 0.6852067112922668\n",
      "Loss: 0.6085010766983032\n",
      "Loss: 0.6725852489471436\n",
      "Loss: 0.6353359222412109\n",
      "Loss: 0.6293057203292847\n",
      "Loss: 0.6392518877983093\n",
      "Loss: 0.6830734014511108\n",
      "Loss: 0.6372097134590149\n",
      "Loss: 0.6938796639442444\n",
      "Loss: 0.5773453116416931\n",
      "Loss: 0.6224140524864197\n",
      "Loss: 0.6876499056816101\n",
      "Loss: 0.563041627407074\n",
      "Loss: 0.6062182188034058\n",
      "Loss: 0.5975664258003235\n",
      "Loss: 0.6131525039672852\n",
      "Loss: 0.6695660352706909\n",
      "Loss: 0.6479738354682922\n",
      "Loss: 0.6089890003204346\n",
      "Loss: 0.6266381740570068\n",
      "Loss: 0.6455729007720947\n",
      "Loss: 0.7019731998443604\n",
      "Loss: 0.7422853708267212\n",
      "Loss: 0.6088957190513611\n",
      "Loss: 0.6547201871871948\n",
      "Loss: 0.6000493764877319\n",
      "Loss: 0.6999480724334717\n",
      "Loss: 0.6662424802780151\n",
      "Loss: 0.5901133418083191\n",
      "Loss: 0.7138634920120239\n",
      "Loss: 0.6356074810028076\n",
      "Loss: 0.6389472484588623\n",
      "Loss: 0.6387308835983276\n",
      "Loss: 0.705034613609314\n",
      "Loss: 0.5894161462783813\n",
      "Loss: 0.731703519821167\n",
      "Loss: 0.6042273044586182\n",
      "Loss: 0.5798727869987488\n",
      "Loss: 0.6953223347663879\n",
      "Loss: 0.6236489415168762\n",
      "Loss: 0.606289267539978\n",
      "Loss: 0.6145436763763428\n",
      "Loss: 0.5797574520111084\n",
      "Loss: 0.6164062023162842\n",
      "Loss: 0.6837893128395081\n",
      "Loss: 0.6274677515029907\n",
      "Loss: 0.6377341747283936\n",
      "Loss: 0.573989748954773\n",
      "Loss: 0.7441765069961548\n",
      "Loss: 0.6042279005050659\n",
      "Loss: 0.6518575549125671\n",
      "Loss: 0.665027379989624\n",
      "Loss: 0.6458203196525574\n",
      "Loss: 0.6127633452415466\n",
      "Loss: 0.6677272319793701\n",
      "Loss: 0.6416956186294556\n",
      "Loss: 0.6855472922325134\n",
      "Loss: 0.6699851155281067\n",
      "Loss: 0.7072049975395203\n",
      "Loss: 0.5825170278549194\n",
      "Loss: 0.764453113079071\n",
      "Loss: 0.6911753416061401\n",
      "Loss: 0.641372799873352\n",
      "Loss: 0.5958670377731323\n",
      "Loss: 0.6976272463798523\n",
      "Loss: 0.6372783184051514\n",
      "Loss: 0.6472092866897583\n",
      "Loss: 0.6993572115898132\n",
      "Loss: 0.6276133060455322\n",
      "Loss: 0.6409582495689392\n",
      "Loss: 0.6396477222442627\n",
      "Loss: 0.655634880065918\n",
      "Loss: 0.6492512822151184\n",
      "Loss: 0.65595942735672\n",
      "Loss: 0.6439356207847595\n",
      "Loss: 0.6252293586730957\n",
      "Loss: 0.6285902261734009\n",
      "Loss: 0.682503879070282\n",
      "Loss: 0.6049683690071106\n",
      "Loss: 0.5990831255912781\n",
      "Loss: 0.6124848127365112\n",
      "Loss: 0.5817803740501404\n",
      "Loss: 0.6236042380332947\n",
      "Loss: 0.691156268119812\n",
      "Loss: 0.6478372812271118\n",
      "Loss: 0.7049987316131592\n",
      "Loss: 0.7429752945899963\n",
      "Loss: 0.6144759058952332\n",
      "Loss: 0.5337326526641846\n",
      "Loss: 0.6240954399108887\n",
      "Loss: 0.6367565393447876\n",
      "Loss: 0.7063177824020386\n",
      "Loss: 0.683057427406311\n",
      "Loss: 0.678662121295929\n",
      "Loss: 0.6620593070983887\n",
      "Loss: 0.6781156063079834\n",
      "Loss: 0.6740721464157104\n",
      "Loss: 0.5960787534713745\n",
      "Loss: 0.6770313382148743\n",
      "Loss: 0.6711991429328918\n",
      "Loss: 0.6149489879608154\n",
      "Loss: 0.6723039150238037\n",
      "Loss: 0.5804972052574158\n",
      "Loss: 0.6470823287963867\n",
      "Loss: 0.6032537817955017\n",
      "Loss: 0.5527452230453491\n",
      "Loss: 0.6328272223472595\n",
      "Loss: 0.6580328941345215\n",
      "Loss: 0.7400814890861511\n",
      "Loss: 0.5658549070358276\n",
      "Loss: 0.7312573194503784\n",
      "Loss: 0.6468966007232666\n",
      "Loss: 0.5549923181533813\n",
      "Loss: 0.6468496322631836\n",
      "Loss: 0.6027306914329529\n",
      "Loss: 0.627933144569397\n",
      "Loss: 0.6487296223640442\n",
      "Loss: 0.7476451396942139\n",
      "Loss: 0.5993332862854004\n",
      "Loss: 0.6540325284004211\n",
      "Loss: 0.6669394969940186\n",
      "Loss: 0.6229076385498047\n",
      "Loss: 0.5543739199638367\n",
      "Loss: 0.6738221049308777\n",
      "Loss: 0.7207327485084534\n",
      "Loss: 0.6314617395401001\n",
      "Loss: 0.6308146715164185\n",
      "Loss: 0.68248450756073\n",
      "Loss: 0.6452701091766357\n",
      "Loss: 0.7000452876091003\n",
      "Loss: 0.6615246534347534\n",
      "Loss: 0.6443694233894348\n",
      "Loss: 0.6811304688453674\n",
      "Loss: 0.6557070016860962\n",
      "Loss: 0.6211797595024109\n",
      "Loss: 0.6708303689956665\n",
      "Loss: 0.6621606349945068\n",
      "Loss: 0.6156012415885925\n",
      "Loss: 0.6046121120452881\n",
      "Loss: 0.6413226127624512\n",
      "Loss: 0.5881823301315308\n",
      "Loss: 0.7019063830375671\n",
      "Loss: 0.6319551467895508\n",
      "Loss: 0.6672656536102295\n",
      "Loss: 0.6728832721710205\n",
      "Loss: 0.7568143010139465\n",
      "Loss: 0.5662734508514404\n",
      "Loss: 0.602441132068634\n",
      "Loss: 0.5624116659164429\n",
      "Loss: 0.6262410283088684\n",
      "Loss: 0.6364061832427979\n",
      "Loss: 0.7240248322486877\n",
      "Loss: 0.684894323348999\n",
      "Loss: 0.6477916240692139\n",
      "Loss: 0.662800669670105\n",
      "Loss: 0.6397839784622192\n",
      "Loss: 0.7317067980766296\n",
      "Loss: 0.637043833732605\n",
      "Loss: 0.6514730453491211\n",
      "Loss: 0.5458208918571472\n",
      "Loss: 0.6379495859146118\n",
      "Loss: 0.6266705989837646\n",
      "Loss: 0.7146022319793701\n",
      "Loss: 0.6580411195755005\n",
      "Loss: 0.6314588785171509\n",
      "Loss: 0.644648551940918\n",
      "Loss: 0.5910736322402954\n",
      "Loss: 0.6218105554580688\n",
      "Loss: 0.6148759722709656\n",
      "Loss: 0.6952588558197021\n",
      "Loss: 0.6663815379142761\n",
      "Loss: 0.6139233708381653\n",
      "Loss: 0.6688567399978638\n",
      "Loss: 0.7014574408531189\n",
      "Loss: 0.6329793334007263\n",
      "Loss: 0.6041995882987976\n",
      "Loss: 0.7129248380661011\n",
      "Loss: 0.7193921208381653\n",
      "Loss: 0.6712955236434937\n",
      "Loss: 0.7089844942092896\n",
      "Loss: 0.65253084897995\n",
      "Loss: 0.6475591659545898\n",
      "Loss: 0.6902086138725281\n",
      "Loss: 0.6822015643119812\n",
      "Loss: 0.6353525519371033\n",
      "Loss: 0.6162818074226379\n",
      "Loss: 0.6322770118713379\n",
      "Loss: 0.5815364718437195\n",
      "Loss: 0.6158021688461304\n",
      "Loss: 0.5673099756240845\n",
      "Loss: 0.5784744620323181\n",
      "Loss: 0.6499188542366028\n",
      "Loss: 0.6322166323661804\n",
      "Loss: 0.6758719086647034\n",
      "Loss: 0.6879881024360657\n",
      "Loss: 0.6223408579826355\n",
      "Loss: 0.6499519348144531\n",
      "Loss: 0.5744628310203552\n",
      "Loss: 0.7423474192619324\n",
      "Loss: 0.6822513937950134\n",
      "Loss: 0.6261908411979675\n",
      "Loss: 0.6737374663352966\n",
      "Loss: 0.6294021606445312\n",
      "Loss: 0.618621289730072\n",
      "Loss: 0.6223229169845581\n",
      "Loss: 0.6096488237380981\n",
      "Loss: 0.6284071207046509\n",
      "Loss: 0.7179495692253113\n",
      "Loss: 0.6322166323661804\n",
      "Loss: 0.6810370087623596\n",
      "Loss: 0.6075528264045715\n",
      "Loss: 0.6061820387840271\n",
      "Loss: 0.6592615246772766\n",
      "Loss: 0.6377371549606323\n",
      "Loss: 0.5957974195480347\n",
      "Loss: 0.6600200533866882\n",
      "Loss: 0.5625665187835693\n",
      "Loss: 0.6649200320243835\n",
      "Loss: 0.66972416639328\n",
      "Loss: 0.6304644346237183\n",
      "Loss: 0.6055183410644531\n",
      "Loss: 0.6467231512069702\n",
      "Loss: 0.6443344950675964\n",
      "Loss: 0.6598770022392273\n",
      "Loss: 0.6222313642501831\n",
      "Loss: 0.6239684224128723\n",
      "Loss: 0.6906445622444153\n",
      "Loss: 0.5589357614517212\n",
      "Loss: 0.6100893020629883\n",
      "Loss: 0.6298384666442871\n",
      "Loss: 0.6399852633476257\n",
      "Loss: 0.6836188435554504\n",
      "Loss: 0.682442307472229\n",
      "Loss: 0.5659118294715881\n",
      "Loss: 0.6605928540229797\n",
      "Loss: 0.5957295894622803\n",
      "Loss: 0.7346533536911011\n",
      "Loss: 0.6107355952262878\n",
      "Loss: 0.600517988204956\n",
      "Loss: 0.6509529948234558\n",
      "Loss: 0.6096247434616089\n",
      "Loss: 0.6549842357635498\n",
      "Loss: 0.6673160791397095\n",
      "Loss: 0.6643788814544678\n",
      "Loss: 0.5966107845306396\n",
      "Loss: 0.7181953191757202\n",
      "Loss: 0.5381735563278198\n",
      "Loss: 0.7306619882583618\n",
      "Loss: 0.6545832753181458\n",
      "Loss: 0.6341513991355896\n",
      "Loss: 0.6449383497238159\n",
      "Loss: 0.7764692902565002\n",
      "Loss: 0.6487499475479126\n",
      "Loss: 0.6525465846061707\n",
      "Loss: 0.6771501898765564\n",
      "Loss: 0.6150457859039307\n",
      "Loss: 0.7045047283172607\n",
      "Loss: 0.6046642065048218\n",
      "Loss: 0.676625669002533\n",
      "Loss: 0.6612607836723328\n",
      "Loss: 0.6952394247055054\n",
      "Loss: 0.6116832494735718\n",
      "Loss: 0.6032588481903076\n",
      "Loss: 0.6181391477584839\n",
      "Loss: 0.7182129621505737\n",
      "Loss: 0.6467334032058716\n",
      "Loss: 0.6316088438034058\n",
      "Loss: 0.6064700484275818\n",
      "Loss: 0.6121503710746765\n",
      "Loss: 0.7133300304412842\n",
      "Loss: 0.625024139881134\n",
      "Loss: 0.61894690990448\n",
      "Loss: 0.670042872428894\n",
      "Loss: 0.6587523221969604\n",
      "Loss: 0.6497697830200195\n",
      "Loss: 0.6302420496940613\n",
      "Loss: 0.577829122543335\n",
      "Loss: 0.5990045666694641\n",
      "Loss: 0.7674437165260315\n",
      "Loss: 0.6245132684707642\n",
      "Loss: 0.6567379236221313\n",
      "Loss: 0.6091193556785583\n",
      "Loss: 0.7205377817153931\n",
      "Loss: 0.6786738634109497\n",
      "Loss: 0.6718834638595581\n",
      "Loss: 0.6747460961341858\n",
      "Loss: 0.6699439883232117\n",
      "Loss: 0.6417218446731567\n",
      "Loss: 0.5754973888397217\n",
      "Loss: 0.6270406246185303\n",
      "Loss: 0.5707060694694519\n",
      "Loss: 0.6028345227241516\n",
      "Loss: 0.5990512371063232\n",
      "Loss: 0.6834539771080017\n",
      "Loss: 0.6807175278663635\n",
      "Loss: 0.6591395139694214\n",
      "Loss: 0.619458794593811\n",
      "Loss: 0.7902913689613342\n",
      "Loss: 0.5526357889175415\n",
      "Loss: 0.6393145322799683\n",
      "Loss: 0.6597622036933899\n",
      "Loss: 0.6991772055625916\n",
      "Loss: 0.6851459741592407\n",
      "Loss: 0.7169862389564514\n",
      "Loss: 0.6785778403282166\n",
      "Loss: 0.6688830852508545\n",
      "Loss: 0.6108968257904053\n",
      "Loss: 0.6502040028572083\n",
      "Loss: 0.631574809551239\n",
      "Loss: 0.6695216298103333\n",
      "Loss: 0.707366406917572\n",
      "Loss: 0.6696811318397522\n",
      "Loss: 0.6067668795585632\n",
      "Loss: 0.6314815878868103\n",
      "Loss: 0.6889580488204956\n",
      "Loss: 0.5848950743675232\n",
      "Loss: 0.6577722430229187\n",
      "Loss: 0.6522291898727417\n",
      "Loss: 0.6231821775436401\n",
      "Loss: 0.6562750935554504\n",
      "Loss: 0.6046978235244751\n",
      "Loss: 0.5889403820037842\n",
      "Loss: 0.6626722812652588\n",
      "Loss: 0.6658844947814941\n",
      "Loss: 0.6077596545219421\n",
      "Loss: 0.6563539505004883\n",
      "Loss: 0.7187450528144836\n",
      "Loss: 0.715541422367096\n",
      "Loss: 0.6637825965881348\n",
      "Loss: 0.6247926950454712\n",
      "Loss: 0.5859105587005615\n",
      "Loss: 0.6188439726829529\n",
      "Loss: 0.6590108275413513\n",
      "Loss: 0.6363887190818787\n",
      "Loss: 0.6295127272605896\n",
      "Loss: 0.6756137013435364\n",
      "Loss: 0.6643743515014648\n",
      "Loss: 0.6839532256126404\n",
      "Loss: 0.5587064027786255\n",
      "Loss: 0.6800450682640076\n",
      "Loss: 0.5925508737564087\n",
      "Loss: 0.7323673963546753\n",
      "Loss: 0.5352694988250732\n",
      "Loss: 0.6849373579025269\n",
      "Loss: 0.6258866190910339\n",
      "Loss: 0.7007039189338684\n",
      "Loss: 0.6199008226394653\n",
      "Loss: 0.7012084126472473\n",
      "Loss: 0.6679316163063049\n",
      "Loss: 0.5776036381721497\n",
      "Loss: 0.6027668118476868\n",
      "Loss: 0.6132516860961914\n",
      "Loss: 0.5667328238487244\n",
      "Loss: 0.6816007494926453\n",
      "Loss: 0.6553188562393188\n",
      "Loss: 0.656183660030365\n",
      "Loss: 0.78777015209198\n",
      "Loss: 0.5752063989639282\n",
      "Loss: 0.6947949528694153\n",
      "Loss: 0.6506399512290955\n",
      "Loss: 0.6951296925544739\n",
      "Loss: 0.6011841893196106\n",
      "Loss: 0.6302397847175598\n",
      "Loss: 0.670810878276825\n",
      "Loss: 0.6373738050460815\n",
      "Loss: 0.6149653792381287\n",
      "Loss: 0.6579406261444092\n",
      "Loss: 0.5933721661567688\n",
      "Loss: 0.5595806837081909\n",
      "Loss: 0.6788561940193176\n",
      "Loss: 0.638861358165741\n",
      "Loss: 0.6837893724441528\n",
      "Loss: 0.6736227869987488\n",
      "Loss: 0.6946595311164856\n",
      "Loss: 0.6339166760444641\n",
      "Loss: 0.6526684165000916\n",
      "Loss: 0.6421962976455688\n",
      "Loss: 0.6154744625091553\n",
      "Loss: 0.6399267911911011\n",
      "Loss: 0.6935430765151978\n",
      "Loss: 0.6852038502693176\n",
      "Loss: 0.6396378874778748\n",
      "Loss: 0.6745120882987976\n",
      "Loss: 0.7422507405281067\n",
      "Loss: 0.7041820883750916\n",
      "Loss: 0.6435316205024719\n",
      "Loss: 0.6408284306526184\n",
      "Loss: 0.6760333180427551\n",
      "Loss: 0.6078294515609741\n",
      "Loss: 0.6235874891281128\n",
      "Loss: 0.7160455584526062\n",
      "Loss: 0.7280329465866089\n",
      "Loss: 0.5469257235527039\n",
      "Loss: 0.6091338396072388\n",
      "Loss: 0.5822188258171082\n",
      "Loss: 0.6023294925689697\n",
      "Loss: 0.6738247275352478\n",
      "Loss: 0.6906713843345642\n",
      "Loss: 0.6334823966026306\n",
      "Loss: 0.5925184488296509\n",
      "Loss: 0.6691824197769165\n",
      "Loss: 0.7192676663398743\n",
      "Loss: 0.6614452600479126\n",
      "Loss: 0.6190826296806335\n",
      "Loss: 0.7246357202529907\n",
      "Loss: 0.6106462478637695\n",
      "Loss: 0.6717157959938049\n",
      "Loss: 0.6949989795684814\n",
      "Loss: 0.6305093765258789\n",
      "Loss: 0.6475143432617188\n",
      "Loss: 0.634880781173706\n",
      "Loss: 0.6589272618293762\n",
      "Loss: 0.6774526834487915\n",
      "Loss: 0.5625194311141968\n",
      "Loss: 0.6409284472465515\n",
      "Loss: 0.6805964112281799\n",
      "Loss: 0.6687463521957397\n",
      "Loss: 0.7105116248130798\n",
      "Loss: 0.625331699848175\n",
      "Loss: 0.6627599596977234\n",
      "Loss: 0.6459416151046753\n",
      "Loss: 0.5671089291572571\n",
      "Loss: 0.6645770072937012\n",
      "Loss: 0.6442235112190247\n",
      "Loss: 0.5794251561164856\n",
      "Loss: 0.6260577440261841\n",
      "Loss: 0.6100177764892578\n",
      "Loss: 0.6520207524299622\n",
      "Loss: 0.6207792162895203\n",
      "Loss: 0.6985441446304321\n",
      "Loss: 0.6291399002075195\n",
      "Loss: 0.6334608793258667\n",
      "Loss: 0.605126142501831\n",
      "Loss: 0.6325977444648743\n",
      "Loss: 0.6100509762763977\n",
      "Loss: 0.7155811786651611\n",
      "Loss: 0.63495272397995\n",
      "Loss: 0.670322835445404\n",
      "Loss: 0.6755760312080383\n",
      "Loss: 0.6649156808853149\n",
      "Loss: 0.7589848637580872\n",
      "Loss: 0.6055156588554382\n",
      "Loss: 0.5856173634529114\n",
      "Loss: 0.666344165802002\n",
      "Loss: 0.6588902473449707\n",
      "Loss: 0.5912790298461914\n",
      "Loss: 0.6332077980041504\n",
      "Loss: 0.7077130079269409\n",
      "Loss: 0.728828489780426\n",
      "Loss: 0.6991148591041565\n",
      "Loss: 0.6643616557121277\n",
      "Loss: 0.6556249856948853\n",
      "Loss: 0.6197550892829895\n",
      "Loss: 0.5892210006713867\n",
      "Loss: 0.648404598236084\n",
      "Loss: 0.6815469264984131\n",
      "Loss: 0.6508026123046875\n",
      "Loss: 0.7291415333747864\n",
      "Loss: 0.6451306343078613\n",
      "Loss: 0.6248142123222351\n",
      "Loss: 0.6881325840950012\n",
      "Loss: 0.6575877070426941\n",
      "Loss: 0.6822763681411743\n",
      "Loss: 0.6460020542144775\n",
      "Loss: 0.6158356070518494\n",
      "Loss: 0.6566137075424194\n",
      "Loss: 0.7716242074966431\n",
      "Loss: 0.6131104230880737\n",
      "Loss: 0.6292229890823364\n",
      "Loss: 0.6697980761528015\n",
      "Loss: 0.7300072908401489\n",
      "Loss: 0.6350609064102173\n",
      "Loss: 0.6435443162918091\n",
      "Loss: 0.6820244193077087\n",
      "Loss: 0.6341416239738464\n",
      "Loss: 0.6625839471817017\n",
      "Loss: 0.6410120725631714\n",
      "Loss: 0.5948895812034607\n",
      "Loss: 0.6847385764122009\n",
      "Loss: 0.6597440242767334\n",
      "Loss: 0.5793853998184204\n",
      "Loss: 0.5930107235908508\n",
      "Loss: 0.6239035129547119\n",
      "Loss: 0.6038588285446167\n",
      "Loss: 0.6748449802398682\n",
      "Loss: 0.6503298878669739\n",
      "Loss: 0.63553786277771\n",
      "Loss: 0.686360776424408\n",
      "Loss: 0.670875608921051\n",
      "Loss: 0.658183753490448\n",
      "Loss: 0.6802653670310974\n",
      "Loss: 0.6589882969856262\n",
      "Loss: 0.6676896214485168\n",
      "Loss: 0.5492510795593262\n",
      "Loss: 0.6895833611488342\n",
      "Loss: 0.6256446242332458\n",
      "Loss: 0.655746579170227\n",
      "Loss: 0.6385473608970642\n",
      "Loss: 0.673799455165863\n",
      "Loss: 0.749703586101532\n",
      "Loss: 0.7604925036430359\n",
      "Loss: 0.7377878427505493\n",
      "Loss: 0.603458046913147\n",
      "Loss: 0.6672858595848083\n",
      "Loss: 0.6472017168998718\n",
      "Loss: 0.6319816708564758\n",
      "Loss: 0.6182384490966797\n",
      "Loss: 0.6914010643959045\n",
      "Loss: 0.6590420007705688\n",
      "Loss: 0.6636463403701782\n",
      "Loss: 0.6096307635307312\n",
      "Loss: 0.6097562909126282\n",
      "Loss: 0.648232102394104\n",
      "Loss: 0.5860993266105652\n",
      "Loss: 0.6443841457366943\n",
      "Loss: 0.6577193737030029\n",
      "Loss: 0.635584831237793\n",
      "Loss: 0.6395828127861023\n",
      "Loss: 0.6182970404624939\n",
      "Loss: 0.6358484029769897\n",
      "Loss: 0.604537308216095\n",
      "Loss: 0.6630455255508423\n",
      "Loss: 0.587269127368927\n",
      "Loss: 0.6455902457237244\n",
      "Loss: 0.677962064743042\n",
      "Loss: 0.5685436129570007\n",
      "Loss: 0.617191731929779\n",
      "Loss: 0.6212524771690369\n",
      "Loss: 0.6214472055435181\n",
      "Loss: 0.6460782885551453\n",
      "Loss: 0.6803508996963501\n",
      "Loss: 0.6416571736335754\n",
      "Loss: 0.7515462040901184\n",
      "Loss: 0.7483890652656555\n",
      "Loss: 0.7565070390701294\n",
      "Loss: 0.6262549757957458\n",
      "Loss: 0.6750562191009521\n",
      "Loss: 0.6292360424995422\n",
      "Loss: 0.5706034898757935\n",
      "Loss: 0.6624571084976196\n",
      "Loss: 0.6672245860099792\n",
      "Loss: 0.6073158979415894\n",
      "Loss: 0.5648025870323181\n",
      "Loss: 0.6557599902153015\n",
      "Loss: 0.6268942952156067\n",
      "Loss: 0.6813949346542358\n",
      "Loss: 0.7541146874427795\n",
      "Loss: 0.6260685920715332\n",
      "Loss: 0.6618679761886597\n",
      "Loss: 0.6140664219856262\n",
      "Loss: 0.6178151965141296\n",
      "Loss: 0.6837389469146729\n",
      "Loss: 0.6897804141044617\n",
      "Loss: 0.6768743991851807\n",
      "Loss: 0.6276280879974365\n",
      "Loss: 0.6243636012077332\n",
      "Loss: 0.6184663772583008\n",
      "Loss: 0.6575725674629211\n",
      "Loss: 0.6295401453971863\n",
      "Loss: 0.6403248906135559\n",
      "Loss: 0.6675183773040771\n",
      "Loss: 0.6818943619728088\n",
      "Loss: 0.6037417650222778\n",
      "Loss: 0.6925966143608093\n",
      "Loss: 0.6670907139778137\n",
      "Loss: 0.6514329314231873\n",
      "Loss: 0.7728869915008545\n",
      "Loss: 0.6662594079971313\n",
      "Loss: 0.662250816822052\n",
      "Loss: 0.669693112373352\n",
      "Loss: 0.5845674276351929\n",
      "Loss: 0.611083447933197\n",
      "Loss: 0.633240818977356\n",
      "Loss: 0.7042879462242126\n",
      "Loss: 0.7015379071235657\n",
      "Loss: 0.684310257434845\n",
      "Loss: 0.7456921339035034\n",
      "Loss: 0.6148603558540344\n",
      "Loss: 0.6712210178375244\n",
      "Loss: 0.6666667461395264\n",
      "Loss: 0.695071816444397\n",
      "Loss: 0.5872694253921509\n",
      "Loss: 0.6018955707550049\n",
      "Loss: 0.6257146000862122\n",
      "Loss: 0.6492277383804321\n",
      "Loss: 0.6558834910392761\n",
      "Loss: 0.6538065671920776\n",
      "Loss: 0.5786827802658081\n",
      "Loss: 0.6744996905326843\n",
      "Loss: 0.712603747844696\n",
      "Loss: 0.6456483602523804\n",
      "Loss: 0.6401659846305847\n",
      "Loss: 0.607221782207489\n",
      "Loss: 0.6217180490493774\n",
      "Loss: 0.6988477110862732\n",
      "Loss: 0.6980472207069397\n",
      "Loss: 0.6437024474143982\n",
      "Loss: 0.6366024017333984\n",
      "Loss: 0.7250939011573792\n",
      "Loss: 0.6118111610412598\n",
      "Loss: 0.6552955508232117\n",
      "Loss: 0.6868693828582764\n",
      "Loss: 0.6761608719825745\n",
      "Loss: 0.6037613749504089\n",
      "Loss: 0.639758825302124\n",
      "Loss: 0.5952835083007812\n",
      "Loss: 0.6355993747711182\n",
      "Loss: 0.6633424758911133\n",
      "Loss: 0.6480329036712646\n",
      "Loss: 0.6393025517463684\n",
      "Loss: 0.6280852556228638\n",
      "Loss: 0.660226583480835\n",
      "Loss: 0.6700721979141235\n",
      "Loss: 0.6619256138801575\n",
      "Loss: 0.6200879216194153\n",
      "Loss: 0.6730660200119019\n",
      "Loss: 0.6691812872886658\n",
      "Loss: 0.6202278137207031\n",
      "Loss: 0.6684460043907166\n",
      "Loss: 0.5398818850517273\n",
      "Loss: 0.6289045810699463\n",
      "Loss: 0.6357744932174683\n",
      "Loss: 0.6717005372047424\n",
      "Loss: 0.6121270656585693\n",
      "Loss: 0.6547828912734985\n",
      "Loss: 0.691008448600769\n",
      "Loss: 0.6399352550506592\n",
      "Loss: 0.6389815807342529\n",
      "Loss: 0.6343092322349548\n",
      "Loss: 0.6178421974182129\n",
      "Loss: 0.5801007747650146\n",
      "Loss: 0.5554235577583313\n",
      "Loss: 0.5846635699272156\n",
      "Loss: 0.613794207572937\n",
      "Loss: 0.6618511080741882\n",
      "Loss: 0.6469563841819763\n",
      "Loss: 0.7067834734916687\n",
      "Loss: 0.5843570232391357\n",
      "Loss: 0.6991965770721436\n",
      "Loss: 0.66514652967453\n",
      "Loss: 0.634028434753418\n",
      "Loss: 0.6820515394210815\n",
      "Loss: 0.5750902891159058\n",
      "Loss: 0.6554795503616333\n",
      "Loss: 0.6843912601470947\n",
      "Loss: 0.6283749341964722\n",
      "Loss: 0.6708106398582458\n",
      "Loss: 0.6512235999107361\n",
      "Loss: 0.6612222790718079\n",
      "Loss: 0.6658283472061157\n",
      "Loss: 0.6744562387466431\n",
      "Loss: 0.5790698528289795\n",
      "Loss: 0.6214755177497864\n",
      "Loss: 0.6536272764205933\n",
      "Loss: 0.738815188407898\n",
      "Loss: 0.6313363909721375\n",
      "Loss: 0.6098078489303589\n",
      "Loss: 0.6719618439674377\n",
      "Loss: 0.7109388113021851\n",
      "Loss: 0.690367579460144\n",
      "Loss: 0.7527020573616028\n",
      "Loss: 0.6898216605186462\n",
      "Loss: 0.6330971121788025\n",
      "Loss: 0.6754825115203857\n",
      "Loss: 0.6824804544448853\n",
      "Loss: 0.6660693287849426\n",
      "Loss: 0.5453791618347168\n",
      "Loss: 0.6479628682136536\n",
      "Loss: 0.6385197639465332\n",
      "Loss: 0.6496791839599609\n",
      "Loss: 0.6777202486991882\n",
      "Loss: 0.6131322383880615\n",
      "Loss: 0.6537389755249023\n",
      "Loss: 0.6371394395828247\n",
      "Loss: 0.6063187718391418\n",
      "Loss: 0.6296844482421875\n",
      "Loss: 0.6348767280578613\n",
      "Loss: 0.6426348090171814\n",
      "Loss: 0.5742579698562622\n",
      "Loss: 0.6073853373527527\n",
      "Loss: 0.6300733089447021\n",
      "Loss: 0.614739716053009\n",
      "Loss: 0.5799692869186401\n",
      "Loss: 0.7088268399238586\n",
      "Loss: 0.6677767038345337\n",
      "Loss: 0.6836827993392944\n",
      "Loss: 0.6451436281204224\n",
      "Loss: 0.655965268611908\n",
      "Loss: 0.6701871156692505\n",
      "Loss: 0.6793866753578186\n",
      "Loss: 0.6914612054824829\n",
      "Loss: 0.6582874655723572\n",
      "Loss: 0.6474927663803101\n",
      "Loss: 0.7069857716560364\n",
      "Loss: 0.670703649520874\n",
      "Loss: 0.6610994338989258\n",
      "Loss: 0.7115047574043274\n",
      "Loss: 0.6635754704475403\n",
      "Loss: 0.6736710667610168\n",
      "Loss: 0.7739661335945129\n",
      "Loss: 0.6447607278823853\n",
      "Loss: 0.70757657289505\n",
      "Loss: 0.6792811155319214\n",
      "Loss: 0.6583427786827087\n",
      "Loss: 0.6787999868392944\n",
      "Loss: 0.6633209586143494\n",
      "Loss: 0.6912726759910583\n",
      "Loss: 0.6449770927429199\n",
      "Loss: 0.678604006767273\n",
      "Loss: 0.6751120090484619\n",
      "Loss: 0.6916103959083557\n",
      "Loss: 0.6944701671600342\n",
      "Loss: 0.6831929683685303\n",
      "Loss: 0.6638025641441345\n",
      "Loss: 0.6760715842247009\n",
      "Loss: 0.651188313961029\n",
      "Loss: 0.7392510175704956\n",
      "Loss: 0.6862233877182007\n",
      "Loss: 0.6708412766456604\n",
      "Loss: 0.631600022315979\n",
      "Loss: 0.7014647126197815\n",
      "Loss: 0.6399649977684021\n",
      "Loss: 0.6407646536827087\n",
      "Loss: 0.6184828281402588\n",
      "Loss: 0.6523192524909973\n",
      "Loss: 0.6551299095153809\n",
      "Loss: 0.6350811719894409\n",
      "Loss: 0.6545074582099915\n",
      "Loss: 0.5868586301803589\n",
      "Loss: 0.6195506453514099\n",
      "Loss: 0.6258296370506287\n",
      "Loss: 0.5994947552680969\n",
      "Loss: 0.6522020101547241\n",
      "Loss: 0.6343178749084473\n",
      "Loss: 0.6141678690910339\n",
      "Loss: 0.6659509539604187\n",
      "Loss: 0.6752225160598755\n",
      "Loss: 0.6973298192024231\n",
      "Loss: 0.5982826352119446\n",
      "Loss: 0.6405178308486938\n",
      "Loss: 0.6348716020584106\n",
      "Loss: 0.5888201594352722\n",
      "Loss: 0.6271513104438782\n",
      "Loss: 0.6542699337005615\n",
      "Loss: 0.6070171594619751\n",
      "Loss: 0.5647921562194824\n",
      "Loss: 0.7262259721755981\n",
      "Loss: 0.706233561038971\n",
      "Loss: 0.6575763821601868\n",
      "Loss: 0.5803238749504089\n",
      "Loss: 0.6244872808456421\n",
      "Loss: 0.6630467176437378\n",
      "Loss: 0.6563183069229126\n",
      "Loss: 0.618445873260498\n",
      "Loss: 0.6585938334465027\n",
      "Loss: 0.6491655111312866\n",
      "Loss: 0.5726547241210938\n",
      "Loss: 0.7494654059410095\n",
      "Loss: 0.6353374719619751\n",
      "Loss: 0.7187551856040955\n",
      "Loss: 0.6957351565361023\n",
      "Loss: 0.6614975333213806\n",
      "Loss: 0.7161352634429932\n",
      "Loss: 0.6687243580818176\n",
      "Loss: 0.5525562167167664\n",
      "Loss: 0.6296021938323975\n",
      "Loss: 0.6636592745780945\n",
      "Loss: 0.6417603492736816\n",
      "Loss: 0.6025444269180298\n",
      "Loss: 0.6061565279960632\n",
      "Loss: 0.6939052939414978\n",
      "Loss: 0.6034777760505676\n",
      "Loss: 0.6253932118415833\n",
      "Loss: 0.6649969816207886\n",
      "Loss: 0.657113254070282\n",
      "Loss: 0.6032690405845642\n",
      "Loss: 0.6716729998588562\n",
      "Loss: 0.6757727861404419\n",
      "Loss: 0.6920196413993835\n",
      "Loss: 0.6949852705001831\n",
      "Loss: 0.6759545207023621\n",
      "Loss: 0.6891980767250061\n",
      "Loss: 0.6654937863349915\n",
      "Loss: 0.6676719188690186\n",
      "Loss: 0.6196717023849487\n",
      "Loss: 0.5286742448806763\n",
      "Loss: 0.6165062189102173\n",
      "Loss: 0.6046887636184692\n",
      "Loss: 0.5909279584884644\n",
      "Loss: 0.69353187084198\n",
      "Loss: 0.6871799826622009\n",
      "Loss: 0.6051709055900574\n",
      "Loss: 0.6316354274749756\n",
      "Loss: 0.603472888469696\n",
      "Loss: 0.6670724153518677\n",
      "Loss: 0.6600891351699829\n",
      "Loss: 0.593845784664154\n",
      "Loss: 0.6539605259895325\n",
      "Loss: 0.6648319959640503\n",
      "Loss: 0.6088027358055115\n",
      "Loss: 0.6937742829322815\n",
      "Loss: 0.7052398920059204\n",
      "Loss: 0.6721205115318298\n",
      "Loss: 0.6322962045669556\n",
      "Loss: 0.6394712328910828\n",
      "Loss: 0.6816582083702087\n",
      "Loss: 0.6202195286750793\n",
      "Loss: 0.6208488345146179\n",
      "Loss: 0.6824103593826294\n",
      "Loss: 0.5943310856819153\n",
      "Loss: 0.7046244740486145\n",
      "Loss: 0.6578699350357056\n",
      "Loss: 0.6811773180961609\n",
      "Loss: 0.6382274627685547\n",
      "Loss: 0.6424593329429626\n",
      "Loss: 0.624342679977417\n",
      "Loss: 0.6674007773399353\n",
      "Loss: 0.7047756910324097\n",
      "Loss: 0.6646196842193604\n",
      "Loss: 0.5743750333786011\n",
      "Loss: 0.6622704267501831\n",
      "Loss: 0.6530973315238953\n",
      "Loss: 0.6417754292488098\n",
      "Loss: 0.6859281063079834\n",
      "Loss: 0.5791544318199158\n",
      "Loss: 0.7034547328948975\n",
      "Loss: 0.6516062021255493\n",
      "Loss: 0.6451179385185242\n",
      "Loss: 0.6247590184211731\n",
      "Loss: 0.6302655339241028\n",
      "Loss: 0.675796627998352\n",
      "Loss: 0.6477409601211548\n",
      "Loss: 0.6043156385421753\n",
      "Loss: 0.6274134516716003\n",
      "Loss: 0.6558749675750732\n",
      "Loss: 0.6291407346725464\n",
      "Loss: 0.6230234503746033\n",
      "Loss: 0.5533709526062012\n",
      "Loss: 0.6109246015548706\n",
      "Loss: 0.6030672788619995\n",
      "Loss: 0.6952193379402161\n",
      "Loss: 0.6690338850021362\n",
      "Loss: 0.7624810338020325\n",
      "Loss: 0.6618263125419617\n",
      "Loss: 0.5318961143493652\n",
      "Loss: 0.6112786531448364\n",
      "Loss: 0.6133553981781006\n",
      "Loss: 0.6827433705329895\n",
      "Loss: 0.6246576309204102\n",
      "Loss: 0.6293884515762329\n",
      "Loss: 0.683933675289154\n",
      "Loss: 0.6775364279747009\n",
      "Loss: 0.7154461145401001\n",
      "Loss: 0.6020017862319946\n",
      "Loss: 0.6523423194885254\n",
      "Loss: 0.6796349287033081\n",
      "Loss: 0.6724539399147034\n",
      "Loss: 0.5981277823448181\n",
      "Loss: 0.6719979643821716\n",
      "Loss: 0.6469601392745972\n",
      "Loss: 0.6466545462608337\n",
      "Loss: 0.6042479276657104\n",
      "Loss: 0.6502084732055664\n",
      "Loss: 0.5979448556900024\n",
      "Loss: 0.5853555798530579\n",
      "Loss: 0.6977208256721497\n",
      "Loss: 0.6579794883728027\n",
      "Loss: 0.6278132200241089\n",
      "Loss: 0.5844745635986328\n",
      "Loss: 0.6550924777984619\n",
      "Loss: 0.6787618398666382\n",
      "Loss: 0.7442246079444885\n",
      "Loss: 0.6124987602233887\n",
      "Loss: 0.6725448369979858\n",
      "Loss: 0.6399053931236267\n",
      "Loss: 0.6510996222496033\n",
      "Loss: 0.6551966667175293\n",
      "Loss: 0.688423216342926\n",
      "Loss: 0.6936675906181335\n",
      "Loss: 0.6243448257446289\n",
      "Loss: 0.6430932879447937\n",
      "Loss: 0.6567777395248413\n",
      "Loss: 0.7068842053413391\n",
      "Loss: 0.6336984038352966\n",
      "Loss: 0.6185687184333801\n",
      "Loss: 0.6448938846588135\n",
      "Loss: 0.6084439754486084\n",
      "Loss: 0.6319760084152222\n",
      "Loss: 0.6883620023727417\n",
      "Loss: 0.603345513343811\n",
      "Loss: 0.6286786198616028\n",
      "Loss: 0.7048016786575317\n",
      "Loss: 0.7368097901344299\n",
      "Loss: 0.6481217741966248\n",
      "Loss: 0.568172037601471\n",
      "Loss: 0.6289644241333008\n",
      "Loss: 0.6361461877822876\n",
      "Loss: 0.6543196439743042\n",
      "Loss: 0.5783103704452515\n",
      "Loss: 0.7119061350822449\n",
      "Loss: 0.6924057602882385\n",
      "Loss: 0.6380863189697266\n",
      "Loss: 0.6869558691978455\n",
      "Loss: 0.7502285242080688\n",
      "Loss: 0.6305322647094727\n",
      "Loss: 0.6479291319847107\n",
      "Loss: 0.6878779530525208\n",
      "Loss: 0.7521613836288452\n",
      "Loss: 0.5970332622528076\n",
      "Loss: 0.6530948877334595\n",
      "Loss: 0.7145448327064514\n",
      "Loss: 0.7091402411460876\n",
      "Loss: 0.6352365016937256\n",
      "Loss: 0.6327921152114868\n",
      "Loss: 0.6402992606163025\n",
      "Loss: 0.7016900181770325\n",
      "Loss: 0.6137612462043762\n",
      "Loss: 0.7063753008842468\n",
      "Loss: 0.6735808849334717\n",
      "Loss: 0.5674693584442139\n",
      "Loss: 0.6029313802719116\n",
      "Loss: 0.6422290802001953\n",
      "Loss: 0.6634330749511719\n",
      "Loss: 0.6977965831756592\n",
      "Loss: 0.6481842398643494\n",
      "Loss: 0.6641173362731934\n",
      "Loss: 0.5917519330978394\n",
      "Loss: 0.6549246907234192\n",
      "Loss: 0.6704615950584412\n",
      "Loss: 0.6562896966934204\n",
      "Loss: 0.6294958591461182\n",
      "Loss: 0.7752256989479065\n",
      "Loss: 0.5933993458747864\n",
      "Loss: 0.712913453578949\n",
      "Loss: 0.675636887550354\n",
      "Loss: 0.7092258334159851\n",
      "Loss: 0.6085695624351501\n",
      "Loss: 0.7349037528038025\n",
      "Loss: 0.5600454211235046\n",
      "Loss: 0.6214152574539185\n",
      "Loss: 0.6755247712135315\n",
      "Loss: 0.8210171461105347\n",
      "Loss: 0.6437244415283203\n",
      "Loss: 0.6540703177452087\n",
      "Loss: 0.6462739109992981\n",
      "Loss: 0.6566832661628723\n",
      "Loss: 0.6932472586631775\n",
      "Loss: 0.6094722151756287\n",
      "Loss: 0.667245626449585\n",
      "Loss: 0.6656927466392517\n",
      "Loss: 0.614949643611908\n",
      "Loss: 0.6438681483268738\n",
      "Loss: 0.5799407958984375\n",
      "Loss: 0.5875537395477295\n",
      "Loss: 0.6502630114555359\n",
      "Loss: 0.6444312930107117\n",
      "Loss: 0.6031531691551208\n",
      "Loss: 0.7086220383644104\n",
      "Loss: 0.6525669097900391\n",
      "Loss: 0.700645387172699\n",
      "Loss: 0.7398788332939148\n",
      "Loss: 0.6236581206321716\n",
      "Loss: 0.6647855043411255\n",
      "Loss: 0.6404116153717041\n",
      "Loss: 0.6345773935317993\n",
      "Loss: 0.6974314451217651\n",
      "Loss: 0.6409263014793396\n",
      "Loss: 0.6676729321479797\n",
      "Loss: 0.6523094177246094\n",
      "Loss: 0.693566083908081\n",
      "Loss: 0.6506695747375488\n",
      "Loss: 0.6667697429656982\n",
      "Loss: 0.700768768787384\n",
      "Loss: 0.6874029040336609\n",
      "Loss: 0.7137068510055542\n",
      "Loss: 0.6045425534248352\n",
      "Loss: 0.6473318934440613\n",
      "Loss: 0.6412885189056396\n",
      "Loss: 0.5518816113471985\n",
      "Loss: 0.6465671062469482\n",
      "Loss: 0.6929500102996826\n",
      "Loss: 0.6200926899909973\n",
      "Loss: 0.6545168161392212\n",
      "Loss: 0.605701208114624\n",
      "Loss: 0.6545130610466003\n",
      "Loss: 0.6748983860015869\n",
      "Loss: 0.6297023892402649\n",
      "Loss: 0.6836512088775635\n",
      "Loss: 0.6546031832695007\n",
      "Loss: 0.6488134264945984\n",
      "Loss: 0.6886425614356995\n",
      "Loss: 0.6189281344413757\n",
      "Loss: 0.682427704334259\n",
      "Loss: 0.562372088432312\n",
      "Loss: 0.589293897151947\n",
      "Loss: 0.6321084499359131\n",
      "Loss: 0.6907417178153992\n",
      "Loss: 0.6570041179656982\n",
      "Loss: 0.6632040739059448\n",
      "Loss: 0.5895617604255676\n",
      "Loss: 0.5936186909675598\n",
      "Loss: 0.6371282935142517\n",
      "Loss: 0.5942282676696777\n",
      "Loss: 0.619415283203125\n",
      "Loss: 0.5529941916465759\n",
      "Loss: 0.6801573038101196\n",
      "Loss: 0.6872369647026062\n",
      "Loss: 0.8003599047660828\n",
      "Loss: 0.714669406414032\n",
      "Loss: 0.5886942148208618\n",
      "Loss: 0.6586683988571167\n",
      "Loss: 0.6791967749595642\n",
      "Loss: 0.7280145287513733\n",
      "Loss: 0.5863422751426697\n",
      "Loss: 0.6390530467033386\n",
      "Loss: 0.6974367499351501\n",
      "Loss: 0.7828605771064758\n",
      "Loss: 0.5800126194953918\n",
      "Loss: 0.5691192746162415\n",
      "Loss: 0.6582036018371582\n",
      "Loss: 0.6421703696250916\n",
      "Loss: 0.7288904786109924\n",
      "Loss: 0.6124343872070312\n",
      "Loss: 0.6398880481719971\n",
      "Loss: 0.6697817444801331\n",
      "Loss: 0.6952657103538513\n",
      "Loss: 0.6508954763412476\n",
      "Loss: 0.6466609239578247\n",
      "Loss: 0.6012895107269287\n",
      "Loss: 0.633574903011322\n",
      "Loss: 0.6482923626899719\n",
      "Loss: 0.6420835852622986\n",
      "Loss: 0.5849176645278931\n",
      "Loss: 0.6156460642814636\n",
      "Loss: 0.547467827796936\n",
      "Loss: 0.5721526145935059\n",
      "Loss: 0.6120645999908447\n",
      "Loss: 0.6885008215904236\n",
      "Loss: 0.67575603723526\n",
      "Loss: 0.6615264415740967\n",
      "Loss: 0.5790328979492188\n",
      "Loss: 0.6671238541603088\n",
      "Loss: 0.6813787817955017\n",
      "Loss: 0.6492923498153687\n",
      "Loss: 0.5367692112922668\n",
      "Loss: 0.6200355291366577\n",
      "Loss: 0.5881698131561279\n",
      "Loss: 0.5959519743919373\n",
      "Loss: 0.6131346225738525\n",
      "Loss: 0.6228507161140442\n",
      "Loss: 0.6491638422012329\n",
      "Loss: 0.6845691204071045\n",
      "Loss: 0.6721530556678772\n",
      "Loss: 0.6763651967048645\n",
      "Loss: 0.6262251138687134\n",
      "Loss: 0.649978518486023\n",
      "Loss: 0.6605777740478516\n",
      "Loss: 0.6335543990135193\n",
      "Loss: 0.6935213804244995\n",
      "Loss: 0.6392183303833008\n",
      "Loss: 0.6973646283149719\n",
      "Loss: 0.6763731241226196\n",
      "Loss: 0.6069964170455933\n",
      "Loss: 0.6110909581184387\n",
      "Loss: 0.6762879490852356\n",
      "Loss: 0.6408117413520813\n",
      "Loss: 0.6025724411010742\n",
      "Loss: 0.5899341106414795\n",
      "Loss: 0.6430532336235046\n",
      "Loss: 0.5940142869949341\n",
      "Loss: 0.654708743095398\n",
      "Loss: 0.6223673224449158\n",
      "Loss: 0.5718303918838501\n",
      "Loss: 0.5674724578857422\n",
      "Loss: 0.7415274977684021\n",
      "Loss: 0.6476772427558899\n",
      "Loss: 0.6711717844009399\n",
      "Loss: 0.6468890309333801\n",
      "Loss: 0.6814823746681213\n",
      "Loss: 0.6786949038505554\n",
      "Loss: 0.6309434771537781\n",
      "Loss: 0.6112384796142578\n",
      "Loss: 0.7100289463996887\n",
      "Loss: 0.5719270706176758\n",
      "Loss: 0.7144734859466553\n",
      "Loss: 0.6022228002548218\n",
      "Loss: 0.5964667201042175\n",
      "Loss: 0.5916671752929688\n",
      "Loss: 0.6189844608306885\n",
      "Loss: 0.710162341594696\n",
      "Loss: 0.6231241226196289\n",
      "Loss: 0.7147592902183533\n",
      "Loss: 0.7394729852676392\n",
      "Loss: 0.5990907549858093\n",
      "Loss: 0.6008219122886658\n",
      "Loss: 0.6479815244674683\n",
      "Loss: 0.6800410151481628\n",
      "Loss: 0.5921738743782043\n",
      "Loss: 0.6350736021995544\n",
      "Loss: 0.6690323948860168\n",
      "Loss: 0.5748236775398254\n",
      "Loss: 0.6571158766746521\n",
      "Loss: 0.6637115478515625\n",
      "Loss: 0.681925892829895\n",
      "Loss: 0.7171440720558167\n",
      "Loss: 0.6391556859016418\n",
      "Loss: 0.7251438498497009\n",
      "Loss: 0.6821986436843872\n",
      "Loss: 0.6504430770874023\n",
      "Loss: 0.6617617011070251\n",
      "Loss: 0.5836912989616394\n",
      "Loss: 0.6796530485153198\n",
      "Loss: 0.6933107972145081\n",
      "Loss: 0.5941004157066345\n",
      "Loss: 0.5667409300804138\n",
      "Loss: 0.6188855171203613\n",
      "Loss: 0.58451247215271\n",
      "Loss: 0.599160373210907\n",
      "Loss: 0.6120597720146179\n",
      "Loss: 0.6036632061004639\n",
      "Loss: 0.6266103982925415\n",
      "Loss: 0.6816799640655518\n",
      "Loss: 0.6395999789237976\n",
      "Loss: 0.6763184070587158\n",
      "Loss: 0.6641072034835815\n",
      "Loss: 0.6019404530525208\n",
      "Loss: 0.6952255964279175\n",
      "Loss: 0.6208277940750122\n",
      "Loss: 0.6262646913528442\n",
      "Loss: 0.676853358745575\n",
      "Loss: 0.5761111378669739\n",
      "Loss: 0.6812781095504761\n",
      "Loss: 0.6769986748695374\n",
      "Loss: 0.68143630027771\n",
      "Loss: 0.677391767501831\n",
      "Loss: 0.5873407125473022\n",
      "Loss: 0.6438210606575012\n",
      "Loss: 0.6823753714561462\n",
      "Loss: 0.6316927671432495\n",
      "Loss: 0.6017690896987915\n",
      "Loss: 0.6882088780403137\n",
      "Loss: 0.6224256753921509\n",
      "Loss: 0.6579701900482178\n",
      "Loss: 0.6991321444511414\n",
      "Loss: 0.6768859624862671\n",
      "Loss: 0.6042777895927429\n",
      "Loss: 0.58137047290802\n",
      "Loss: 0.6774812936782837\n",
      "Loss: 0.6099902987480164\n",
      "Loss: 0.7213970422744751\n",
      "Loss: 0.6136094927787781\n",
      "Loss: 0.6868346929550171\n",
      "Loss: 0.5846872329711914\n",
      "Loss: 0.6434237957000732\n",
      "Loss: 0.6698215007781982\n",
      "Loss: 0.5423526167869568\n",
      "Loss: 0.6566969752311707\n",
      "Loss: 0.6744924187660217\n",
      "Loss: 0.6660056114196777\n",
      "Loss: 0.658923864364624\n",
      "Loss: 0.6293811202049255\n",
      "Loss: 0.637298583984375\n",
      "Loss: 0.6229453086853027\n",
      "Loss: 0.6145700812339783\n",
      "Loss: 0.7191280722618103\n",
      "Loss: 0.6447656154632568\n",
      "Loss: 0.5760582089424133\n",
      "Loss: 0.6107280254364014\n",
      "Loss: 0.6012576222419739\n",
      "Loss: 0.657590389251709\n",
      "Loss: 0.6281518936157227\n",
      "Loss: 0.6490830183029175\n",
      "Loss: 0.6885931491851807\n",
      "Loss: 0.6495270133018494\n",
      "Loss: 0.5950319170951843\n",
      "Loss: 0.6620336771011353\n",
      "Loss: 0.5873382091522217\n",
      "Loss: 0.6000247001647949\n",
      "Loss: 0.6538407802581787\n",
      "Loss: 0.674260675907135\n",
      "Loss: 0.7161516547203064\n",
      "Loss: 0.7242847681045532\n",
      "Loss: 0.6388397216796875\n",
      "Loss: 0.6970674991607666\n",
      "Loss: 0.5713981986045837\n",
      "Loss: 0.6197730898857117\n",
      "Loss: 0.6703136563301086\n",
      "Loss: 0.7038061022758484\n",
      "Loss: 0.6070588231086731\n",
      "Loss: 0.5925324559211731\n",
      "Loss: 0.7035308480262756\n",
      "Loss: 0.630820095539093\n",
      "Loss: 0.5889137983322144\n",
      "Loss: 0.622670590877533\n",
      "Loss: 0.665282666683197\n",
      "Loss: 0.7010500431060791\n",
      "Loss: 0.6482871174812317\n",
      "Loss: 0.6319387555122375\n",
      "Loss: 0.6449092626571655\n",
      "Loss: 0.5667991638183594\n",
      "Loss: 0.6230108141899109\n",
      "Loss: 0.6154203414916992\n",
      "Loss: 0.6652862429618835\n",
      "Loss: 0.6674870252609253\n",
      "Loss: 0.6037548780441284\n",
      "Loss: 0.6863783597946167\n",
      "Loss: 0.624121367931366\n",
      "Loss: 0.6640251874923706\n",
      "Loss: 0.676660418510437\n",
      "Loss: 0.6213745474815369\n",
      "Loss: 0.6271306872367859\n",
      "Loss: 0.7017382979393005\n",
      "Loss: 0.612679123878479\n",
      "Loss: 0.5359609723091125\n",
      "Loss: 0.5831195712089539\n",
      "Loss: 0.7212342023849487\n",
      "Loss: 0.5961458086967468\n",
      "Loss: 0.6683875322341919\n",
      "Loss: 0.5716625452041626\n",
      "Loss: 0.6917542219161987\n",
      "Loss: 0.5729175806045532\n",
      "Loss: 0.5911453366279602\n",
      "Loss: 0.5782753825187683\n",
      "Loss: 0.659616231918335\n",
      "Loss: 0.6567031741142273\n",
      "Loss: 0.5967526435852051\n",
      "Loss: 0.638472855091095\n",
      "Loss: 0.6736570596694946\n",
      "Loss: 0.6553268432617188\n",
      "Loss: 0.5789365768432617\n",
      "Loss: 0.6358392238616943\n",
      "Loss: 0.6256546378135681\n",
      "Loss: 0.6444344520568848\n",
      "Loss: 0.6642085909843445\n",
      "Loss: 0.6745966672897339\n",
      "Loss: 0.6486379504203796\n",
      "Loss: 0.7039029598236084\n",
      "Loss: 0.7303631901741028\n",
      "Loss: 0.6435705423355103\n",
      "Loss: 0.6786248683929443\n",
      "Loss: 0.6677349805831909\n",
      "Loss: 0.6313903331756592\n",
      "Loss: 0.6026251912117004\n",
      "Loss: 0.7055490612983704\n",
      "Loss: 0.559541642665863\n",
      "Loss: 0.5810043811798096\n",
      "Loss: 0.6902884840965271\n",
      "Loss: 0.7080495357513428\n",
      "Loss: 0.6770616173744202\n",
      "Loss: 0.6203864812850952\n",
      "Loss: 0.6488868594169617\n",
      "Loss: 0.6574666500091553\n",
      "Loss: 0.6088379621505737\n",
      "Loss: 0.627039909362793\n",
      "Loss: 0.5781846046447754\n",
      "Loss: 0.624360978603363\n",
      "Loss: 0.6912583708763123\n",
      "Loss: 0.614475429058075\n",
      "Loss: 0.5799986124038696\n",
      "Loss: 0.7207882404327393\n",
      "Loss: 0.6787624955177307\n",
      "Loss: 0.7146192789077759\n",
      "Loss: 0.6178765296936035\n",
      "Loss: 0.6117615699768066\n",
      "Loss: 0.5636128783226013\n",
      "Loss: 0.6077878475189209\n",
      "Loss: 0.6002360582351685\n",
      "Loss: 0.6855239272117615\n",
      "Loss: 0.5744999647140503\n",
      "Loss: 0.6031472682952881\n",
      "Loss: 0.6331480741500854\n",
      "Loss: 0.5941195487976074\n",
      "Loss: 0.6767928004264832\n",
      "Loss: 0.6520647406578064\n",
      "Loss: 0.6802060008049011\n",
      "Loss: 0.663343071937561\n",
      "Loss: 0.6786349415779114\n",
      "Loss: 0.5985830426216125\n",
      "Loss: 0.625872790813446\n",
      "Loss: 0.6125516295433044\n",
      "Loss: 0.5998584628105164\n",
      "Loss: 0.6473914384841919\n",
      "Loss: 0.6324028372764587\n",
      "Loss: 0.6805883049964905\n",
      "Loss: 0.7428285479545593\n",
      "Loss: 0.6168662905693054\n",
      "Loss: 0.7272024750709534\n",
      "Loss: 0.6722404360771179\n",
      "Loss: 0.6645596027374268\n",
      "Loss: 0.6538909077644348\n",
      "Loss: 0.6765231490135193\n",
      "Loss: 0.6958284974098206\n",
      "Loss: 0.6343179941177368\n",
      "Loss: 0.6834271550178528\n",
      "Loss: 0.6037324070930481\n",
      "Loss: 0.6185629963874817\n",
      "Loss: 0.6389302015304565\n",
      "Loss: 0.6355122327804565\n",
      "Loss: 0.6622159481048584\n",
      "Loss: 0.7084543704986572\n",
      "Loss: 0.6127769947052002\n",
      "Loss: 0.6452243328094482\n",
      "Loss: 0.6656663417816162\n",
      "Loss: 0.674177348613739\n",
      "Loss: 0.5845638513565063\n",
      "Loss: 0.6119998097419739\n",
      "Loss: 0.59185391664505\n",
      "Loss: 0.6167976260185242\n",
      "Loss: 0.6880261898040771\n",
      "Loss: 0.6895973086357117\n",
      "Loss: 0.5614653825759888\n",
      "Loss: 0.6390535235404968\n",
      "Loss: 0.650576114654541\n",
      "Loss: 0.6658791303634644\n",
      "Loss: 0.5870122909545898\n",
      "Loss: 0.5718163251876831\n",
      "Loss: 0.5955567359924316\n",
      "Loss: 0.6525462865829468\n",
      "Loss: 0.7168583273887634\n",
      "Loss: 0.6161214709281921\n",
      "Loss: 0.646520733833313\n",
      "Loss: 0.6574665307998657\n",
      "Loss: 0.661660373210907\n",
      "Loss: 0.6899430155754089\n",
      "Loss: 0.6884567141532898\n",
      "Loss: 0.6880133152008057\n",
      "Loss: 0.626703679561615\n",
      "Loss: 0.6426677107810974\n",
      "Loss: 0.6025292873382568\n",
      "Loss: 0.7405907511711121\n",
      "Loss: 0.5816441774368286\n",
      "Loss: 0.6640080213546753\n",
      "Loss: 0.614567220211029\n",
      "Loss: 0.6105431318283081\n",
      "Loss: 0.5548607707023621\n",
      "Loss: 0.6964384913444519\n",
      "Loss: 0.6141630411148071\n",
      "Loss: 0.6366685032844543\n",
      "Loss: 0.6264013648033142\n",
      "Loss: 0.7062941789627075\n",
      "Loss: 0.6489812731742859\n",
      "Loss: 0.6088256239891052\n",
      "Loss: 0.7173901796340942\n",
      "Loss: 0.6939393877983093\n",
      "Loss: 0.6810066103935242\n",
      "Loss: 0.6385673880577087\n",
      "Loss: 0.6141393184661865\n",
      "Loss: 0.6585854291915894\n",
      "Loss: 0.650425910949707\n",
      "Loss: 0.6503498554229736\n",
      "Loss: 0.6113699674606323\n",
      "Loss: 0.6308461427688599\n",
      "Loss: 0.6587493419647217\n",
      "Loss: 0.6229679584503174\n",
      "Loss: 0.6136029362678528\n",
      "Loss: 0.7330230474472046\n",
      "Loss: 0.624545693397522\n",
      "Loss: 0.6753107309341431\n",
      "Loss: 0.7496196627616882\n",
      "Loss: 0.7255715131759644\n",
      "Loss: 0.6422369480133057\n",
      "Loss: 0.6269059181213379\n",
      "Loss: 0.7437321543693542\n",
      "Loss: 0.7089143991470337\n",
      "Loss: 0.6588861346244812\n",
      "Loss: 0.6114610433578491\n",
      "Loss: 0.5627832412719727\n",
      "Loss: 0.6480203866958618\n",
      "Loss: 0.6123853921890259\n",
      "Loss: 0.6104037761688232\n",
      "Loss: 0.6074435710906982\n",
      "Loss: 0.6302065253257751\n",
      "Loss: 0.6542233228683472\n",
      "Loss: 0.7192733883857727\n",
      "Loss: 0.7061301469802856\n",
      "Loss: 0.6520743370056152\n",
      "Loss: 0.6000725626945496\n",
      "Loss: 0.7022431492805481\n",
      "Loss: 0.6838609576225281\n",
      "Loss: 0.6489970684051514\n",
      "Loss: 0.5643165111541748\n",
      "Loss: 0.6645196676254272\n",
      "Loss: 0.6993778944015503\n",
      "Loss: 0.6371753215789795\n",
      "Loss: 0.6477267742156982\n",
      "Loss: 0.6571215391159058\n",
      "Loss: 0.6587667465209961\n",
      "Loss: 0.6356592178344727\n",
      "Loss: 0.6721211075782776\n",
      "Loss: 0.6253994703292847\n",
      "Loss: 0.6968544125556946\n",
      "Loss: 0.7419546246528625\n",
      "Loss: 0.6334083080291748\n",
      "Loss: 0.5925363898277283\n",
      "Loss: 0.6990851759910583\n",
      "Loss: 0.6244801878929138\n",
      "Loss: 0.7343431115150452\n",
      "Loss: 0.6884884238243103\n",
      "Loss: 0.6985951066017151\n",
      "Loss: 0.5818489789962769\n",
      "Loss: 0.614263653755188\n",
      "Loss: 0.6426992416381836\n",
      "Loss: 0.6532537341117859\n",
      "Loss: 0.71552973985672\n",
      "Loss: 0.5920359492301941\n",
      "Loss: 0.6999382376670837\n",
      "Loss: 0.6295440196990967\n",
      "Loss: 0.7456886172294617\n",
      "Loss: 0.6438833475112915\n",
      "Loss: 0.7226302623748779\n",
      "Loss: 0.631417453289032\n",
      "Loss: 0.6961377263069153\n",
      "Loss: 0.610516369342804\n",
      "Loss: 0.6764938831329346\n",
      "Loss: 0.6162570714950562\n",
      "Loss: 0.5644068717956543\n",
      "Loss: 0.638079047203064\n",
      "Loss: 0.609254777431488\n",
      "Loss: 0.6560841798782349\n",
      "Loss: 0.5804256796836853\n",
      "Loss: 0.6028551459312439\n",
      "Loss: 0.548026442527771\n",
      "Loss: 0.6030980944633484\n",
      "Loss: 0.6809712648391724\n",
      "Loss: 0.6492266058921814\n",
      "Loss: 0.6164478063583374\n",
      "Loss: 0.5985429286956787\n",
      "Loss: 0.7024169564247131\n",
      "Loss: 0.6029718518257141\n",
      "Loss: 0.6245018243789673\n",
      "Loss: 0.6156480312347412\n",
      "Loss: 0.6054381132125854\n",
      "Loss: 0.6080068945884705\n",
      "Loss: 0.6906943917274475\n",
      "Loss: 0.5753673315048218\n",
      "Loss: 0.5766454935073853\n",
      "Loss: 0.6167240142822266\n",
      "Loss: 0.6935317516326904\n",
      "Loss: 0.668679416179657\n",
      "Loss: 0.6954219341278076\n",
      "Loss: 0.6872168183326721\n",
      "Loss: 0.6669170260429382\n",
      "Loss: 0.7161215543746948\n",
      "Loss: 0.6465158462524414\n",
      "Loss: 0.5787094831466675\n",
      "Loss: 0.6495408415794373\n",
      "Loss: 0.6191470623016357\n",
      "Loss: 0.6201876401901245\n",
      "Loss: 0.6461161971092224\n",
      "Loss: 0.6003235578536987\n",
      "Loss: 0.5658753514289856\n",
      "Loss: 0.6443303227424622\n",
      "Loss: 0.6852527260780334\n",
      "Loss: 0.6706136465072632\n",
      "Loss: 0.66716468334198\n",
      "Loss: 0.6633375883102417\n",
      "Loss: 0.5822688937187195\n",
      "Loss: 0.6367561221122742\n",
      "Loss: 0.7061320543289185\n",
      "Loss: 0.6040984988212585\n",
      "Loss: 0.6660251617431641\n",
      "Loss: 0.6073316931724548\n",
      "Loss: 0.6057514548301697\n",
      "Loss: 0.6464204788208008\n",
      "Loss: 0.6443872451782227\n",
      "Loss: 0.6821548342704773\n",
      "Loss: 0.6655371785163879\n",
      "Loss: 0.6831019520759583\n",
      "Loss: 0.6258045434951782\n",
      "Loss: 0.6541919708251953\n",
      "Loss: 0.6357409358024597\n",
      "Loss: 0.7207802534103394\n",
      "Loss: 0.6837203502655029\n",
      "Loss: 0.7472688555717468\n",
      "Loss: 0.664594829082489\n",
      "Loss: 0.6686327457427979\n",
      "Loss: 0.6254479289054871\n",
      "Loss: 0.6258573532104492\n",
      "Loss: 0.6477676630020142\n",
      "Loss: 0.6200627684593201\n",
      "Loss: 0.6334718465805054\n",
      "Loss: 0.6817447543144226\n",
      "Loss: 0.7130929231643677\n",
      "Loss: 0.7391544580459595\n",
      "Loss: 0.7321574687957764\n",
      "Loss: 0.6439202427864075\n",
      "Loss: 0.573689341545105\n",
      "Loss: 0.6443181037902832\n",
      "Loss: 0.6088403463363647\n",
      "Loss: 0.5995513796806335\n",
      "Loss: 0.6737571358680725\n",
      "Loss: 0.6549552083015442\n",
      "Loss: 0.6101927161216736\n",
      "Loss: 0.6116034984588623\n",
      "Loss: 0.5600039958953857\n",
      "Loss: 0.6563030481338501\n",
      "Loss: 0.6778684258460999\n",
      "Loss: 0.6477312445640564\n",
      "Loss: 0.6078519821166992\n",
      "Loss: 0.670397937297821\n",
      "Loss: 0.6186500787734985\n",
      "Loss: 0.6861532926559448\n",
      "Loss: 0.5461445450782776\n",
      "Loss: 0.664401650428772\n",
      "Loss: 0.7536645531654358\n",
      "Loss: 0.6353725790977478\n",
      "Loss: 0.5897212028503418\n",
      "Loss: 0.6774317622184753\n",
      "Loss: 0.5980032682418823\n",
      "Loss: 0.6071996688842773\n",
      "Loss: 0.6236135363578796\n",
      "Loss: 0.6638551950454712\n",
      "Loss: 0.7170082330703735\n",
      "Loss: 0.6715958118438721\n",
      "Loss: 0.6760829091072083\n",
      "Loss: 0.6745833158493042\n",
      "Loss: 0.6639644503593445\n",
      "Loss: 0.5824850797653198\n",
      "Loss: 0.6286472082138062\n",
      "Loss: 0.7109275460243225\n",
      "Loss: 0.5889326333999634\n",
      "Loss: 0.6252913475036621\n",
      "Loss: 0.7106470465660095\n",
      "Loss: 0.6973730325698853\n",
      "Loss: 0.7123287320137024\n",
      "Loss: 0.6319559812545776\n",
      "Loss: 0.6799346208572388\n",
      "Loss: 0.6703269481658936\n",
      "Loss: 0.6650413870811462\n",
      "Loss: 0.6861871480941772\n",
      "Loss: 0.6700226068496704\n",
      "Loss: 0.6171863079071045\n",
      "Loss: 0.6847050786018372\n",
      "Loss: 0.6380455493927002\n",
      "Loss: 0.5989339351654053\n",
      "Loss: 0.6525123119354248\n",
      "Loss: 0.6128877997398376\n",
      "Loss: 0.5629563331604004\n",
      "Loss: 0.650184154510498\n",
      "Loss: 0.6362199783325195\n",
      "Loss: 0.6588848233222961\n",
      "Loss: 0.662281334400177\n",
      "Loss: 0.6330148577690125\n",
      "Loss: 0.6165012121200562\n",
      "Loss: 0.6458403468132019\n",
      "Loss: 0.6189943552017212\n",
      "Loss: 0.5838382244110107\n",
      "Loss: 0.6395325064659119\n",
      "Loss: 0.6770687699317932\n",
      "Loss: 0.6167658567428589\n",
      "Loss: 0.6136147975921631\n",
      "Loss: 0.6275060176849365\n",
      "Loss: 0.6398071646690369\n",
      "Loss: 0.7563194632530212\n",
      "Loss: 0.7502101063728333\n",
      "Loss: 0.6554120779037476\n",
      "Loss: 0.609830379486084\n",
      "Loss: 0.7113679051399231\n",
      "Loss: 0.6705920100212097\n",
      "Loss: 0.6839572191238403\n",
      "Loss: 0.6034611463546753\n",
      "Loss: 0.6017230153083801\n",
      "Loss: 0.7000142335891724\n",
      "Loss: 0.686931848526001\n",
      "Loss: 0.6989367604255676\n",
      "Loss: 0.5351141095161438\n",
      "Loss: 0.6246396899223328\n",
      "Loss: 0.6753748655319214\n",
      "Loss: 0.5689548850059509\n",
      "Loss: 0.6743819713592529\n",
      "Loss: 0.5839229822158813\n",
      "Loss: 0.5791787505149841\n",
      "Loss: 0.717975378036499\n",
      "Loss: 0.6531695127487183\n",
      "Loss: 0.6530579328536987\n",
      "Loss: 0.6344527006149292\n",
      "Loss: 0.648473858833313\n",
      "Loss: 0.6494835615158081\n",
      "Loss: 0.7266682386398315\n",
      "Loss: 0.6811856031417847\n",
      "Loss: 0.6296584606170654\n",
      "Loss: 0.6509459614753723\n",
      "Loss: 0.6644317507743835\n",
      "Loss: 0.7217760682106018\n",
      "Loss: 0.5904786586761475\n",
      "Loss: 0.6059645414352417\n",
      "Loss: 0.6494373083114624\n",
      "Loss: 0.6258643269538879\n",
      "Loss: 0.6136287450790405\n",
      "Loss: 0.6954158544540405\n",
      "Loss: 0.6725674271583557\n",
      "Loss: 0.5830537676811218\n",
      "Loss: 0.6265362501144409\n",
      "Loss: 0.6633599400520325\n",
      "Loss: 0.6793769598007202\n",
      "Loss: 0.6464487314224243\n",
      "Loss: 0.53546142578125\n",
      "Loss: 0.6470497250556946\n",
      "Loss: 0.6640634536743164\n",
      "Loss: 0.6297053098678589\n",
      "Loss: 0.6530517339706421\n",
      "Loss: 0.6612250208854675\n",
      "Loss: 0.6749271154403687\n",
      "Loss: 0.6664375066757202\n",
      "Loss: 0.6069332957267761\n",
      "Loss: 0.6792841553688049\n",
      "Loss: 0.6398747563362122\n",
      "Loss: 0.5814706087112427\n",
      "Loss: 0.5736643075942993\n",
      "Loss: 0.650765061378479\n",
      "Loss: 0.5719683766365051\n",
      "Loss: 0.6259000301361084\n",
      "Loss: 0.6577159762382507\n",
      "Loss: 0.6097225546836853\n",
      "Loss: 0.6992352604866028\n",
      "Loss: 0.6655227541923523\n",
      "Loss: 0.7723951935768127\n",
      "Loss: 0.5714125633239746\n",
      "Loss: 0.587410569190979\n",
      "Loss: 0.5808202624320984\n",
      "Loss: 0.6481666564941406\n",
      "Loss: 0.590670108795166\n",
      "Loss: 0.6692022681236267\n",
      "Loss: 0.5583574175834656\n",
      "Loss: 0.6776733994483948\n",
      "Loss: 0.5355536937713623\n",
      "Loss: 0.6933363080024719\n",
      "Loss: 0.655873715877533\n",
      "Loss: 0.5794132351875305\n",
      "Loss: 0.6614106297492981\n",
      "Loss: 0.6063247919082642\n",
      "Loss: 0.5411850214004517\n",
      "Loss: 0.7037874460220337\n",
      "Loss: 0.675835371017456\n",
      "Loss: 0.6192997097969055\n",
      "Loss: 0.700603187084198\n",
      "Loss: 0.6935247778892517\n",
      "Loss: 0.6756927371025085\n",
      "Loss: 0.6653936505317688\n",
      "Loss: 0.5825511813163757\n",
      "Loss: 0.5407373309135437\n",
      "Loss: 0.5428591966629028\n",
      "Loss: 0.5840399861335754\n",
      "Loss: 0.7358652353286743\n",
      "Loss: 0.6025223731994629\n",
      "Loss: 0.6608776450157166\n",
      "Loss: 0.6074175238609314\n",
      "Loss: 0.6347763538360596\n",
      "Loss: 0.6646005511283875\n",
      "Loss: 0.6970122456550598\n",
      "Loss: 0.6678209900856018\n",
      "Loss: 0.6480718851089478\n",
      "Loss: 0.6606802344322205\n",
      "Loss: 0.6887808442115784\n",
      "Loss: 0.6284892559051514\n",
      "Loss: 0.6990807056427002\n",
      "Loss: 0.6967677474021912\n",
      "Loss: 0.7009822726249695\n",
      "Loss: 0.5910579562187195\n",
      "Loss: 0.5405848026275635\n",
      "Loss: 0.6965802311897278\n",
      "Loss: 0.6298641562461853\n",
      "Loss: 0.6470233798027039\n",
      "Loss: 0.6430258750915527\n",
      "Loss: 0.6067758798599243\n",
      "Loss: 0.5609812140464783\n",
      "Loss: 0.7198259830474854\n",
      "Loss: 0.612617015838623\n",
      "Loss: 0.5675134062767029\n",
      "Loss: 0.6240949630737305\n",
      "Loss: 0.6308879852294922\n",
      "Loss: 0.6354740262031555\n",
      "Loss: 0.6464166641235352\n",
      "Loss: 0.6461726427078247\n",
      "Loss: 0.6059252023696899\n",
      "Loss: 0.703597366809845\n",
      "Loss: 0.6947173476219177\n",
      "Loss: 0.6164094805717468\n",
      "Loss: 0.6148783564567566\n",
      "Loss: 0.6628867983818054\n",
      "Loss: 0.6414129137992859\n",
      "Loss: 0.6445692777633667\n",
      "Loss: 0.7219617366790771\n",
      "Loss: 0.6853635311126709\n",
      "Loss: 0.6358879804611206\n",
      "Loss: 0.5922182202339172\n",
      "Loss: 0.6485932469367981\n",
      "Loss: 0.6341339349746704\n",
      "Loss: 0.6921196579933167\n",
      "Loss: 0.6409586668014526\n",
      "Loss: 0.6394582986831665\n",
      "Loss: 0.6300038695335388\n",
      "Loss: 0.6295212507247925\n",
      "Loss: 0.7077263593673706\n",
      "Loss: 0.6555887460708618\n",
      "Loss: 0.6825258731842041\n",
      "Loss: 0.606231689453125\n",
      "Loss: 0.6854458451271057\n",
      "Loss: 0.6218859553337097\n",
      "Loss: 0.598842442035675\n",
      "Loss: 0.6283573508262634\n",
      "Loss: 0.7478838562965393\n",
      "Loss: 0.6454724669456482\n",
      "Loss: 0.6393130421638489\n",
      "Loss: 0.6248077750205994\n",
      "Loss: 0.6098165512084961\n",
      "Loss: 0.5608954429626465\n",
      "Loss: 0.615038275718689\n",
      "Loss: 0.5830897092819214\n",
      "Loss: 0.6617316007614136\n",
      "Loss: 0.6222769021987915\n",
      "Loss: 0.5849239230155945\n",
      "Loss: 0.6439474821090698\n",
      "Loss: 0.6843438744544983\n",
      "Loss: 0.6121717691421509\n",
      "Loss: 0.6085129976272583\n",
      "Loss: 0.6605798602104187\n",
      "Loss: 0.670479416847229\n",
      "Loss: 0.618133008480072\n",
      "Loss: 0.6127859950065613\n",
      "Loss: 0.6200220584869385\n",
      "Loss: 0.6139506697654724\n",
      "Loss: 0.6479323506355286\n",
      "Loss: 0.6272515058517456\n",
      "Loss: 0.6449158787727356\n",
      "Loss: 0.6152580380439758\n",
      "Loss: 0.6150530576705933\n",
      "Loss: 0.5744463801383972\n",
      "Loss: 0.6657924652099609\n",
      "Loss: 0.6653842926025391\n",
      "Loss: 0.6131451725959778\n",
      "Loss: 0.6574366688728333\n",
      "Loss: 0.6699362397193909\n",
      "Loss: 0.6118360757827759\n",
      "Loss: 0.6073352694511414\n",
      "Loss: 0.6621813178062439\n",
      "Loss: 0.6184765696525574\n",
      "Loss: 0.6725111603736877\n",
      "Loss: 0.6802022457122803\n",
      "Loss: 0.6510083079338074\n",
      "Loss: 0.6041313409805298\n",
      "Loss: 0.6596752405166626\n",
      "Loss: 0.6360915303230286\n",
      "Loss: 0.5642290115356445\n",
      "Loss: 0.5469921827316284\n",
      "Loss: 0.6405395269393921\n",
      "Loss: 0.7139976024627686\n",
      "Loss: 0.6688439249992371\n",
      "Loss: 0.6967725157737732\n",
      "Loss: 0.607253909111023\n",
      "Loss: 0.5617079734802246\n",
      "Loss: 0.7029407024383545\n",
      "Loss: 0.6150087714195251\n",
      "Loss: 0.6574243903160095\n",
      "Loss: 0.6221238374710083\n",
      "Loss: 0.5748003721237183\n",
      "Loss: 0.6863406300544739\n",
      "Loss: 0.583828866481781\n",
      "Loss: 0.6599328517913818\n",
      "Loss: 0.7643710970878601\n",
      "Loss: 0.6556109189987183\n",
      "Loss: 0.6577019691467285\n",
      "Loss: 0.5620721578598022\n",
      "Loss: 0.6223591566085815\n",
      "Loss: 0.6859120726585388\n",
      "Loss: 0.719211757183075\n",
      "Loss: 0.6257773637771606\n",
      "Loss: 0.5824715495109558\n",
      "Loss: 0.6152849197387695\n",
      "Loss: 0.6313751935958862\n",
      "Loss: 0.6742762923240662\n",
      "Loss: 0.6878589987754822\n",
      "Loss: 0.6801139712333679\n",
      "Loss: 0.5579506158828735\n",
      "Loss: 0.6781041622161865\n",
      "Loss: 0.5934020280838013\n",
      "Loss: 0.603729248046875\n",
      "Loss: 0.6468446254730225\n",
      "Loss: 0.5739666819572449\n",
      "Loss: 0.7162977457046509\n",
      "Loss: 0.6473687291145325\n",
      "Loss: 0.6560177206993103\n",
      "Loss: 0.6758667230606079\n",
      "Loss: 0.6708535552024841\n",
      "Loss: 0.5725404024124146\n",
      "Loss: 0.732679009437561\n",
      "Loss: 0.5616795420646667\n",
      "Loss: 0.6717392802238464\n",
      "Loss: 0.7020675539970398\n",
      "Loss: 0.6145960688591003\n",
      "Loss: 0.6356804966926575\n",
      "Loss: 0.6562768816947937\n",
      "Loss: 0.704890787601471\n",
      "Loss: 0.6564388275146484\n",
      "Loss: 0.612238347530365\n",
      "Loss: 0.612218976020813\n",
      "Loss: 0.5931006669998169\n",
      "Loss: 0.6600807905197144\n",
      "Loss: 0.6606194972991943\n",
      "Loss: 0.6490060091018677\n",
      "Loss: 0.5700833201408386\n",
      "Loss: 0.5757097601890564\n",
      "Loss: 0.662670910358429\n",
      "Loss: 0.5704976916313171\n",
      "Loss: 0.5900975465774536\n",
      "Loss: 0.6672660708427429\n",
      "Loss: 0.6099936962127686\n",
      "Loss: 0.650089681148529\n",
      "Loss: 0.6336172819137573\n",
      "Loss: 0.6670053601264954\n",
      "Loss: 0.5926102995872498\n",
      "Loss: 0.7114192247390747\n",
      "Loss: 0.6369441747665405\n",
      "Loss: 0.6324173212051392\n",
      "Loss: 0.6357784271240234\n",
      "Loss: 0.6336333751678467\n",
      "Loss: 0.6505531668663025\n",
      "Loss: 0.6196512579917908\n",
      "Loss: 0.5546798706054688\n",
      "Loss: 0.6820691227912903\n",
      "Loss: 0.6369079947471619\n",
      "Loss: 0.6281417012214661\n",
      "Loss: 0.6322669386863708\n",
      "Loss: 0.5991858243942261\n",
      "Loss: 0.7037577033042908\n",
      "Loss: 0.6118490695953369\n",
      "Loss: 0.6738424897193909\n",
      "Loss: 0.6375576257705688\n",
      "Loss: 0.5660597681999207\n",
      "Loss: 0.639556884765625\n",
      "Loss: 0.6786526441574097\n",
      "Loss: 0.6219520568847656\n",
      "Loss: 0.6784884333610535\n",
      "Loss: 0.5917011499404907\n",
      "Loss: 0.5646357536315918\n",
      "Loss: 0.6985758543014526\n",
      "Loss: 0.6232305765151978\n",
      "Loss: 0.6309536099433899\n",
      "Loss: 0.5958666801452637\n",
      "Loss: 0.6234031915664673\n",
      "Loss: 0.6657353639602661\n",
      "Loss: 0.6912479996681213\n",
      "Loss: 0.5594995021820068\n",
      "Loss: 0.5657040476799011\n",
      "Loss: 0.5934013724327087\n",
      "Loss: 0.5911040306091309\n",
      "Loss: 0.6215399503707886\n",
      "Loss: 0.6101517081260681\n",
      "Loss: 0.5255381464958191\n",
      "Loss: 0.6385038495063782\n",
      "Loss: 0.6546233892440796\n",
      "Loss: 0.6529882550239563\n",
      "Loss: 0.6688594222068787\n",
      "Loss: 0.579054057598114\n",
      "Loss: 0.6227278113365173\n",
      "Loss: 0.643272340297699\n",
      "Loss: 0.5918038487434387\n",
      "Loss: 0.6240513920783997\n",
      "Loss: 0.7252331376075745\n",
      "Loss: 0.6466773748397827\n",
      "Loss: 0.6218263506889343\n",
      "Loss: 0.6277544498443604\n",
      "Loss: 0.6094775199890137\n",
      "Loss: 0.633479118347168\n",
      "Loss: 0.5796406269073486\n",
      "Loss: 0.7328537702560425\n",
      "Loss: 0.6662328839302063\n",
      "Loss: 0.6483229994773865\n",
      "Loss: 0.6803056597709656\n",
      "Loss: 0.6921325325965881\n",
      "Loss: 0.676476240158081\n",
      "Loss: 0.5982927680015564\n",
      "Loss: 0.6042473316192627\n",
      "Loss: 0.6406692862510681\n",
      "Loss: 0.6458942294120789\n",
      "Loss: 0.6113495230674744\n",
      "Loss: 0.6219308376312256\n",
      "Loss: 0.6332672834396362\n",
      "Loss: 0.5997331142425537\n",
      "Loss: 0.6168054342269897\n",
      "Loss: 0.673132061958313\n",
      "Loss: 0.748073935508728\n",
      "Loss: 0.6347295641899109\n",
      "Loss: 0.6970996260643005\n",
      "Loss: 0.6138451099395752\n",
      "Loss: 0.629269003868103\n",
      "Loss: 0.5988815426826477\n",
      "Loss: 0.6112443208694458\n",
      "Loss: 0.6103445291519165\n",
      "Loss: 0.5493542551994324\n",
      "Loss: 0.6460158228874207\n",
      "Loss: 0.5903167724609375\n",
      "Loss: 0.6606046557426453\n",
      "Loss: 0.6432659029960632\n",
      "Loss: 0.6421826481819153\n",
      "Loss: 0.6961552500724792\n",
      "Loss: 0.6888576149940491\n",
      "Loss: 0.5623085498809814\n",
      "Loss: 0.5920411348342896\n",
      "Loss: 0.6560714244842529\n",
      "Loss: 0.6592685580253601\n",
      "Loss: 0.6896057724952698\n",
      "Loss: 0.6339372396469116\n",
      "Loss: 0.6563831567764282\n",
      "Loss: 0.6441901326179504\n",
      "Loss: 0.6747584939002991\n",
      "Loss: 0.7297661900520325\n",
      "Loss: 0.6433798670768738\n",
      "Loss: 0.6069409251213074\n",
      "Loss: 0.6368430256843567\n",
      "Loss: 0.6342451572418213\n",
      "Loss: 0.6643163561820984\n",
      "Loss: 0.6591162085533142\n",
      "Loss: 0.7077093720436096\n",
      "Loss: 0.6848455667495728\n",
      "Loss: 0.6850250959396362\n",
      "Loss: 0.6480987071990967\n",
      "Loss: 0.7474740743637085\n",
      "Loss: 0.6527305841445923\n",
      "Loss: 0.7004735469818115\n",
      "Loss: 0.6403603553771973\n",
      "Loss: 0.6655628681182861\n",
      "Loss: 0.7444974780082703\n",
      "Loss: 0.5827062726020813\n",
      "Loss: 0.7058852910995483\n",
      "Loss: 0.6101145148277283\n",
      "Loss: 0.6186949014663696\n",
      "Loss: 0.5472432971000671\n",
      "Loss: 0.6409667134284973\n",
      "Loss: 0.6517446041107178\n",
      "Loss: 0.5168254375457764\n",
      "Loss: 0.6819249391555786\n",
      "Loss: 0.5647518038749695\n",
      "Loss: 0.6543926000595093\n",
      "Loss: 0.6194194555282593\n",
      "Loss: 0.6717633008956909\n",
      "Loss: 0.6923931837081909\n",
      "Loss: 0.6850801706314087\n",
      "Loss: 0.6558017730712891\n",
      "Loss: 0.6668477654457092\n",
      "Loss: 0.5887370109558105\n",
      "Loss: 0.6319298148155212\n",
      "Loss: 0.7034223079681396\n",
      "Loss: 0.6581695079803467\n",
      "Loss: 0.5856682062149048\n",
      "Loss: 0.7300330996513367\n",
      "Loss: 0.7463977932929993\n",
      "Loss: 0.6316396594047546\n",
      "Loss: 0.5886581540107727\n",
      "Loss: 0.6326684951782227\n",
      "Loss: 0.6772645711898804\n",
      "Loss: 0.6783540844917297\n",
      "Loss: 0.6433274745941162\n",
      "Loss: 0.6632575988769531\n",
      "Loss: 0.6375167369842529\n",
      "Loss: 0.5900627374649048\n",
      "Loss: 0.6199714541435242\n",
      "Loss: 0.6651906371116638\n",
      "Loss: 0.6410773396492004\n",
      "Loss: 0.6713451743125916\n",
      "Loss: 0.5999324321746826\n",
      "Loss: 0.6225606799125671\n",
      "Loss: 0.5868704915046692\n",
      "Loss: 0.6209577322006226\n",
      "Loss: 0.6721585392951965\n",
      "Loss: 0.5666682124137878\n",
      "Loss: 0.656049907207489\n",
      "Loss: 0.7009167075157166\n",
      "Loss: 0.6661033630371094\n",
      "Loss: 0.5662354230880737\n",
      "Loss: 0.6614953279495239\n",
      "Loss: 0.7081920504570007\n",
      "Loss: 0.6469331979751587\n",
      "Loss: 0.6442064046859741\n",
      "Loss: 0.6811489462852478\n",
      "Loss: 0.5880363583564758\n",
      "Loss: 0.6126064658164978\n",
      "Loss: 0.6455609798431396\n",
      "Loss: 0.7908121943473816\n",
      "Loss: 0.6249925494194031\n",
      "Loss: 0.5860267877578735\n",
      "Loss: 0.6717924475669861\n",
      "Loss: 0.5895538330078125\n",
      "Loss: 0.6332498788833618\n",
      "Loss: 0.6706860661506653\n",
      "Loss: 0.7210732102394104\n",
      "Loss: 0.6183090209960938\n",
      "Loss: 0.5993623733520508\n",
      "Loss: 0.6299500465393066\n",
      "Loss: 0.6165801882743835\n",
      "Loss: 0.6097737550735474\n",
      "Loss: 0.6149064898490906\n",
      "Loss: 0.656336784362793\n",
      "Loss: 0.6773363351821899\n",
      "Loss: 0.6962898969650269\n",
      "Loss: 0.6665459871292114\n",
      "Loss: 0.6554837226867676\n",
      "Loss: 0.6116536855697632\n",
      "Loss: 0.5328847169876099\n",
      "Loss: 0.6441471576690674\n",
      "Loss: 0.6175217628479004\n",
      "Loss: 0.6597251296043396\n",
      "Loss: 0.6839158535003662\n",
      "Loss: 0.6428651809692383\n",
      "Loss: 0.6079005002975464\n",
      "Loss: 0.6752908229827881\n",
      "Loss: 0.6756744980812073\n",
      "Loss: 0.5737112760543823\n",
      "Loss: 0.6169775724411011\n",
      "Loss: 0.665696918964386\n",
      "Loss: 0.6090529561042786\n",
      "Loss: 0.6546859741210938\n",
      "Loss: 0.6130977869033813\n",
      "Loss: 0.675794780254364\n",
      "Loss: 0.6067603230476379\n",
      "Loss: 0.704807698726654\n",
      "Loss: 0.700190007686615\n",
      "Loss: 0.6381509900093079\n",
      "Loss: 0.6368138790130615\n",
      "Loss: 0.6443979144096375\n",
      "Loss: 0.6944952607154846\n",
      "Loss: 0.6799715757369995\n",
      "Loss: 0.6791639924049377\n",
      "Loss: 0.6430186033248901\n",
      "Loss: 0.6805372834205627\n",
      "Loss: 0.636380672454834\n",
      "Loss: 0.6857277154922485\n",
      "Loss: 0.5803011655807495\n",
      "Loss: 0.6278085708618164\n",
      "Loss: 0.6139242053031921\n",
      "Loss: 0.728628396987915\n",
      "Loss: 0.6381500959396362\n",
      "Loss: 0.6649954319000244\n",
      "Loss: 0.5648026466369629\n",
      "Loss: 0.6789087653160095\n",
      "Loss: 0.573466956615448\n",
      "Loss: 0.6741184592247009\n",
      "Loss: 0.7085624933242798\n",
      "Loss: 0.6348785161972046\n",
      "Loss: 0.675125002861023\n",
      "Loss: 0.6978909969329834\n",
      "Loss: 0.5748247504234314\n",
      "Loss: 0.6195501685142517\n",
      "Loss: 0.5766124725341797\n",
      "Loss: 0.6022696495056152\n",
      "Loss: 0.5745567083358765\n",
      "Loss: 0.6620113253593445\n",
      "Loss: 0.7043542265892029\n",
      "Loss: 0.6709347367286682\n",
      "Loss: 0.7010327577590942\n",
      "Loss: 0.6242907643318176\n",
      "Loss: 0.6070621013641357\n",
      "Loss: 0.630502462387085\n",
      "Loss: 0.6258425116539001\n",
      "Loss: 0.6264569759368896\n",
      "Loss: 0.6347743272781372\n",
      "Loss: 0.579927921295166\n",
      "Loss: 0.6122103929519653\n",
      "Loss: 0.6852650046348572\n",
      "Loss: 0.6693095564842224\n",
      "Loss: 0.6129111051559448\n",
      "Loss: 0.6491222381591797\n",
      "Loss: 0.646540641784668\n",
      "Loss: 0.5501176118850708\n",
      "Loss: 0.6643581390380859\n",
      "Loss: 0.6297842264175415\n",
      "Loss: 0.6793960928916931\n",
      "Loss: 0.6150699853897095\n",
      "Loss: 0.6447308659553528\n",
      "Loss: 0.6372559070587158\n",
      "Loss: 0.5924599766731262\n",
      "Loss: 0.6959549188613892\n",
      "Loss: 0.7093569040298462\n",
      "Loss: 0.6152588129043579\n",
      "Loss: 0.5903794765472412\n",
      "Loss: 0.6974018216133118\n",
      "Loss: 0.6159068942070007\n",
      "Loss: 0.6288987994194031\n",
      "Loss: 0.6318402290344238\n",
      "Loss: 0.5491169691085815\n",
      "Loss: 0.6456063985824585\n",
      "Loss: 0.6168819665908813\n",
      "Loss: 0.6173709630966187\n",
      "Loss: 0.6085995435714722\n",
      "Loss: 0.6899606585502625\n",
      "Loss: 0.6833116412162781\n",
      "Loss: 0.6224534511566162\n",
      "Loss: 0.6330989003181458\n",
      "Loss: 0.6689130663871765\n",
      "Loss: 0.6391918063163757\n",
      "Loss: 0.6442483067512512\n",
      "Loss: 0.5656684041023254\n",
      "Loss: 0.6348757743835449\n",
      "Loss: 0.6669873595237732\n",
      "Loss: 0.6538978815078735\n",
      "Loss: 0.628909707069397\n",
      "Loss: 0.6579868197441101\n",
      "Loss: 0.6682182550430298\n",
      "Loss: 0.6218723654747009\n",
      "Loss: 0.6335541605949402\n",
      "Loss: 0.5872894525527954\n",
      "Loss: 0.6571800708770752\n",
      "Loss: 0.6383880376815796\n",
      "Loss: 0.6753143072128296\n",
      "Loss: 0.7140090465545654\n",
      "Loss: 0.6314293146133423\n",
      "Loss: 0.6460025906562805\n",
      "Loss: 0.6244333386421204\n",
      "Loss: 0.6241539716720581\n",
      "Loss: 0.6334390044212341\n",
      "Loss: 0.6573991775512695\n",
      "Loss: 0.5771093368530273\n",
      "Loss: 0.7426327466964722\n",
      "Loss: 0.6820147633552551\n",
      "Loss: 0.6109613180160522\n",
      "Loss: 0.6123921871185303\n",
      "Loss: 0.6018051505088806\n",
      "Loss: 0.7745401263237\n",
      "Loss: 0.6541106700897217\n",
      "Loss: 0.6099315881729126\n",
      "Loss: 0.6380127668380737\n",
      "Loss: 0.5997551679611206\n",
      "Loss: 0.7190721035003662\n",
      "Loss: 0.6066032648086548\n",
      "Loss: 0.6067153215408325\n",
      "Loss: 0.5827571749687195\n",
      "Loss: 0.6447420120239258\n",
      "Loss: 0.6934196949005127\n",
      "Loss: 0.6502307057380676\n",
      "Loss: 0.6646074652671814\n",
      "Loss: 0.6278091669082642\n",
      "Loss: 0.6869768500328064\n",
      "Loss: 0.6484887599945068\n",
      "Loss: 0.6327922344207764\n",
      "Loss: 0.6557114720344543\n",
      "Loss: 0.6243036985397339\n",
      "Loss: 0.6442627310752869\n",
      "Loss: 0.6918064951896667\n",
      "Loss: 0.6720103025436401\n",
      "Loss: 0.6452996730804443\n",
      "Loss: 0.6366716623306274\n",
      "Loss: 0.6961332559585571\n",
      "Loss: 0.6706035137176514\n",
      "Loss: 0.7201228737831116\n",
      "Loss: 0.5961230397224426\n",
      "Loss: 0.6330763697624207\n",
      "Loss: 0.544991135597229\n",
      "Loss: 0.6805074214935303\n",
      "Loss: 0.6275471448898315\n",
      "Loss: 0.622789740562439\n",
      "Loss: 0.6182830333709717\n",
      "Loss: 0.5637871623039246\n",
      "Loss: 0.6677097082138062\n",
      "Loss: 0.6790212392807007\n",
      "Loss: 0.6814588308334351\n",
      "Loss: 0.5801169872283936\n",
      "Loss: 0.6085748672485352\n",
      "Loss: 0.5722748041152954\n",
      "Loss: 0.6780135035514832\n",
      "Loss: 0.6857290863990784\n",
      "Loss: 0.6859412789344788\n",
      "Loss: 0.6330079436302185\n",
      "Loss: 0.6256392598152161\n",
      "Loss: 0.7261344790458679\n",
      "Loss: 0.6155874133110046\n",
      "Loss: 0.6102814674377441\n",
      "Loss: 0.6288946866989136\n",
      "Loss: 0.632340669631958\n",
      "Loss: 0.649976372718811\n",
      "Loss: 0.6152193546295166\n",
      "Loss: 0.6126911044120789\n",
      "Loss: 0.6745330691337585\n",
      "Loss: 0.6446627378463745\n",
      "Loss: 0.5855358242988586\n",
      "Loss: 0.6257543563842773\n",
      "Loss: 0.67478346824646\n",
      "Loss: 0.6489717364311218\n",
      "Loss: 0.5932974815368652\n",
      "Loss: 0.5447815656661987\n",
      "Loss: 0.620919406414032\n",
      "Loss: 0.6760562062263489\n",
      "Loss: 0.6957569718360901\n",
      "Loss: 0.686069667339325\n",
      "Loss: 0.6289706230163574\n",
      "Loss: 0.6269997358322144\n",
      "Loss: 0.6341767311096191\n",
      "Loss: 0.6624339818954468\n",
      "Loss: 0.6141811609268188\n",
      "Loss: 0.6891516447067261\n",
      "Loss: 0.6285170912742615\n",
      "Loss: 0.6709926128387451\n",
      "Loss: 0.6025339365005493\n",
      "Loss: 0.6392990946769714\n",
      "Loss: 0.6188298463821411\n",
      "Loss: 0.6785182356834412\n",
      "Loss: 0.636572003364563\n",
      "Loss: 0.6803361773490906\n",
      "Loss: 0.6298521757125854\n",
      "Loss: 0.6654828190803528\n",
      "Loss: 0.6330348253250122\n",
      "Loss: 0.6550877690315247\n",
      "Loss: 0.6235572695732117\n",
      "Loss: 0.6431192755699158\n",
      "Loss: 0.6838847398757935\n",
      "Loss: 0.699079155921936\n",
      "Loss: 0.58563232421875\n",
      "Loss: 0.5790082216262817\n",
      "Loss: 0.7015378475189209\n",
      "Loss: 0.7129682898521423\n",
      "Loss: 0.6200449466705322\n",
      "Loss: 0.6583130955696106\n",
      "Loss: 0.6140985488891602\n",
      "Loss: 0.6537319421768188\n",
      "Loss: 0.6446917653083801\n",
      "Loss: 0.5707265734672546\n",
      "Loss: 0.675108015537262\n",
      "Loss: 0.6908759474754333\n",
      "Loss: 0.5862646102905273\n",
      "Loss: 0.6260507702827454\n",
      "Loss: 0.6601371765136719\n",
      "Loss: 0.7148535847663879\n",
      "Loss: 0.6284198760986328\n",
      "Loss: 0.5724870562553406\n",
      "Loss: 0.6138004064559937\n",
      "Loss: 0.6838633418083191\n",
      "Loss: 0.7169454097747803\n",
      "Loss: 0.6327840685844421\n",
      "Loss: 0.6029284000396729\n",
      "Loss: 0.6094358563423157\n",
      "Loss: 0.633230447769165\n",
      "Loss: 0.6273870468139648\n",
      "Loss: 0.7092193961143494\n",
      "Loss: 0.5804386138916016\n",
      "Loss: 0.7312643527984619\n",
      "Loss: 0.6077508926391602\n",
      "Loss: 0.5383999347686768\n",
      "Loss: 0.64458167552948\n",
      "Loss: 0.7289604544639587\n",
      "Loss: 0.6252462267875671\n",
      "Loss: 0.6583618521690369\n",
      "Loss: 0.5923585891723633\n",
      "Loss: 0.624972939491272\n",
      "Loss: 0.6536146402359009\n",
      "Loss: 0.7210050821304321\n",
      "Loss: 0.740720808506012\n",
      "Loss: 0.7118044495582581\n",
      "Loss: 0.6744105219841003\n",
      "Loss: 0.5890187621116638\n",
      "Loss: 0.658362627029419\n",
      "Loss: 0.6504518389701843\n",
      "Loss: 0.6661155223846436\n",
      "Loss: 0.6413106918334961\n",
      "Loss: 0.5904399752616882\n",
      "Loss: 0.6416303515434265\n",
      "Loss: 0.6107203364372253\n",
      "Loss: 0.6952522397041321\n",
      "Loss: 0.6365145444869995\n",
      "Loss: 0.7059115171432495\n",
      "Loss: 0.65431147813797\n",
      "Loss: 0.6175584197044373\n",
      "Loss: 0.6474088430404663\n",
      "Loss: 0.651118278503418\n",
      "Loss: 0.6874727606773376\n",
      "Loss: 0.5944728255271912\n",
      "Loss: 0.6903030276298523\n",
      "Loss: 0.7151681780815125\n",
      "Loss: 0.6579024195671082\n",
      "Loss: 0.6342934966087341\n",
      "Loss: 0.626081645488739\n",
      "Loss: 0.5848473310470581\n",
      "Loss: 0.6208860278129578\n",
      "Loss: 0.6456829905509949\n",
      "Loss: 0.6190999746322632\n",
      "Loss: 0.667231023311615\n",
      "Loss: 0.6601385474205017\n",
      "Loss: 0.6094368696212769\n",
      "Loss: 0.6098756194114685\n",
      "Loss: 0.7043172717094421\n",
      "Loss: 0.6291208267211914\n",
      "Loss: 0.6454610228538513\n",
      "Loss: 0.6903413534164429\n",
      "Loss: 0.6247152090072632\n",
      "Loss: 0.6613170504570007\n",
      "Loss: 0.6846553683280945\n",
      "Loss: 0.6901289224624634\n",
      "Loss: 0.6007126569747925\n",
      "Loss: 0.6994683742523193\n",
      "Loss: 0.5988829731941223\n",
      "Loss: 0.6175706386566162\n",
      "Loss: 0.6795952916145325\n",
      "Loss: 0.6569316387176514\n",
      "Loss: 0.6585865020751953\n",
      "Loss: 0.6815208196640015\n",
      "Loss: 0.6937659382820129\n",
      "Loss: 0.6339852809906006\n",
      "Loss: 0.6606125235557556\n",
      "Loss: 0.6303132176399231\n",
      "Loss: 0.6186664700508118\n",
      "Loss: 0.6306508779525757\n",
      "Loss: 0.6736090779304504\n",
      "Loss: 0.5603646636009216\n",
      "Loss: 0.601222038269043\n",
      "Loss: 0.6830251216888428\n",
      "Loss: 0.6673027276992798\n",
      "Loss: 0.6083114147186279\n",
      "Loss: 0.6482113599777222\n",
      "Loss: 0.6632521152496338\n",
      "Loss: 0.6151578426361084\n",
      "Loss: 0.6113814115524292\n",
      "Loss: 0.6351005434989929\n",
      "Loss: 0.6708353757858276\n",
      "Loss: 0.6364916563034058\n",
      "Loss: 0.690422773361206\n",
      "Loss: 0.5928367972373962\n",
      "Loss: 0.6660743951797485\n",
      "Loss: 0.6679127216339111\n",
      "Loss: 0.6616802215576172\n",
      "Loss: 0.5449460744857788\n",
      "Loss: 0.683373212814331\n",
      "Loss: 0.6282836198806763\n",
      "Loss: 0.6953950524330139\n",
      "Loss: 0.7396668195724487\n",
      "Loss: 0.6539636850357056\n",
      "Loss: 0.6642574071884155\n",
      "Loss: 0.6449401378631592\n",
      "Loss: 0.619240939617157\n",
      "Loss: 0.6321464776992798\n",
      "Loss: 0.5620822906494141\n",
      "Loss: 0.7130938172340393\n",
      "Loss: 0.6674472689628601\n",
      "Loss: 0.6342410445213318\n",
      "Loss: 0.6940509676933289\n",
      "Loss: 0.6384865641593933\n",
      "Loss: 0.6453437805175781\n",
      "Loss: 0.6570037603378296\n",
      "Loss: 0.7225516438484192\n",
      "Loss: 0.6028286218643188\n",
      "Loss: 0.6176193356513977\n",
      "Loss: 0.7421627640724182\n",
      "Loss: 0.5554015040397644\n",
      "Loss: 0.6781952977180481\n",
      "Loss: 0.6904755234718323\n",
      "Loss: 0.6019474864006042\n",
      "Loss: 0.6896364688873291\n",
      "Loss: 0.5421628355979919\n",
      "Loss: 0.615339994430542\n",
      "Loss: 0.6850435733795166\n",
      "Loss: 0.6749001145362854\n",
      "Loss: 0.6779696941375732\n",
      "Loss: 0.5972523093223572\n",
      "Loss: 0.5995079874992371\n",
      "Loss: 0.6514031291007996\n",
      "Loss: 0.5940410494804382\n",
      "Loss: 0.6533421874046326\n",
      "Loss: 0.5839685797691345\n",
      "Loss: 0.6153160929679871\n",
      "Loss: 0.6778956651687622\n",
      "Loss: 0.6595979928970337\n",
      "Loss: 0.6738064885139465\n",
      "Loss: 0.6609476804733276\n",
      "Loss: 0.6346126794815063\n",
      "Loss: 0.6651102900505066\n",
      "Loss: 0.5888646841049194\n",
      "Loss: 0.6613396406173706\n",
      "Loss: 0.5606173872947693\n",
      "Loss: 0.7147079706192017\n",
      "Loss: 0.6530001759529114\n",
      "Loss: 0.6559396982192993\n",
      "Loss: 0.6413082480430603\n",
      "Loss: 0.6660319566726685\n",
      "Loss: 0.6705532670021057\n",
      "Loss: 0.7192236185073853\n",
      "Loss: 0.711936354637146\n",
      "Loss: 0.6821415424346924\n",
      "Loss: 0.6173152327537537\n",
      "Loss: 0.6878501772880554\n",
      "Loss: 0.6382765173912048\n",
      "Loss: 0.5192241072654724\n",
      "Loss: 0.6288336515426636\n",
      "Loss: 0.6363298296928406\n",
      "Loss: 0.6361894607543945\n",
      "Loss: 0.6674298644065857\n",
      "Loss: 0.6083481907844543\n",
      "Loss: 0.6807801723480225\n",
      "Loss: 0.6587448120117188\n",
      "Loss: 0.697747528553009\n",
      "Loss: 0.6660453677177429\n",
      "Loss: 0.6662943959236145\n",
      "Loss: 0.611688494682312\n",
      "Loss: 0.6233418583869934\n",
      "Loss: 0.6331758499145508\n",
      "Loss: 0.6358069181442261\n",
      "Loss: 0.6375026702880859\n",
      "Loss: 0.5432593822479248\n",
      "Loss: 0.7036308646202087\n",
      "Loss: 0.7306159734725952\n",
      "Loss: 0.6854838132858276\n",
      "Loss: 0.574365496635437\n",
      "Loss: 0.6582103967666626\n",
      "Loss: 0.6409361362457275\n",
      "Loss: 0.652138352394104\n",
      "Loss: 0.6533228158950806\n",
      "Loss: 0.6471387147903442\n",
      "Loss: 0.6690254807472229\n",
      "Loss: 0.604322612285614\n",
      "Loss: 0.6564609408378601\n",
      "Loss: 0.6372735500335693\n",
      "Loss: 0.6515872478485107\n",
      "Loss: 0.6379300951957703\n",
      "Loss: 0.6217478513717651\n",
      "Loss: 0.6870619654655457\n",
      "Loss: 0.6565343141555786\n",
      "Loss: 0.6627002954483032\n",
      "Loss: 0.6201388835906982\n",
      "Loss: 0.6781182885169983\n",
      "Loss: 0.6692982316017151\n",
      "Loss: 0.6279419660568237\n",
      "Loss: 0.5896419882774353\n",
      "Loss: 0.5978953838348389\n",
      "Loss: 0.62852942943573\n",
      "Loss: 0.7131073474884033\n",
      "Loss: 0.6740421652793884\n",
      "Loss: 0.6494935154914856\n",
      "Loss: 0.6592478156089783\n",
      "Loss: 0.6886872053146362\n",
      "Loss: 0.6725476384162903\n",
      "Loss: 0.6549304127693176\n",
      "Loss: 0.7306363582611084\n",
      "Loss: 0.6564356088638306\n",
      "Loss: 0.6074949502944946\n",
      "Loss: 0.671141505241394\n",
      "Loss: 0.6396791934967041\n",
      "Loss: 0.6364037990570068\n",
      "Loss: 0.6731528043746948\n",
      "Loss: 0.6874879002571106\n",
      "Loss: 0.6848978400230408\n",
      "Loss: 0.5883838534355164\n",
      "Loss: 0.7264264225959778\n",
      "Loss: 0.6116536855697632\n",
      "Loss: 0.6758652925491333\n",
      "Loss: 0.6756985783576965\n",
      "Loss: 0.6892969012260437\n",
      "Loss: 0.6351868510246277\n",
      "Loss: 0.6963649988174438\n",
      "Loss: 0.6957055926322937\n",
      "Loss: 0.5848855972290039\n",
      "Loss: 0.6794936656951904\n",
      "Loss: 0.5885223150253296\n",
      "Loss: 0.7224537134170532\n",
      "Loss: 0.642366349697113\n",
      "Loss: 0.5605723261833191\n",
      "Loss: 0.6221444606781006\n",
      "Loss: 0.6460555791854858\n",
      "Loss: 0.6840461492538452\n",
      "Loss: 0.6971105933189392\n",
      "Loss: 0.5983697772026062\n",
      "Loss: 0.5824762582778931\n",
      "Loss: 0.7057487368583679\n",
      "Loss: 0.650718092918396\n",
      "Loss: 0.5784439444541931\n",
      "Loss: 0.6574367880821228\n",
      "Loss: 0.6769381165504456\n",
      "Loss: 0.7069709897041321\n",
      "Loss: 0.6449661254882812\n",
      "Loss: 0.6552406549453735\n",
      "Loss: 0.6695520877838135\n",
      "Loss: 0.6538320779800415\n",
      "Loss: 0.6654817461967468\n",
      "Loss: 0.6168783903121948\n",
      "Loss: 0.6262420415878296\n",
      "Loss: 0.6211983561515808\n",
      "Loss: 0.6032746434211731\n",
      "Loss: 0.645233154296875\n",
      "Loss: 0.6669919490814209\n",
      "Loss: 0.6605280041694641\n",
      "Loss: 0.6993150115013123\n",
      "Loss: 0.5605740547180176\n",
      "Loss: 0.5833141207695007\n",
      "Loss: 0.6564900279045105\n",
      "Loss: 0.6461641192436218\n",
      "Loss: 0.5964628458023071\n",
      "Loss: 0.7350754141807556\n",
      "Loss: 0.6612762808799744\n",
      "Loss: 0.6872352957725525\n",
      "Loss: 0.6685001254081726\n",
      "Loss: 0.6718007922172546\n",
      "Loss: 0.7186387181282043\n",
      "Loss: 0.6606025695800781\n",
      "Loss: 0.6890760064125061\n",
      "Loss: 0.6616215109825134\n",
      "Loss: 0.6839646100997925\n",
      "Loss: 0.5979174375534058\n",
      "Loss: 0.6499338150024414\n",
      "Loss: 0.6229698657989502\n",
      "Loss: 0.6609770059585571\n",
      "Loss: 0.6369897127151489\n",
      "Loss: 0.6921854615211487\n",
      "Loss: 0.6815693974494934\n",
      "Loss: 0.7219445705413818\n",
      "Loss: 0.6451901197433472\n",
      "Loss: 0.563840389251709\n",
      "Loss: 0.6797549724578857\n",
      "Loss: 0.6496508717536926\n",
      "Loss: 0.6961950659751892\n",
      "Loss: 0.6821032166481018\n",
      "Loss: 0.6708734631538391\n",
      "Loss: 0.6192534565925598\n",
      "Loss: 0.6557467579841614\n",
      "Loss: 0.6490738987922668\n",
      "Loss: 0.6039199829101562\n",
      "Loss: 0.6949177980422974\n",
      "Loss: 0.6604570746421814\n",
      "Loss: 0.6637789011001587\n",
      "Loss: 0.6765754222869873\n",
      "Loss: 0.6056114435195923\n",
      "Loss: 0.5715376138687134\n",
      "Loss: 0.6152486801147461\n",
      "Loss: 0.6491174697875977\n",
      "Loss: 0.6253084540367126\n",
      "Loss: 0.6829260587692261\n",
      "Loss: 0.652154803276062\n",
      "Loss: 0.6827336549758911\n",
      "Loss: 0.6768807172775269\n",
      "Loss: 0.6345465779304504\n",
      "Loss: 0.6704567670822144\n",
      "Loss: 0.6371623873710632\n",
      "Loss: 0.619454026222229\n",
      "Loss: 0.6652879118919373\n",
      "Loss: 0.6173882484436035\n",
      "Loss: 0.6710435152053833\n",
      "Loss: 0.5645931959152222\n",
      "Loss: 0.577198326587677\n",
      "Loss: 0.7342444062232971\n",
      "Loss: 0.6969414949417114\n",
      "Loss: 0.6756793856620789\n",
      "Loss: 0.6418206691741943\n",
      "Loss: 0.5989159345626831\n",
      "Loss: 0.6413543224334717\n",
      "Loss: 0.633233368396759\n",
      "Loss: 0.6811244487762451\n",
      "Loss: 0.665978193283081\n",
      "Loss: 0.6643189191818237\n",
      "Loss: 0.5855765342712402\n",
      "Loss: 0.6038569211959839\n",
      "Loss: 0.6577731966972351\n",
      "Loss: 0.6940658092498779\n",
      "Loss: 0.6498897671699524\n",
      "Loss: 0.6748082041740417\n",
      "Loss: 0.6425738334655762\n",
      "Loss: 0.6644290089607239\n",
      "Loss: 0.6038044095039368\n",
      "Loss: 0.6692160367965698\n",
      "Loss: 0.6358373761177063\n",
      "Loss: 0.5467192530632019\n",
      "Loss: 0.6613895297050476\n",
      "Loss: 0.6100891828536987\n",
      "Loss: 0.5889617800712585\n",
      "Loss: 0.6490026712417603\n",
      "Loss: 0.5961474776268005\n",
      "Loss: 0.7234508395195007\n",
      "Loss: 0.7035876512527466\n",
      "Loss: 0.6346835494041443\n",
      "Loss: 0.6926340460777283\n",
      "Loss: 0.6724288463592529\n",
      "Loss: 0.6786238551139832\n",
      "Loss: 0.6317729353904724\n",
      "Loss: 0.6098732352256775\n",
      "Loss: 0.5944581031799316\n",
      "Loss: 0.6242920160293579\n",
      "Loss: 0.6673896312713623\n",
      "Loss: 0.7125853300094604\n",
      "Loss: 0.6132186055183411\n",
      "Loss: 0.5682076811790466\n",
      "Loss: 0.6761406064033508\n",
      "Loss: 0.6129865646362305\n",
      "Loss: 0.6181489825248718\n",
      "Loss: 0.6909332871437073\n",
      "Loss: 0.685707688331604\n",
      "Loss: 0.6121811270713806\n",
      "Loss: 0.6539983749389648\n",
      "Loss: 0.6526147723197937\n",
      "Loss: 0.6899758577346802\n",
      "Loss: 0.6733869314193726\n",
      "Loss: 0.6636964678764343\n",
      "Loss: 0.666456937789917\n",
      "Loss: 0.6408358812332153\n",
      "Loss: 0.6841071844100952\n",
      "Loss: 0.6789502501487732\n",
      "Loss: 0.7225525379180908\n",
      "Loss: 0.6503378748893738\n",
      "Loss: 0.662000298500061\n",
      "Loss: 0.6710482239723206\n",
      "Loss: 0.6521844267845154\n",
      "Loss: 0.6538571119308472\n",
      "Loss: 0.5655291080474854\n",
      "Loss: 0.7196749448776245\n",
      "Loss: 0.6536662578582764\n",
      "Loss: 0.6741693615913391\n",
      "Loss: 0.5874007940292358\n",
      "Loss: 0.7774719595909119\n",
      "Loss: 0.6000474095344543\n",
      "Loss: 0.613276481628418\n",
      "Loss: 0.6148198246955872\n",
      "Loss: 0.5887646079063416\n",
      "Loss: 0.516324520111084\n",
      "Loss: 0.6745703220367432\n",
      "Loss: 0.7161548137664795\n",
      "Loss: 0.6612682342529297\n",
      "Loss: 0.5740154981613159\n",
      "Loss: 0.6818899512290955\n",
      "Loss: 0.6685338616371155\n",
      "Loss: 0.6094148755073547\n",
      "Loss: 0.6646608114242554\n",
      "Loss: 0.6573386192321777\n",
      "Loss: 0.6341133117675781\n",
      "Loss: 0.6826735138893127\n",
      "Loss: 0.6800973415374756\n",
      "Loss: 0.6107367277145386\n",
      "Loss: 0.6903666257858276\n",
      "Loss: 0.6673237085342407\n",
      "Loss: 0.6674101948738098\n",
      "Loss: 0.6022106409072876\n",
      "Loss: 0.6481992602348328\n",
      "Loss: 0.570779025554657\n",
      "Loss: 0.6690236330032349\n",
      "Loss: 0.6916180849075317\n",
      "Loss: 0.717483639717102\n",
      "Loss: 0.6711753010749817\n",
      "Loss: 0.5596243739128113\n",
      "Loss: 0.6627520322799683\n",
      "Loss: 0.6625640392303467\n",
      "Loss: 0.5908283591270447\n",
      "Loss: 0.6579673290252686\n",
      "Loss: 0.6886149048805237\n",
      "Loss: 0.6727202534675598\n",
      "Loss: 0.5976703763008118\n",
      "Loss: 0.6419991850852966\n",
      "Loss: 0.5901491641998291\n",
      "Loss: 0.6409910917282104\n",
      "Loss: 0.7957808971405029\n",
      "Loss: 0.668050229549408\n",
      "Loss: 0.6009611487388611\n",
      "Loss: 0.732837438583374\n",
      "Loss: 0.7003485560417175\n",
      "Loss: 0.5949233770370483\n",
      "Loss: 0.6757410168647766\n",
      "Loss: 0.6441863179206848\n",
      "Loss: 0.6298359632492065\n",
      "Loss: 0.6022340655326843\n",
      "Loss: 0.577788770198822\n",
      "Loss: 0.6824268102645874\n",
      "Loss: 0.6399585008621216\n",
      "Loss: 0.6432170867919922\n",
      "Loss: 0.6687286496162415\n",
      "Loss: 0.6889493465423584\n",
      "Loss: 0.6345163583755493\n",
      "Loss: 0.6240577697753906\n",
      "Loss: 0.6921438574790955\n",
      "Loss: 0.7169453501701355\n",
      "Loss: 0.6738936305046082\n",
      "Loss: 0.6171747446060181\n",
      "Loss: 0.6475192904472351\n",
      "Loss: 0.6932710409164429\n",
      "Loss: 0.5971317291259766\n",
      "Loss: 0.6581408977508545\n",
      "Loss: 0.7044644951820374\n",
      "Loss: 0.6723800897598267\n",
      "Loss: 0.610750138759613\n",
      "Loss: 0.6860916018486023\n",
      "Loss: 0.6499408483505249\n",
      "Loss: 0.6967958807945251\n",
      "Loss: 0.635729968547821\n",
      "Loss: 0.5899445414543152\n",
      "Loss: 0.6118950843811035\n",
      "Loss: 0.6245970726013184\n",
      "Loss: 0.6830116510391235\n",
      "Loss: 0.5993712544441223\n",
      "Loss: 0.6470865607261658\n",
      "Loss: 0.7217077612876892\n",
      "Loss: 0.6345910429954529\n",
      "Loss: 0.5537250638008118\n",
      "Loss: 0.6556545495986938\n",
      "Loss: 0.6700589656829834\n",
      "Loss: 0.6485649943351746\n",
      "Loss: 0.6400877237319946\n",
      "Loss: 0.6387430429458618\n",
      "Loss: 0.7594934701919556\n",
      "Loss: 0.6445825695991516\n",
      "Loss: 0.6633085608482361\n",
      "Loss: 0.626819908618927\n",
      "Loss: 0.6210330724716187\n",
      "Loss: 0.6370412111282349\n",
      "Loss: 0.6257990598678589\n",
      "Loss: 0.6052932143211365\n",
      "Loss: 0.6295619010925293\n",
      "Loss: 0.6357945203781128\n",
      "Loss: 0.6481133699417114\n",
      "Loss: 0.5982921123504639\n",
      "Loss: 0.627942681312561\n",
      "Loss: 0.6793638467788696\n",
      "Loss: 0.7581913471221924\n",
      "Loss: 0.60600745677948\n",
      "Loss: 0.720464289188385\n",
      "Loss: 0.7050984501838684\n",
      "Loss: 0.7301803827285767\n",
      "Loss: 0.6392428278923035\n",
      "Loss: 0.6286956667900085\n",
      "Loss: 0.6001970171928406\n",
      "Loss: 0.7044175267219543\n",
      "Loss: 0.6894952654838562\n",
      "Loss: 0.6402899026870728\n",
      "Loss: 0.6555773019790649\n",
      "Loss: 0.5435242652893066\n",
      "Loss: 0.682121992111206\n",
      "Loss: 0.6819560527801514\n",
      "Loss: 0.6755186319351196\n",
      "Loss: 0.6494988203048706\n",
      "Loss: 0.6701720356941223\n",
      "Loss: 0.6409982442855835\n",
      "Loss: 0.6508129239082336\n",
      "Loss: 0.5909613370895386\n",
      "Loss: 0.6677547097206116\n",
      "Loss: 0.59565269947052\n",
      "Loss: 0.6075755953788757\n",
      "Loss: 0.7164662480354309\n",
      "Loss: 0.6043551564216614\n",
      "Loss: 0.6322748064994812\n",
      "Loss: 0.7174365520477295\n",
      "Loss: 0.7325816750526428\n",
      "Loss: 0.5927339792251587\n",
      "Loss: 0.6154311299324036\n",
      "Loss: 0.6452016830444336\n",
      "Loss: 0.674203634262085\n",
      "Loss: 0.6781633496284485\n",
      "Loss: 0.6387941241264343\n",
      "Loss: 0.6502928137779236\n",
      "Loss: 0.6034815907478333\n",
      "Loss: 0.6036202907562256\n",
      "Loss: 0.6123834848403931\n",
      "Loss: 0.6591314673423767\n",
      "Loss: 0.6595738530158997\n",
      "Loss: 0.6387850046157837\n",
      "Loss: 0.6378402709960938\n",
      "Loss: 0.647464394569397\n",
      "Loss: 0.6703374981880188\n",
      "Loss: 0.7149317264556885\n",
      "Loss: 0.6512062549591064\n",
      "Loss: 0.5973272323608398\n",
      "Loss: 0.6543747186660767\n",
      "Loss: 0.6240640878677368\n",
      "Loss: 0.574199378490448\n",
      "Loss: 0.6249655485153198\n",
      "Loss: 0.6380047798156738\n",
      "Loss: 0.6413110494613647\n",
      "Loss: 0.7063122391700745\n",
      "Loss: 0.5922571420669556\n",
      "Loss: 0.6428200006484985\n",
      "Loss: 0.6550354957580566\n",
      "Loss: 0.6839548945426941\n",
      "Loss: 0.5976954698562622\n",
      "Loss: 0.65125972032547\n",
      "Loss: 0.6305122375488281\n",
      "Loss: 0.6723490357398987\n",
      "Loss: 0.6019423604011536\n",
      "Loss: 0.6156546473503113\n",
      "Loss: 0.5866717100143433\n",
      "Loss: 0.6381025314331055\n",
      "Loss: 0.6050349473953247\n",
      "Loss: 0.6519822478294373\n",
      "Loss: 0.6422638297080994\n",
      "Loss: 0.5717050433158875\n",
      "Loss: 0.5786361694335938\n",
      "Loss: 0.634239673614502\n",
      "Loss: 0.5976136326789856\n",
      "Loss: 0.6790015697479248\n",
      "Loss: 0.6126664876937866\n",
      "Loss: 0.711877167224884\n",
      "Loss: 0.6339635848999023\n",
      "Loss: 0.6610538959503174\n",
      "Loss: 0.6161011457443237\n",
      "Loss: 0.7371231317520142\n",
      "Loss: 0.6280925869941711\n",
      "Loss: 0.5872526168823242\n",
      "Loss: 0.7373514771461487\n",
      "Loss: 0.632010817527771\n",
      "Loss: 0.5774939656257629\n",
      "Loss: 0.6618189215660095\n",
      "Loss: 0.6324005126953125\n",
      "Loss: 0.6611365079879761\n",
      "Loss: 0.598518967628479\n",
      "Loss: 0.6958008408546448\n",
      "Loss: 0.5711114406585693\n",
      "Loss: 0.5522698760032654\n",
      "Loss: 0.6590327620506287\n",
      "Loss: 0.7074495553970337\n",
      "Loss: 0.6784939169883728\n",
      "Loss: 0.6808154582977295\n",
      "Loss: 0.5879322290420532\n",
      "Loss: 0.7103124260902405\n",
      "Loss: 0.6829552054405212\n",
      "Loss: 0.6360166072845459\n",
      "Loss: 0.6603927612304688\n",
      "Loss: 0.593587338924408\n",
      "Loss: 0.6775023937225342\n",
      "Loss: 0.6666473746299744\n",
      "Loss: 0.7484966516494751\n",
      "Loss: 0.7070973515510559\n",
      "Loss: 0.6622065305709839\n",
      "Loss: 0.6661118268966675\n",
      "Loss: 0.6623049974441528\n",
      "Loss: 0.562428891658783\n",
      "Loss: 0.7015477418899536\n",
      "Loss: 0.6319223642349243\n",
      "Loss: 0.6482503414154053\n",
      "Loss: 0.6131055951118469\n",
      "Loss: 0.6524873971939087\n",
      "Loss: 0.6800973415374756\n",
      "Loss: 0.5409111380577087\n",
      "Loss: 0.5997528433799744\n",
      "Loss: 0.6427879333496094\n",
      "Loss: 0.7187966108322144\n",
      "Loss: 0.6452144980430603\n",
      "Loss: 0.6276333928108215\n",
      "Loss: 0.6172596216201782\n",
      "Loss: 0.6930519342422485\n",
      "Loss: 0.5824913382530212\n",
      "Loss: 0.6499907374382019\n",
      "Loss: 0.6008980870246887\n",
      "Loss: 0.7178519368171692\n",
      "Loss: 0.6935399174690247\n",
      "Loss: 0.677240788936615\n",
      "Loss: 0.5993165373802185\n",
      "Loss: 0.7658349871635437\n",
      "Loss: 0.682306170463562\n",
      "Loss: 0.6133248805999756\n",
      "Loss: 0.5988156795501709\n",
      "Loss: 0.6042726635932922\n",
      "Loss: 0.6301305294036865\n",
      "Loss: 0.6267974376678467\n",
      "Loss: 0.6197161078453064\n",
      "Loss: 0.6246353387832642\n",
      "Loss: 0.6686639189720154\n",
      "Loss: 0.6712271571159363\n",
      "Loss: 0.5701183676719666\n",
      "Loss: 0.6903079152107239\n",
      "Loss: 0.6241371035575867\n",
      "Loss: 0.6650407314300537\n",
      "Loss: 0.6085541844367981\n",
      "Loss: 0.6282762885093689\n",
      "Loss: 0.6641160845756531\n",
      "Loss: 0.6756775975227356\n",
      "Loss: 0.69764643907547\n",
      "Loss: 0.7044996619224548\n",
      "Loss: 0.6121295690536499\n",
      "Loss: 0.5669102668762207\n",
      "Loss: 0.6554811000823975\n",
      "Loss: 0.5979042053222656\n",
      "Loss: 0.7093006372451782\n",
      "Loss: 0.6804117560386658\n",
      "Loss: 0.6251338124275208\n",
      "Loss: 0.6336992383003235\n",
      "Loss: 0.6400395631790161\n",
      "Loss: 0.6601805090904236\n",
      "Loss: 0.7157583832740784\n",
      "Loss: 0.6154937148094177\n",
      "Loss: 0.650869607925415\n",
      "Loss: 0.7002766728401184\n",
      "Loss: 0.6219397783279419\n",
      "Loss: 0.5890465974807739\n",
      "Loss: 0.6314537525177002\n",
      "Loss: 0.6111664175987244\n",
      "Loss: 0.6944935321807861\n",
      "Loss: 0.629014790058136\n",
      "Loss: 0.6169698238372803\n",
      "Loss: 0.639051616191864\n",
      "Loss: 0.6322243213653564\n",
      "Loss: 0.6566494107246399\n",
      "Loss: 0.7004373073577881\n",
      "Loss: 0.658247709274292\n",
      "Loss: 0.6168040633201599\n",
      "Loss: 0.6141255497932434\n",
      "Loss: 0.6133403182029724\n",
      "Loss: 0.7706577777862549\n",
      "Loss: 0.680855393409729\n",
      "Loss: 0.6564738750457764\n",
      "Loss: 0.6482276916503906\n",
      "Loss: 0.6932381391525269\n",
      "Loss: 0.5704129338264465\n",
      "Loss: 0.6931963562965393\n",
      "Loss: 0.6313081979751587\n",
      "Loss: 0.6221177577972412\n",
      "Loss: 0.6374576091766357\n",
      "Loss: 0.6809853315353394\n",
      "Loss: 0.6701849699020386\n",
      "Loss: 0.6802895069122314\n",
      "Loss: 0.6608335375785828\n",
      "Loss: 0.5758307576179504\n",
      "Loss: 0.606762707233429\n",
      "Loss: 0.5806376934051514\n",
      "Loss: 0.6374635696411133\n",
      "Loss: 0.5868418216705322\n",
      "Loss: 0.706180214881897\n",
      "Loss: 0.6087993383407593\n",
      "Loss: 0.617845892906189\n",
      "Loss: 0.6499724388122559\n",
      "Loss: 0.6679230332374573\n",
      "Loss: 0.5929789543151855\n",
      "Loss: 0.5946623086929321\n",
      "Loss: 0.7049438953399658\n",
      "Loss: 0.624057412147522\n",
      "Loss: 0.6484131217002869\n",
      "Loss: 0.6769298315048218\n",
      "Loss: 0.6371227502822876\n",
      "Loss: 0.6340711712837219\n",
      "Loss: 0.6485081911087036\n",
      "Loss: 0.6226877570152283\n",
      "Loss: 0.5723713636398315\n",
      "Loss: 0.6185621619224548\n",
      "Loss: 0.6030009388923645\n",
      "Loss: 0.6248762011528015\n",
      "Loss: 0.6258053183555603\n",
      "Loss: 0.7104880809783936\n",
      "Loss: 0.7145107388496399\n",
      "Loss: 0.6440352201461792\n",
      "Loss: 0.5865826606750488\n",
      "Loss: 0.5893459320068359\n",
      "Loss: 0.6689387559890747\n",
      "Loss: 0.6670364737510681\n",
      "Loss: 0.7009068131446838\n",
      "Loss: 0.6293798685073853\n",
      "Loss: 0.5759505033493042\n",
      "Loss: 0.6789430379867554\n",
      "Loss: 0.6407594680786133\n",
      "Loss: 0.657637357711792\n",
      "Loss: 0.6618747115135193\n",
      "Loss: 0.6468007564544678\n",
      "Loss: 0.6110679507255554\n",
      "Loss: 0.6375105977058411\n",
      "Loss: 0.5963415503501892\n",
      "Loss: 0.5645323991775513\n",
      "Loss: 0.6911517977714539\n",
      "Loss: 0.6185270547866821\n",
      "Loss: 0.6543825268745422\n",
      "Loss: 0.6195274591445923\n",
      "Loss: 0.6189243197441101\n",
      "Loss: 0.623103141784668\n",
      "Loss: 0.5709511637687683\n",
      "Loss: 0.6723129749298096\n",
      "Loss: 0.6435816287994385\n",
      "Loss: 0.7018877863883972\n",
      "Loss: 0.6333467960357666\n",
      "Loss: 0.6112740635871887\n",
      "Loss: 0.638710618019104\n",
      "Loss: 0.6785967946052551\n",
      "Loss: 0.6926934719085693\n",
      "Loss: 0.6298343539237976\n",
      "Loss: 0.658389687538147\n",
      "Loss: 0.5631930828094482\n",
      "Loss: 0.6497289538383484\n",
      "Loss: 0.5516009330749512\n",
      "Loss: 0.7090376615524292\n",
      "Loss: 0.70993971824646\n",
      "Loss: 0.6956437826156616\n",
      "Loss: 0.6374689340591431\n",
      "Loss: 0.6199268698692322\n",
      "Loss: 0.6420397162437439\n",
      "Loss: 0.6267313361167908\n",
      "Loss: 0.6386514902114868\n",
      "Loss: 0.6679798364639282\n",
      "Loss: 0.6253668665885925\n",
      "Loss: 0.6722185015678406\n",
      "Loss: 0.6100997924804688\n",
      "Loss: 0.6187794804573059\n",
      "Loss: 0.7050274610519409\n",
      "Loss: 0.6075598001480103\n",
      "Loss: 0.6204083561897278\n",
      "Loss: 0.5343878269195557\n",
      "Loss: 0.6855078339576721\n",
      "Loss: 0.6041633486747742\n",
      "Loss: 0.6310224533081055\n",
      "Loss: 0.7411054968833923\n",
      "Loss: 0.7177197933197021\n",
      "Loss: 0.5989366769790649\n",
      "Loss: 0.620162308216095\n",
      "Loss: 0.5659593343734741\n",
      "Loss: 0.6413276195526123\n",
      "Loss: 0.6792805790901184\n",
      "Loss: 0.6281895637512207\n",
      "Loss: 0.659995436668396\n",
      "Loss: 0.6299575567245483\n",
      "Loss: 0.6052274703979492\n",
      "Loss: 0.6294784545898438\n",
      "Loss: 0.7038853764533997\n",
      "Loss: 0.6093143820762634\n",
      "Loss: 0.6766656041145325\n",
      "Loss: 0.6127960085868835\n",
      "Loss: 0.6246930360794067\n",
      "Loss: 0.7120785117149353\n",
      "Loss: 0.6105296611785889\n",
      "Loss: 0.6337246894836426\n",
      "Loss: 0.5677499771118164\n",
      "Loss: 0.7508364915847778\n",
      "Loss: 0.6135514378547668\n",
      "Loss: 0.6315644979476929\n",
      "Loss: 0.6438606977462769\n",
      "Loss: 0.6265074610710144\n",
      "Loss: 0.6768545508384705\n",
      "Loss: 0.6985781788825989\n",
      "Loss: 0.6632227897644043\n",
      "Loss: 0.6499919891357422\n",
      "Loss: 0.6637551784515381\n",
      "Loss: 0.6658705472946167\n",
      "Loss: 0.6705900430679321\n",
      "Loss: 0.693998396396637\n",
      "Loss: 0.6248175501823425\n",
      "Loss: 0.6772386431694031\n",
      "Loss: 0.6948663592338562\n",
      "Loss: 0.7171928286552429\n",
      "Loss: 0.6528834104537964\n",
      "Loss: 0.7102207541465759\n",
      "Loss: 0.6500730514526367\n",
      "Loss: 0.7034793496131897\n",
      "Loss: 0.6887182593345642\n",
      "Loss: 0.6804779767990112\n",
      "Loss: 0.6266102194786072\n",
      "Loss: 0.5950329899787903\n",
      "Loss: 0.6393483877182007\n",
      "Loss: 0.7212652564048767\n",
      "Loss: 0.6388555765151978\n",
      "Loss: 0.6420086026191711\n",
      "Loss: 0.658344030380249\n",
      "Loss: 0.6585313081741333\n",
      "Loss: 0.6789815425872803\n",
      "Loss: 0.6286978125572205\n",
      "Loss: 0.5828584432601929\n",
      "Loss: 0.6973779797554016\n",
      "Loss: 0.681659996509552\n",
      "Loss: 0.6684340238571167\n",
      "Loss: 0.617664098739624\n",
      "Loss: 0.6935881972312927\n",
      "Loss: 0.690626859664917\n",
      "Loss: 0.5994833707809448\n",
      "Loss: 0.7128903865814209\n",
      "Loss: 0.5985512137413025\n",
      "Loss: 0.6314764022827148\n",
      "Loss: 0.6166399121284485\n",
      "Loss: 0.6355883479118347\n",
      "Loss: 0.6301137208938599\n",
      "Loss: 0.599858283996582\n",
      "Loss: 0.6456708908081055\n",
      "Loss: 0.6187944412231445\n",
      "Loss: 0.5734034776687622\n",
      "Loss: 0.6445878744125366\n",
      "Loss: 0.6541746854782104\n",
      "Loss: 0.6920357346534729\n",
      "Loss: 0.7256733179092407\n",
      "Loss: 0.6343256235122681\n",
      "Loss: 0.667859673500061\n",
      "Loss: 0.6894518136978149\n",
      "Loss: 0.6114318370819092\n",
      "Loss: 0.6858921647071838\n",
      "Loss: 0.6288918256759644\n",
      "Loss: 0.7204177379608154\n",
      "Loss: 0.7267878651618958\n",
      "Loss: 0.6260550618171692\n",
      "Loss: 0.610554039478302\n",
      "Loss: 0.6809492707252502\n",
      "Loss: 0.685682475566864\n",
      "Loss: 0.6473106741905212\n",
      "Loss: 0.5692028403282166\n",
      "Loss: 0.623242199420929\n",
      "Loss: 0.6967507004737854\n",
      "Loss: 0.6218208074569702\n",
      "Loss: 0.5763913989067078\n",
      "Loss: 0.6734070181846619\n",
      "Loss: 0.7179847955703735\n",
      "Loss: 0.6535652875900269\n",
      "Loss: 0.6408865451812744\n",
      "Loss: 0.6438052654266357\n",
      "Loss: 0.6807352304458618\n",
      "Loss: 0.6336338520050049\n",
      "Loss: 0.6684414744377136\n",
      "Loss: 0.5979384183883667\n",
      "Loss: 0.6690337657928467\n",
      "Loss: 0.5596179962158203\n",
      "Loss: 0.6497371792793274\n",
      "Loss: 0.5817983150482178\n",
      "Loss: 0.6647756695747375\n",
      "Loss: 0.6734239459037781\n",
      "Loss: 0.6543223261833191\n",
      "Loss: 0.6020668148994446\n",
      "Loss: 0.712084174156189\n",
      "Loss: 0.6757944822311401\n",
      "Loss: 0.6496155858039856\n",
      "Loss: 0.6351925730705261\n",
      "Loss: 0.7049111127853394\n",
      "Loss: 0.7019379138946533\n",
      "Loss: 0.5901480913162231\n",
      "Loss: 0.6124746799468994\n",
      "Loss: 0.6379522681236267\n",
      "Loss: 0.6059266328811646\n",
      "Loss: 0.6418614387512207\n",
      "Loss: 0.6448259353637695\n",
      "Loss: 0.6496323347091675\n",
      "Loss: 0.630561351776123\n",
      "Loss: 0.69801265001297\n",
      "Loss: 0.7118017077445984\n",
      "Loss: 0.5692205429077148\n",
      "Loss: 0.632283091545105\n",
      "Loss: 0.6677238345146179\n",
      "Loss: 0.6575572490692139\n",
      "Loss: 0.6848004460334778\n",
      "Loss: 0.5999586582183838\n",
      "Loss: 0.6292155385017395\n",
      "Loss: 0.611989438533783\n",
      "Loss: 0.6467186212539673\n",
      "Loss: 0.641314685344696\n",
      "Loss: 0.5385836362838745\n",
      "Loss: 0.6087096333503723\n",
      "Loss: 0.5809116363525391\n",
      "Loss: 0.7088519930839539\n",
      "Loss: 0.7215983867645264\n",
      "Loss: 0.6581270098686218\n",
      "Loss: 0.6162939071655273\n",
      "Loss: 0.5801686644554138\n",
      "Loss: 0.586158037185669\n",
      "Loss: 0.587406575679779\n",
      "Loss: 0.6092923879623413\n",
      "Loss: 0.6297311186790466\n",
      "Loss: 0.5945661664009094\n",
      "Loss: 0.6746243238449097\n",
      "Loss: 0.7374351024627686\n",
      "Loss: 0.5970346927642822\n",
      "Loss: 0.6253073811531067\n",
      "Loss: 0.6492162942886353\n",
      "Loss: 0.6657411456108093\n",
      "Loss: 0.587973952293396\n",
      "Loss: 0.6128648519515991\n",
      "Loss: 0.6285310983657837\n",
      "Loss: 0.5752264261245728\n",
      "Loss: 0.634506344795227\n",
      "Loss: 0.5902878642082214\n",
      "Loss: 0.6248771548271179\n",
      "Loss: 0.6262556314468384\n",
      "Loss: 0.6710641980171204\n",
      "Loss: 0.6421737670898438\n",
      "Loss: 0.6525341272354126\n",
      "Loss: 0.6181875467300415\n",
      "Loss: 0.6263023614883423\n",
      "Loss: 0.6368942260742188\n",
      "Loss: 0.6579958200454712\n",
      "Loss: 0.6431212425231934\n",
      "Loss: 0.6844984292984009\n",
      "Loss: 0.5965130925178528\n",
      "Loss: 0.6241220831871033\n",
      "Loss: 0.6894515156745911\n",
      "Loss: 0.6341649293899536\n",
      "Loss: 0.6201885938644409\n",
      "Loss: 0.7193416357040405\n",
      "Loss: 0.6215869784355164\n",
      "Loss: 0.5920822620391846\n",
      "Loss: 0.6341997385025024\n",
      "Loss: 0.6191352605819702\n",
      "Loss: 0.6720834970474243\n",
      "Loss: 0.6018600463867188\n",
      "Loss: 0.5803487300872803\n",
      "Loss: 0.6533924341201782\n",
      "Loss: 0.6654860973358154\n",
      "Loss: 0.616448163986206\n",
      "Loss: 0.6510918140411377\n",
      "Loss: 0.6855737566947937\n",
      "Loss: 0.6086814403533936\n",
      "Loss: 0.6654912829399109\n",
      "Loss: 0.6396201252937317\n",
      "Loss: 0.6643521785736084\n",
      "Loss: 0.6133589744567871\n",
      "Loss: 0.6176584959030151\n",
      "Loss: 0.6706293225288391\n",
      "Loss: 0.7262002229690552\n",
      "Loss: 0.6567294001579285\n",
      "Loss: 0.6637715697288513\n",
      "Loss: 0.6242673397064209\n",
      "Loss: 0.5218762159347534\n",
      "Loss: 0.6939162611961365\n",
      "Loss: 0.6372004747390747\n",
      "Loss: 0.6990968585014343\n",
      "Loss: 0.6402267217636108\n",
      "Loss: 0.7514029145240784\n",
      "Loss: 0.6528629660606384\n",
      "Loss: 0.645080029964447\n",
      "Loss: 0.6618005633354187\n",
      "Loss: 0.5812669992446899\n",
      "Loss: 0.6765636801719666\n",
      "Loss: 0.6501428484916687\n",
      "Loss: 0.5948437452316284\n",
      "Loss: 0.6186937689781189\n",
      "Loss: 0.5506662130355835\n",
      "Loss: 0.6223169565200806\n",
      "Loss: 0.5923903584480286\n",
      "Loss: 0.6280676126480103\n",
      "Loss: 0.6625876426696777\n",
      "Loss: 0.6126088500022888\n",
      "Loss: 0.59453284740448\n",
      "Loss: 0.6265451312065125\n",
      "Loss: 0.5804921984672546\n",
      "Loss: 0.5870055556297302\n",
      "Loss: 0.6255961656570435\n",
      "Loss: 0.6396183371543884\n",
      "Loss: 0.7262147068977356\n",
      "Loss: 0.6184439659118652\n",
      "Loss: 0.6887115836143494\n",
      "Loss: 0.7397900223731995\n",
      "Loss: 0.6506502032279968\n",
      "Loss: 0.5725359916687012\n",
      "Loss: 0.720053493976593\n",
      "Loss: 0.6985639929771423\n",
      "Loss: 0.5756990313529968\n",
      "Loss: 0.7157555222511292\n",
      "Loss: 0.7280812859535217\n",
      "Loss: 0.6163743138313293\n",
      "Loss: 0.7449690103530884\n",
      "Loss: 0.6262162923812866\n",
      "Loss: 0.6500371694564819\n",
      "Loss: 0.6803491711616516\n",
      "Loss: 0.6435333490371704\n",
      "Loss: 0.6533105969429016\n",
      "Loss: 0.6331474781036377\n",
      "Loss: 0.6348492503166199\n",
      "Loss: 0.6255611181259155\n",
      "Loss: 0.6553173065185547\n",
      "Loss: 0.6161918640136719\n",
      "Loss: 0.6788255572319031\n",
      "Loss: 0.659190833568573\n",
      "Loss: 0.7040762305259705\n",
      "Loss: 0.6649473905563354\n",
      "Loss: 0.6172202229499817\n",
      "Loss: 0.6254280209541321\n",
      "Loss: 0.6391299366950989\n",
      "Loss: 0.5900211334228516\n",
      "Loss: 0.7383927702903748\n",
      "Loss: 0.7798073887825012\n",
      "Loss: 0.626632809638977\n",
      "Loss: 0.6180594563484192\n",
      "Loss: 0.6076020002365112\n",
      "Loss: 0.69948410987854\n",
      "Loss: 0.6639745831489563\n",
      "Loss: 0.6046554446220398\n",
      "Loss: 0.6134021282196045\n",
      "Loss: 0.7006317973136902\n",
      "Loss: 0.6852825880050659\n",
      "Loss: 0.6599361300468445\n",
      "Loss: 0.6636267900466919\n",
      "Loss: 0.5633209943771362\n",
      "Loss: 0.6174864172935486\n",
      "Loss: 0.6182702779769897\n",
      "Loss: 0.5495957136154175\n",
      "Loss: 0.6641191244125366\n",
      "Loss: 0.5645527243614197\n",
      "Loss: 0.6527246236801147\n",
      "Loss: 0.6904829740524292\n",
      "Loss: 0.680880606174469\n",
      "Loss: 0.6945504546165466\n",
      "Loss: 0.6138405799865723\n",
      "Loss: 0.5922157168388367\n",
      "Loss: 0.6350329518318176\n",
      "Loss: 0.7216570973396301\n",
      "Loss: 0.7363727688789368\n",
      "Loss: 0.682549774646759\n",
      "Loss: 0.6364358067512512\n",
      "Loss: 0.7450207471847534\n",
      "Loss: 0.7211782932281494\n",
      "Loss: 0.6486598253250122\n",
      "Loss: 0.7393001914024353\n",
      "Loss: 0.756502091884613\n",
      "Loss: 0.666083037853241\n",
      "Loss: 0.7109431028366089\n",
      "Loss: 0.6252704858779907\n",
      "Loss: 0.5985310673713684\n",
      "Loss: 0.6680281758308411\n",
      "Loss: 0.6917270421981812\n",
      "Loss: 0.6140987277030945\n",
      "Loss: 0.6474999189376831\n",
      "Loss: 0.6863962411880493\n",
      "Loss: 0.6951810717582703\n",
      "Loss: 0.6964472532272339\n",
      "Loss: 0.6731391549110413\n",
      "Loss: 0.5955650210380554\n",
      "Loss: 0.6258251667022705\n",
      "Loss: 0.6723009943962097\n",
      "Loss: 0.6699811816215515\n",
      "Loss: 0.5995418429374695\n",
      "Loss: 0.6785231828689575\n",
      "Loss: 0.580406904220581\n",
      "Loss: 0.654833972454071\n",
      "Loss: 0.6888638138771057\n",
      "Loss: 0.6287245154380798\n",
      "Loss: 0.6160686612129211\n",
      "Loss: 0.5641987919807434\n",
      "Loss: 0.588749885559082\n",
      "Loss: 0.5787522196769714\n",
      "Loss: 0.6897308826446533\n",
      "Loss: 0.7078458666801453\n",
      "Loss: 0.6415022015571594\n",
      "Loss: 0.6489989757537842\n",
      "Loss: 0.6789796352386475\n",
      "Loss: 0.6555739641189575\n",
      "Loss: 0.5913813710212708\n",
      "Loss: 0.6524575352668762\n",
      "Loss: 0.600045919418335\n",
      "Loss: 0.6525388956069946\n",
      "Loss: 0.6803256869316101\n",
      "Loss: 0.5794873237609863\n",
      "Loss: 0.5426782965660095\n",
      "Loss: 0.6822911500930786\n",
      "Loss: 0.5410223007202148\n",
      "Loss: 0.711918294429779\n",
      "Loss: 0.5620171427726746\n",
      "Loss: 0.6658006906509399\n",
      "Loss: 0.6036617755889893\n",
      "Loss: 0.5373603105545044\n",
      "Loss: 0.6479624509811401\n",
      "Loss: 0.6160802841186523\n",
      "Loss: 0.6953344941139221\n",
      "Loss: 0.66312575340271\n",
      "Loss: 0.6995906233787537\n",
      "Loss: 0.6735841631889343\n",
      "Loss: 0.5403153300285339\n",
      "Loss: 0.6962921619415283\n",
      "Loss: 0.6134408116340637\n",
      "Loss: 0.6416008472442627\n",
      "Loss: 0.608508288860321\n",
      "Loss: 0.5882706046104431\n",
      "Loss: 0.6981348395347595\n",
      "Loss: 0.6422604322433472\n",
      "Loss: 0.5752723217010498\n",
      "Loss: 0.635831356048584\n",
      "Loss: 0.6119319796562195\n",
      "Loss: 0.6339609026908875\n",
      "Loss: 0.6378012895584106\n",
      "Loss: 0.5799764394760132\n",
      "Loss: 0.6455674171447754\n",
      "Loss: 0.5956521034240723\n",
      "Loss: 0.6798229813575745\n",
      "Loss: 0.6422646045684814\n",
      "Loss: 0.7132738828659058\n",
      "Loss: 0.5742447972297668\n",
      "Loss: 0.6657769680023193\n",
      "Loss: 0.6499894261360168\n",
      "Loss: 0.6730024218559265\n",
      "Loss: 0.7018232941627502\n",
      "Loss: 0.6719272136688232\n",
      "Loss: 0.5851860046386719\n",
      "Loss: 0.6989824175834656\n",
      "Loss: 0.6709744930267334\n",
      "Loss: 0.564600944519043\n",
      "Loss: 0.6776897311210632\n",
      "Loss: 0.6426109671592712\n",
      "Loss: 0.6775467395782471\n",
      "Loss: 0.687524676322937\n",
      "Loss: 0.6356217861175537\n",
      "Loss: 0.6826079487800598\n",
      "Loss: 0.6312397718429565\n",
      "Loss: 0.568239688873291\n",
      "Loss: 0.6307147145271301\n",
      "Loss: 0.6685742139816284\n",
      "Loss: 0.6830040216445923\n",
      "Loss: 0.6485364437103271\n",
      "Loss: 0.6213384866714478\n",
      "Loss: 0.6356388926506042\n",
      "Loss: 0.6515139937400818\n",
      "Loss: 0.6851913332939148\n",
      "Loss: 0.670978844165802\n",
      "Loss: 0.6731036305427551\n",
      "Loss: 0.6132509112358093\n",
      "Loss: 0.6355075836181641\n",
      "Loss: 0.622848391532898\n",
      "Loss: 0.6650608777999878\n",
      "Loss: 0.625967264175415\n",
      "Loss: 0.7406352162361145\n",
      "Loss: 0.5742179155349731\n",
      "Loss: 0.6635336875915527\n",
      "Loss: 0.7072694897651672\n",
      "Loss: 0.6128713488578796\n",
      "Loss: 0.6878023743629456\n",
      "Loss: 0.6229107975959778\n",
      "Loss: 0.702771782875061\n",
      "Loss: 0.6600141525268555\n",
      "Loss: 0.6083728671073914\n",
      "Loss: 0.6792946457862854\n",
      "Loss: 0.6360101699829102\n",
      "Loss: 0.6769289374351501\n",
      "Loss: 0.6995605230331421\n",
      "Loss: 0.6297043561935425\n",
      "Loss: 0.5426732897758484\n",
      "Loss: 0.662406325340271\n",
      "Loss: 0.6811118721961975\n",
      "Loss: 0.6011626124382019\n",
      "Loss: 0.6630854606628418\n",
      "Loss: 0.5797929763793945\n",
      "Loss: 0.6442036032676697\n",
      "Loss: 0.6756946444511414\n",
      "Loss: 0.6453523635864258\n",
      "Loss: 0.6849510073661804\n",
      "Loss: 0.7184022068977356\n",
      "Loss: 0.6133293509483337\n",
      "Loss: 0.6027438640594482\n",
      "Loss: 0.6376994848251343\n",
      "Loss: 0.5591763257980347\n",
      "Loss: 0.5641111135482788\n",
      "Loss: 0.6244776844978333\n",
      "Loss: 0.6194714903831482\n",
      "Loss: 0.7239919304847717\n",
      "Loss: 0.6656715869903564\n",
      "Loss: 0.6241468787193298\n",
      "Loss: 0.6300844550132751\n",
      "Loss: 0.711286187171936\n",
      "Loss: 0.6842107176780701\n",
      "Loss: 0.6589614152908325\n",
      "Loss: 0.7050888538360596\n",
      "Loss: 0.6374573111534119\n",
      "Loss: 0.6313156485557556\n",
      "Loss: 0.5604825019836426\n",
      "Loss: 0.6891303658485413\n",
      "Loss: 0.606827974319458\n",
      "Loss: 0.7142584323883057\n",
      "Loss: 0.6048367619514465\n",
      "Loss: 0.6334496736526489\n",
      "Loss: 0.6701603531837463\n",
      "Loss: 0.6283648014068604\n",
      "Loss: 0.6984602808952332\n",
      "Loss: 0.6508490443229675\n",
      "Loss: 0.6262375116348267\n",
      "Loss: 0.6153282523155212\n",
      "Loss: 0.618388831615448\n",
      "Loss: 0.6698814630508423\n",
      "Loss: 0.6285514831542969\n",
      "Loss: 0.6359831094741821\n",
      "Loss: 0.5829302668571472\n",
      "Loss: 0.6837834119796753\n",
      "Loss: 0.5931608080863953\n",
      "Loss: 0.6238331198692322\n",
      "Loss: 0.6445724964141846\n",
      "Loss: 0.6082646250724792\n",
      "Loss: 0.607954740524292\n",
      "Loss: 0.6091667413711548\n",
      "Loss: 0.5927910208702087\n",
      "Loss: 0.6842868328094482\n",
      "Loss: 0.6335933208465576\n",
      "Loss: 0.6743065118789673\n",
      "Loss: 0.6391801238059998\n",
      "Loss: 0.6604709029197693\n",
      "Loss: 0.6198213696479797\n",
      "Loss: 0.5689558982849121\n",
      "Loss: 0.5912148952484131\n",
      "Loss: 0.6182956695556641\n",
      "Loss: 0.5893216133117676\n",
      "Loss: 0.6230878829956055\n",
      "Loss: 0.6087616086006165\n",
      "Loss: 0.6379780173301697\n",
      "Loss: 0.6341044902801514\n",
      "Loss: 0.646864116191864\n",
      "Loss: 0.6913973689079285\n",
      "Loss: 0.6235578060150146\n",
      "Loss: 0.68422931432724\n",
      "Loss: 0.7089831829071045\n",
      "Loss: 0.6769450306892395\n",
      "Loss: 0.6379191875457764\n",
      "Loss: 0.6447603106498718\n",
      "Loss: 0.679311215877533\n",
      "Loss: 0.5545541048049927\n",
      "Loss: 0.6190650463104248\n",
      "Loss: 0.5839990973472595\n",
      "Loss: 0.6291720271110535\n",
      "Loss: 0.5928959250450134\n",
      "Loss: 0.7042285799980164\n",
      "Loss: 0.6630038619041443\n",
      "Loss: 0.6088743209838867\n",
      "Loss: 0.7067587971687317\n",
      "Loss: 0.7280877232551575\n",
      "Loss: 0.6626290678977966\n",
      "Loss: 0.6414302587509155\n",
      "Loss: 0.7126771807670593\n",
      "Loss: 0.7082754373550415\n",
      "Loss: 0.6092671751976013\n",
      "Loss: 0.6191847324371338\n",
      "Loss: 0.6206046938896179\n",
      "Loss: 0.6573058366775513\n",
      "Loss: 0.7206653356552124\n",
      "Loss: 0.613843560218811\n",
      "Loss: 0.6464988589286804\n",
      "Loss: 0.6518775820732117\n",
      "Loss: 0.5830819010734558\n",
      "Loss: 0.6211161613464355\n",
      "Loss: 0.6471700072288513\n",
      "Loss: 0.6157739162445068\n",
      "Loss: 0.6824252605438232\n",
      "Loss: 0.6424398422241211\n",
      "Loss: 0.717758059501648\n",
      "Loss: 0.6482625007629395\n",
      "Loss: 0.6377127766609192\n",
      "Loss: 0.6623197793960571\n",
      "Loss: 0.6268896460533142\n",
      "Loss: 0.651685893535614\n",
      "Loss: 0.6632764935493469\n",
      "Loss: 0.5944240689277649\n",
      "Loss: 0.6569358706474304\n",
      "Loss: 0.6742157340049744\n",
      "Loss: 0.6382670402526855\n",
      "Loss: 0.6913400888442993\n",
      "Loss: 0.7010220289230347\n",
      "Loss: 0.669145941734314\n",
      "Loss: 0.6909773945808411\n",
      "Loss: 0.638361394405365\n",
      "Loss: 0.7027198076248169\n",
      "Loss: 0.7018221616744995\n",
      "Loss: 0.7627483010292053\n",
      "Loss: 0.7026838064193726\n",
      "Loss: 0.5850784778594971\n",
      "Loss: 0.6952652335166931\n",
      "Loss: 0.6919306516647339\n",
      "Loss: 0.6563560366630554\n",
      "Loss: 0.700599730014801\n",
      "Loss: 0.6751419305801392\n",
      "Loss: 0.588037371635437\n",
      "Loss: 0.6162064671516418\n",
      "Loss: 0.6726211905479431\n",
      "Loss: 0.5889790058135986\n",
      "Loss: 0.6575021743774414\n",
      "Loss: 0.6926127076148987\n",
      "Loss: 0.690507709980011\n",
      "Loss: 0.640558123588562\n",
      "Loss: 0.6897989511489868\n",
      "Loss: 0.6548293232917786\n",
      "Loss: 0.6678093671798706\n",
      "Loss: 0.6081781387329102\n",
      "Loss: 0.6646883487701416\n",
      "Loss: 0.5983912348747253\n",
      "Loss: 0.7240911722183228\n",
      "Loss: 0.6468184590339661\n",
      "Loss: 0.5947513580322266\n",
      "Loss: 0.6646022200584412\n",
      "Loss: 0.632664680480957\n",
      "Loss: 0.5770611763000488\n",
      "Loss: 0.7436491250991821\n",
      "Loss: 0.654784619808197\n",
      "Loss: 0.5866353511810303\n",
      "Loss: 0.6060476303100586\n",
      "Loss: 0.6518809795379639\n",
      "Loss: 0.5611308217048645\n",
      "Loss: 0.6585967540740967\n",
      "Loss: 0.6621230244636536\n",
      "Loss: 0.6531939506530762\n",
      "Loss: 0.6498297452926636\n",
      "Loss: 0.684585452079773\n",
      "Loss: 0.6783869862556458\n",
      "Loss: 0.6454681754112244\n",
      "Loss: 0.7440335750579834\n",
      "Loss: 0.6371705532073975\n",
      "Loss: 0.6635816693305969\n",
      "Loss: 0.5997282266616821\n",
      "Loss: 0.635120689868927\n",
      "Loss: 0.6770751476287842\n",
      "Loss: 0.615774393081665\n",
      "Loss: 0.6660040020942688\n",
      "Loss: 0.6742042899131775\n",
      "Loss: 0.58293217420578\n",
      "Loss: 0.6863898634910583\n",
      "Loss: 0.5683709979057312\n",
      "Loss: 0.5792157649993896\n",
      "Loss: 0.6836065649986267\n",
      "Loss: 0.6156240701675415\n",
      "Loss: 0.6186715364456177\n",
      "Loss: 0.6632270216941833\n",
      "Loss: 0.7363909482955933\n",
      "Loss: 0.6298863291740417\n",
      "Loss: 0.6655834913253784\n",
      "Loss: 0.6705296635627747\n",
      "Loss: 0.588601291179657\n",
      "Loss: 0.6791623830795288\n",
      "Loss: 0.5837090611457825\n",
      "Loss: 0.6981155276298523\n",
      "Loss: 0.6392103433609009\n",
      "Loss: 0.7001012563705444\n",
      "Loss: 0.6635321378707886\n",
      "Loss: 0.5868973135948181\n",
      "Loss: 0.6531127691268921\n",
      "Loss: 0.6487969756126404\n",
      "Loss: 0.6224313974380493\n",
      "Loss: 0.6717262864112854\n",
      "Loss: 0.6083641052246094\n",
      "Loss: 0.6869409084320068\n",
      "Loss: 0.6772169470787048\n",
      "Loss: 0.5778025388717651\n",
      "Loss: 0.576760470867157\n",
      "Loss: 0.6067392230033875\n",
      "Loss: 0.7105661630630493\n",
      "Loss: 0.7078332304954529\n",
      "Loss: 0.6445798873901367\n",
      "Loss: 0.5659486651420593\n",
      "Loss: 0.630723237991333\n",
      "Loss: 0.790969729423523\n",
      "Loss: 0.5993562936782837\n",
      "Loss: 0.6847154498100281\n",
      "Loss: 0.673263430595398\n",
      "Loss: 0.7270366549491882\n",
      "Loss: 0.664448082447052\n",
      "Loss: 0.698326826095581\n",
      "Loss: 0.6027729511260986\n",
      "Loss: 0.632195234298706\n",
      "Loss: 0.5621951818466187\n",
      "Loss: 0.6293420195579529\n",
      "Loss: 0.6307722330093384\n",
      "Loss: 0.6308256983757019\n",
      "Loss: 0.6104301810264587\n",
      "Loss: 0.541743278503418\n",
      "Loss: 0.6732016205787659\n",
      "Loss: 0.7079018354415894\n",
      "Loss: 0.5796416401863098\n",
      "Loss: 0.6188262701034546\n",
      "Loss: 0.6976546049118042\n",
      "Loss: 0.6455089449882507\n",
      "Loss: 0.6968590617179871\n",
      "Loss: 0.643115758895874\n",
      "Loss: 0.6319583654403687\n",
      "Loss: 0.6510409116744995\n",
      "Loss: 0.6440966129302979\n",
      "Loss: 0.595907986164093\n",
      "Loss: 0.6080359220504761\n",
      "Loss: 0.6652500033378601\n",
      "Loss: 0.6916671991348267\n",
      "Loss: 0.703005850315094\n",
      "Loss: 0.6422404050827026\n",
      "Loss: 0.6396001577377319\n",
      "Loss: 0.6929189562797546\n",
      "Loss: 0.6463882327079773\n",
      "Loss: 0.6447805166244507\n",
      "Loss: 0.6037181615829468\n",
      "Loss: 0.7097001671791077\n",
      "Loss: 0.6755435466766357\n",
      "Loss: 0.5670648813247681\n",
      "Loss: 0.7037385702133179\n",
      "Loss: 0.6789563894271851\n",
      "Loss: 0.674738347530365\n",
      "Loss: 0.6598781943321228\n",
      "Loss: 0.6497300863265991\n",
      "Loss: 0.6009746789932251\n",
      "Loss: 0.6504947543144226\n",
      "Loss: 0.6605231165885925\n",
      "Loss: 0.5833857655525208\n",
      "Loss: 0.6589763760566711\n",
      "Loss: 0.6488848924636841\n",
      "Loss: 0.682729959487915\n",
      "Loss: 0.7168043851852417\n",
      "Loss: 0.6298567056655884\n",
      "Loss: 0.6747609972953796\n",
      "Loss: 0.5997809767723083\n",
      "Loss: 0.6640686988830566\n",
      "Loss: 0.7193518877029419\n",
      "Loss: 0.5893843770027161\n",
      "Loss: 0.6397236585617065\n",
      "Loss: 0.6215499639511108\n",
      "Loss: 0.5757240653038025\n",
      "Loss: 0.5955011248588562\n",
      "Loss: 0.5869320034980774\n",
      "Loss: 0.6317449808120728\n",
      "Loss: 0.5689787268638611\n",
      "Loss: 0.6907873749732971\n",
      "Loss: 0.6155961155891418\n",
      "Loss: 0.5899803042411804\n",
      "Loss: 0.686823308467865\n",
      "Loss: 0.5817014575004578\n",
      "Loss: 0.6899805665016174\n",
      "Loss: 0.6541091799736023\n",
      "Loss: 0.5836923122406006\n",
      "Loss: 0.5757428407669067\n",
      "Loss: 0.6295717358589172\n",
      "Loss: 0.6667602062225342\n",
      "Loss: 0.6013401746749878\n",
      "Loss: 0.6174576282501221\n",
      "Loss: 0.6825083494186401\n",
      "Loss: 0.6328434348106384\n",
      "Loss: 0.7403625845909119\n",
      "Loss: 0.7414066791534424\n",
      "Loss: 0.6058506369590759\n",
      "Loss: 0.6994799971580505\n",
      "Loss: 0.697790801525116\n",
      "Loss: 0.6535940170288086\n",
      "Loss: 0.6406411528587341\n",
      "Loss: 0.648434042930603\n",
      "Loss: 0.6690427660942078\n",
      "Loss: 0.6381686329841614\n",
      "Loss: 0.5845902562141418\n",
      "Loss: 0.6573117971420288\n",
      "Loss: 0.5781619548797607\n",
      "Loss: 0.5871548056602478\n",
      "Loss: 0.6073401570320129\n",
      "Loss: 0.6690099239349365\n",
      "Loss: 0.6019615530967712\n",
      "Loss: 0.6595126986503601\n",
      "Loss: 0.6571535468101501\n",
      "Loss: 0.5804318189620972\n",
      "Loss: 0.6223637461662292\n",
      "Loss: 0.6036146879196167\n",
      "Loss: 0.6129605770111084\n",
      "Loss: 0.5901939272880554\n",
      "Loss: 0.6273729205131531\n",
      "Loss: 0.6068868637084961\n",
      "Loss: 0.6213734745979309\n",
      "Loss: 0.6239216923713684\n",
      "Loss: 0.6084582805633545\n",
      "Loss: 0.6678855419158936\n",
      "Loss: 0.6539634466171265\n",
      "Loss: 0.734943151473999\n",
      "Loss: 0.6349042057991028\n",
      "Loss: 0.7167599201202393\n",
      "Loss: 0.6612520217895508\n",
      "Loss: 0.6757939457893372\n",
      "Loss: 0.5798823237419128\n",
      "Loss: 0.6626774072647095\n",
      "Loss: 0.7192110419273376\n",
      "Loss: 0.7002886533737183\n",
      "Loss: 0.7152364253997803\n",
      "Loss: 0.6369328498840332\n",
      "Loss: 0.6793200969696045\n",
      "Loss: 0.5780476331710815\n",
      "Loss: 0.6748105883598328\n",
      "Loss: 0.695484459400177\n",
      "Loss: 0.6064718961715698\n",
      "Loss: 0.6521551012992859\n",
      "Loss: 0.6587458848953247\n",
      "Loss: 0.7007535099983215\n",
      "Loss: 0.6347378492355347\n",
      "Loss: 0.6900804042816162\n",
      "Loss: 0.6261817812919617\n",
      "Loss: 0.6450570821762085\n",
      "Loss: 0.69265216588974\n",
      "Loss: 0.5727123618125916\n",
      "Loss: 0.5876500606536865\n",
      "Loss: 0.6698891520500183\n",
      "Loss: 0.7074382901191711\n",
      "Loss: 0.6820086240768433\n",
      "Loss: 0.6103326678276062\n",
      "Loss: 0.6163037419319153\n",
      "Loss: 0.5945678949356079\n",
      "Loss: 0.73384028673172\n",
      "Loss: 0.6374776363372803\n",
      "Loss: 0.6626328229904175\n",
      "Loss: 0.6932206749916077\n",
      "Loss: 0.6752399206161499\n",
      "Loss: 0.7015543580055237\n",
      "Loss: 0.6802414655685425\n",
      "Loss: 0.7409479022026062\n",
      "Loss: 0.6637437343597412\n",
      "Loss: 0.6306145191192627\n",
      "Loss: 0.6288262605667114\n",
      "Loss: 0.7024953365325928\n",
      "Loss: 0.635481059551239\n",
      "Loss: 0.6824404001235962\n",
      "Loss: 0.6282705068588257\n",
      "Loss: 0.6357671022415161\n",
      "Loss: 0.6198427677154541\n",
      "Loss: 0.604451596736908\n",
      "Loss: 0.7098433375358582\n",
      "Loss: 0.5834495425224304\n",
      "Loss: 0.6941802501678467\n",
      "Loss: 0.6644580364227295\n",
      "Loss: 0.5892941951751709\n",
      "Loss: 0.6905535459518433\n",
      "Loss: 0.6010834574699402\n",
      "Loss: 0.6149566173553467\n",
      "Loss: 0.6817206740379333\n",
      "Loss: 0.6581639051437378\n",
      "Loss: 0.7226877808570862\n",
      "Loss: 0.5509217977523804\n",
      "Loss: 0.69333815574646\n",
      "Loss: 0.6804850697517395\n",
      "Loss: 0.697874903678894\n",
      "Loss: 0.6697981357574463\n",
      "Loss: 0.6288566589355469\n",
      "Loss: 0.7209341526031494\n",
      "Loss: 0.6856677532196045\n",
      "Loss: 0.6209239959716797\n",
      "Loss: 0.6524567604064941\n",
      "Loss: 0.7248073816299438\n",
      "Loss: 0.5883821845054626\n",
      "Loss: 0.7189614772796631\n",
      "Loss: 0.5772629976272583\n",
      "Loss: 0.6669987440109253\n",
      "Loss: 0.6286848783493042\n",
      "Loss: 0.6018761992454529\n",
      "Loss: 0.6455072164535522\n",
      "Loss: 0.6101834177970886\n",
      "Loss: 0.5355420708656311\n",
      "Loss: 0.6425853967666626\n",
      "Loss: 0.6189157366752625\n",
      "Loss: 0.706831157207489\n",
      "Loss: 0.5853015780448914\n",
      "Loss: 0.5798938274383545\n",
      "Loss: 0.6685864925384521\n",
      "Loss: 0.6312677264213562\n",
      "Loss: 0.6720756888389587\n",
      "Loss: 0.6528555154800415\n",
      "Loss: 0.6373533010482788\n",
      "Loss: 0.6461955904960632\n",
      "Loss: 0.7056391835212708\n",
      "Loss: 0.6468661427497864\n",
      "Loss: 0.7207363247871399\n",
      "Loss: 0.6456221342086792\n",
      "Loss: 0.6537652015686035\n",
      "Loss: 0.6511062979698181\n",
      "Loss: 0.6224187016487122\n",
      "Loss: 0.7261370420455933\n",
      "Loss: 0.6133744716644287\n",
      "Loss: 0.6120187640190125\n",
      "Loss: 0.5858765840530396\n",
      "Loss: 0.6228715777397156\n",
      "Loss: 0.5689877271652222\n",
      "Loss: 0.6449570059776306\n",
      "Loss: 0.6298441290855408\n",
      "Loss: 0.6953267455101013\n",
      "Loss: 0.6598188281059265\n",
      "Loss: 0.6373888254165649\n",
      "Loss: 0.7378367185592651\n",
      "Loss: 0.6321274042129517\n",
      "Loss: 0.6654949188232422\n",
      "Loss: 0.6242198944091797\n",
      "Loss: 0.6359988451004028\n",
      "Loss: 0.6823808550834656\n",
      "Loss: 0.6433203220367432\n",
      "Loss: 0.5978586077690125\n",
      "Loss: 0.6633437275886536\n",
      "Loss: 0.7134993672370911\n",
      "Loss: 0.6335270404815674\n",
      "Loss: 0.6914125680923462\n",
      "Loss: 0.5701720714569092\n",
      "Loss: 0.593346893787384\n",
      "Loss: 0.6231347918510437\n",
      "Loss: 0.6863706707954407\n",
      "Loss: 0.5688493251800537\n",
      "Loss: 0.6598933339118958\n",
      "Loss: 0.6875665783882141\n",
      "Loss: 0.7165874242782593\n",
      "Loss: 0.6705793142318726\n",
      "Loss: 0.7015479207038879\n",
      "Loss: 0.6503909230232239\n",
      "Loss: 0.6499577760696411\n",
      "Loss: 0.5419453978538513\n",
      "Loss: 0.620320737361908\n",
      "Loss: 0.6862114667892456\n",
      "Loss: 0.6623343825340271\n",
      "Loss: 0.6166552901268005\n",
      "Loss: 0.6588887572288513\n",
      "Loss: 0.7151685953140259\n",
      "Loss: 0.6466640830039978\n",
      "Loss: 0.6356543898582458\n",
      "Loss: 0.6312095522880554\n",
      "Loss: 0.6248111724853516\n",
      "Loss: 0.5826247334480286\n",
      "Loss: 0.6910014748573303\n",
      "Loss: 0.6419190764427185\n",
      "Loss: 0.6376597285270691\n",
      "Loss: 0.5759710073471069\n",
      "Loss: 0.6689103245735168\n",
      "Loss: 0.657853364944458\n",
      "Loss: 0.7140365839004517\n",
      "Loss: 0.6520090103149414\n",
      "Loss: 0.64921635389328\n",
      "Loss: 0.7471598386764526\n",
      "Loss: 0.613235354423523\n",
      "Loss: 0.7262573838233948\n",
      "Loss: 0.5803274512290955\n",
      "Loss: 0.7653539180755615\n",
      "Loss: 0.646687924861908\n",
      "Loss: 0.6118049025535583\n",
      "Loss: 0.6727307438850403\n",
      "Loss: 0.652622401714325\n",
      "Loss: 0.6109622716903687\n",
      "Loss: 0.5756286978721619\n",
      "Loss: 0.6175674796104431\n",
      "Loss: 0.6817834377288818\n",
      "Loss: 0.7147092223167419\n",
      "Loss: 0.7357927560806274\n",
      "Loss: 0.6409615278244019\n",
      "Loss: 0.696975588798523\n",
      "Loss: 0.7114417552947998\n",
      "Loss: 0.662975013256073\n",
      "Loss: 0.607792317867279\n",
      "Loss: 0.6858059167861938\n",
      "Loss: 0.5896040201187134\n",
      "Loss: 0.5432009696960449\n",
      "Loss: 0.6748518347740173\n",
      "Loss: 0.6397084593772888\n",
      "Loss: 0.6403703689575195\n",
      "Loss: 0.7309818863868713\n",
      "Loss: 0.7410297989845276\n",
      "Loss: 0.5994710922241211\n",
      "Loss: 0.6376925706863403\n",
      "Loss: 0.7150334119796753\n",
      "Loss: 0.6818812489509583\n",
      "Loss: 0.6610972881317139\n",
      "Loss: 0.5601022243499756\n",
      "Loss: 0.6861355900764465\n",
      "Loss: 0.6265835762023926\n",
      "Loss: 0.6873511672019958\n",
      "Loss: 0.5839828848838806\n",
      "Loss: 0.6123859286308289\n",
      "Loss: 0.6269741058349609\n",
      "Loss: 0.7005050182342529\n",
      "Loss: 0.6789879202842712\n",
      "Loss: 0.7123314142227173\n",
      "Loss: 0.6989673376083374\n",
      "Loss: 0.666647732257843\n",
      "Loss: 0.6178901791572571\n",
      "Loss: 0.6172383427619934\n",
      "Loss: 0.7431095838546753\n",
      "Loss: 0.6168409585952759\n",
      "Loss: 0.6699031591415405\n",
      "Loss: 0.5905031561851501\n",
      "Loss: 0.5711974501609802\n",
      "Loss: 0.5940874218940735\n",
      "Loss: 0.6399084329605103\n",
      "Loss: 0.6237866878509521\n",
      "Loss: 0.6864882111549377\n",
      "Loss: 0.6229432225227356\n",
      "Loss: 0.5589147806167603\n",
      "Loss: 0.6494802832603455\n",
      "Loss: 0.6954237818717957\n",
      "Loss: 0.6126481890678406\n",
      "Loss: 0.5855938196182251\n",
      "Loss: 0.6632053256034851\n",
      "Loss: 0.694312334060669\n",
      "Loss: 0.7310381531715393\n",
      "Loss: 0.6612362265586853\n",
      "Loss: 0.6050981879234314\n",
      "Loss: 0.6609653234481812\n",
      "Loss: 0.6662637591362\n",
      "Loss: 0.5516070127487183\n",
      "Loss: 0.6239097714424133\n",
      "Loss: 0.6565864086151123\n",
      "Loss: 0.6088983416557312\n",
      "Loss: 0.6327745318412781\n",
      "Loss: 0.6063873767852783\n",
      "Loss: 0.6614744067192078\n",
      "Loss: 0.6959407925605774\n",
      "Loss: 0.6345717310905457\n",
      "Loss: 0.7457950115203857\n",
      "Loss: 0.6095564961433411\n",
      "Loss: 0.5746347904205322\n",
      "Loss: 0.6567074060440063\n",
      "Loss: 0.6675326824188232\n",
      "Loss: 0.6931191086769104\n",
      "Loss: 0.6140406727790833\n",
      "Loss: 0.6086418032646179\n",
      "Loss: 0.5791385173797607\n",
      "Loss: 0.7018731236457825\n",
      "Loss: 0.5990585684776306\n",
      "Loss: 0.6805139780044556\n",
      "Loss: 0.6071695685386658\n",
      "Loss: 0.6742770671844482\n",
      "Loss: 0.6723620891571045\n",
      "Loss: 0.6885637640953064\n",
      "Loss: 0.6407104730606079\n",
      "Loss: 0.5813950896263123\n",
      "Loss: 0.6519941687583923\n",
      "Loss: 0.6401075720787048\n",
      "Loss: 0.6515659689903259\n",
      "Loss: 0.6888548135757446\n",
      "Loss: 0.613605797290802\n",
      "Loss: 0.5456140637397766\n",
      "Loss: 0.6802782416343689\n",
      "Loss: 0.6794096231460571\n",
      "Loss: 0.642372727394104\n",
      "Loss: 0.6908963322639465\n",
      "Loss: 0.6349146962165833\n",
      "Loss: 0.6244066953659058\n",
      "Loss: 0.6874913573265076\n",
      "Loss: 0.6106860637664795\n",
      "Loss: 0.7007191777229309\n",
      "Loss: 0.624590277671814\n",
      "Loss: 0.6374297142028809\n",
      "Loss: 0.6491638422012329\n",
      "Loss: 0.6743976473808289\n",
      "Loss: 0.5361670255661011\n",
      "Loss: 0.6654160618782043\n",
      "Loss: 0.6474255323410034\n",
      "Loss: 0.7173417210578918\n",
      "Loss: 0.5751394629478455\n",
      "Loss: 0.6200683116912842\n",
      "Loss: 0.6403457522392273\n",
      "Loss: 0.6315634846687317\n",
      "Loss: 0.7047215104103088\n",
      "Loss: 0.5775520205497742\n",
      "Loss: 0.6878053545951843\n",
      "Loss: 0.7133751511573792\n",
      "Loss: 0.5639517307281494\n",
      "Loss: 0.642276406288147\n",
      "Loss: 0.6779515743255615\n",
      "Loss: 0.7434408068656921\n",
      "Loss: 0.6599156856536865\n",
      "Loss: 0.642979085445404\n",
      "Loss: 0.6658102869987488\n",
      "Loss: 0.6506915092468262\n",
      "Loss: 0.6736899614334106\n",
      "Loss: 0.6313144564628601\n",
      "Loss: 0.6385335922241211\n",
      "Loss: 0.673012912273407\n",
      "Loss: 0.6863590478897095\n",
      "Loss: 0.5875605940818787\n",
      "Loss: 0.7183710336685181\n",
      "Loss: 0.5994337797164917\n",
      "Loss: 0.719322919845581\n",
      "Loss: 0.6344250440597534\n",
      "Loss: 0.630955159664154\n",
      "Loss: 0.7092757821083069\n",
      "Loss: 0.6186200976371765\n",
      "Loss: 0.6900193691253662\n",
      "Loss: 0.6648966670036316\n",
      "Loss: 0.663258969783783\n",
      "Loss: 0.5529372096061707\n",
      "Loss: 0.6549771428108215\n",
      "Loss: 0.7143150568008423\n",
      "Loss: 0.6055777072906494\n",
      "Loss: 0.633766770362854\n",
      "Loss: 0.690133810043335\n",
      "Loss: 0.6424223780632019\n",
      "Loss: 0.7017199397087097\n",
      "Loss: 0.6789772510528564\n",
      "Loss: 0.6169818043708801\n",
      "Loss: 0.6340081095695496\n",
      "Loss: 0.6546310186386108\n",
      "Loss: 0.7032814621925354\n",
      "Loss: 0.6388028860092163\n",
      "Loss: 0.6341980695724487\n",
      "Loss: 0.6860221028327942\n",
      "Loss: 0.6153386235237122\n",
      "Loss: 0.5934860110282898\n",
      "Loss: 0.5587911605834961\n",
      "Loss: 0.7116033434867859\n",
      "Loss: 0.5982886552810669\n",
      "Loss: 0.5727375745773315\n",
      "Loss: 0.5908592343330383\n",
      "Loss: 0.6141631007194519\n",
      "Loss: 0.6318677067756653\n",
      "Loss: 0.7954103946685791\n",
      "Loss: 0.6618368029594421\n",
      "Loss: 0.6768413782119751\n",
      "Loss: 0.6873843669891357\n",
      "Loss: 0.6967697739601135\n",
      "Loss: 0.6499823331832886\n",
      "Loss: 0.6726171970367432\n",
      "Loss: 0.6839338541030884\n",
      "Loss: 0.7112120389938354\n",
      "Loss: 0.7166491150856018\n",
      "Loss: 0.7749761343002319\n",
      "Loss: 0.6489896774291992\n",
      "Loss: 0.6334627866744995\n",
      "Loss: 0.6893368363380432\n",
      "Loss: 0.6472781300544739\n",
      "Loss: 0.6653069257736206\n",
      "Loss: 0.5861690044403076\n",
      "Loss: 0.6748529672622681\n",
      "Loss: 0.7219671607017517\n",
      "Loss: 0.6752293705940247\n",
      "Loss: 0.6605664491653442\n",
      "Loss: 0.6394419074058533\n",
      "Loss: 0.6176406741142273\n",
      "Loss: 0.5713416934013367\n",
      "Loss: 0.6752117872238159\n",
      "Loss: 0.7169800400733948\n",
      "Loss: 0.6166536211967468\n",
      "Loss: 0.6431668996810913\n",
      "Loss: 0.6162863969802856\n",
      "Loss: 0.6532349586486816\n",
      "Loss: 0.7056912779808044\n",
      "Loss: 0.6479268074035645\n",
      "Loss: 0.6214081048965454\n",
      "Loss: 0.5797306895256042\n",
      "Loss: 0.6772981882095337\n",
      "Loss: 0.6773496270179749\n",
      "Loss: 0.6084374785423279\n",
      "Loss: 0.700443685054779\n",
      "Loss: 0.7220045328140259\n",
      "Loss: 0.6270259022712708\n",
      "Loss: 0.6531578302383423\n",
      "Loss: 0.6290111541748047\n",
      "Loss: 0.6607035398483276\n",
      "Loss: 0.6274922490119934\n",
      "Loss: 0.6733351945877075\n",
      "Loss: 0.6391175389289856\n",
      "Loss: 0.6078891158103943\n",
      "Loss: 0.6031109094619751\n",
      "Loss: 0.6211520433425903\n",
      "Loss: 0.757561445236206\n",
      "Loss: 0.5995703935623169\n",
      "Loss: 0.6206101179122925\n",
      "Loss: 0.6723355650901794\n",
      "Loss: 0.6475219130516052\n",
      "Loss: 0.6333726048469543\n",
      "Loss: 0.6086357831954956\n",
      "Loss: 0.6738483905792236\n",
      "Loss: 0.5847837924957275\n",
      "Loss: 0.5896644592285156\n",
      "Loss: 0.6271246671676636\n",
      "Loss: 0.6140416264533997\n",
      "Loss: 0.6732702851295471\n",
      "Loss: 0.654510498046875\n",
      "Loss: 0.6561123132705688\n",
      "Loss: 0.678692638874054\n",
      "Loss: 0.7094341516494751\n",
      "Loss: 0.6512621641159058\n",
      "Loss: 0.6644479632377625\n",
      "Loss: 0.6594829559326172\n",
      "Loss: 0.6196559071540833\n",
      "Loss: 0.6324375867843628\n",
      "Loss: 0.6606502532958984\n",
      "Loss: 0.6897298097610474\n",
      "Loss: 0.6190195083618164\n",
      "Loss: 0.5979768633842468\n",
      "Loss: 0.6638187766075134\n",
      "Loss: 0.6970444321632385\n",
      "Loss: 0.6755384802818298\n",
      "Loss: 0.6485854983329773\n",
      "Loss: 0.6411184668540955\n",
      "Loss: 0.6054027080535889\n",
      "Loss: 0.6272636651992798\n",
      "Loss: 0.5995601415634155\n",
      "Loss: 0.6270875930786133\n",
      "Loss: 0.6583310961723328\n",
      "Loss: 0.6112431287765503\n",
      "Loss: 0.6693204641342163\n",
      "Loss: 0.6931483745574951\n",
      "Loss: 0.6539067625999451\n",
      "Loss: 0.6703771948814392\n",
      "Loss: 0.6748617887496948\n",
      "Loss: 0.6801460981369019\n",
      "Loss: 0.6621642112731934\n",
      "Loss: 0.6478296518325806\n",
      "Loss: 0.7445886135101318\n",
      "Loss: 0.6616915464401245\n",
      "Loss: 0.6037771701812744\n",
      "Loss: 0.5867147445678711\n",
      "Loss: 0.6310069561004639\n",
      "Loss: 0.6609582304954529\n",
      "Loss: 0.6402106285095215\n",
      "Loss: 0.7069953083992004\n",
      "Loss: 0.7036744952201843\n",
      "Loss: 0.6418473720550537\n",
      "Loss: 0.6805545687675476\n",
      "Loss: 0.6751974821090698\n",
      "Loss: 0.7812926173210144\n",
      "Loss: 0.637098491191864\n",
      "Loss: 0.6695314645767212\n",
      "Loss: 0.6574358344078064\n",
      "Loss: 0.69401615858078\n",
      "Loss: 0.6383512020111084\n",
      "Loss: 0.6602400541305542\n",
      "Loss: 0.5986088514328003\n",
      "Loss: 0.6608368158340454\n",
      "Loss: 0.7089502215385437\n",
      "Loss: 0.6993408799171448\n",
      "Loss: 0.6529453992843628\n",
      "Loss: 0.6850341558456421\n",
      "Loss: 0.7124499082565308\n",
      "Loss: 0.6078564524650574\n",
      "Loss: 0.7004371881484985\n",
      "Loss: 0.609950840473175\n",
      "Loss: 0.6690343618392944\n",
      "Loss: 0.6474559903144836\n",
      "Loss: 0.601240336894989\n",
      "Loss: 0.6753761172294617\n",
      "Loss: 0.6533696055412292\n",
      "Loss: 0.61500483751297\n",
      "Loss: 0.6427789926528931\n",
      "Loss: 0.6181076765060425\n",
      "Loss: 0.5749064683914185\n",
      "Loss: 0.6016038656234741\n",
      "Loss: 0.6634789705276489\n",
      "Loss: 0.6880837082862854\n",
      "Loss: 0.6233429312705994\n",
      "Loss: 0.6243481040000916\n",
      "Loss: 0.6440288424491882\n",
      "Loss: 0.6135903596878052\n",
      "Loss: 0.49213889241218567\n",
      "Loss: 0.6823278665542603\n",
      "Loss: 0.6348575353622437\n",
      "Loss: 0.69107985496521\n",
      "Loss: 0.6792887449264526\n",
      "Loss: 0.6267004013061523\n",
      "Loss: 0.6436235308647156\n",
      "Loss: 0.6478719115257263\n",
      "Loss: 0.6370136737823486\n",
      "Loss: 0.6008785367012024\n",
      "Loss: 0.6323191523551941\n",
      "Loss: 0.6916109919548035\n",
      "Loss: 0.6161654591560364\n",
      "Loss: 0.63572096824646\n",
      "Loss: 0.6762529015541077\n",
      "Loss: 0.6091710329055786\n",
      "Loss: 0.6871458888053894\n",
      "Loss: 0.7014364004135132\n",
      "Loss: 0.644084095954895\n",
      "Loss: 0.6801027655601501\n",
      "Loss: 0.5887758135795593\n",
      "Loss: 0.6773965954780579\n",
      "Loss: 0.6362532377243042\n",
      "Loss: 0.6583122611045837\n",
      "Loss: 0.6686879992485046\n",
      "Loss: 0.6454620361328125\n",
      "Loss: 0.5876890420913696\n",
      "Loss: 0.6803533434867859\n",
      "Loss: 0.6440896391868591\n",
      "Loss: 0.6488402485847473\n",
      "Loss: 0.6894081234931946\n",
      "Loss: 0.5658495426177979\n",
      "Loss: 0.5828781127929688\n",
      "Loss: 0.6493784189224243\n",
      "Loss: 0.6128538846969604\n",
      "Loss: 0.672676146030426\n",
      "Loss: 0.7191833853721619\n",
      "Loss: 0.6420736312866211\n",
      "Loss: 0.6682081818580627\n",
      "Loss: 0.6259238719940186\n",
      "Loss: 0.6921184659004211\n",
      "Loss: 0.6291263103485107\n",
      "Loss: 0.6406413912773132\n",
      "Loss: 0.5609303116798401\n",
      "Loss: 0.5971717834472656\n",
      "Loss: 0.611555814743042\n",
      "Loss: 0.6171721816062927\n",
      "Loss: 0.6592990756034851\n",
      "Loss: 0.670306921005249\n",
      "Loss: 0.6508166193962097\n",
      "Loss: 0.6170082092285156\n",
      "Loss: 0.6374390721321106\n",
      "Loss: 0.5833943486213684\n",
      "Loss: 0.6059976816177368\n",
      "Loss: 0.6801897287368774\n",
      "Loss: 0.6544211506843567\n",
      "Loss: 0.6435226202011108\n",
      "Loss: 0.6592427492141724\n",
      "Loss: 0.6232225298881531\n",
      "Loss: 0.7347977757453918\n",
      "Loss: 0.6554081439971924\n",
      "Loss: 0.6651077270507812\n",
      "Loss: 0.7426594495773315\n",
      "Loss: 0.6208639144897461\n",
      "Loss: 0.7452899813652039\n",
      "Loss: 0.6953328847885132\n",
      "Loss: 0.6625957489013672\n",
      "Loss: 0.6088205575942993\n",
      "Loss: 0.69212806224823\n",
      "Loss: 0.6357811689376831\n",
      "Loss: 0.6281431317329407\n",
      "Loss: 0.6391250491142273\n",
      "Loss: 0.6826325058937073\n",
      "Loss: 0.6326472759246826\n",
      "Loss: 0.6067390441894531\n",
      "Loss: 0.5792036056518555\n",
      "Loss: 0.6823616623878479\n",
      "Loss: 0.7489336729049683\n",
      "Loss: 0.5823325514793396\n",
      "Loss: 0.6096750497817993\n",
      "Loss: 0.7534380555152893\n",
      "Loss: 0.6144540309906006\n",
      "Loss: 0.726876974105835\n",
      "Loss: 0.7008674144744873\n",
      "Loss: 0.6871580481529236\n",
      "Loss: 0.6225004196166992\n",
      "Loss: 0.6809467077255249\n",
      "Loss: 0.6525590419769287\n",
      "Loss: 0.6534919738769531\n",
      "Loss: 0.644173800945282\n",
      "Loss: 0.6103658676147461\n",
      "Loss: 0.632472813129425\n",
      "Loss: 0.6481539011001587\n",
      "Loss: 0.6628427505493164\n",
      "Loss: 0.6611582040786743\n",
      "Loss: 0.6345517635345459\n",
      "Loss: 0.5803263783454895\n",
      "Loss: 0.609649658203125\n",
      "Loss: 0.6451195478439331\n",
      "Loss: 0.6693235039710999\n",
      "Loss: 0.5639853477478027\n",
      "Loss: 0.5726286172866821\n",
      "Loss: 0.5395354628562927\n",
      "Loss: 0.5524133443832397\n",
      "Loss: 0.5845257043838501\n",
      "Loss: 0.6959907412528992\n",
      "Loss: 0.6541870832443237\n",
      "Loss: 0.5287813544273376\n",
      "Loss: 0.6260596513748169\n",
      "Loss: 0.6356980800628662\n",
      "Loss: 0.6665131449699402\n",
      "Loss: 0.5621783137321472\n",
      "Loss: 0.6099193096160889\n",
      "Loss: 0.64156174659729\n",
      "Loss: 0.5997101068496704\n",
      "Loss: 0.6939862370491028\n",
      "Loss: 0.63302081823349\n",
      "Loss: 0.6756826639175415\n",
      "Loss: 0.631677508354187\n",
      "Loss: 0.5996655821800232\n",
      "Loss: 0.5970700979232788\n",
      "Loss: 0.698506772518158\n",
      "Loss: 0.6475940942764282\n",
      "Loss: 0.612557590007782\n",
      "Loss: 0.6715947985649109\n",
      "Loss: 0.6405412554740906\n",
      "Loss: 0.6418537497520447\n",
      "Loss: 0.7114871144294739\n",
      "Loss: 0.6271708607673645\n",
      "Loss: 0.6903700232505798\n",
      "Loss: 0.6456875205039978\n",
      "Loss: 0.5870943069458008\n",
      "Loss: 0.6335636377334595\n",
      "Loss: 0.6853605508804321\n",
      "Loss: 0.6076340079307556\n",
      "Loss: 0.6694029569625854\n",
      "Loss: 0.6631066203117371\n",
      "Loss: 0.663678765296936\n",
      "Loss: 0.5636023283004761\n",
      "Loss: 0.6414362192153931\n",
      "Loss: 0.5883235931396484\n",
      "Loss: 0.6450643539428711\n",
      "Loss: 0.6289386749267578\n",
      "Loss: 0.6949902176856995\n",
      "Loss: 0.6264132261276245\n",
      "Loss: 0.6776958107948303\n",
      "Loss: 0.7148863673210144\n",
      "Loss: 0.5639507174491882\n",
      "Loss: 0.6092512607574463\n",
      "Loss: 0.6188533306121826\n",
      "Loss: 0.6258230209350586\n",
      "Loss: 0.6985108852386475\n",
      "Loss: 0.7107704281806946\n",
      "Loss: 0.6056782007217407\n",
      "Loss: 0.6755239367485046\n",
      "Loss: 0.7093241214752197\n",
      "Loss: 0.6571921110153198\n",
      "Loss: 0.5936124324798584\n",
      "Loss: 0.6361009478569031\n",
      "Loss: 0.6661039590835571\n",
      "Loss: 0.7289570569992065\n",
      "Loss: 0.6497434377670288\n",
      "Loss: 0.6715688109397888\n",
      "Loss: 0.6424500346183777\n",
      "Loss: 0.6620885729789734\n",
      "Loss: 0.6748157739639282\n",
      "Loss: 0.6004714965820312\n",
      "Loss: 0.652595043182373\n",
      "Loss: 0.674941897392273\n",
      "Loss: 0.594868004322052\n",
      "Loss: 0.7248772382736206\n",
      "Loss: 0.6986145377159119\n",
      "Loss: 0.70256507396698\n",
      "Loss: 0.6830044388771057\n",
      "Loss: 0.6098010540008545\n",
      "Loss: 0.5970584154129028\n",
      "Loss: 0.6525466442108154\n",
      "Loss: 0.6711079478263855\n",
      "Loss: 0.7114384770393372\n",
      "Loss: 0.7029834389686584\n",
      "Loss: 0.7832081913948059\n",
      "Loss: 0.6547375917434692\n",
      "Loss: 0.6377484202384949\n",
      "Loss: 0.649030327796936\n",
      "Loss: 0.7086634039878845\n",
      "Loss: 0.6177447438240051\n",
      "Loss: 0.611229419708252\n",
      "Loss: 0.7431086301803589\n",
      "Loss: 0.6825721263885498\n",
      "Loss: 0.6324474215507507\n",
      "Loss: 0.6147578954696655\n",
      "Loss: 0.616346538066864\n",
      "Loss: 0.5586993098258972\n",
      "Loss: 0.5822060108184814\n",
      "Loss: 0.6736987233161926\n",
      "Loss: 0.6160604357719421\n",
      "Loss: 0.6536335349082947\n",
      "Loss: 0.6150456666946411\n",
      "Loss: 0.726624608039856\n",
      "Loss: 0.6375411748886108\n",
      "Loss: 0.6824888586997986\n",
      "Loss: 0.7006326913833618\n",
      "Loss: 0.6024309992790222\n",
      "Loss: 0.6519033312797546\n",
      "Loss: 0.5948490500450134\n",
      "Loss: 0.5927783250808716\n",
      "Loss: 0.688193678855896\n",
      "Loss: 0.6985074877738953\n",
      "Loss: 0.5595624446868896\n",
      "Loss: 0.7160308957099915\n",
      "Loss: 0.6469711065292358\n",
      "Loss: 0.6216155886650085\n",
      "Loss: 0.6801748871803284\n",
      "Loss: 0.6242359280586243\n",
      "Loss: 0.665892481803894\n",
      "Loss: 0.6799824237823486\n",
      "Loss: 0.6637254953384399\n",
      "Loss: 0.5917519330978394\n",
      "Loss: 0.6667200326919556\n",
      "Loss: 0.5546882748603821\n",
      "Loss: 0.7120534777641296\n",
      "Loss: 0.6243430376052856\n",
      "Loss: 0.6912720203399658\n",
      "Loss: 0.6790555715560913\n",
      "Loss: 0.6815000772476196\n",
      "Loss: 0.6472443342208862\n",
      "Loss: 0.6677919626235962\n",
      "Loss: 0.6953638792037964\n",
      "Loss: 0.6820980310440063\n",
      "Loss: 0.7038418054580688\n",
      "Loss: 0.6668260097503662\n",
      "Loss: 0.6313034296035767\n",
      "Loss: 0.6168964505195618\n",
      "Loss: 0.6472490429878235\n",
      "Loss: 0.5620119571685791\n",
      "Loss: 0.6493673324584961\n",
      "Loss: 0.7039204239845276\n",
      "Loss: 0.628826379776001\n",
      "Loss: 0.6680585741996765\n",
      "Loss: 0.6600116491317749\n",
      "Loss: 0.6270414590835571\n",
      "Loss: 0.6701290011405945\n",
      "Loss: 0.6034047603607178\n",
      "Loss: 0.6594850420951843\n",
      "Loss: 0.7574477791786194\n",
      "Loss: 0.6211345791816711\n",
      "Loss: 0.7055334448814392\n",
      "Loss: 0.6777359247207642\n",
      "Loss: 0.661546528339386\n",
      "Loss: 0.6538863182067871\n",
      "Loss: 0.6704851388931274\n",
      "Loss: 0.5930869579315186\n",
      "Loss: 0.6271263360977173\n",
      "Loss: 0.6321903467178345\n",
      "Loss: 0.6206759214401245\n",
      "Loss: 0.6855401396751404\n",
      "Loss: 0.7060424089431763\n",
      "Loss: 0.6317716836929321\n",
      "Loss: 0.6742321252822876\n",
      "Loss: 0.6148465871810913\n",
      "Loss: 0.5787951350212097\n",
      "Loss: 0.6096698641777039\n",
      "Loss: 0.6483244299888611\n",
      "Loss: 0.6283543109893799\n",
      "Loss: 0.6177213788032532\n",
      "Loss: 0.5952360033988953\n",
      "Loss: 0.5888241529464722\n",
      "Loss: 0.6766120791435242\n",
      "Loss: 0.6271635293960571\n",
      "Loss: 0.5790761709213257\n",
      "Loss: 0.6012650728225708\n",
      "Loss: 0.5932083129882812\n",
      "Loss: 0.6905177235603333\n",
      "Loss: 0.6197284460067749\n",
      "Loss: 0.6987505555152893\n",
      "Loss: 0.6651461124420166\n",
      "Loss: 0.6895096898078918\n",
      "Loss: 0.6248988509178162\n",
      "Loss: 0.6395158767700195\n",
      "Loss: 0.750497043132782\n",
      "Loss: 0.691226065158844\n",
      "Loss: 0.6396119594573975\n",
      "Loss: 0.6132948398590088\n",
      "Loss: 0.6206857562065125\n",
      "Loss: 0.618518054485321\n",
      "Loss: 0.6280644536018372\n",
      "Loss: 0.621039092540741\n",
      "Loss: 0.6526266932487488\n",
      "Loss: 0.6831116080284119\n",
      "Loss: 0.652439296245575\n",
      "Loss: 0.637554943561554\n",
      "Loss: 0.5928243398666382\n",
      "Loss: 0.6983925700187683\n",
      "Loss: 0.6435732841491699\n",
      "Loss: 0.6594547033309937\n",
      "Loss: 0.6706455945968628\n",
      "Loss: 0.6428375244140625\n",
      "Loss: 0.5981756448745728\n",
      "Loss: 0.6561626195907593\n",
      "Loss: 0.6283921003341675\n",
      "Loss: 0.603905975818634\n",
      "Loss: 0.6921426653862\n",
      "Loss: 0.6444756984710693\n",
      "Loss: 0.7433173060417175\n",
      "Loss: 0.6310780644416809\n",
      "Loss: 0.6266331076622009\n",
      "Loss: 0.6915197968482971\n",
      "Loss: 0.6430070400238037\n",
      "Loss: 0.6534464955329895\n",
      "Loss: 0.6482492685317993\n",
      "Loss: 0.6828978657722473\n",
      "Loss: 0.6701971292495728\n",
      "Loss: 0.7095221877098083\n",
      "Loss: 0.6631160974502563\n",
      "Loss: 0.6472340822219849\n",
      "Loss: 0.6592111587524414\n",
      "Loss: 0.6894537210464478\n",
      "Loss: 0.592548131942749\n",
      "Loss: 0.7275378108024597\n",
      "Loss: 0.6129595041275024\n",
      "Loss: 0.6342432498931885\n",
      "Loss: 0.7014492750167847\n",
      "Loss: 0.5543645620346069\n",
      "Loss: 0.6235688328742981\n",
      "Loss: 0.6203550696372986\n",
      "Loss: 0.673883318901062\n",
      "Loss: 0.7925136089324951\n",
      "Loss: 0.6859913468360901\n",
      "Loss: 0.7146181464195251\n",
      "Loss: 0.671714723110199\n",
      "Loss: 0.6755803227424622\n",
      "Loss: 0.6732916235923767\n",
      "Loss: 0.6267465353012085\n",
      "Loss: 0.6787077784538269\n",
      "Loss: 0.6038883924484253\n",
      "Loss: 0.6670209765434265\n",
      "Loss: 0.6238412857055664\n",
      "Loss: 0.6573953032493591\n",
      "Loss: 0.6007446646690369\n",
      "Loss: 0.6482294797897339\n",
      "Loss: 0.6611562967300415\n",
      "Loss: 0.6671772599220276\n",
      "Loss: 0.5636709332466125\n",
      "Loss: 0.6431695818901062\n",
      "Loss: 0.6442917585372925\n",
      "Loss: 0.5641876459121704\n",
      "Loss: 0.7027870416641235\n",
      "Loss: 0.7082439661026001\n",
      "Loss: 0.6491846442222595\n",
      "Loss: 0.6193516254425049\n",
      "Loss: 0.6842223405838013\n",
      "Loss: 0.6730167865753174\n",
      "Loss: 0.6706680655479431\n",
      "Loss: 0.6407642364501953\n",
      "Loss: 0.678301215171814\n",
      "Loss: 0.5972435474395752\n",
      "Loss: 0.6451336145401001\n",
      "Loss: 0.6238086819648743\n",
      "Loss: 0.6137871146202087\n",
      "Loss: 0.6450852751731873\n",
      "Loss: 0.651237428188324\n",
      "Loss: 0.726645290851593\n",
      "Loss: 0.6249635219573975\n",
      "Loss: 0.6846392750740051\n",
      "Loss: 0.7183082103729248\n",
      "Loss: 0.6613982319831848\n",
      "Loss: 0.6986306309700012\n",
      "Loss: 0.6043490171432495\n",
      "Loss: 0.6961373090744019\n",
      "Loss: 0.6310054063796997\n",
      "Loss: 0.6574922800064087\n",
      "Loss: 0.6076739430427551\n",
      "Loss: 0.6552921533584595\n",
      "Loss: 0.6194994449615479\n",
      "Loss: 0.6395387649536133\n",
      "Loss: 0.6639295816421509\n",
      "Loss: 0.6593173146247864\n",
      "Loss: 0.6424757242202759\n",
      "Loss: 0.6563684344291687\n",
      "Loss: 0.6855345368385315\n",
      "Loss: 0.6376258134841919\n",
      "Loss: 0.6808702945709229\n",
      "Loss: 0.7336848378181458\n",
      "Loss: 0.6621344685554504\n",
      "Loss: 0.5794814229011536\n",
      "Loss: 0.600132167339325\n",
      "Loss: 0.6073482036590576\n",
      "Loss: 0.6647061109542847\n",
      "Loss: 0.5995409488677979\n",
      "Loss: 0.647795557975769\n",
      "Loss: 0.6735032200813293\n",
      "Loss: 0.650741696357727\n",
      "Loss: 0.6678721904754639\n",
      "Loss: 0.6145687103271484\n",
      "Loss: 0.7094298601150513\n",
      "Loss: 0.6221729516983032\n",
      "Loss: 0.7256144285202026\n",
      "Loss: 0.6054194569587708\n",
      "Loss: 0.7261309027671814\n",
      "Loss: 0.6177101135253906\n",
      "Loss: 0.5604507327079773\n",
      "Loss: 0.6210712790489197\n",
      "Loss: 0.5800666809082031\n",
      "Loss: 0.6545860171318054\n",
      "Loss: 0.6717690229415894\n",
      "Loss: 0.5599303245544434\n",
      "Loss: 0.6287682056427002\n",
      "Loss: 0.6046070456504822\n",
      "Loss: 0.5970512628555298\n",
      "Loss: 0.5795770883560181\n",
      "Loss: 0.679717481136322\n",
      "Loss: 0.6270140409469604\n",
      "Loss: 0.681685209274292\n",
      "Loss: 0.6628360152244568\n",
      "Loss: 0.6483349204063416\n",
      "Loss: 0.6574329733848572\n",
      "Loss: 0.6206545233726501\n",
      "Loss: 0.6641321182250977\n",
      "Loss: 0.6966532468795776\n",
      "Loss: 0.6436050534248352\n",
      "Loss: 0.6601560115814209\n",
      "Loss: 0.6690163016319275\n",
      "Loss: 0.6734736561775208\n",
      "Loss: 0.6026844382286072\n",
      "Loss: 0.6899550557136536\n",
      "Loss: 0.6064762473106384\n",
      "Loss: 0.6271632313728333\n",
      "Loss: 0.6434643864631653\n",
      "Loss: 0.6374788284301758\n",
      "Loss: 0.7404865622520447\n",
      "Loss: 0.6355099081993103\n",
      "Loss: 0.6252207159996033\n",
      "Loss: 0.5839164853096008\n",
      "Loss: 0.6850382685661316\n",
      "Loss: 0.6441363096237183\n",
      "Loss: 0.6485692262649536\n",
      "Loss: 0.6326476335525513\n",
      "Loss: 0.6460111141204834\n",
      "Loss: 0.6833491921424866\n",
      "Loss: 0.7656759023666382\n",
      "Loss: 0.6804046034812927\n",
      "Loss: 0.6721819043159485\n",
      "Loss: 0.6555430889129639\n",
      "Loss: 0.7083157300949097\n",
      "Loss: 0.6510001420974731\n",
      "Loss: 0.6097649335861206\n",
      "Loss: 0.6311833262443542\n",
      "Loss: 0.6911066174507141\n",
      "Loss: 0.6485907435417175\n",
      "Loss: 0.671477735042572\n",
      "Loss: 0.6453487277030945\n",
      "Loss: 0.6414594650268555\n",
      "Loss: 0.6468378305435181\n",
      "Loss: 0.5764726400375366\n",
      "Loss: 0.6420832872390747\n",
      "Loss: 0.6207851767539978\n",
      "Loss: 0.7188405394554138\n",
      "Loss: 0.6443933844566345\n",
      "Loss: 0.6836675405502319\n",
      "Loss: 0.6829994320869446\n",
      "Loss: 0.6552485227584839\n",
      "Loss: 0.6099885106086731\n",
      "Loss: 0.5887800455093384\n",
      "Loss: 0.6022976040840149\n",
      "Loss: 0.6244242787361145\n",
      "Loss: 0.5987944602966309\n",
      "Loss: 0.6385093927383423\n",
      "Loss: 0.6365653872489929\n",
      "Loss: 0.6583172082901001\n",
      "Loss: 0.6403687000274658\n",
      "Loss: 0.6476578116416931\n",
      "Loss: 0.6362918019294739\n",
      "Loss: 0.6714980006217957\n",
      "Loss: 0.6271430253982544\n",
      "Loss: 0.6180285811424255\n",
      "Loss: 0.67994624376297\n",
      "Loss: 0.7585312128067017\n",
      "Loss: 0.6659744381904602\n",
      "Loss: 0.5911861658096313\n",
      "Loss: 0.6431713104248047\n",
      "Loss: 0.6734516024589539\n",
      "Loss: 0.595522403717041\n",
      "Loss: 0.6763063669204712\n",
      "Loss: 0.6319873929023743\n",
      "Loss: 0.602046012878418\n",
      "Loss: 0.6696585416793823\n",
      "Loss: 0.5824041366577148\n",
      "Loss: 0.5642113089561462\n",
      "Loss: 0.633586049079895\n",
      "Loss: 0.6725867390632629\n",
      "Loss: 0.6034310460090637\n",
      "Loss: 0.6548874974250793\n",
      "Loss: 0.6072905659675598\n",
      "Loss: 0.7099422812461853\n",
      "Loss: 0.6678839921951294\n",
      "Loss: 0.7501177191734314\n",
      "Loss: 0.6149281859397888\n",
      "Loss: 0.6839032769203186\n",
      "Loss: 0.6852508783340454\n",
      "Loss: 0.581480860710144\n",
      "Loss: 0.6500329971313477\n",
      "Loss: 0.6326560974121094\n",
      "Loss: 0.5931112766265869\n",
      "Loss: 0.6066758632659912\n",
      "Loss: 0.6501415967941284\n",
      "Loss: 0.7003738880157471\n",
      "Loss: 0.6511156558990479\n",
      "Loss: 0.6521267294883728\n",
      "Loss: 0.6281822919845581\n",
      "Loss: 0.723645031452179\n",
      "Loss: 0.6840251088142395\n",
      "Loss: 0.6939166188240051\n",
      "Loss: 0.6873968839645386\n",
      "Loss: 0.6444973349571228\n",
      "Loss: 0.6560988426208496\n",
      "Loss: 0.6895154714584351\n",
      "Loss: 0.6291141510009766\n",
      "Loss: 0.6550639271736145\n",
      "Loss: 0.6522082090377808\n",
      "Loss: 0.6285173296928406\n",
      "Loss: 0.6405461430549622\n",
      "Loss: 0.652547299861908\n",
      "Loss: 0.7536643743515015\n",
      "Loss: 0.6792906522750854\n",
      "Loss: 0.7152753472328186\n",
      "Loss: 0.6036992073059082\n",
      "Loss: 0.6026491522789001\n",
      "Loss: 0.601061224937439\n",
      "Loss: 0.6762491464614868\n",
      "Loss: 0.5908568501472473\n",
      "Loss: 0.6331478357315063\n",
      "Loss: 0.6624943017959595\n",
      "Loss: 0.6425080299377441\n",
      "Loss: 0.6546911597251892\n",
      "Loss: 0.7066137790679932\n",
      "Loss: 0.6680845022201538\n",
      "Loss: 0.6347054243087769\n",
      "Loss: 0.6730553507804871\n",
      "Loss: 0.6573938727378845\n",
      "Loss: 0.6767605543136597\n",
      "Loss: 0.6285733580589294\n",
      "Loss: 0.6290216445922852\n",
      "Loss: 0.5899409055709839\n",
      "Loss: 0.694517195224762\n",
      "Loss: 0.6517685055732727\n",
      "Loss: 0.6985116600990295\n",
      "Loss: 0.6422939300537109\n",
      "Loss: 0.691396176815033\n",
      "Loss: 0.638579785823822\n",
      "Loss: 0.7031334042549133\n",
      "Loss: 0.609203040599823\n",
      "Loss: 0.7110946178436279\n",
      "Loss: 0.6302087306976318\n",
      "Loss: 0.6243616342544556\n",
      "Loss: 0.6634615659713745\n",
      "Loss: 0.6505823135375977\n",
      "Loss: 0.6088473796844482\n",
      "Loss: 0.69082111120224\n",
      "Loss: 0.608707845211029\n",
      "Loss: 0.6446107029914856\n",
      "Loss: 0.6719421744346619\n",
      "Loss: 0.6354043483734131\n",
      "Loss: 0.7426075339317322\n",
      "Loss: 0.6773799657821655\n",
      "Loss: 0.6610596776008606\n",
      "Loss: 0.6694972515106201\n",
      "Loss: 0.6868887543678284\n",
      "Loss: 0.5598517656326294\n",
      "Loss: 0.6099556088447571\n",
      "Loss: 0.5603382587432861\n",
      "Loss: 0.7299786806106567\n",
      "Loss: 0.7226272821426392\n",
      "Loss: 0.6624082326889038\n",
      "Loss: 0.6571997404098511\n",
      "Loss: 0.6519755125045776\n",
      "Loss: 0.6541634798049927\n",
      "Loss: 0.6121647953987122\n",
      "Loss: 0.7270419597625732\n",
      "Loss: 0.7560226321220398\n",
      "Loss: 0.678068220615387\n",
      "Loss: 0.6612817049026489\n",
      "Loss: 0.698016345500946\n",
      "Loss: 0.6877008676528931\n",
      "Loss: 0.6771494746208191\n",
      "Loss: 0.6600611805915833\n",
      "Loss: 0.5792262554168701\n",
      "Loss: 0.6500255465507507\n",
      "Loss: 0.683493971824646\n",
      "Loss: 0.6651350855827332\n",
      "Loss: 0.5939229130744934\n",
      "Loss: 0.6560280919075012\n",
      "Loss: 0.5713304281234741\n",
      "Loss: 0.5499708652496338\n",
      "Loss: 0.6676514744758606\n",
      "Loss: 0.6954347491264343\n",
      "Loss: 0.6866697072982788\n",
      "Loss: 0.6324952244758606\n",
      "Loss: 0.6374750137329102\n",
      "Loss: 0.6543253660202026\n",
      "Loss: 0.6385382413864136\n",
      "Loss: 0.6654914021492004\n",
      "Loss: 0.589022159576416\n",
      "Loss: 0.5952374339103699\n",
      "Loss: 0.6216971278190613\n",
      "Loss: 0.552013099193573\n",
      "Loss: 0.6349919438362122\n",
      "Loss: 0.697330892086029\n",
      "Loss: 0.578469455242157\n",
      "Loss: 0.6199716925621033\n",
      "Loss: 0.5435117483139038\n",
      "Loss: 0.6313905715942383\n",
      "Loss: 0.7511065006256104\n",
      "Loss: 0.762600302696228\n",
      "Loss: 0.610733151435852\n",
      "Loss: 0.6191677451133728\n",
      "Loss: 0.585372805595398\n",
      "Loss: 0.7617785930633545\n",
      "Loss: 0.6943036913871765\n",
      "Loss: 0.5983471274375916\n",
      "Loss: 0.641417920589447\n",
      "Loss: 0.7018419504165649\n",
      "Loss: 0.60435551404953\n",
      "Loss: 0.6407000422477722\n",
      "Loss: 0.692415177822113\n",
      "Loss: 0.6503004431724548\n",
      "Loss: 0.6876131296157837\n",
      "Loss: 0.6636902093887329\n",
      "Loss: 0.6361257433891296\n",
      "Loss: 0.6336595416069031\n",
      "Loss: 0.653718888759613\n",
      "Loss: 0.6187364459037781\n",
      "Loss: 0.6566423177719116\n",
      "Loss: 0.6909478306770325\n",
      "Loss: 0.6817994713783264\n",
      "Loss: 0.7025226950645447\n",
      "Loss: 0.6138334274291992\n",
      "Loss: 0.6272708773612976\n",
      "Loss: 0.6425638198852539\n",
      "Loss: 0.6683241128921509\n",
      "Loss: 0.6094646453857422\n",
      "Loss: 0.6524343490600586\n",
      "Loss: 0.5783283710479736\n",
      "Loss: 0.7427260875701904\n",
      "Loss: 0.682782769203186\n",
      "Loss: 0.7019050717353821\n",
      "Loss: 0.6265088319778442\n",
      "Loss: 0.6690075397491455\n",
      "Loss: 0.6963489651679993\n",
      "Loss: 0.6100125312805176\n",
      "Loss: 0.6596739888191223\n",
      "Loss: 0.7028464078903198\n",
      "Loss: 0.6716359257698059\n",
      "Loss: 0.6336871385574341\n",
      "Loss: 0.6995968222618103\n",
      "Loss: 0.6004866361618042\n",
      "Loss: 0.6948298811912537\n",
      "Loss: 0.6400387287139893\n",
      "Loss: 0.7139379978179932\n",
      "Loss: 0.6482703685760498\n",
      "Loss: 0.6472674608230591\n",
      "Loss: 0.7296012043952942\n",
      "Loss: 0.6304286122322083\n",
      "Loss: 0.6194888353347778\n",
      "Loss: 0.6686064600944519\n",
      "Loss: 0.7034413814544678\n",
      "Loss: 0.6755766272544861\n",
      "Loss: 0.7101917862892151\n",
      "Loss: 0.6241839528083801\n",
      "Loss: 0.6490272879600525\n",
      "Loss: 0.618236243724823\n",
      "Loss: 0.605742335319519\n",
      "Loss: 0.6856814026832581\n",
      "Loss: 0.6671653985977173\n",
      "Loss: 0.6633613705635071\n",
      "Loss: 0.6749600768089294\n",
      "Loss: 0.6757565140724182\n",
      "Loss: 0.6495339870452881\n",
      "Loss: 0.720951497554779\n",
      "Loss: 0.6700604557991028\n",
      "Loss: 0.5911733508110046\n",
      "Loss: 0.6470400094985962\n",
      "Loss: 0.6492125391960144\n",
      "Loss: 0.6161158084869385\n",
      "Loss: 0.7686225175857544\n",
      "Loss: 0.6638348698616028\n",
      "Loss: 0.5778965353965759\n",
      "Loss: 0.688770055770874\n",
      "Loss: 0.7268248200416565\n",
      "Loss: 0.6587111949920654\n",
      "Loss: 0.6517132520675659\n",
      "Loss: 0.6158061027526855\n",
      "Loss: 0.6882557272911072\n",
      "Loss: 0.5809682607650757\n",
      "Loss: 0.7287513613700867\n",
      "Loss: 0.6498738527297974\n",
      "Loss: 0.6497368812561035\n",
      "Loss: 0.6275155544281006\n",
      "Loss: 0.6393497586250305\n",
      "Loss: 0.6059772968292236\n",
      "Loss: 0.7186261415481567\n",
      "Loss: 0.6017559766769409\n",
      "Loss: 0.6001033782958984\n",
      "Loss: 0.5176513195037842\n",
      "Loss: 0.6332300901412964\n",
      "Loss: 0.7060821056365967\n",
      "Loss: 0.54921555519104\n",
      "Loss: 0.5943887829780579\n",
      "Loss: 0.684271514415741\n",
      "Loss: 0.6490146517753601\n",
      "Loss: 0.6167719960212708\n",
      "Loss: 0.5932884216308594\n",
      "Loss: 0.6312822699546814\n",
      "Loss: 0.5665618181228638\n",
      "Loss: 0.6635754108428955\n",
      "Loss: 0.6304581761360168\n",
      "Loss: 0.6486577987670898\n",
      "Loss: 0.6596009731292725\n",
      "Loss: 0.5566977262496948\n",
      "Loss: 0.6501677632331848\n",
      "Loss: 0.6477729678153992\n",
      "Loss: 0.6336405277252197\n",
      "Loss: 0.6682382225990295\n",
      "Loss: 0.6323898434638977\n",
      "Loss: 0.6455850005149841\n",
      "Loss: 0.6311818957328796\n",
      "Loss: 0.6168086528778076\n",
      "Loss: 0.6667517423629761\n",
      "Loss: 0.6296125650405884\n",
      "Loss: 0.625415563583374\n",
      "Loss: 0.5904462933540344\n",
      "Loss: 0.645765483379364\n",
      "Loss: 0.5902537703514099\n",
      "Loss: 0.669938325881958\n",
      "Loss: 0.7286660075187683\n",
      "Loss: 0.7532824277877808\n",
      "Loss: 0.566114604473114\n",
      "Loss: 0.6550273895263672\n",
      "Loss: 0.546983540058136\n",
      "Loss: 0.6290077567100525\n",
      "Loss: 0.692173421382904\n",
      "Loss: 0.6807385087013245\n",
      "Loss: 0.6388932466506958\n",
      "Loss: 0.6620500683784485\n",
      "Loss: 0.6680265665054321\n",
      "Loss: 0.6984848380088806\n",
      "Loss: 0.588913083076477\n",
      "Loss: 0.5734347701072693\n",
      "Loss: 0.7533166408538818\n",
      "Loss: 0.6679649949073792\n",
      "Loss: 0.5875838398933411\n",
      "Loss: 0.7001792788505554\n",
      "Loss: 0.6329872608184814\n",
      "Loss: 0.602683424949646\n",
      "Loss: 0.6290046572685242\n",
      "Loss: 0.6127899885177612\n",
      "Loss: 0.637198805809021\n",
      "Loss: 0.722124457359314\n",
      "Loss: 0.5698623061180115\n",
      "Loss: 0.6033245921134949\n",
      "Loss: 0.6190469264984131\n",
      "Loss: 0.6192402243614197\n",
      "Loss: 0.7357990145683289\n",
      "Loss: 0.614374577999115\n",
      "Loss: 0.6681204438209534\n",
      "Loss: 0.6450891494750977\n",
      "Loss: 0.6322606205940247\n",
      "Loss: 0.6136226654052734\n",
      "Loss: 0.5882457494735718\n",
      "Loss: 0.6095374226570129\n",
      "Loss: 0.6559566259384155\n",
      "Loss: 0.6246441602706909\n",
      "Loss: 0.6781812906265259\n",
      "Loss: 0.6336641311645508\n",
      "Loss: 0.6797570586204529\n",
      "Loss: 0.6532610058784485\n",
      "Loss: 0.6592857241630554\n",
      "Loss: 0.6889740228652954\n",
      "Loss: 0.6915134787559509\n",
      "Loss: 0.6132074594497681\n",
      "Loss: 0.6485235691070557\n",
      "Loss: 0.6405560374259949\n",
      "Loss: 0.6137307286262512\n",
      "Loss: 0.6878138184547424\n",
      "Loss: 0.6878865957260132\n",
      "Loss: 0.5901399850845337\n",
      "Loss: 0.6677300333976746\n",
      "Loss: 0.6118271946907043\n",
      "Loss: 0.6933373808860779\n",
      "Loss: 0.6764234900474548\n",
      "Loss: 0.6382848024368286\n",
      "Loss: 0.6204755902290344\n",
      "Loss: 0.6326084136962891\n",
      "Loss: 0.6092562675476074\n",
      "Loss: 0.68266761302948\n",
      "Loss: 0.6448511481285095\n",
      "Loss: 0.6803996562957764\n",
      "Loss: 0.6792455911636353\n",
      "Loss: 0.6731045842170715\n",
      "Loss: 0.7319449186325073\n",
      "Loss: 0.62890625\n",
      "Loss: 0.7030505537986755\n",
      "Loss: 0.6493820548057556\n",
      "Loss: 0.6747692823410034\n",
      "Loss: 0.6436090469360352\n",
      "Loss: 0.6433481574058533\n",
      "Loss: 0.7504797577857971\n",
      "Loss: 0.6210373640060425\n",
      "Loss: 0.6156637072563171\n",
      "Loss: 0.6027223467826843\n",
      "Loss: 0.5957145094871521\n",
      "Loss: 0.6251223683357239\n",
      "Loss: 0.6755653619766235\n",
      "Loss: 0.5696441531181335\n",
      "Loss: 0.6170128583908081\n",
      "Loss: 0.6799746155738831\n",
      "Loss: 0.6398248076438904\n",
      "Loss: 0.7324445247650146\n",
      "Loss: 0.701766848564148\n",
      "Loss: 0.6499139666557312\n",
      "Loss: 0.6443389654159546\n",
      "Loss: 0.6662576198577881\n",
      "Loss: 0.6631557941436768\n",
      "Loss: 0.6594550013542175\n",
      "Loss: 0.722007691860199\n",
      "Loss: 0.6897760033607483\n",
      "Loss: 0.6330828070640564\n",
      "Loss: 0.5940369367599487\n",
      "Loss: 0.6963301301002502\n",
      "Loss: 0.6237209439277649\n",
      "Loss: 0.6280210614204407\n",
      "Loss: 0.6674595475196838\n",
      "Loss: 0.6595795154571533\n",
      "Loss: 0.6644176840782166\n",
      "Loss: 0.6166304349899292\n",
      "Loss: 0.6633012294769287\n",
      "Loss: 0.681432843208313\n",
      "Loss: 0.6766988039016724\n",
      "Loss: 0.6501755714416504\n",
      "Loss: 0.6719061136245728\n",
      "Loss: 0.6082651615142822\n",
      "Loss: 0.7507744431495667\n",
      "Loss: 0.579151451587677\n",
      "Loss: 0.6291241645812988\n",
      "Loss: 0.6507967710494995\n",
      "Loss: 0.7313079237937927\n",
      "Loss: 0.6447521448135376\n",
      "Loss: 0.6561287045478821\n",
      "Loss: 0.6978182196617126\n",
      "Loss: 0.5592729449272156\n",
      "Loss: 0.6395136117935181\n",
      "Loss: 0.654617965221405\n",
      "Loss: 0.6211079359054565\n",
      "Loss: 0.6378278732299805\n",
      "Loss: 0.6130102872848511\n",
      "Loss: 0.5572454333305359\n",
      "Loss: 0.6749679446220398\n",
      "Loss: 0.6260765790939331\n",
      "Loss: 0.7065807580947876\n",
      "Loss: 0.6479474902153015\n",
      "Loss: 0.6592777967453003\n",
      "Loss: 0.633396565914154\n",
      "Loss: 0.6841351985931396\n",
      "Loss: 0.6547861099243164\n",
      "Loss: 0.6567896604537964\n",
      "Loss: 0.5776388049125671\n",
      "Loss: 0.6314510107040405\n",
      "Loss: 0.6754254698753357\n",
      "Loss: 0.5910303592681885\n",
      "Loss: 0.6773649454116821\n",
      "Loss: 0.6774558424949646\n",
      "Loss: 0.5851014256477356\n",
      "Loss: 0.6742674112319946\n",
      "Loss: 0.6684953570365906\n",
      "Loss: 0.6501108407974243\n",
      "Loss: 0.5790018439292908\n",
      "Loss: 0.6718071699142456\n",
      "Loss: 0.613429069519043\n",
      "Loss: 0.6502290964126587\n",
      "Loss: 0.6709813475608826\n",
      "Loss: 0.6644342541694641\n",
      "Loss: 0.5998332500457764\n",
      "Loss: 0.5903987884521484\n",
      "Loss: 0.70075923204422\n",
      "Loss: 0.6158096194267273\n",
      "Loss: 0.614320695400238\n",
      "Loss: 0.6355800032615662\n",
      "Loss: 0.7093536257743835\n",
      "Loss: 0.6714479327201843\n",
      "Loss: 0.620194137096405\n",
      "Loss: 0.6779601573944092\n",
      "Loss: 0.6374363899230957\n",
      "Loss: 0.7367583513259888\n",
      "Loss: 0.648884117603302\n",
      "Loss: 0.655768632888794\n",
      "Loss: 0.6258589029312134\n",
      "Loss: 0.7225247025489807\n",
      "Loss: 0.687250018119812\n",
      "Loss: 0.6707307696342468\n",
      "Loss: 0.5514388680458069\n",
      "Loss: 0.5887105464935303\n",
      "Loss: 0.658193051815033\n",
      "Loss: 0.65189528465271\n",
      "Loss: 0.6070060729980469\n",
      "Loss: 0.6624242663383484\n",
      "Loss: 0.574880063533783\n",
      "Loss: 0.6360241174697876\n",
      "Loss: 0.6113093495368958\n",
      "Loss: 0.6464561820030212\n",
      "Loss: 0.6043204069137573\n",
      "Loss: 0.6656308174133301\n",
      "Loss: 0.5819964408874512\n",
      "Loss: 0.624407947063446\n",
      "Loss: 0.6711371541023254\n",
      "Loss: 0.6235274076461792\n",
      "Loss: 0.6750363707542419\n",
      "Loss: 0.6314112544059753\n",
      "Loss: 0.6017739772796631\n",
      "Loss: 0.6499788761138916\n",
      "Loss: 0.7490620017051697\n",
      "Loss: 0.6335079669952393\n",
      "Loss: 0.688694417476654\n",
      "Loss: 0.6293916702270508\n",
      "Loss: 0.7005492448806763\n",
      "Loss: 0.5996158719062805\n",
      "Loss: 0.6440462470054626\n",
      "Loss: 0.645939290523529\n",
      "Loss: 0.6333662271499634\n",
      "Loss: 0.632470428943634\n",
      "Loss: 0.5947641730308533\n",
      "Loss: 0.5905197858810425\n",
      "Loss: 0.6455001831054688\n",
      "Loss: 0.6114214658737183\n",
      "Loss: 0.6374683380126953\n",
      "Loss: 0.5966978073120117\n",
      "Loss: 0.6299933195114136\n",
      "Loss: 0.6313361525535583\n",
      "Loss: 0.6083669662475586\n",
      "Loss: 0.6028157472610474\n",
      "Loss: 0.6641332507133484\n",
      "Loss: 0.665658712387085\n",
      "Loss: 0.670208752155304\n",
      "Loss: 0.7142356038093567\n",
      "Loss: 0.6003632545471191\n",
      "Loss: 0.6418881416320801\n",
      "Loss: 0.6989203095436096\n",
      "Loss: 0.7262843251228333\n",
      "Loss: 0.7089431285858154\n",
      "Loss: 0.598388135433197\n",
      "Loss: 0.6670222878456116\n",
      "Loss: 0.6027197241783142\n",
      "Loss: 0.6983969211578369\n",
      "Loss: 0.7375847697257996\n",
      "Loss: 0.5670580267906189\n",
      "Loss: 0.6610562205314636\n",
      "Loss: 0.6077958941459656\n",
      "Loss: 0.6415485739707947\n",
      "Loss: 0.6243360638618469\n",
      "Loss: 0.6577545404434204\n",
      "Loss: 0.6053223609924316\n",
      "Loss: 0.6286662220954895\n",
      "Loss: 0.6803189516067505\n",
      "Loss: 0.657276451587677\n",
      "Loss: 0.5242380499839783\n",
      "Loss: 0.686693012714386\n",
      "Loss: 0.6218426823616028\n",
      "Loss: 0.6367353796958923\n",
      "Loss: 0.6746849417686462\n",
      "Loss: 0.6362612843513489\n",
      "Loss: 0.645033597946167\n",
      "Loss: 0.6769744753837585\n",
      "Loss: 0.7371159195899963\n",
      "Loss: 0.5595712661743164\n",
      "Loss: 0.6008797883987427\n",
      "Loss: 0.6895604729652405\n",
      "Loss: 0.7135430574417114\n",
      "Loss: 0.6198588609695435\n",
      "Loss: 0.6229193806648254\n",
      "Loss: 0.6456061601638794\n",
      "Loss: 0.673489511013031\n",
      "Loss: 0.6517660021781921\n",
      "Loss: 0.6197370290756226\n",
      "Loss: 0.5424819588661194\n",
      "Loss: 0.6393846869468689\n",
      "Loss: 0.6699812412261963\n",
      "Loss: 0.6555353403091431\n",
      "Loss: 0.66356360912323\n",
      "Loss: 0.6849226355552673\n",
      "Loss: 0.6821454167366028\n",
      "Loss: 0.7129510045051575\n",
      "Loss: 0.6458107829093933\n",
      "Loss: 0.6182188391685486\n",
      "Loss: 0.6888673901557922\n",
      "Loss: 0.6052774786949158\n",
      "Loss: 0.6354552507400513\n",
      "Loss: 0.6860045790672302\n",
      "Loss: 0.6220249533653259\n",
      "Loss: 0.6646456718444824\n",
      "Loss: 0.6493241786956787\n",
      "Loss: 0.6253200769424438\n",
      "Loss: 0.5832836031913757\n",
      "Loss: 0.6995505690574646\n",
      "Loss: 0.6605828404426575\n",
      "Loss: 0.6256693601608276\n",
      "Loss: 0.6777578592300415\n",
      "Loss: 0.6237399578094482\n",
      "Loss: 0.6659895777702332\n",
      "Loss: 0.6343560218811035\n",
      "Loss: 0.772860586643219\n",
      "Loss: 0.7040449976921082\n",
      "Loss: 0.7627227306365967\n",
      "Loss: 0.6384477019309998\n",
      "Loss: 0.6907483339309692\n",
      "Loss: 0.5567080974578857\n",
      "Loss: 0.6681114435195923\n",
      "Loss: 0.7216616272926331\n",
      "Loss: 0.6355236172676086\n",
      "Loss: 0.5709346532821655\n",
      "Loss: 0.663261353969574\n",
      "Loss: 0.6290023326873779\n",
      "Loss: 0.6254696249961853\n",
      "Loss: 0.6819527745246887\n",
      "Loss: 0.6467195749282837\n",
      "Loss: 0.5018565654754639\n",
      "Loss: 0.5982599258422852\n",
      "Loss: 0.6654353141784668\n",
      "Loss: 0.639661431312561\n",
      "Loss: 0.6714411377906799\n",
      "Loss: 0.7308419346809387\n",
      "Loss: 0.626804769039154\n",
      "Loss: 0.6876549124717712\n",
      "Loss: 0.7232931852340698\n",
      "Loss: 0.7040626406669617\n",
      "Loss: 0.6652355194091797\n",
      "Loss: 0.574622631072998\n",
      "Loss: 0.5594860315322876\n",
      "Loss: 0.6614496111869812\n",
      "Loss: 0.622199535369873\n",
      "Loss: 0.6636485457420349\n",
      "Loss: 0.662111759185791\n",
      "Loss: 0.6435338854789734\n",
      "Loss: 0.6553249359130859\n",
      "Loss: 0.6987384557723999\n",
      "Loss: 0.6576642990112305\n",
      "Loss: 0.6065293550491333\n",
      "Loss: 0.5778272151947021\n",
      "Loss: 0.6247369647026062\n",
      "Loss: 0.7047369480133057\n",
      "Loss: 0.608305811882019\n",
      "Loss: 0.5884630084037781\n",
      "Loss: 0.7288554906845093\n",
      "Loss: 0.6628002524375916\n",
      "Loss: 0.6535595655441284\n",
      "Loss: 0.6922114491462708\n",
      "Loss: 0.673123300075531\n",
      "Loss: 0.7106028199195862\n",
      "Loss: 0.6849932074546814\n",
      "Loss: 0.65273517370224\n",
      "Loss: 0.6548506617546082\n",
      "Loss: 0.6121847033500671\n",
      "Loss: 0.6414311528205872\n",
      "Loss: 0.7521164417266846\n",
      "Loss: 0.5976881980895996\n",
      "Loss: 0.623308539390564\n",
      "Loss: 0.6679272055625916\n",
      "Loss: 0.6519741415977478\n",
      "Loss: 0.6901229023933411\n",
      "Loss: 0.5942894220352173\n",
      "Loss: 0.7001510262489319\n",
      "Loss: 0.6574997305870056\n",
      "Loss: 0.6111915111541748\n",
      "Loss: 0.6374877095222473\n",
      "Loss: 0.6484143733978271\n",
      "Loss: 0.618560254573822\n",
      "Loss: 0.6839941740036011\n",
      "Loss: 0.6072632074356079\n",
      "Loss: 0.5407999753952026\n",
      "Loss: 0.6568793058395386\n",
      "Loss: 0.6573346257209778\n",
      "Loss: 0.655238151550293\n",
      "Loss: 0.6087456941604614\n",
      "Loss: 0.6651874780654907\n",
      "Loss: 0.6508575677871704\n",
      "Loss: 0.6709069609642029\n",
      "Loss: 0.6797865629196167\n",
      "Loss: 0.7519571185112\n",
      "Loss: 0.683928370475769\n",
      "Loss: 0.6781827807426453\n",
      "Loss: 0.6247891783714294\n",
      "Loss: 0.6808933615684509\n",
      "Loss: 0.6226586103439331\n",
      "Loss: 0.6364647150039673\n",
      "Loss: 0.7002060413360596\n",
      "Loss: 0.6201977133750916\n",
      "Loss: 0.6442921161651611\n",
      "Loss: 0.6147649884223938\n",
      "Loss: 0.6448262333869934\n",
      "Loss: 0.6857154369354248\n",
      "Loss: 0.612104594707489\n",
      "Loss: 0.6409634351730347\n",
      "Loss: 0.6292247772216797\n",
      "Loss: 0.6939812302589417\n",
      "Loss: 0.6769683361053467\n",
      "Loss: 0.5610868334770203\n",
      "Loss: 0.6375735998153687\n",
      "Loss: 0.6342372894287109\n",
      "Loss: 0.5890700817108154\n",
      "Loss: 0.7079166769981384\n",
      "Loss: 0.7462794780731201\n",
      "Loss: 0.6776506304740906\n",
      "Loss: 0.6550906300544739\n",
      "Loss: 0.702356219291687\n",
      "Loss: 0.6797117590904236\n",
      "Loss: 0.7099607586860657\n",
      "Loss: 0.5841274261474609\n",
      "Loss: 0.6075344085693359\n",
      "Loss: 0.5971059799194336\n",
      "Loss: 0.6632422208786011\n",
      "Loss: 0.5728128552436829\n",
      "Loss: 0.6631190776824951\n",
      "Loss: 0.6578180193901062\n",
      "Loss: 0.6470829248428345\n",
      "Loss: 0.6693839430809021\n",
      "Loss: 0.6536824107170105\n",
      "Loss: 0.6315252780914307\n",
      "Loss: 0.6176725625991821\n",
      "Loss: 0.6124218106269836\n",
      "Loss: 0.6142746210098267\n",
      "Loss: 0.5970291495323181\n",
      "Loss: 0.7079617977142334\n",
      "Loss: 0.5968455076217651\n",
      "Loss: 0.6251091957092285\n",
      "Loss: 0.6540842056274414\n",
      "Loss: 0.573185920715332\n",
      "Loss: 0.7142087817192078\n",
      "Loss: 0.6847917437553406\n",
      "Loss: 0.6691171526908875\n",
      "Loss: 0.6282774209976196\n",
      "Loss: 0.6558640599250793\n",
      "Loss: 0.6718445420265198\n",
      "Loss: 0.7153617739677429\n",
      "Loss: 0.6556373834609985\n",
      "Loss: 0.6806743144989014\n",
      "Loss: 0.6139470338821411\n",
      "Loss: 0.6125046014785767\n",
      "Loss: 0.7372192740440369\n",
      "Loss: 0.686862051486969\n",
      "Loss: 0.6830565929412842\n",
      "Loss: 0.715977132320404\n",
      "Loss: 0.6577879786491394\n",
      "Loss: 0.7283069491386414\n",
      "Loss: 0.6148940920829773\n",
      "Loss: 0.6297975778579712\n",
      "Loss: 0.6517190933227539\n",
      "Loss: 0.6791059374809265\n",
      "Loss: 0.7076005339622498\n",
      "Loss: 0.7130725383758545\n",
      "Loss: 0.5054841041564941\n",
      "Loss: 0.6344327330589294\n",
      "Loss: 0.6494506001472473\n",
      "Loss: 0.5863947868347168\n",
      "Loss: 0.6267508268356323\n",
      "Loss: 0.615463376045227\n",
      "Loss: 0.6359741687774658\n",
      "Loss: 0.6388740539550781\n",
      "Loss: 0.535737156867981\n",
      "Loss: 0.5597199201583862\n",
      "Loss: 0.6572429537773132\n",
      "Loss: 0.632797360420227\n",
      "Loss: 0.5964736938476562\n",
      "Loss: 0.6604801416397095\n",
      "Loss: 0.6760897040367126\n",
      "Loss: 0.6587269902229309\n",
      "Loss: 0.7400429844856262\n",
      "Loss: 0.6317285895347595\n",
      "Loss: 0.7326487302780151\n",
      "Loss: 0.6611930727958679\n",
      "Loss: 0.6563118696212769\n",
      "Loss: 0.6673089861869812\n",
      "Loss: 0.6503477096557617\n",
      "Loss: 0.6388260126113892\n",
      "Loss: 0.6386532187461853\n",
      "Loss: 0.6307947039604187\n",
      "Loss: 0.62135249376297\n",
      "Loss: 0.7421392202377319\n",
      "Loss: 0.6777096390724182\n",
      "Loss: 0.664042592048645\n",
      "Loss: 0.57219398021698\n",
      "Loss: 0.6559047698974609\n",
      "Loss: 0.5346279740333557\n",
      "Loss: 0.6662678122520447\n",
      "Loss: 0.6498184204101562\n",
      "Loss: 0.6446620225906372\n",
      "Loss: 0.7064991593360901\n",
      "Loss: 0.6488935947418213\n",
      "Loss: 0.5463636517524719\n",
      "Loss: 0.6458518505096436\n",
      "Loss: 0.6622359752655029\n",
      "Loss: 0.6427198648452759\n",
      "Loss: 0.5877990126609802\n",
      "Loss: 0.6695073246955872\n",
      "Loss: 0.6459611654281616\n",
      "Loss: 0.6633411645889282\n",
      "Loss: 0.5940524339675903\n",
      "Loss: 0.7007545232772827\n",
      "Loss: 0.6236135363578796\n",
      "Loss: 0.6280081868171692\n",
      "Loss: 0.583267867565155\n",
      "Loss: 0.6423002481460571\n",
      "Loss: 0.6978314518928528\n",
      "Loss: 0.6562075018882751\n",
      "Loss: 0.6806115508079529\n",
      "Loss: 0.7021178007125854\n",
      "Loss: 0.6266523599624634\n",
      "Loss: 0.6321026086807251\n",
      "Loss: 0.6210077404975891\n",
      "Loss: 0.5775071382522583\n",
      "Loss: 0.6362480521202087\n",
      "Loss: 0.5982069969177246\n",
      "Loss: 0.6981632709503174\n",
      "Loss: 0.5922560095787048\n",
      "Loss: 0.6215704679489136\n",
      "Loss: 0.7044565081596375\n",
      "Loss: 0.6950880289077759\n",
      "Loss: 0.7681816816329956\n",
      "Loss: 0.7219144701957703\n",
      "Loss: 0.655179500579834\n",
      "Loss: 0.569056510925293\n",
      "Loss: 0.6697871685028076\n",
      "Loss: 0.6769984364509583\n",
      "Loss: 0.5380446910858154\n",
      "Loss: 0.595077395439148\n",
      "Loss: 0.5786168575286865\n",
      "Loss: 0.6693077683448792\n",
      "Loss: 0.7238103151321411\n",
      "Loss: 0.6639885306358337\n",
      "Loss: 0.5946815013885498\n",
      "Loss: 0.5796322226524353\n",
      "Loss: 0.6617755889892578\n",
      "Loss: 0.7244743704795837\n",
      "Loss: 0.7357848286628723\n",
      "Loss: 0.6317941546440125\n",
      "Loss: 0.6732639074325562\n",
      "Loss: 0.6921392679214478\n",
      "Loss: 0.6947828531265259\n",
      "Loss: 0.6474202275276184\n",
      "Loss: 0.5970441102981567\n",
      "Loss: 0.6736693978309631\n",
      "Loss: 0.6344579458236694\n",
      "Loss: 0.6380317211151123\n",
      "Loss: 0.553652286529541\n",
      "Loss: 0.6264382600784302\n",
      "Loss: 0.6397870779037476\n",
      "Loss: 0.6407710313796997\n",
      "Loss: 0.6786110997200012\n",
      "Loss: 0.6402802467346191\n",
      "Loss: 0.5832546353340149\n",
      "Loss: 0.6397234797477722\n",
      "Loss: 0.5944716334342957\n",
      "Loss: 0.6410207748413086\n",
      "Loss: 0.6355660557746887\n",
      "Loss: 0.6070989370346069\n",
      "Loss: 0.6319629549980164\n",
      "Loss: 0.6450663805007935\n",
      "Loss: 0.6597644090652466\n",
      "Loss: 0.7120676636695862\n",
      "Loss: 0.6494808197021484\n",
      "Loss: 0.7318899035453796\n",
      "Loss: 0.6476771831512451\n",
      "Loss: 0.6668950915336609\n",
      "Loss: 0.6187538504600525\n",
      "Loss: 0.6621628999710083\n",
      "Loss: 0.6888378262519836\n",
      "Loss: 0.6117608547210693\n",
      "Loss: 0.6039799451828003\n",
      "Loss: 0.7036870121955872\n",
      "Loss: 0.625372588634491\n",
      "Loss: 0.6052788496017456\n",
      "Loss: 0.6662807464599609\n",
      "Loss: 0.583088755607605\n",
      "Loss: 0.7230252027511597\n",
      "Loss: 0.6328431963920593\n",
      "Loss: 0.6224948763847351\n",
      "Loss: 0.6808382272720337\n",
      "Loss: 0.6360466480255127\n",
      "Loss: 0.6379534602165222\n",
      "Loss: 0.6839171051979065\n",
      "Loss: 0.6820655465126038\n",
      "Loss: 0.7154409289360046\n",
      "Loss: 0.7597249150276184\n",
      "Loss: 0.6146551370620728\n",
      "Loss: 0.6845136880874634\n",
      "Loss: 0.5458528995513916\n",
      "Loss: 0.6420335173606873\n",
      "Loss: 0.6770135760307312\n",
      "Loss: 0.7103827595710754\n",
      "Loss: 0.6621927618980408\n",
      "Loss: 0.6143957376480103\n",
      "Loss: 0.6867908835411072\n",
      "Loss: 0.6664631962776184\n",
      "Loss: 0.6370455622673035\n",
      "Loss: 0.6227516531944275\n",
      "Loss: 0.6561231017112732\n",
      "Loss: 0.6627833843231201\n",
      "Loss: 0.6653154492378235\n",
      "Loss: 0.67616206407547\n",
      "Loss: 0.7206966280937195\n",
      "Loss: 0.5854007601737976\n",
      "Loss: 0.6919691562652588\n",
      "Loss: 0.6831133961677551\n",
      "Loss: 0.7000558376312256\n",
      "Loss: 0.7027484774589539\n",
      "Loss: 0.5809605717658997\n",
      "Loss: 0.6176934242248535\n",
      "Loss: 0.6436083912849426\n",
      "Loss: 0.624125599861145\n",
      "Loss: 0.6235084533691406\n",
      "Loss: 0.7526445984840393\n",
      "Loss: 0.5804882049560547\n",
      "Loss: 0.6283592581748962\n",
      "Loss: 0.7077090740203857\n",
      "Loss: 0.6621355414390564\n",
      "Loss: 0.5498306155204773\n",
      "Loss: 0.5787528157234192\n",
      "Loss: 0.6949593424797058\n",
      "Loss: 0.6561734676361084\n",
      "Loss: 0.6563275456428528\n",
      "Loss: 0.5689213871955872\n",
      "Loss: 0.5650267004966736\n",
      "Loss: 0.6166450381278992\n",
      "Loss: 0.6246880292892456\n",
      "Loss: 0.6696394085884094\n",
      "Loss: 0.5801448822021484\n",
      "Loss: 0.6182746291160583\n",
      "Loss: 0.6109195947647095\n",
      "Loss: 0.6453089118003845\n",
      "Loss: 0.6636389493942261\n",
      "Loss: 0.6079691648483276\n",
      "Loss: 0.6177282333374023\n",
      "Loss: 0.6558148860931396\n",
      "Loss: 0.6224811673164368\n",
      "Loss: 0.658716082572937\n",
      "Loss: 0.6045430302619934\n",
      "Loss: 0.6418882608413696\n",
      "Loss: 0.7166999578475952\n",
      "Loss: 0.635967493057251\n",
      "Loss: 0.6058314442634583\n",
      "Loss: 0.5702008008956909\n",
      "Loss: 0.6297707557678223\n",
      "Loss: 0.6634279489517212\n",
      "Loss: 0.6306151151657104\n",
      "Loss: 0.6066166758537292\n",
      "Loss: 0.6108947992324829\n",
      "Loss: 0.6485293507575989\n",
      "Loss: 0.6101739406585693\n",
      "Loss: 0.6595367193222046\n",
      "Loss: 0.6388329267501831\n",
      "Loss: 0.6311348676681519\n",
      "Loss: 0.690726637840271\n",
      "Loss: 0.5352331399917603\n",
      "Loss: 0.6219943761825562\n",
      "Loss: 0.6337578892707825\n",
      "Loss: 0.5767256617546082\n",
      "Loss: 0.713275671005249\n",
      "Loss: 0.6450878977775574\n",
      "Loss: 0.631339967250824\n",
      "Loss: 0.6390478014945984\n",
      "Loss: 0.60662841796875\n",
      "Loss: 0.6345856785774231\n",
      "Loss: 0.6551400423049927\n",
      "Loss: 0.7226492166519165\n",
      "Loss: 0.5862047076225281\n",
      "Loss: 0.7333340048789978\n",
      "Loss: 0.6234620213508606\n",
      "Loss: 0.6843244433403015\n",
      "Loss: 0.6219565868377686\n",
      "Loss: 0.5864056348800659\n",
      "Loss: 0.6347110867500305\n",
      "Loss: 0.7134260535240173\n",
      "Loss: 0.707929790019989\n",
      "Loss: 0.6611232757568359\n",
      "Loss: 0.6492105722427368\n",
      "Loss: 0.7135597467422485\n",
      "Loss: 0.731296956539154\n",
      "Loss: 0.7190718054771423\n",
      "Loss: 0.6230899691581726\n",
      "Loss: 0.647286593914032\n",
      "Loss: 0.6266986131668091\n",
      "Loss: 0.5920681953430176\n",
      "Loss: 0.6118814945220947\n",
      "Loss: 0.6431241035461426\n",
      "Loss: 0.6114822626113892\n",
      "Loss: 0.7045405507087708\n",
      "Loss: 0.6769167184829712\n",
      "Loss: 0.6462699770927429\n",
      "Loss: 0.6062561273574829\n",
      "Loss: 0.6357935667037964\n",
      "Loss: 0.707014799118042\n",
      "Loss: 0.6669203042984009\n",
      "Loss: 0.6095420122146606\n",
      "Loss: 0.738744854927063\n",
      "Loss: 0.6807672381401062\n",
      "Loss: 0.6000156402587891\n",
      "Loss: 0.7309731841087341\n",
      "Loss: 0.6547891497612\n",
      "Loss: 0.7376665472984314\n",
      "Loss: 0.6161678433418274\n",
      "Loss: 0.6469186544418335\n",
      "Loss: 0.6306748390197754\n",
      "Loss: 0.6977393627166748\n",
      "Loss: 0.6304004192352295\n",
      "Loss: 0.648817241191864\n",
      "Loss: 0.6524408459663391\n",
      "Loss: 0.5675594806671143\n",
      "Loss: 0.6268057227134705\n",
      "Loss: 0.6105117797851562\n",
      "Loss: 0.6332660913467407\n",
      "Loss: 0.6250863075256348\n",
      "Loss: 0.7200745344161987\n",
      "Loss: 0.575125515460968\n",
      "Loss: 0.6944686770439148\n",
      "Loss: 0.6727402806282043\n",
      "Loss: 0.5841113328933716\n",
      "Loss: 0.6283749341964722\n",
      "Loss: 0.6416528820991516\n",
      "Loss: 0.6324183344841003\n",
      "Loss: 0.6458165645599365\n",
      "Loss: 0.6225051879882812\n",
      "Loss: 0.7362641096115112\n",
      "Loss: 0.6208423972129822\n",
      "Loss: 0.5983884930610657\n",
      "Loss: 0.6557114720344543\n",
      "Loss: 0.5624163746833801\n",
      "Loss: 0.531828761100769\n",
      "Loss: 0.6232175827026367\n",
      "Loss: 0.67287677526474\n",
      "Loss: 0.6872059106826782\n",
      "Loss: 0.6930333971977234\n",
      "Loss: 0.7426391839981079\n",
      "Loss: 0.7043721675872803\n",
      "Loss: 0.6044477820396423\n",
      "Loss: 0.6154493689537048\n",
      "Loss: 0.7127496004104614\n",
      "Loss: 0.6604987978935242\n",
      "Loss: 0.6779568791389465\n",
      "Loss: 0.5687922239303589\n",
      "Loss: 0.5886608958244324\n",
      "Loss: 0.6737949252128601\n",
      "Loss: 0.6877928376197815\n",
      "Loss: 0.6320562362670898\n",
      "Loss: 0.7073180675506592\n",
      "Loss: 0.6390156745910645\n",
      "Loss: 0.6407326459884644\n",
      "Loss: 0.6186255216598511\n",
      "Loss: 0.7461575269699097\n",
      "Loss: 0.6031133532524109\n",
      "Loss: 0.6875274181365967\n",
      "Loss: 0.548578679561615\n",
      "Loss: 0.6567121744155884\n",
      "Loss: 0.5952701568603516\n",
      "Loss: 0.6069514155387878\n",
      "Loss: 0.6827582120895386\n",
      "Loss: 0.6386539936065674\n",
      "Loss: 0.6708516478538513\n",
      "Loss: 0.6104143261909485\n",
      "Loss: 0.614301323890686\n",
      "Loss: 0.664549708366394\n",
      "Loss: 0.5520955920219421\n",
      "Loss: 0.6840999722480774\n",
      "Loss: 0.5401591062545776\n",
      "Loss: 0.6667520999908447\n",
      "Loss: 0.6698604226112366\n",
      "Loss: 0.6608389019966125\n",
      "Loss: 0.6850577592849731\n",
      "Loss: 0.700067937374115\n",
      "Loss: 0.6960775256156921\n",
      "Loss: 0.6481426358222961\n",
      "Loss: 0.6630553007125854\n",
      "Loss: 0.6952725052833557\n",
      "Loss: 0.6501492261886597\n",
      "Loss: 0.6209324598312378\n",
      "Loss: 0.6327822804450989\n",
      "Loss: 0.6258471608161926\n",
      "Loss: 0.6590125560760498\n",
      "Loss: 0.6647577285766602\n",
      "Loss: 0.6398488283157349\n",
      "Loss: 0.5753218531608582\n",
      "Loss: 0.6703924536705017\n",
      "Loss: 0.6501558423042297\n",
      "Loss: 0.6466066241264343\n",
      "Loss: 0.5983289480209351\n",
      "Loss: 0.6226428151130676\n",
      "Loss: 0.6748043894767761\n",
      "Loss: 0.6407158374786377\n",
      "Loss: 0.617232084274292\n",
      "Loss: 0.5799639821052551\n",
      "Loss: 0.685493528842926\n",
      "Loss: 0.6611030101776123\n",
      "Loss: 0.6352112889289856\n",
      "Loss: 0.5920263528823853\n",
      "Loss: 0.6190971732139587\n",
      "Loss: 0.6466231346130371\n",
      "Loss: 0.699146568775177\n",
      "Loss: 0.6953907608985901\n",
      "Loss: 0.6933535933494568\n",
      "Loss: 0.6818360090255737\n",
      "Loss: 0.6054675579071045\n",
      "Loss: 0.6333111524581909\n",
      "Loss: 0.6175340414047241\n",
      "Loss: 0.6218947172164917\n",
      "Loss: 0.6790191531181335\n",
      "Loss: 0.6622890830039978\n",
      "Loss: 0.612838625907898\n",
      "Loss: 0.5876260995864868\n",
      "Loss: 0.6645310521125793\n",
      "Loss: 0.5079252123832703\n",
      "Loss: 0.6128320097923279\n",
      "Loss: 0.5900887250900269\n",
      "Loss: 0.686653733253479\n",
      "Loss: 0.6246189475059509\n",
      "Loss: 0.6312559247016907\n",
      "Loss: 0.6527456641197205\n",
      "Loss: 0.6628401875495911\n",
      "Loss: 0.6485121846199036\n",
      "Loss: 0.6938771605491638\n",
      "Loss: 0.6470362544059753\n",
      "Loss: 0.5602600574493408\n",
      "Loss: 0.642928421497345\n",
      "Loss: 0.5995758771896362\n",
      "Loss: 0.6725608706474304\n",
      "Loss: 0.636305034160614\n",
      "Loss: 0.66493821144104\n",
      "Loss: 0.6326495409011841\n",
      "Loss: 0.6480960845947266\n",
      "Loss: 0.7025157809257507\n",
      "Loss: 0.6215877532958984\n",
      "Loss: 0.5883273482322693\n",
      "Loss: 0.7066147923469543\n",
      "Loss: 0.6396921873092651\n",
      "Loss: 0.6657177209854126\n",
      "Loss: 0.6873533129692078\n",
      "Loss: 0.7149275541305542\n",
      "Loss: 0.6647185683250427\n",
      "Loss: 0.6696265935897827\n",
      "Loss: 0.5833443403244019\n",
      "Loss: 0.6401098370552063\n",
      "Loss: 0.5402251482009888\n",
      "Loss: 0.6328351497650146\n",
      "Loss: 0.5575863718986511\n",
      "Loss: 0.6109864115715027\n",
      "Loss: 0.6584860682487488\n",
      "Loss: 0.6716078519821167\n",
      "Loss: 0.6455939412117004\n",
      "Loss: 0.6305578351020813\n",
      "Loss: 0.7381570339202881\n",
      "Loss: 0.6435825228691101\n",
      "Loss: 0.6603196263313293\n",
      "Loss: 0.628353476524353\n",
      "Loss: 0.5903332233428955\n",
      "Loss: 0.6651031374931335\n",
      "Loss: 0.6383912563323975\n",
      "Loss: 0.6042964458465576\n",
      "Loss: 0.5258342027664185\n",
      "Loss: 0.6556951403617859\n",
      "Loss: 0.6117171049118042\n",
      "Loss: 0.7784697413444519\n",
      "Loss: 0.548549473285675\n",
      "Loss: 0.7129819393157959\n",
      "Loss: 0.6196342706680298\n",
      "Loss: 0.6270288825035095\n",
      "Loss: 0.563666045665741\n",
      "Loss: 0.6684203743934631\n",
      "Loss: 0.6331712603569031\n",
      "Loss: 0.5741786360740662\n",
      "Loss: 0.7464317083358765\n",
      "Loss: 0.6746446490287781\n",
      "Loss: 0.6379521489143372\n",
      "Loss: 0.6563652753829956\n",
      "Loss: 0.6547101140022278\n",
      "Loss: 0.5851219892501831\n",
      "Loss: 0.6034141778945923\n",
      "Loss: 0.6985998749732971\n",
      "Loss: 0.6548336148262024\n",
      "Loss: 0.6370737552642822\n",
      "Loss: 0.6530353426933289\n",
      "Loss: 0.597371518611908\n",
      "Loss: 0.641675591468811\n",
      "Loss: 0.7340362071990967\n",
      "Loss: 0.5717258453369141\n",
      "Loss: 0.6066353917121887\n",
      "Loss: 0.6656092405319214\n",
      "Loss: 0.7149351239204407\n",
      "Loss: 0.5859602093696594\n",
      "Loss: 0.609005331993103\n",
      "Loss: 0.672814130783081\n",
      "Loss: 0.6359368562698364\n",
      "Loss: 0.6358174681663513\n",
      "Loss: 0.6610015630722046\n",
      "Loss: 0.6579986810684204\n",
      "Loss: 0.6890820264816284\n",
      "Loss: 0.6697223782539368\n",
      "Loss: 0.71949702501297\n",
      "Loss: 0.6482171416282654\n",
      "Loss: 0.5656716227531433\n",
      "Loss: 0.6740228533744812\n",
      "Loss: 0.6596211791038513\n",
      "Loss: 0.7183477282524109\n",
      "Loss: 0.6443797945976257\n",
      "Loss: 0.6277481913566589\n",
      "Loss: 0.6848255395889282\n",
      "Loss: 0.6685305833816528\n",
      "Loss: 0.6411611437797546\n",
      "Loss: 0.6233551502227783\n",
      "Loss: 0.5716816186904907\n",
      "Loss: 0.5819839835166931\n",
      "Loss: 0.6695663332939148\n",
      "Loss: 0.7048229575157166\n",
      "Loss: 0.6994931697845459\n",
      "Loss: 0.6344308257102966\n",
      "Loss: 0.6871253848075867\n",
      "Loss: 0.6485860347747803\n",
      "Loss: 0.6376732587814331\n",
      "Loss: 0.6274697780609131\n",
      "Loss: 0.5450054407119751\n",
      "Loss: 0.5450453758239746\n",
      "Loss: 0.5705118775367737\n",
      "Loss: 0.7137262225151062\n",
      "Loss: 0.5739768147468567\n",
      "Loss: 0.6121858358383179\n",
      "Loss: 0.620217502117157\n",
      "Loss: 0.6128107309341431\n",
      "Loss: 0.642882764339447\n",
      "Loss: 0.6720536351203918\n",
      "Loss: 0.6119558215141296\n",
      "Loss: 0.722809910774231\n",
      "Loss: 0.6024916768074036\n",
      "Loss: 0.6600261926651001\n",
      "Loss: 0.7064465284347534\n",
      "Loss: 0.6367452144622803\n",
      "Loss: 0.6290239691734314\n",
      "Loss: 0.6793624758720398\n",
      "Loss: 0.6685470938682556\n",
      "Loss: 0.6894209980964661\n",
      "Loss: 0.6304276585578918\n",
      "Loss: 0.698827862739563\n",
      "Loss: 0.6471174955368042\n",
      "Loss: 0.569473385810852\n",
      "Loss: 0.6595999002456665\n",
      "Loss: 0.6448613405227661\n",
      "Loss: 0.6365644335746765\n",
      "Loss: 0.7168682813644409\n",
      "Loss: 0.6016814112663269\n",
      "Loss: 0.7661407589912415\n",
      "Loss: 0.6111714243888855\n",
      "Loss: 0.6454500555992126\n",
      "Loss: 0.7191372513771057\n",
      "Loss: 0.6519575119018555\n",
      "Loss: 0.5784348249435425\n",
      "Loss: 0.6094526052474976\n",
      "Loss: 0.5723199844360352\n",
      "Loss: 0.5568246841430664\n",
      "Loss: 0.6489259600639343\n",
      "Loss: 0.5989912748336792\n",
      "Loss: 0.5642971992492676\n",
      "Loss: 0.6244938373565674\n",
      "Loss: 0.6121862530708313\n",
      "Loss: 0.6323248147964478\n",
      "Loss: 0.6699209809303284\n",
      "Loss: 0.6326217651367188\n",
      "Loss: 0.5360163450241089\n",
      "Loss: 0.6793150305747986\n",
      "Loss: 0.6352565288543701\n",
      "Loss: 0.6400727033615112\n",
      "Loss: 0.6599332690238953\n",
      "Loss: 0.7142370939254761\n",
      "Loss: 0.6454480290412903\n",
      "Loss: 0.6407591104507446\n",
      "Loss: 0.6905392408370972\n",
      "Loss: 0.6772909760475159\n",
      "Loss: 0.7522208094596863\n",
      "Loss: 0.6251985430717468\n",
      "Loss: 0.5705922842025757\n",
      "Loss: 0.6881207227706909\n",
      "Loss: 0.6817685961723328\n",
      "Loss: 0.6643316745758057\n",
      "Loss: 0.5423083305358887\n",
      "Loss: 0.6541789174079895\n",
      "Loss: 0.6121799349784851\n",
      "Loss: 0.6682497262954712\n",
      "Loss: 0.6468545198440552\n",
      "Loss: 0.6420864462852478\n",
      "Loss: 0.6286978721618652\n",
      "Loss: 0.6906498670578003\n",
      "Loss: 0.7295302152633667\n",
      "Loss: 0.5884720087051392\n",
      "Loss: 0.6017122268676758\n",
      "Loss: 0.6657524108886719\n",
      "Loss: 0.6888254880905151\n",
      "Loss: 0.5949757695198059\n",
      "Loss: 0.7067806124687195\n",
      "Loss: 0.6637519001960754\n",
      "Loss: 0.6129893064498901\n",
      "Loss: 0.597731351852417\n",
      "Loss: 0.6007749438285828\n",
      "Loss: 0.6599159240722656\n",
      "Loss: 0.679767906665802\n",
      "Loss: 0.6359918713569641\n",
      "Loss: 0.7018014788627625\n",
      "Loss: 0.589158296585083\n",
      "Loss: 0.7428489327430725\n",
      "Loss: 0.7064417600631714\n",
      "Loss: 0.6004817485809326\n",
      "Loss: 0.6272497177124023\n",
      "Loss: 0.6392476558685303\n",
      "Loss: 0.5856138467788696\n",
      "Loss: 0.6338626146316528\n",
      "Loss: 0.6484331488609314\n",
      "Loss: 0.7111844420433044\n",
      "Loss: 0.6500239372253418\n",
      "Loss: 0.6734292507171631\n",
      "Loss: 0.6707974076271057\n",
      "Loss: 0.6085900068283081\n",
      "Loss: 0.689279317855835\n",
      "Loss: 0.651552140712738\n",
      "Loss: 0.662412166595459\n",
      "Loss: 0.6544694900512695\n",
      "Loss: 0.7020043134689331\n",
      "Loss: 0.588642418384552\n",
      "Loss: 0.6002629995346069\n",
      "Loss: 0.648896336555481\n",
      "Loss: 0.6971284747123718\n",
      "Loss: 0.6354780197143555\n",
      "Loss: 0.6402654051780701\n",
      "Loss: 0.6915367841720581\n",
      "Loss: 0.661890983581543\n",
      "Loss: 0.6549146175384521\n",
      "Loss: 0.6108243465423584\n",
      "Loss: 0.7000311613082886\n",
      "Loss: 0.666511058807373\n",
      "Loss: 0.6269816756248474\n",
      "Loss: 0.650731086730957\n",
      "Loss: 0.652546763420105\n",
      "Loss: 0.633449375629425\n",
      "Loss: 0.6138939261436462\n",
      "Loss: 0.6150511503219604\n",
      "Loss: 0.6365114450454712\n",
      "Loss: 0.6570261716842651\n",
      "Loss: 0.6473871469497681\n",
      "Loss: 0.6361870169639587\n",
      "Loss: 0.5863469243049622\n",
      "Loss: 0.6793379187583923\n",
      "Loss: 0.6394245028495789\n",
      "Loss: 0.5550109148025513\n",
      "Loss: 0.6709855794906616\n",
      "Loss: 0.6462754011154175\n",
      "Loss: 0.6622574925422668\n",
      "Loss: 0.6142361164093018\n",
      "Loss: 0.6549413800239563\n",
      "Loss: 0.609319806098938\n",
      "Loss: 0.6006877422332764\n",
      "Loss: 0.6337876319885254\n",
      "Loss: 0.612806499004364\n",
      "Loss: 0.6658495664596558\n",
      "Loss: 0.6437234878540039\n",
      "Loss: 0.6250736117362976\n",
      "Loss: 0.5912630558013916\n",
      "Loss: 0.602277934551239\n",
      "Loss: 0.5778969526290894\n",
      "Loss: 0.6668073534965515\n",
      "Loss: 0.6029045581817627\n",
      "Loss: 0.6598317623138428\n",
      "Loss: 0.5912082195281982\n",
      "Loss: 0.7051457166671753\n",
      "Loss: 0.6158888936042786\n",
      "Loss: 0.6393686532974243\n",
      "Loss: 0.5832685828208923\n",
      "Loss: 0.6501654982566833\n",
      "Loss: 0.644037663936615\n",
      "Loss: 0.7389773726463318\n",
      "Loss: 0.6349204182624817\n",
      "Loss: 0.595497727394104\n",
      "Loss: 0.5591777563095093\n",
      "Loss: 0.6236154437065125\n",
      "Loss: 0.6290553212165833\n",
      "Loss: 0.7741515040397644\n",
      "Loss: 0.7354002594947815\n",
      "Loss: 0.6472853422164917\n",
      "Loss: 0.5978009700775146\n",
      "Loss: 0.6453798413276672\n",
      "Loss: 0.6490669250488281\n",
      "Loss: 0.6312884092330933\n",
      "Loss: 0.7304731011390686\n",
      "Loss: 0.6368874311447144\n",
      "Loss: 0.7130367159843445\n",
      "Loss: 0.6676980257034302\n",
      "Loss: 0.6122849583625793\n",
      "Loss: 0.6647651195526123\n",
      "Loss: 0.6131312251091003\n",
      "Loss: 0.615686297416687\n",
      "Loss: 0.5849675536155701\n",
      "Loss: 0.5638514757156372\n",
      "Loss: 0.6688691973686218\n",
      "Loss: 0.6221985816955566\n",
      "Loss: 0.6352285742759705\n",
      "Loss: 0.7092643976211548\n",
      "Loss: 0.6595670580863953\n",
      "Loss: 0.6683447360992432\n",
      "Loss: 0.6987416744232178\n",
      "Loss: 0.6737872958183289\n",
      "Loss: 0.7280557751655579\n",
      "Loss: 0.6169478893280029\n",
      "Loss: 0.6768514513969421\n",
      "Loss: 0.6695775389671326\n",
      "Loss: 0.6206198930740356\n",
      "Loss: 0.6348403692245483\n",
      "Loss: 0.7522969841957092\n",
      "Loss: 0.6550989151000977\n",
      "Loss: 0.6375476717948914\n",
      "Loss: 0.6969663500785828\n",
      "Loss: 0.678301990032196\n",
      "Loss: 0.655482292175293\n",
      "Loss: 0.6560897827148438\n",
      "Loss: 0.6629173159599304\n",
      "Loss: 0.6377216577529907\n",
      "Loss: 0.6583397388458252\n",
      "Loss: 0.658116340637207\n",
      "Loss: 0.6643054485321045\n",
      "Loss: 0.7389985918998718\n",
      "Loss: 0.6408255100250244\n",
      "Loss: 0.5939907431602478\n",
      "Loss: 0.6192490458488464\n",
      "Loss: 0.6502019762992859\n",
      "Loss: 0.6018511056900024\n",
      "Loss: 0.5428208708763123\n",
      "Loss: 0.6117948889732361\n",
      "Loss: 0.5884637236595154\n",
      "Loss: 0.6564189791679382\n",
      "Loss: 0.6705898642539978\n",
      "Loss: 0.67870032787323\n",
      "Loss: 0.6215114593505859\n",
      "Loss: 0.641798198223114\n",
      "Loss: 0.6211904883384705\n",
      "Loss: 0.7073202729225159\n",
      "Loss: 0.6570932269096375\n",
      "Loss: 0.6265970468521118\n",
      "Loss: 0.6649320721626282\n",
      "Loss: 0.6313122510910034\n",
      "Loss: 0.6374167799949646\n",
      "Loss: 0.6785659193992615\n",
      "Loss: 0.6356643438339233\n",
      "Loss: 0.6976616978645325\n",
      "Loss: 0.6388168334960938\n",
      "Loss: 0.6567243337631226\n",
      "Loss: 0.5881574153900146\n",
      "Loss: 0.6380078792572021\n",
      "Loss: 0.6557794809341431\n",
      "Loss: 0.596434473991394\n",
      "Loss: 0.5940748453140259\n",
      "Loss: 0.6124961972236633\n",
      "Loss: 0.6170057654380798\n",
      "Loss: 0.6360498666763306\n",
      "Loss: 0.6375484466552734\n",
      "Loss: 0.7003968954086304\n",
      "Loss: 0.6518094539642334\n",
      "Loss: 0.6187251806259155\n",
      "Loss: 0.6530847549438477\n",
      "Loss: 0.6146581172943115\n",
      "Loss: 0.5778368711471558\n",
      "Loss: 0.6539391875267029\n",
      "Loss: 0.6145489811897278\n",
      "Loss: 0.6346050500869751\n",
      "Loss: 0.7519655823707581\n",
      "Loss: 0.6316509246826172\n",
      "Loss: 0.6285703182220459\n",
      "Loss: 0.7281038165092468\n",
      "Loss: 0.6484537124633789\n",
      "Loss: 0.6381920576095581\n",
      "Loss: 0.6304896473884583\n",
      "Loss: 0.6917665004730225\n",
      "Loss: 0.6350008249282837\n",
      "Loss: 0.6813117861747742\n",
      "Loss: 0.5480078458786011\n",
      "Loss: 0.6313828229904175\n",
      "Loss: 0.7397864460945129\n",
      "Loss: 0.6300935745239258\n",
      "Loss: 0.6008593440055847\n",
      "Loss: 0.638694703578949\n",
      "Loss: 0.6538491249084473\n",
      "Loss: 0.6585661768913269\n",
      "Loss: 0.708068311214447\n",
      "Loss: 0.6695243716239929\n",
      "Loss: 0.6320728659629822\n",
      "Loss: 0.7396957278251648\n",
      "Loss: 0.6128404140472412\n",
      "Loss: 0.7314437031745911\n",
      "Loss: 0.7502297163009644\n",
      "Loss: 0.5918025374412537\n",
      "Loss: 0.5817105174064636\n",
      "Loss: 0.626293957233429\n",
      "Loss: 0.5884079933166504\n",
      "Loss: 0.7196829915046692\n",
      "Loss: 0.7444649934768677\n",
      "Loss: 0.6796879172325134\n",
      "Loss: 0.5724371671676636\n",
      "Loss: 0.5739145278930664\n",
      "Loss: 0.5993622541427612\n",
      "Loss: 0.7285065054893494\n",
      "Loss: 0.6464118361473083\n",
      "Loss: 0.6293758153915405\n",
      "Loss: 0.6852360367774963\n",
      "Loss: 0.6275272369384766\n",
      "Loss: 0.7204529643058777\n",
      "Loss: 0.6253435015678406\n",
      "Loss: 0.655517578125\n",
      "Loss: 0.5511322021484375\n",
      "Loss: 0.6213810443878174\n",
      "Loss: 0.7138429880142212\n",
      "Loss: 0.6394766569137573\n",
      "Loss: 0.7042012810707092\n",
      "Loss: 0.630495548248291\n",
      "Loss: 0.6137272715568542\n",
      "Loss: 0.6723732352256775\n",
      "Loss: 0.619296669960022\n",
      "Loss: 0.6466681957244873\n",
      "Loss: 0.6601407527923584\n",
      "Loss: 0.6577538251876831\n",
      "Loss: 0.6886805295944214\n",
      "Loss: 0.6381086111068726\n",
      "Loss: 0.6337975859642029\n",
      "Loss: 0.7067373394966125\n",
      "Loss: 0.6911929249763489\n",
      "Loss: 0.7105234265327454\n",
      "Loss: 0.6542014479637146\n",
      "Loss: 0.6878277659416199\n",
      "Loss: 0.6046867370605469\n",
      "Loss: 0.6536741256713867\n",
      "Loss: 0.6358045339584351\n",
      "Loss: 0.6004592776298523\n",
      "Loss: 0.6598151922225952\n",
      "Loss: 0.6605731844902039\n",
      "Loss: 0.596150279045105\n",
      "Loss: 0.6105562448501587\n",
      "Loss: 0.6493675708770752\n",
      "Loss: 0.6507116556167603\n",
      "Loss: 0.672370195388794\n",
      "Loss: 0.5661483407020569\n",
      "Loss: 0.6804644465446472\n",
      "Loss: 0.6255940794944763\n",
      "Loss: 0.6571042537689209\n",
      "Loss: 0.5855153203010559\n",
      "Loss: 0.6342474222183228\n",
      "Loss: 0.6487800478935242\n",
      "Loss: 0.7263286113739014\n",
      "Loss: 0.6508954167366028\n",
      "Loss: 0.6559398174285889\n",
      "Loss: 0.6685798168182373\n",
      "Loss: 0.6428076028823853\n",
      "Loss: 0.6895002722740173\n",
      "Loss: 0.7044383883476257\n",
      "Loss: 0.6238865256309509\n",
      "Loss: 0.7243340611457825\n",
      "Loss: 0.6996058225631714\n",
      "Loss: 0.6189777255058289\n",
      "Loss: 0.6537525057792664\n",
      "Loss: 0.6486332416534424\n",
      "Loss: 0.7195154428482056\n",
      "Loss: 0.6536125540733337\n",
      "Loss: 0.626996636390686\n",
      "Loss: 0.5762179493904114\n",
      "Loss: 0.5631269216537476\n",
      "Loss: 0.6954490542411804\n",
      "Loss: 0.6642228960990906\n",
      "Loss: 0.7175999879837036\n",
      "Loss: 0.5906683206558228\n",
      "Loss: 0.6371514201164246\n",
      "Loss: 0.6276841163635254\n",
      "Loss: 0.7069279551506042\n",
      "Loss: 0.6737192869186401\n",
      "Loss: 0.6538533568382263\n",
      "Loss: 0.6035577654838562\n",
      "Loss: 0.637381911277771\n",
      "Loss: 0.6594870090484619\n",
      "Loss: 0.6639784574508667\n",
      "Loss: 0.6340495944023132\n",
      "Loss: 0.6564079523086548\n",
      "Loss: 0.5898879766464233\n",
      "Loss: 0.6369640827178955\n",
      "Loss: 0.6718641519546509\n",
      "Loss: 0.6592720746994019\n",
      "Loss: 0.6795108318328857\n",
      "Loss: 0.6597577929496765\n",
      "Loss: 0.5813703536987305\n",
      "Loss: 0.642135739326477\n",
      "Loss: 0.6581400036811829\n",
      "Loss: 0.6840918660163879\n",
      "Loss: 0.6297351121902466\n",
      "Loss: 0.6669840216636658\n",
      "Loss: 0.631915271282196\n",
      "Loss: 0.698322057723999\n",
      "Loss: 0.5997440218925476\n",
      "Loss: 0.6623023748397827\n",
      "Loss: 0.6168638467788696\n",
      "Loss: 0.7006610631942749\n",
      "Loss: 0.6339644193649292\n",
      "Loss: 0.6239591836929321\n",
      "Loss: 0.569098174571991\n",
      "Loss: 0.6975551843643188\n",
      "Loss: 0.6223148107528687\n",
      "Loss: 0.5893852710723877\n",
      "Loss: 0.5605823397636414\n",
      "Loss: 0.6145915389060974\n",
      "Loss: 0.6707313656806946\n",
      "Loss: 0.6219584941864014\n",
      "Loss: 0.6540996432304382\n",
      "Loss: 0.7255756258964539\n",
      "Loss: 0.563289999961853\n",
      "Loss: 0.6509706377983093\n",
      "Loss: 0.6128034591674805\n",
      "Loss: 0.6961429119110107\n",
      "Loss: 0.641732394695282\n",
      "Loss: 0.6385407447814941\n",
      "Loss: 0.5876157283782959\n",
      "Loss: 0.5466635227203369\n",
      "Loss: 0.62160325050354\n",
      "Loss: 0.6940957903862\n",
      "Loss: 0.6892246007919312\n",
      "Loss: 0.6175218820571899\n",
      "Loss: 0.7124348282814026\n",
      "Loss: 0.7086198925971985\n",
      "Loss: 0.6705246567726135\n",
      "Loss: 0.5811911821365356\n",
      "Loss: 0.6661721467971802\n",
      "Loss: 0.6205936670303345\n",
      "Loss: 0.6114408373832703\n",
      "Loss: 0.6076721549034119\n",
      "Loss: 0.6531421542167664\n",
      "Loss: 0.6424110531806946\n",
      "Loss: 0.6504198312759399\n",
      "Loss: 0.6620495915412903\n",
      "Loss: 0.6260005831718445\n",
      "Loss: 0.643502950668335\n",
      "Loss: 0.6606835722923279\n",
      "Loss: 0.6689373850822449\n",
      "Loss: 0.6781343221664429\n",
      "Loss: 0.6235429644584656\n",
      "Loss: 0.6633051633834839\n",
      "Loss: 0.6079700589179993\n",
      "Loss: 0.5942800641059875\n",
      "Loss: 0.6650121212005615\n",
      "Loss: 0.637800395488739\n",
      "Loss: 0.6417719125747681\n",
      "Loss: 0.6329758167266846\n",
      "Loss: 0.6363027095794678\n",
      "Loss: 0.6706167459487915\n",
      "Loss: 0.7005771398544312\n",
      "Loss: 0.6311908960342407\n",
      "Loss: 0.7019003629684448\n",
      "Loss: 0.6524580717086792\n",
      "Loss: 0.6818640828132629\n",
      "Loss: 0.6356005072593689\n",
      "Loss: 0.5980798006057739\n",
      "Loss: 0.6302034258842468\n",
      "Loss: 0.5954057574272156\n",
      "Loss: 0.7376424670219421\n",
      "Loss: 0.6027601957321167\n",
      "Loss: 0.6716931462287903\n",
      "Loss: 0.6790582537651062\n",
      "Loss: 0.6413265466690063\n",
      "Loss: 0.6718838810920715\n",
      "Loss: 0.6926397681236267\n",
      "Loss: 0.672224760055542\n",
      "Loss: 0.678163468837738\n",
      "Loss: 0.6063554883003235\n",
      "Loss: 0.652634859085083\n",
      "Loss: 0.723640501499176\n",
      "Loss: 0.6878949999809265\n",
      "Loss: 0.7242680191993713\n",
      "Loss: 0.6262496113777161\n",
      "Loss: 0.6296205520629883\n",
      "Loss: 0.6202673316001892\n",
      "Loss: 0.6081300973892212\n",
      "Loss: 0.6500928401947021\n",
      "Loss: 0.6524623036384583\n",
      "Loss: 0.562160849571228\n",
      "Loss: 0.6138416528701782\n",
      "Loss: 0.619246780872345\n",
      "Loss: 0.5965924263000488\n",
      "Loss: 0.5827255249023438\n",
      "Loss: 0.6372581720352173\n",
      "Loss: 0.7234188914299011\n",
      "Loss: 0.6684486269950867\n",
      "Loss: 0.5703284740447998\n",
      "Loss: 0.6222745180130005\n",
      "Loss: 0.7057979106903076\n",
      "Loss: 0.6161941289901733\n",
      "Loss: 0.6077003479003906\n",
      "Loss: 0.6145834922790527\n",
      "Loss: 0.7384467720985413\n",
      "Loss: 0.6216533780097961\n",
      "Loss: 0.5940843820571899\n",
      "Loss: 0.5702394843101501\n",
      "Loss: 0.6731972098350525\n",
      "Loss: 0.6780945062637329\n",
      "Loss: 0.646788477897644\n",
      "Loss: 0.6442214846611023\n",
      "Loss: 0.6638761758804321\n",
      "Loss: 0.6298258304595947\n",
      "Loss: 0.6071437001228333\n",
      "Loss: 0.599104642868042\n",
      "Loss: 0.7444161772727966\n",
      "Loss: 0.61907559633255\n",
      "Loss: 0.6040170192718506\n",
      "Loss: 0.6360633373260498\n",
      "Loss: 0.6230385899543762\n",
      "Loss: 0.6748613715171814\n",
      "Loss: 0.6491130590438843\n",
      "Loss: 0.6698232293128967\n",
      "Loss: 0.6006438732147217\n",
      "Loss: 0.6095148324966431\n",
      "Loss: 0.6180747747421265\n",
      "Loss: 0.671863853931427\n",
      "Loss: 0.6721624732017517\n",
      "Loss: 0.6233962774276733\n",
      "Loss: 0.6917551755905151\n",
      "Loss: 0.6483117938041687\n",
      "Loss: 0.6538194417953491\n",
      "Loss: 0.5949155688285828\n",
      "Loss: 0.6361281871795654\n",
      "Loss: 0.6613167524337769\n",
      "Loss: 0.6515958309173584\n",
      "Loss: 0.5945004224777222\n",
      "Loss: 0.7124698162078857\n",
      "Loss: 0.6936102509498596\n",
      "Loss: 0.5473354458808899\n",
      "Loss: 0.6764830946922302\n",
      "Loss: 0.6375738978385925\n",
      "Loss: 0.5850533246994019\n",
      "Loss: 0.632058322429657\n",
      "Loss: 0.6615160703659058\n",
      "Loss: 0.6414651870727539\n",
      "Loss: 0.6164339780807495\n",
      "Loss: 0.6262578964233398\n",
      "Loss: 0.6136900186538696\n",
      "Loss: 0.681149423122406\n",
      "Loss: 0.5977741479873657\n",
      "Loss: 0.6013422012329102\n",
      "Loss: 0.5936776399612427\n",
      "Loss: 0.6179589033126831\n",
      "Loss: 0.6168745160102844\n",
      "Loss: 0.6984524130821228\n",
      "Loss: 0.7240049242973328\n",
      "Loss: 0.6498636603355408\n",
      "Loss: 0.6396732330322266\n",
      "Loss: 0.6273558139801025\n",
      "Loss: 0.5785590410232544\n",
      "Loss: 0.6662339568138123\n",
      "Loss: 0.6680580377578735\n",
      "Loss: 0.6513521075248718\n",
      "Loss: 0.6014182567596436\n",
      "Loss: 0.6070154309272766\n",
      "Loss: 0.6873047351837158\n",
      "Loss: 0.6577037572860718\n",
      "Loss: 0.6294889450073242\n",
      "Loss: 0.7291315197944641\n",
      "Loss: 0.6020191311836243\n",
      "Loss: 0.6290649175643921\n",
      "Loss: 0.6958411335945129\n",
      "Loss: 0.6997409462928772\n",
      "Loss: 0.6182743906974792\n",
      "Loss: 0.6257412433624268\n",
      "Loss: 0.6830893754959106\n",
      "Loss: 0.6343799829483032\n",
      "Loss: 0.6579240560531616\n",
      "Loss: 0.642821192741394\n",
      "Loss: 0.6904863715171814\n",
      "Loss: 0.624189555644989\n",
      "Loss: 0.6626309156417847\n",
      "Loss: 0.6048232913017273\n",
      "Loss: 0.6812903881072998\n",
      "Loss: 0.6602015495300293\n",
      "Loss: 0.7189005017280579\n",
      "Loss: 0.6393164396286011\n",
      "Loss: 0.6273539662361145\n",
      "Loss: 0.6696134805679321\n",
      "Loss: 0.5668519139289856\n",
      "Loss: 0.6724646091461182\n",
      "Loss: 0.6444699168205261\n",
      "Loss: 0.7186402082443237\n",
      "Loss: 0.6448063254356384\n",
      "Loss: 0.6455853581428528\n",
      "Loss: 0.6623392105102539\n",
      "Loss: 0.7115398645401001\n",
      "Loss: 0.6324481964111328\n",
      "Loss: 0.6925234198570251\n",
      "Loss: 0.7216856479644775\n",
      "Loss: 0.6362126469612122\n",
      "Loss: 0.6760537028312683\n",
      "Loss: 0.6878769993782043\n",
      "Loss: 0.6942357420921326\n",
      "Loss: 0.7038835883140564\n",
      "Loss: 0.7019103169441223\n",
      "Loss: 0.6775795221328735\n",
      "Loss: 0.6367971301078796\n",
      "Loss: 0.6735789179801941\n",
      "Loss: 0.6346288919448853\n",
      "Loss: 0.6258596777915955\n",
      "Loss: 0.6351064443588257\n",
      "Loss: 0.5520870685577393\n",
      "Loss: 0.6317428350448608\n",
      "Loss: 0.6511549353599548\n",
      "Loss: 0.5737935900688171\n",
      "Loss: 0.716886579990387\n",
      "Loss: 0.6142163276672363\n",
      "Loss: 0.5982235074043274\n",
      "Loss: 0.6381306052207947\n",
      "Loss: 0.649281919002533\n",
      "Loss: 0.6469247341156006\n",
      "Loss: 0.7242979407310486\n",
      "Loss: 0.6665257811546326\n",
      "Loss: 0.5570106506347656\n",
      "Loss: 0.6609315872192383\n",
      "Loss: 0.595428466796875\n",
      "Loss: 0.5916215777397156\n",
      "Loss: 0.6079730987548828\n",
      "Loss: 0.7221298813819885\n",
      "Loss: 0.5680068731307983\n",
      "Loss: 0.5877113342285156\n",
      "Loss: 0.6504194140434265\n",
      "Loss: 0.6445118188858032\n",
      "Loss: 0.5948350429534912\n",
      "Loss: 0.7025815844535828\n",
      "Loss: 0.6759270429611206\n",
      "Loss: 0.6749487519264221\n",
      "Loss: 0.6243914365768433\n",
      "Loss: 0.5817932486534119\n",
      "Loss: 0.6744969487190247\n",
      "Loss: 0.6651343107223511\n",
      "Loss: 0.6627321243286133\n",
      "Loss: 0.6817666292190552\n",
      "Loss: 0.6182560920715332\n",
      "Loss: 0.5954437255859375\n",
      "Loss: 0.5995640158653259\n",
      "Loss: 0.6428022384643555\n",
      "Loss: 0.6020439863204956\n",
      "Loss: 0.6503514647483826\n",
      "Loss: 0.737156093120575\n",
      "Loss: 0.627486526966095\n",
      "Loss: 0.6733313202857971\n",
      "Loss: 0.6320013403892517\n",
      "Loss: 0.6251285076141357\n",
      "Loss: 0.6163833141326904\n",
      "Loss: 0.6218993663787842\n",
      "Loss: 0.5938394069671631\n",
      "Loss: 0.6572587490081787\n",
      "Loss: 0.5934677124023438\n",
      "Loss: 0.6137301921844482\n",
      "Loss: 0.6192095875740051\n",
      "Loss: 0.6250976920127869\n",
      "Loss: 0.6814376711845398\n",
      "Loss: 0.581678569316864\n",
      "Loss: 0.6259565353393555\n",
      "Loss: 0.6429992914199829\n",
      "Loss: 0.6907321810722351\n",
      "Loss: 0.5815693140029907\n",
      "Loss: 0.6792386174201965\n",
      "Loss: 0.6143734455108643\n",
      "Loss: 0.6751981973648071\n",
      "Loss: 0.6372119784355164\n",
      "Loss: 0.6472928524017334\n",
      "Loss: 0.5849917531013489\n",
      "Loss: 0.7101161479949951\n",
      "Loss: 0.6652562618255615\n",
      "Loss: 0.7180901169776917\n",
      "Loss: 0.7280863523483276\n",
      "Loss: 0.6721300482749939\n",
      "Loss: 0.6218112111091614\n",
      "Loss: 0.5926526188850403\n",
      "Loss: 0.643603503704071\n",
      "Loss: 0.6417120099067688\n",
      "Loss: 0.7043753862380981\n",
      "Loss: 0.6104501485824585\n",
      "Loss: 0.7046605944633484\n",
      "Loss: 0.6493673324584961\n",
      "Loss: 0.6488212943077087\n",
      "Loss: 0.6533787846565247\n",
      "Loss: 0.6530650854110718\n",
      "Loss: 0.6916940808296204\n",
      "Loss: 0.6971108317375183\n",
      "Loss: 0.6280369162559509\n",
      "Loss: 0.6284649968147278\n",
      "Loss: 0.602772057056427\n",
      "Loss: 0.6693718433380127\n",
      "Loss: 0.6689892411231995\n",
      "Loss: 0.6636186838150024\n",
      "Loss: 0.6569775342941284\n",
      "Loss: 0.6815615296363831\n",
      "Loss: 0.6452848315238953\n",
      "Loss: 0.6821977496147156\n",
      "Loss: 0.6294387578964233\n",
      "Loss: 0.6483380794525146\n",
      "Loss: 0.6653685569763184\n",
      "Loss: 0.6612875461578369\n",
      "Loss: 0.6536850333213806\n",
      "Loss: 0.6223316192626953\n",
      "Loss: 0.6608848571777344\n",
      "Loss: 0.6424789428710938\n",
      "Loss: 0.6414649486541748\n",
      "Loss: 0.5963260531425476\n",
      "Loss: 0.6597360968589783\n",
      "Loss: 0.6127010583877563\n",
      "Loss: 0.5882911682128906\n",
      "Loss: 0.5973719358444214\n",
      "Loss: 0.6345493197441101\n",
      "Loss: 0.7190714478492737\n",
      "Loss: 0.6918038129806519\n",
      "Loss: 0.6406437754631042\n",
      "Loss: 0.6097409725189209\n",
      "Loss: 0.5981931686401367\n",
      "Loss: 0.5717227458953857\n",
      "Loss: 0.5726016163825989\n",
      "Loss: 0.6181596517562866\n",
      "Loss: 0.6621249914169312\n",
      "Loss: 0.6288579702377319\n",
      "Loss: 0.6912512183189392\n",
      "Loss: 0.6463112235069275\n",
      "Loss: 0.6056041121482849\n",
      "Loss: 0.5944974422454834\n",
      "Loss: 0.6561927199363708\n",
      "Loss: 0.5386119484901428\n",
      "Loss: 0.6026855707168579\n",
      "Loss: 0.6952019333839417\n",
      "Loss: 0.6594516038894653\n",
      "Loss: 0.6845051050186157\n",
      "Loss: 0.6208014488220215\n",
      "Loss: 0.6566750407218933\n",
      "Loss: 0.615683376789093\n",
      "Loss: 0.5791633129119873\n",
      "Loss: 0.6479414701461792\n",
      "Loss: 0.6226508617401123\n",
      "Loss: 0.6246649622917175\n",
      "Loss: 0.5945777893066406\n",
      "Loss: 0.6313177347183228\n",
      "Loss: 0.683967649936676\n",
      "Loss: 0.5605332851409912\n",
      "Loss: 0.6861017942428589\n",
      "Loss: 0.6477330923080444\n",
      "Loss: 0.5829130411148071\n",
      "Loss: 0.6352601051330566\n",
      "Loss: 0.6089339256286621\n",
      "Loss: 0.7103086709976196\n",
      "Loss: 0.576354444026947\n",
      "Loss: 0.6595182418823242\n",
      "Loss: 0.6228104829788208\n",
      "Loss: 0.5982040762901306\n",
      "Loss: 0.6852303743362427\n",
      "Loss: 0.6992224454879761\n",
      "Loss: 0.6788300275802612\n",
      "Loss: 0.6372978091239929\n",
      "Loss: 0.5520569086074829\n",
      "Loss: 0.7062462568283081\n",
      "Loss: 0.5754314661026001\n",
      "Loss: 0.6089013814926147\n",
      "Loss: 0.6832321286201477\n",
      "Loss: 0.6387495994567871\n",
      "Loss: 0.6793781518936157\n",
      "Loss: 0.6672559976577759\n",
      "Loss: 0.622002363204956\n",
      "Loss: 0.5684616565704346\n",
      "Loss: 0.6696394681930542\n",
      "Loss: 0.6392688155174255\n",
      "Loss: 0.675381064414978\n",
      "Loss: 0.6750228404998779\n",
      "Loss: 0.6263378858566284\n",
      "Loss: 0.6552247405052185\n",
      "Loss: 0.6325216293334961\n",
      "Loss: 0.5337650179862976\n",
      "Loss: 0.6394853591918945\n",
      "Loss: 0.6391156315803528\n",
      "Loss: 0.679599940776825\n",
      "Loss: 0.7005060911178589\n",
      "Loss: 0.675484836101532\n",
      "Loss: 0.6262729167938232\n",
      "Loss: 0.6610628366470337\n",
      "Loss: 0.6698029637336731\n",
      "Loss: 0.660885751247406\n",
      "Loss: 0.6426705718040466\n",
      "Loss: 0.7265929579734802\n",
      "Loss: 0.6745168566703796\n",
      "Loss: 0.6205242276191711\n",
      "Loss: 0.6107776165008545\n",
      "Loss: 0.6357205510139465\n",
      "Loss: 0.6846225261688232\n",
      "Loss: 0.6807214021682739\n",
      "Loss: 0.5874098539352417\n",
      "Loss: 0.6144184470176697\n",
      "Loss: 0.6887881755828857\n",
      "Loss: 0.6501163840293884\n",
      "Loss: 0.6731932759284973\n",
      "Loss: 0.5972873568534851\n",
      "Loss: 0.6113460063934326\n",
      "Loss: 0.5696789622306824\n",
      "Loss: 0.6869803071022034\n",
      "Loss: 0.6639119386672974\n",
      "Loss: 0.5881485342979431\n",
      "Loss: 0.5809003114700317\n",
      "Loss: 0.5999573469161987\n",
      "Loss: 0.6359966993331909\n",
      "Loss: 0.6407719850540161\n",
      "Loss: 0.6906570196151733\n",
      "Loss: 0.5918790698051453\n",
      "Loss: 0.7132068872451782\n",
      "Loss: 0.5521364212036133\n",
      "Loss: 0.633806049823761\n",
      "Loss: 0.5983060002326965\n",
      "Loss: 0.6387235522270203\n",
      "Loss: 0.6999341249465942\n",
      "Loss: 0.6610548496246338\n",
      "Loss: 0.7590641379356384\n",
      "Loss: 0.6009430289268494\n",
      "Loss: 0.6260208487510681\n",
      "Loss: 0.622147262096405\n",
      "Loss: 0.6107217073440552\n",
      "Loss: 0.5646569132804871\n",
      "Loss: 0.669510543346405\n",
      "Loss: 0.6612923741340637\n",
      "Loss: 0.6748225688934326\n",
      "Loss: 0.6358087658882141\n",
      "Loss: 0.58602374792099\n",
      "Loss: 0.5968397855758667\n",
      "Loss: 0.6871377825737\n",
      "Loss: 0.6406480073928833\n",
      "Loss: 0.6156179904937744\n",
      "Loss: 0.7046492695808411\n",
      "Loss: 0.6374377608299255\n",
      "Loss: 0.5629664063453674\n",
      "Loss: 0.5996080636978149\n",
      "Loss: 0.6717966794967651\n",
      "Loss: 0.6182697415351868\n",
      "Loss: 0.7436991333961487\n",
      "Loss: 0.6053545475006104\n",
      "Loss: 0.6495797038078308\n",
      "Loss: 0.6178905367851257\n",
      "Loss: 0.5717434287071228\n",
      "Loss: 0.6773305535316467\n",
      "Loss: 0.6332930326461792\n",
      "Loss: 0.6641075611114502\n",
      "Loss: 0.6673199534416199\n",
      "Loss: 0.687798798084259\n",
      "Loss: 0.655866801738739\n",
      "Loss: 0.7079137563705444\n",
      "Loss: 0.6207360625267029\n",
      "Loss: 0.6790429949760437\n",
      "Loss: 0.6632118225097656\n",
      "Loss: 0.638533353805542\n",
      "Loss: 0.7127074003219604\n",
      "Loss: 0.5232531428337097\n",
      "Loss: 0.7371619343757629\n",
      "Loss: 0.5756676197052002\n",
      "Loss: 0.5775556564331055\n",
      "Loss: 0.6433994770050049\n",
      "Loss: 0.6361028552055359\n",
      "Loss: 0.6680025458335876\n",
      "Loss: 0.6628475189208984\n",
      "Loss: 0.6748274564743042\n",
      "Loss: 0.6220787763595581\n",
      "Loss: 0.6409366130828857\n",
      "Loss: 0.6903495192527771\n",
      "Loss: 0.5655973553657532\n",
      "Loss: 0.5931777358055115\n",
      "Loss: 0.6205123066902161\n",
      "Loss: 0.6545501947402954\n",
      "Loss: 0.6602019667625427\n",
      "Loss: 0.6727442145347595\n",
      "Loss: 0.5783374905586243\n",
      "Loss: 0.6584506034851074\n",
      "Loss: 0.6808651685714722\n",
      "Loss: 0.6486968398094177\n",
      "Loss: 0.5720152854919434\n",
      "Loss: 0.6388616561889648\n",
      "Loss: 0.6688166856765747\n",
      "Loss: 0.637699544429779\n",
      "Loss: 0.6801198720932007\n",
      "Loss: 0.6117929220199585\n",
      "Loss: 0.5739513635635376\n",
      "Loss: 0.6611210107803345\n",
      "Loss: 0.6225439310073853\n",
      "Loss: 0.6421213150024414\n",
      "Loss: 0.5566166043281555\n",
      "Loss: 0.6625608205795288\n",
      "Loss: 0.6987594366073608\n",
      "Loss: 0.5566035509109497\n",
      "Loss: 0.5984559059143066\n",
      "Loss: 0.7279770374298096\n",
      "Loss: 0.6271114349365234\n",
      "Loss: 0.6463209390640259\n",
      "Loss: 0.6943665146827698\n",
      "Loss: 0.5964711904525757\n",
      "Loss: 0.693989634513855\n",
      "Loss: 0.6685675978660583\n",
      "Loss: 0.5853617787361145\n",
      "Loss: 0.6131204962730408\n",
      "Loss: 0.595992922782898\n",
      "Loss: 0.6836116313934326\n",
      "Loss: 0.6445534825325012\n",
      "Loss: 0.61543208360672\n",
      "Loss: 0.67420494556427\n",
      "Loss: 0.7029163241386414\n",
      "Loss: 0.6961539387702942\n",
      "Loss: 0.6756775975227356\n",
      "Loss: 0.60611891746521\n",
      "Loss: 0.6761043071746826\n",
      "Loss: 0.6174642443656921\n",
      "Loss: 0.7690719962120056\n",
      "Loss: 0.7042470574378967\n",
      "Loss: 0.6826776266098022\n",
      "Loss: 0.6477458477020264\n",
      "Loss: 0.6820148825645447\n",
      "Loss: 0.6860759258270264\n",
      "Loss: 0.5867664217948914\n",
      "Loss: 0.6484013795852661\n",
      "Loss: 0.5235027074813843\n",
      "Loss: 0.5980100631713867\n",
      "Loss: 0.6934738755226135\n",
      "Loss: 0.532088041305542\n",
      "Loss: 0.6168506145477295\n",
      "Loss: 0.6078432202339172\n",
      "Loss: 0.6595978736877441\n",
      "Loss: 0.6716924905776978\n",
      "Loss: 0.7529512643814087\n",
      "Loss: 0.6780003309249878\n",
      "Loss: 0.6196921467781067\n",
      "Loss: 0.5862521529197693\n",
      "Loss: 0.605518102645874\n",
      "Loss: 0.6785619258880615\n",
      "Loss: 0.6192852854728699\n",
      "Loss: 0.6203882694244385\n",
      "Loss: 0.5957393646240234\n",
      "Loss: 0.6789108514785767\n",
      "Loss: 0.6382846832275391\n",
      "Loss: 0.6751108765602112\n",
      "Loss: 0.5837380886077881\n",
      "Loss: 0.6449129581451416\n",
      "Loss: 0.6187782287597656\n",
      "Loss: 0.6471220850944519\n",
      "Loss: 0.5831679701805115\n",
      "Loss: 0.629285991191864\n",
      "Loss: 0.5695482492446899\n",
      "Loss: 0.7590044736862183\n",
      "Loss: 0.7309772372245789\n",
      "Loss: 0.6625542640686035\n",
      "Loss: 0.6369021534919739\n",
      "Loss: 0.6333343386650085\n",
      "Loss: 0.6928136348724365\n",
      "Loss: 0.6522406339645386\n",
      "Loss: 0.648341178894043\n",
      "Loss: 0.7999877333641052\n",
      "Loss: 0.6702927350997925\n",
      "Loss: 0.5694222450256348\n",
      "Loss: 0.5988385677337646\n",
      "Loss: 0.6800971627235413\n",
      "Loss: 0.688887894153595\n",
      "Loss: 0.5625022649765015\n",
      "Loss: 0.5788225531578064\n",
      "Loss: 0.6493718028068542\n",
      "Loss: 0.6336681842803955\n",
      "Loss: 0.6624727249145508\n",
      "Loss: 0.6289194822311401\n",
      "Loss: 0.6604915857315063\n",
      "Loss: 0.6266972422599792\n",
      "Loss: 0.6896049976348877\n",
      "Loss: 0.6573976874351501\n",
      "Loss: 0.7176710367202759\n",
      "Loss: 0.6364356875419617\n",
      "Loss: 0.6238014698028564\n",
      "Loss: 0.6511742472648621\n",
      "Loss: 0.6215397119522095\n",
      "Loss: 0.6194418668746948\n",
      "Loss: 0.6439736485481262\n",
      "Loss: 0.6705638766288757\n",
      "Loss: 0.6746293902397156\n",
      "Loss: 0.6391563415527344\n",
      "Loss: 0.5931980609893799\n",
      "Loss: 0.6252264380455017\n",
      "Loss: 0.6503292322158813\n",
      "Loss: 0.6001359224319458\n",
      "Loss: 0.6410150527954102\n",
      "Loss: 0.7156623005867004\n",
      "Loss: 0.6348735690116882\n",
      "Loss: 0.678712010383606\n",
      "Loss: 0.6175850629806519\n",
      "Loss: 0.7434131503105164\n",
      "Loss: 0.6148477792739868\n",
      "Loss: 0.690789520740509\n",
      "Loss: 0.5988457202911377\n",
      "Loss: 0.7561870813369751\n",
      "Loss: 0.6182924509048462\n",
      "Loss: 0.7265967130661011\n",
      "Loss: 0.7104019522666931\n",
      "Loss: 0.701526939868927\n",
      "Loss: 0.7408844828605652\n",
      "Loss: 0.691318929195404\n",
      "Loss: 0.5958177447319031\n",
      "Loss: 0.6606256365776062\n",
      "Loss: 0.6127979159355164\n",
      "Loss: 0.6047085523605347\n",
      "Loss: 0.6443394422531128\n",
      "Loss: 0.6638796925544739\n",
      "Loss: 0.6233890056610107\n",
      "Loss: 0.6233953237533569\n",
      "Loss: 0.6432406902313232\n",
      "Loss: 0.6311113238334656\n",
      "Loss: 0.5667973756790161\n",
      "Loss: 0.6509950160980225\n",
      "Loss: 0.6484421491622925\n",
      "Loss: 0.610991895198822\n",
      "Loss: 0.6177148818969727\n",
      "Loss: 0.6358058452606201\n",
      "Loss: 0.7178733348846436\n",
      "Loss: 0.5807898640632629\n",
      "Loss: 0.7139976024627686\n",
      "Loss: 0.6687686443328857\n",
      "Loss: 0.604158878326416\n",
      "Loss: 0.5698932409286499\n",
      "Loss: 0.513822615146637\n",
      "Loss: 0.6687148809432983\n",
      "Loss: 0.6511834263801575\n",
      "Loss: 0.6272595524787903\n",
      "Loss: 0.6888111233711243\n",
      "Loss: 0.6341814994812012\n",
      "Loss: 0.6636156439781189\n",
      "Loss: 0.6171916127204895\n",
      "Loss: 0.6879374980926514\n",
      "Loss: 0.6520780920982361\n",
      "Loss: 0.6778515577316284\n",
      "Loss: 0.6798579692840576\n",
      "Loss: 0.5949320197105408\n",
      "Loss: 0.7231442928314209\n",
      "Loss: 0.6112995147705078\n",
      "Loss: 0.6874353885650635\n",
      "Loss: 0.5567748546600342\n",
      "Loss: 0.6406896114349365\n",
      "Loss: 0.7172504663467407\n",
      "Loss: 0.6892802715301514\n",
      "Loss: 0.6028734445571899\n",
      "Loss: 0.670648992061615\n",
      "Loss: 0.5655469298362732\n",
      "Loss: 0.6213064193725586\n",
      "Loss: 0.6765459775924683\n",
      "Loss: 0.6265653371810913\n",
      "Loss: 0.6572068333625793\n",
      "Loss: 0.6625539064407349\n",
      "Loss: 0.6869674324989319\n",
      "Loss: 0.6888353824615479\n",
      "Loss: 0.6695059537887573\n",
      "Loss: 0.7091033458709717\n",
      "Loss: 0.7044329047203064\n",
      "Loss: 0.6200196743011475\n",
      "Loss: 0.6598162651062012\n",
      "Loss: 0.6176150441169739\n",
      "Loss: 0.6459257006645203\n",
      "Loss: 0.6946061253547668\n",
      "Loss: 0.6171905398368835\n",
      "Loss: 0.6580862998962402\n",
      "Loss: 0.5893561840057373\n",
      "Loss: 0.5967438220977783\n",
      "Loss: 0.6614991426467896\n",
      "Loss: 0.6164916157722473\n",
      "Loss: 0.6708282232284546\n",
      "Loss: 0.6619868278503418\n",
      "Loss: 0.5449057221412659\n",
      "Loss: 0.622248113155365\n",
      "Loss: 0.6352212429046631\n",
      "Loss: 0.6688384413719177\n",
      "Loss: 0.6317607760429382\n",
      "Loss: 0.772860586643219\n",
      "Loss: 0.6669613122940063\n",
      "Loss: 0.6812573075294495\n",
      "Loss: 0.6043516397476196\n",
      "Loss: 0.5788602232933044\n",
      "Loss: 0.6545421481132507\n",
      "Loss: 0.6263132095336914\n",
      "Loss: 0.6029547452926636\n",
      "Loss: 0.6457127928733826\n",
      "Loss: 0.6220462322235107\n",
      "Loss: 0.6130722761154175\n",
      "Loss: 0.5944623947143555\n",
      "Loss: 0.6288888454437256\n",
      "Loss: 0.6163237690925598\n",
      "Loss: 0.6021191477775574\n",
      "Loss: 0.5986894369125366\n",
      "Loss: 0.5965836048126221\n",
      "Loss: 0.676038920879364\n",
      "Loss: 0.7203993201255798\n",
      "Loss: 0.6157280206680298\n",
      "Loss: 0.622479259967804\n",
      "Loss: 0.6684033870697021\n",
      "Loss: 0.6174213886260986\n",
      "Loss: 0.6505411863327026\n",
      "Loss: 0.6066710352897644\n",
      "Loss: 0.6621749997138977\n",
      "Loss: 0.6760360598564148\n",
      "Loss: 0.5381292700767517\n",
      "Loss: 0.6951659321784973\n",
      "Loss: 0.6977927684783936\n",
      "Loss: 0.6450976729393005\n",
      "Loss: 0.6894264817237854\n",
      "Loss: 0.6481730937957764\n",
      "Loss: 0.6571327447891235\n",
      "Loss: 0.5931705236434937\n",
      "Loss: 0.7096872925758362\n",
      "Loss: 0.6247662305831909\n",
      "Loss: 0.6414477825164795\n",
      "Loss: 0.6595531702041626\n",
      "Loss: 0.6304177045822144\n",
      "Loss: 0.611151933670044\n",
      "Loss: 0.599770724773407\n",
      "Loss: 0.6820899844169617\n",
      "Loss: 0.6695109009742737\n",
      "Loss: 0.6203282475471497\n",
      "Loss: 0.6504825949668884\n",
      "Loss: 0.6261093020439148\n",
      "Loss: 0.687606692314148\n",
      "Loss: 0.649941623210907\n",
      "Loss: 0.650100827217102\n",
      "Loss: 0.6338825225830078\n",
      "Loss: 0.6003989577293396\n",
      "Loss: 0.6057217121124268\n",
      "Loss: 0.6889306902885437\n",
      "Loss: 0.6564638018608093\n",
      "Loss: 0.6290096044540405\n",
      "Loss: 0.6205556988716125\n",
      "Loss: 0.6840181946754456\n",
      "Loss: 0.7486588358879089\n",
      "Loss: 0.647661030292511\n",
      "Loss: 0.6641813516616821\n",
      "Loss: 0.7188422083854675\n",
      "Loss: 0.6246755719184875\n",
      "Loss: 0.696940541267395\n",
      "Loss: 0.6802461743354797\n",
      "Loss: 0.6045775413513184\n",
      "Loss: 0.6546623110771179\n",
      "Loss: 0.5985981822013855\n",
      "Loss: 0.630567729473114\n",
      "Loss: 0.7242756485939026\n",
      "Loss: 0.6586588621139526\n",
      "Loss: 0.6707869172096252\n",
      "Loss: 0.6682465076446533\n",
      "Loss: 0.6725156307220459\n",
      "Loss: 0.6381471157073975\n",
      "Loss: 0.6863610148429871\n",
      "Loss: 0.6113648414611816\n",
      "Loss: 0.6028809547424316\n",
      "Loss: 0.6537100672721863\n",
      "Loss: 0.6595721244812012\n",
      "Loss: 0.6415249109268188\n",
      "Loss: 0.6369490623474121\n",
      "Loss: 0.6543416976928711\n",
      "Loss: 0.6004239320755005\n",
      "Loss: 0.6907222270965576\n",
      "Loss: 0.608552098274231\n",
      "Loss: 0.6126030683517456\n",
      "Loss: 0.5898942947387695\n",
      "Loss: 0.6778656840324402\n",
      "Loss: 0.6079556941986084\n",
      "Loss: 0.6962087750434875\n",
      "Loss: 0.6324697732925415\n",
      "Loss: 0.7021669745445251\n",
      "Loss: 0.6979566812515259\n",
      "Loss: 0.654222846031189\n",
      "Loss: 0.626738429069519\n",
      "Loss: 0.6039505004882812\n",
      "Loss: 0.6847559213638306\n",
      "Loss: 0.5888588428497314\n",
      "Loss: 0.6233571171760559\n",
      "Loss: 0.5778067708015442\n",
      "Loss: 0.7519911527633667\n",
      "Loss: 0.6290534138679504\n",
      "Loss: 0.7111164927482605\n",
      "Loss: 0.6413310170173645\n",
      "Loss: 0.5889570116996765\n",
      "Loss: 0.593016505241394\n",
      "Loss: 0.6304271221160889\n",
      "Loss: 0.7133262157440186\n",
      "Loss: 0.5961766242980957\n",
      "Loss: 0.6548885703086853\n",
      "Loss: 0.6749367117881775\n",
      "Loss: 0.6518102884292603\n",
      "Loss: 0.5869550108909607\n",
      "Loss: 0.6161222457885742\n",
      "Loss: 0.6316028833389282\n",
      "Loss: 0.6555565595626831\n",
      "Loss: 0.6352773904800415\n",
      "Loss: 0.5517023205757141\n",
      "Loss: 0.6166113018989563\n",
      "Loss: 0.6452609300613403\n",
      "Loss: 0.622850239276886\n",
      "Loss: 0.6238539218902588\n",
      "Loss: 0.5874260663986206\n",
      "Loss: 0.6181022524833679\n",
      "Loss: 0.6724125146865845\n",
      "Loss: 0.6022663116455078\n",
      "Loss: 0.7302640080451965\n",
      "Loss: 0.6640856862068176\n",
      "Loss: 0.5973116159439087\n",
      "Loss: 0.7009804248809814\n",
      "Loss: 0.6339914202690125\n",
      "Loss: 0.6339174509048462\n",
      "Loss: 0.6818260550498962\n",
      "Loss: 0.7230177521705627\n",
      "Loss: 0.6359188556671143\n",
      "Loss: 0.6704246401786804\n",
      "Loss: 0.6125701069831848\n",
      "Loss: 0.6397250294685364\n",
      "Loss: 0.6827403903007507\n",
      "Loss: 0.6569443941116333\n",
      "Loss: 0.7054455280303955\n",
      "Loss: 0.6903008818626404\n",
      "Loss: 0.6096054315567017\n",
      "Loss: 0.6504597663879395\n",
      "Loss: 0.6372680068016052\n",
      "Loss: 0.6523538827896118\n",
      "Loss: 0.6746914982795715\n",
      "Loss: 0.5195345878601074\n",
      "Loss: 0.6275997161865234\n",
      "Loss: 0.6738783121109009\n",
      "Loss: 0.588651180267334\n",
      "Loss: 0.6655544638633728\n",
      "Loss: 0.6447747349739075\n",
      "Loss: 0.6561045050621033\n",
      "Loss: 0.6526201963424683\n",
      "Loss: 0.6147794127464294\n",
      "Loss: 0.6889538168907166\n",
      "Loss: 0.5843855738639832\n",
      "Loss: 0.5264519453048706\n",
      "Loss: 0.6177360415458679\n",
      "Loss: 0.6670461297035217\n",
      "Loss: 0.6339890956878662\n",
      "Loss: 0.659064531326294\n",
      "Loss: 0.6296020746231079\n",
      "Loss: 0.6349004507064819\n",
      "Loss: 0.6765857934951782\n",
      "Loss: 0.6525394320487976\n",
      "Loss: 0.6968770623207092\n",
      "Loss: 0.6871630549430847\n",
      "Loss: 0.6834126114845276\n",
      "Loss: 0.6744264960289001\n",
      "Loss: 0.6048378348350525\n",
      "Loss: 0.6361082792282104\n",
      "Loss: 0.6908575892448425\n",
      "Loss: 0.5953654050827026\n",
      "Loss: 0.5901355743408203\n",
      "Loss: 0.6981506943702698\n",
      "Loss: 0.6166898608207703\n",
      "Loss: 0.6901183724403381\n",
      "Loss: 0.6025698184967041\n",
      "Loss: 0.6350806951522827\n",
      "Loss: 0.6288926601409912\n",
      "Loss: 0.7620307803153992\n",
      "Loss: 0.6249317526817322\n",
      "Loss: 0.613204300403595\n",
      "Loss: 0.6027194857597351\n",
      "Loss: 0.6310091018676758\n",
      "Loss: 0.6533842086791992\n",
      "Loss: 0.6588609218597412\n",
      "Loss: 0.6310283541679382\n",
      "Loss: 0.6126583814620972\n",
      "Loss: 0.6330456137657166\n",
      "Loss: 0.6697075963020325\n",
      "Loss: 0.6827601194381714\n",
      "Loss: 0.6449092030525208\n",
      "Loss: 0.7588000893592834\n",
      "Loss: 0.6440498232841492\n",
      "Loss: 0.5995941162109375\n",
      "Loss: 0.6511146426200867\n",
      "Loss: 0.6283935904502869\n",
      "Loss: 0.6259020566940308\n",
      "Loss: 0.7547158002853394\n",
      "Loss: 0.6320981383323669\n",
      "Loss: 0.6255249381065369\n",
      "Loss: 0.6209114789962769\n",
      "Loss: 0.5496838688850403\n",
      "Loss: 0.6313579678535461\n",
      "Loss: 0.7046240568161011\n",
      "Loss: 0.609710156917572\n",
      "Loss: 0.6986282467842102\n",
      "Loss: 0.6269114017486572\n",
      "Loss: 0.5964400768280029\n",
      "Loss: 0.6434712409973145\n",
      "Loss: 0.646418035030365\n",
      "Loss: 0.6538004279136658\n",
      "Loss: 0.7052584886550903\n",
      "Loss: 0.6141765713691711\n",
      "Loss: 0.6455956697463989\n",
      "Loss: 0.6840356588363647\n",
      "Loss: 0.6903406381607056\n",
      "Loss: 0.6172100305557251\n",
      "Loss: 0.6340193152427673\n",
      "Loss: 0.621472954750061\n",
      "Loss: 0.6826056838035583\n",
      "Loss: 0.482568621635437\n",
      "Loss: 0.6221537590026855\n",
      "Loss: 0.6326875686645508\n",
      "Loss: 0.6068742275238037\n",
      "Loss: 0.6153411269187927\n",
      "Loss: 0.621555745601654\n",
      "Loss: 0.6735321879386902\n",
      "Loss: 0.6782530546188354\n",
      "Loss: 0.6238876581192017\n",
      "Loss: 0.6541255116462708\n",
      "Loss: 0.5917469263076782\n",
      "Loss: 0.6766092777252197\n",
      "Loss: 0.6585566997528076\n",
      "Loss: 0.629895031452179\n",
      "Loss: 0.6096245646476746\n",
      "Loss: 0.6092718243598938\n",
      "Loss: 0.6740471124649048\n",
      "Loss: 0.5679451823234558\n",
      "Loss: 0.7765694260597229\n",
      "Loss: 0.6539081335067749\n",
      "Loss: 0.691013753414154\n",
      "Loss: 0.616795539855957\n",
      "Loss: 0.6474191546440125\n",
      "Loss: 0.6336363554000854\n",
      "Loss: 0.6196076273918152\n",
      "Loss: 0.7015894651412964\n",
      "Loss: 0.7033220529556274\n",
      "Loss: 0.6336143016815186\n",
      "Loss: 0.6837967038154602\n",
      "Loss: 0.6722728610038757\n",
      "Loss: 0.6697213053703308\n",
      "Loss: 0.5610690116882324\n",
      "Loss: 0.7177379131317139\n",
      "Loss: 0.6369997262954712\n",
      "Loss: 0.5715171694755554\n",
      "Loss: 0.7730876207351685\n",
      "Loss: 0.5932091474533081\n",
      "Loss: 0.5930278301239014\n",
      "Loss: 0.6430987119674683\n",
      "Loss: 0.6489302515983582\n",
      "Loss: 0.6543905735015869\n",
      "Loss: 0.6522645950317383\n",
      "Loss: 0.6102850437164307\n",
      "Loss: 0.6983810663223267\n",
      "Loss: 0.6377521753311157\n",
      "Loss: 0.607089638710022\n",
      "Loss: 0.7415493726730347\n",
      "Loss: 0.6816192269325256\n",
      "Loss: 0.6166367530822754\n",
      "Loss: 0.7158429026603699\n",
      "Loss: 0.5877458453178406\n",
      "Loss: 0.618996798992157\n",
      "Loss: 0.6383172869682312\n",
      "Loss: 0.6167200803756714\n",
      "Loss: 0.6547907590866089\n",
      "Loss: 0.58599853515625\n",
      "Loss: 0.6314355134963989\n",
      "Loss: 0.575169563293457\n",
      "Loss: 0.6760579943656921\n",
      "Loss: 0.5736973881721497\n",
      "Loss: 0.6914045214653015\n",
      "Loss: 0.6697818040847778\n",
      "Loss: 0.6598320007324219\n",
      "Loss: 0.6510526537895203\n",
      "Loss: 0.6050889492034912\n",
      "Loss: 0.6342817544937134\n",
      "Loss: 0.6288803219795227\n",
      "Loss: 0.6875587105751038\n",
      "Loss: 0.6774212121963501\n",
      "Loss: 0.7688397169113159\n",
      "Loss: 0.5651324391365051\n",
      "Loss: 0.6869494318962097\n",
      "Loss: 0.7200596928596497\n",
      "Loss: 0.5993020534515381\n",
      "Loss: 0.5739307403564453\n",
      "Loss: 0.7154690623283386\n",
      "Loss: 0.6697098612785339\n",
      "Loss: 0.6938587427139282\n",
      "Loss: 0.6958892345428467\n",
      "Loss: 0.6455809473991394\n",
      "Loss: 0.6722466945648193\n",
      "Loss: 0.6911189556121826\n",
      "Loss: 0.644559383392334\n",
      "Loss: 0.5685815811157227\n",
      "Loss: 0.6014661192893982\n",
      "Loss: 0.6964570879936218\n",
      "Loss: 0.6896013617515564\n",
      "Loss: 0.6817503571510315\n",
      "Loss: 0.6054646372795105\n",
      "Loss: 0.6667459607124329\n",
      "Loss: 0.7280979752540588\n",
      "Loss: 0.6417352557182312\n",
      "Loss: 0.6424586772918701\n",
      "Loss: 0.676649272441864\n",
      "Loss: 0.6326899528503418\n",
      "Loss: 0.6358458995819092\n",
      "Loss: 0.6861244440078735\n",
      "Loss: 0.6150650382041931\n",
      "Loss: 0.644543468952179\n",
      "Loss: 0.6710168719291687\n",
      "Loss: 0.729834258556366\n",
      "Loss: 0.6450637578964233\n",
      "Loss: 0.5696070790290833\n",
      "Loss: 0.6179494857788086\n",
      "Loss: 0.616168200969696\n",
      "Loss: 0.5971329808235168\n",
      "Loss: 0.6579334735870361\n",
      "Loss: 0.7189896702766418\n",
      "Loss: 0.647370457649231\n",
      "Loss: 0.6463618278503418\n",
      "Loss: 0.7219638228416443\n",
      "Loss: 0.6823519468307495\n",
      "Loss: 0.6069608926773071\n",
      "Loss: 0.6817852258682251\n",
      "Loss: 0.745501697063446\n",
      "Loss: 0.6381241679191589\n",
      "Loss: 0.7238648533821106\n",
      "Loss: 0.70406574010849\n",
      "Loss: 0.6574133038520813\n",
      "Loss: 0.6810805797576904\n",
      "Loss: 0.6902701258659363\n",
      "Loss: 0.6603758335113525\n",
      "Loss: 0.614750862121582\n",
      "Loss: 0.6694115400314331\n",
      "Loss: 0.6464735865592957\n",
      "Loss: 0.5937358736991882\n",
      "Loss: 0.6547518968582153\n",
      "Loss: 0.7159240245819092\n",
      "Loss: 0.6518057584762573\n",
      "Loss: 0.7170565128326416\n",
      "Loss: 0.5645514726638794\n",
      "Loss: 0.6459473371505737\n",
      "Loss: 0.7600932717323303\n",
      "Loss: 0.6105639934539795\n",
      "Loss: 0.6548725366592407\n",
      "Loss: 0.5253094434738159\n",
      "Loss: 0.6318055987358093\n",
      "Loss: 0.6064811944961548\n",
      "Loss: 0.7203916311264038\n",
      "Loss: 0.6348545551300049\n",
      "Loss: 0.6732594966888428\n",
      "Loss: 0.7125332951545715\n",
      "Loss: 0.6539714336395264\n",
      "Loss: 0.6855744123458862\n",
      "Loss: 0.5743392705917358\n",
      "Loss: 0.6774827241897583\n",
      "Loss: 0.6432110071182251\n",
      "Loss: 0.6395785808563232\n",
      "Loss: 0.6866682171821594\n",
      "Loss: 0.6764971017837524\n",
      "Loss: 0.6803966164588928\n",
      "Loss: 0.673498809337616\n",
      "Loss: 0.7124842405319214\n",
      "Loss: 0.682779848575592\n",
      "Loss: 0.6697703003883362\n",
      "Loss: 0.6604068875312805\n",
      "Loss: 0.5974090099334717\n",
      "Loss: 0.6472394466400146\n",
      "Loss: 0.6557067632675171\n",
      "Loss: 0.6548899412155151\n",
      "Loss: 0.699767529964447\n",
      "Loss: 0.6137425899505615\n",
      "Loss: 0.6707375645637512\n",
      "Loss: 0.6857492923736572\n",
      "Loss: 0.7155002951622009\n",
      "Loss: 0.6347979307174683\n",
      "Loss: 0.6971501111984253\n",
      "Loss: 0.6380994319915771\n",
      "Loss: 0.5553538203239441\n",
      "Loss: 0.6059558391571045\n",
      "Loss: 0.5706765651702881\n",
      "Loss: 0.5860242247581482\n",
      "Loss: 0.7012348771095276\n",
      "Loss: 0.5856739282608032\n",
      "Loss: 0.5744892358779907\n",
      "Loss: 0.6323484778404236\n",
      "Loss: 0.648277997970581\n",
      "Loss: 0.6252050399780273\n",
      "Loss: 0.5904237627983093\n",
      "Loss: 0.6079098582267761\n",
      "Loss: 0.6356151103973389\n",
      "Loss: 0.7034603357315063\n",
      "Loss: 0.6349000930786133\n",
      "Loss: 0.6894684433937073\n",
      "Loss: 0.6159480810165405\n",
      "Loss: 0.5925799608230591\n",
      "Loss: 0.5876874923706055\n",
      "Loss: 0.6968567967414856\n",
      "Loss: 0.6644986271858215\n",
      "Loss: 0.6022508144378662\n",
      "Loss: 0.6580192446708679\n",
      "Loss: 0.6582667827606201\n",
      "Loss: 0.6778272986412048\n",
      "Loss: 0.679547905921936\n",
      "Loss: 0.7271788716316223\n",
      "Loss: 0.6789343953132629\n",
      "Loss: 0.7133805751800537\n",
      "Loss: 0.67893385887146\n",
      "Loss: 0.6344558596611023\n",
      "Loss: 0.5726017355918884\n",
      "Loss: 0.7026062607765198\n",
      "Loss: 0.6215819120407104\n",
      "Loss: 0.5957501530647278\n",
      "Loss: 0.6164783239364624\n",
      "Loss: 0.6729247570037842\n",
      "Loss: 0.6419495344161987\n",
      "Loss: 0.6146957278251648\n",
      "Loss: 0.582330584526062\n",
      "Loss: 0.6390039324760437\n",
      "Loss: 0.6173884868621826\n",
      "Loss: 0.6195682883262634\n",
      "Loss: 0.6636527180671692\n",
      "Loss: 0.6195308566093445\n",
      "Loss: 0.6197401285171509\n",
      "Loss: 0.5803729891777039\n",
      "Loss: 0.6302152872085571\n",
      "Loss: 0.7348911762237549\n",
      "Loss: 0.6123594045639038\n",
      "Loss: 0.6972349286079407\n",
      "Loss: 0.621447741985321\n",
      "Loss: 0.6463584899902344\n",
      "Loss: 0.6524239778518677\n",
      "Loss: 0.7715267539024353\n",
      "Loss: 0.6812885999679565\n",
      "Loss: 0.6768037676811218\n",
      "Loss: 0.6171368956565857\n",
      "Loss: 0.6184135675430298\n",
      "Loss: 0.583540141582489\n",
      "Loss: 0.6403705477714539\n",
      "Loss: 0.6903908848762512\n",
      "Loss: 0.6692642569541931\n",
      "Loss: 0.6281955242156982\n",
      "Loss: 0.7014409899711609\n",
      "Loss: 0.7061983942985535\n",
      "Loss: 0.6462919116020203\n",
      "Loss: 0.6088137030601501\n",
      "Loss: 0.5888804197311401\n",
      "Loss: 0.5576643943786621\n",
      "Loss: 0.5647952556610107\n",
      "Loss: 0.6403887867927551\n",
      "Loss: 0.6672945618629456\n",
      "Loss: 0.6222847104072571\n",
      "Loss: 0.6232921481132507\n",
      "Loss: 0.6447113752365112\n",
      "Loss: 0.5821449160575867\n",
      "Loss: 0.6140695810317993\n",
      "Loss: 0.6340036392211914\n",
      "Loss: 0.6088947653770447\n",
      "Loss: 0.712209939956665\n",
      "Loss: 0.609379231929779\n",
      "Loss: 0.5721484422683716\n",
      "Loss: 0.727859377861023\n",
      "Loss: 0.6344135999679565\n",
      "Loss: 0.5958197712898254\n",
      "Loss: 0.6380347013473511\n",
      "Loss: 0.6571766138076782\n",
      "Loss: 0.6953243613243103\n",
      "Loss: 0.6641438603401184\n",
      "Loss: 0.67909175157547\n",
      "Loss: 0.6624963283538818\n",
      "Loss: 0.5892517566680908\n",
      "Loss: 0.6203632354736328\n",
      "Loss: 0.5513343214988708\n",
      "Loss: 0.6643476486206055\n",
      "Loss: 0.6471508145332336\n",
      "Loss: 0.5986175537109375\n",
      "Loss: 0.6467387080192566\n",
      "Loss: 0.6469453573226929\n",
      "Loss: 0.5894119143486023\n",
      "Loss: 0.6450318098068237\n",
      "Loss: 0.6510312557220459\n",
      "Loss: 0.6380354166030884\n",
      "Loss: 0.623181939125061\n",
      "Loss: 0.6319229602813721\n",
      "Loss: 0.567991316318512\n",
      "Loss: 0.5853139162063599\n",
      "Loss: 0.6454117894172668\n",
      "Loss: 0.6426725387573242\n",
      "Loss: 0.6081201434135437\n",
      "Loss: 0.648584246635437\n",
      "Loss: 0.629848837852478\n",
      "Loss: 0.6678874492645264\n",
      "Loss: 0.6668112277984619\n",
      "Loss: 0.6501831412315369\n",
      "Loss: 0.7238919138908386\n",
      "Loss: 0.6467428207397461\n",
      "Loss: 0.6779387593269348\n",
      "Loss: 0.6727108359336853\n",
      "Loss: 0.5765599012374878\n",
      "Loss: 0.7134226560592651\n",
      "Loss: 0.6287125945091248\n",
      "Loss: 0.6006205677986145\n",
      "Loss: 0.6250088214874268\n",
      "Loss: 0.5942463874816895\n",
      "Loss: 0.6460755467414856\n",
      "Loss: 0.6058420538902283\n",
      "Loss: 0.6441811323165894\n",
      "Loss: 0.6493642330169678\n",
      "Loss: 0.7470892071723938\n",
      "Loss: 0.6808508634567261\n",
      "Loss: 0.6055316925048828\n",
      "Loss: 0.6291673183441162\n",
      "Loss: 0.6943092942237854\n",
      "Loss: 0.6414169669151306\n",
      "Loss: 0.6375061273574829\n",
      "Loss: 0.6965271234512329\n",
      "Loss: 0.5768886804580688\n",
      "Loss: 0.6851752996444702\n",
      "Loss: 0.6665363311767578\n",
      "Loss: 0.7800700664520264\n",
      "Loss: 0.577519416809082\n",
      "Loss: 0.5923564434051514\n",
      "Loss: 0.6888962984085083\n",
      "Loss: 0.6110656261444092\n",
      "Loss: 0.6397398710250854\n",
      "Loss: 0.6226313710212708\n",
      "Loss: 0.5858327746391296\n",
      "Loss: 0.5722574591636658\n",
      "Loss: 0.5703965425491333\n",
      "Loss: 0.63111811876297\n",
      "Loss: 0.6869979500770569\n",
      "Loss: 0.5742827653884888\n",
      "Loss: 0.6792138814926147\n",
      "Loss: 0.6517540812492371\n",
      "Loss: 0.6191934943199158\n",
      "Loss: 0.6343176960945129\n",
      "Loss: 0.6538559198379517\n",
      "Loss: 0.6430313587188721\n",
      "Loss: 0.6770904064178467\n",
      "Loss: 0.6113947629928589\n",
      "Loss: 0.7368572950363159\n",
      "Loss: 0.5751160383224487\n",
      "Loss: 0.5771363377571106\n",
      "Loss: 0.6303020715713501\n",
      "Loss: 0.6033655405044556\n",
      "Loss: 0.6338031888008118\n",
      "Loss: 0.5810022354125977\n",
      "Loss: 0.6476959586143494\n",
      "Loss: 0.6869832873344421\n",
      "Loss: 0.6222448348999023\n",
      "Loss: 0.5395233035087585\n",
      "Loss: 0.6802765130996704\n",
      "Loss: 0.6136497855186462\n",
      "Loss: 0.6141117215156555\n",
      "Loss: 0.6597106456756592\n",
      "Loss: 0.6850884556770325\n",
      "Loss: 0.6294687390327454\n",
      "Loss: 0.6725542545318604\n",
      "Loss: 0.6727878451347351\n",
      "Loss: 0.5920683145523071\n",
      "Loss: 0.5894367098808289\n",
      "Loss: 0.6626023054122925\n",
      "Loss: 0.6331537365913391\n",
      "Loss: 0.6729267835617065\n",
      "Loss: 0.6543864011764526\n",
      "Loss: 0.7381470799446106\n",
      "Loss: 0.6557799577713013\n",
      "Loss: 0.6385750770568848\n",
      "Loss: 0.6718220114707947\n",
      "Loss: 0.6133851408958435\n",
      "Loss: 0.6400516033172607\n",
      "Loss: 0.6237921118736267\n",
      "Loss: 0.6831665635108948\n",
      "Loss: 0.641016960144043\n",
      "Loss: 0.6953298449516296\n",
      "Loss: 0.6654847860336304\n",
      "Loss: 0.6097424626350403\n",
      "Loss: 0.6590162515640259\n",
      "Loss: 0.5911239981651306\n",
      "Loss: 0.6656693816184998\n",
      "Loss: 0.6751883625984192\n",
      "Loss: 0.6702061295509338\n",
      "Loss: 0.7071682214736938\n",
      "Loss: 0.6633069515228271\n",
      "Loss: 0.6631671190261841\n",
      "Loss: 0.7031885981559753\n",
      "Loss: 0.6619433760643005\n",
      "Loss: 0.6251735687255859\n",
      "Loss: 0.658069372177124\n",
      "Loss: 0.695408046245575\n",
      "Loss: 0.6463850140571594\n",
      "Loss: 0.6806727647781372\n",
      "Loss: 0.7653267979621887\n",
      "Loss: 0.5477750301361084\n",
      "Loss: 0.6255572438240051\n",
      "Loss: 0.6818295121192932\n",
      "Loss: 0.6465727090835571\n",
      "Loss: 0.664783775806427\n",
      "Loss: 0.6620379686355591\n",
      "Loss: 0.6763193011283875\n",
      "Loss: 0.6922743320465088\n",
      "Loss: 0.6714932918548584\n",
      "Loss: 0.6661092638969421\n",
      "Loss: 0.5987873077392578\n",
      "Loss: 0.6760918498039246\n",
      "Loss: 0.6628764271736145\n",
      "Loss: 0.6472451090812683\n",
      "Loss: 0.6516388654708862\n",
      "Loss: 0.7555821537971497\n",
      "Loss: 0.5444237589836121\n",
      "Loss: 0.6300358176231384\n",
      "Loss: 0.6873249411582947\n",
      "Loss: 0.6906042695045471\n",
      "Loss: 0.6050179600715637\n",
      "Loss: 0.6917470693588257\n",
      "Loss: 0.6311696767807007\n",
      "Loss: 0.6739761233329773\n",
      "Loss: 0.6159809827804565\n",
      "Loss: 0.5889633297920227\n",
      "Loss: 0.6238135099411011\n",
      "Loss: 0.7087057828903198\n",
      "Loss: 0.6495775580406189\n",
      "Loss: 0.7394232153892517\n",
      "Loss: 0.6676945090293884\n",
      "Loss: 0.5886573791503906\n",
      "Loss: 0.6713191866874695\n",
      "Loss: 0.5998746752738953\n",
      "Loss: 0.6530731916427612\n",
      "Loss: 0.6712394952774048\n",
      "Loss: 0.6695500612258911\n",
      "Loss: 0.6712347269058228\n",
      "Loss: 0.5951092839241028\n",
      "Loss: 0.5759580135345459\n",
      "Loss: 0.679812490940094\n",
      "Loss: 0.6899621486663818\n",
      "Loss: 0.7418350577354431\n",
      "Loss: 0.6861376166343689\n",
      "Loss: 0.654808759689331\n",
      "Loss: 0.6706708073616028\n",
      "Loss: 0.6740252375602722\n",
      "Loss: 0.6228123903274536\n",
      "Loss: 0.665745735168457\n",
      "Loss: 0.6194013953208923\n",
      "Loss: 0.6207980513572693\n",
      "Loss: 0.6456446051597595\n",
      "Loss: 0.6423138380050659\n",
      "Loss: 0.5711419582366943\n",
      "Loss: 0.6454017162322998\n",
      "Loss: 0.6561545133590698\n",
      "Loss: 0.6196067333221436\n",
      "Loss: 0.6358694434165955\n",
      "Loss: 0.655926525592804\n",
      "Loss: 0.6807013154029846\n",
      "Loss: 0.6627816557884216\n",
      "Loss: 0.6728026866912842\n",
      "Loss: 0.7210671305656433\n",
      "Loss: 0.6673702597618103\n",
      "Loss: 0.6140273809432983\n",
      "Loss: 0.5838310718536377\n",
      "Loss: 0.6255790591239929\n",
      "Loss: 0.6065543293952942\n",
      "Loss: 0.622085690498352\n",
      "Loss: 0.6456093192100525\n",
      "Loss: 0.7246108651161194\n",
      "Loss: 0.6847545504570007\n",
      "Loss: 0.6175289154052734\n",
      "Loss: 0.6202556490898132\n",
      "Loss: 0.6180868148803711\n",
      "Loss: 0.6348251700401306\n",
      "Loss: 0.6530680060386658\n",
      "Loss: 0.707473635673523\n",
      "Loss: 0.694966197013855\n",
      "Loss: 0.6300536394119263\n",
      "Loss: 0.5359652638435364\n",
      "Loss: 0.6006067991256714\n",
      "Loss: 0.6130364537239075\n",
      "Loss: 0.6942769885063171\n",
      "Loss: 0.6256691217422485\n",
      "Loss: 0.6056821346282959\n",
      "Loss: 0.6027296185493469\n",
      "Loss: 0.6666656732559204\n",
      "Loss: 0.6725087761878967\n",
      "Loss: 0.6593425273895264\n",
      "Loss: 0.6666154861450195\n",
      "Loss: 0.6028239727020264\n",
      "Loss: 0.705707311630249\n",
      "Loss: 0.7119418382644653\n",
      "Loss: 0.6786848306655884\n",
      "Loss: 0.6148459911346436\n",
      "Loss: 0.6773722767829895\n",
      "Loss: 0.673903226852417\n",
      "Loss: 0.5496508479118347\n",
      "Loss: 0.6435217261314392\n",
      "Loss: 0.643722653388977\n",
      "Loss: 0.5935567617416382\n",
      "Loss: 0.5900020003318787\n",
      "Loss: 0.5938875079154968\n",
      "Loss: 0.6474374532699585\n",
      "Loss: 0.6705528497695923\n",
      "Loss: 0.6239933371543884\n",
      "Loss: 0.654792308807373\n",
      "Loss: 0.5667225122451782\n",
      "Loss: 0.5883046984672546\n",
      "Loss: 0.6636893153190613\n",
      "Loss: 0.6786372661590576\n",
      "Loss: 0.6378427743911743\n",
      "Loss: 0.6547344326972961\n",
      "Loss: 0.6505228877067566\n",
      "Loss: 0.6503480076789856\n",
      "Loss: 0.6173186302185059\n",
      "Loss: 0.6106510162353516\n",
      "Loss: 0.6346370577812195\n",
      "Loss: 0.652599573135376\n",
      "Loss: 0.5931991934776306\n",
      "Loss: 0.6331527233123779\n",
      "Loss: 0.6797444820404053\n",
      "Loss: 0.6771510243415833\n",
      "Loss: 0.7742368578910828\n",
      "Loss: 0.6763597726821899\n",
      "Loss: 0.6270939111709595\n",
      "Loss: 0.7061660289764404\n",
      "Loss: 0.6333116888999939\n",
      "Loss: 0.7018652558326721\n",
      "Loss: 0.6225248575210571\n",
      "Loss: 0.6114857196807861\n",
      "Loss: 0.696670413017273\n",
      "Loss: 0.6187376379966736\n",
      "Loss: 0.6898526549339294\n",
      "Loss: 0.7271419763565063\n",
      "Loss: 0.6322555541992188\n",
      "Loss: 0.6409900784492493\n",
      "Loss: 0.7028983235359192\n",
      "Loss: 0.6330065131187439\n",
      "Loss: 0.607592761516571\n",
      "Loss: 0.628788948059082\n",
      "Loss: 0.7225039005279541\n",
      "Loss: 0.5344047546386719\n",
      "Loss: 0.664833664894104\n",
      "Loss: 0.6389080286026001\n",
      "Loss: 0.5625825524330139\n",
      "Loss: 0.6469513177871704\n",
      "Loss: 0.6480393409729004\n",
      "Loss: 0.7617022395133972\n",
      "Loss: 0.625732421875\n",
      "Loss: 0.6782752871513367\n",
      "Loss: 0.6138566136360168\n",
      "Loss: 0.6328985691070557\n",
      "Loss: 0.7121978998184204\n",
      "Loss: 0.5509388446807861\n",
      "Loss: 0.7480962872505188\n",
      "Loss: 0.6916010975837708\n",
      "Loss: 0.6478703618049622\n",
      "Loss: 0.6625378131866455\n",
      "Loss: 0.65519118309021\n",
      "Loss: 0.6560728549957275\n",
      "Loss: 0.6446942090988159\n",
      "Loss: 0.7003952264785767\n",
      "Loss: 0.5992259979248047\n",
      "Loss: 0.6156685948371887\n",
      "Loss: 0.6213151812553406\n",
      "Loss: 0.7007681131362915\n",
      "Loss: 0.7176454067230225\n",
      "Loss: 0.6594737768173218\n",
      "Loss: 0.6438599824905396\n",
      "Loss: 0.6302675604820251\n",
      "Loss: 0.677758514881134\n",
      "Loss: 0.6187500357627869\n",
      "Loss: 0.6495625972747803\n",
      "Loss: 0.5623766779899597\n",
      "Loss: 0.6258186101913452\n",
      "Loss: 0.6514478921890259\n",
      "Loss: 0.6422544717788696\n",
      "Loss: 0.5962672233581543\n",
      "Loss: 0.652818500995636\n",
      "Loss: 0.7354210615158081\n",
      "Loss: 0.6742145419120789\n",
      "Loss: 0.5915512442588806\n",
      "Loss: 0.6180410385131836\n",
      "Loss: 0.7212528586387634\n",
      "Loss: 0.6147265434265137\n",
      "Loss: 0.6442469954490662\n",
      "Loss: 0.6530677676200867\n",
      "Loss: 0.6608422994613647\n",
      "Loss: 0.655633807182312\n",
      "Loss: 0.6667245030403137\n",
      "Loss: 0.6396658420562744\n",
      "Loss: 0.6081008911132812\n",
      "Loss: 0.6177652478218079\n",
      "Loss: 0.6757429838180542\n",
      "Loss: 0.6810078024864197\n",
      "Loss: 0.5647763013839722\n",
      "Loss: 0.6318639516830444\n",
      "Loss: 0.6081428527832031\n",
      "Loss: 0.6163398623466492\n",
      "Loss: 0.6592227220535278\n",
      "Loss: 0.5921205282211304\n",
      "Loss: 0.6304877400398254\n",
      "Loss: 0.6308343410491943\n",
      "Loss: 0.6360517740249634\n",
      "Loss: 0.587093710899353\n",
      "Loss: 0.6769326329231262\n",
      "Loss: 0.6081735491752625\n",
      "Loss: 0.715361475944519\n",
      "Loss: 0.6113647818565369\n",
      "Loss: 0.6087349653244019\n",
      "Loss: 0.6573072671890259\n",
      "Loss: 0.621268093585968\n",
      "Loss: 0.6589645743370056\n",
      "Loss: 0.6353448629379272\n",
      "Loss: 0.5963867902755737\n",
      "Loss: 0.634759783744812\n",
      "Loss: 0.7608092427253723\n",
      "Loss: 0.6452734470367432\n",
      "Loss: 0.6359440088272095\n",
      "Loss: 0.6680638790130615\n",
      "Loss: 0.6708780527114868\n",
      "Loss: 0.5977969169616699\n",
      "Loss: 0.6637009382247925\n",
      "Loss: 0.6486775279045105\n",
      "Loss: 0.669746458530426\n",
      "Loss: 0.6709809899330139\n",
      "Loss: 0.6450968980789185\n",
      "Loss: 0.6109510660171509\n",
      "Loss: 0.6170272827148438\n",
      "Loss: 0.6926849484443665\n",
      "Loss: 0.6031595468521118\n",
      "Loss: 0.7377289533615112\n",
      "Loss: 0.6499100923538208\n",
      "Loss: 0.702206552028656\n",
      "Loss: 0.6911486387252808\n",
      "Loss: 0.612769365310669\n",
      "Loss: 0.6869319081306458\n",
      "Loss: 0.5880023837089539\n",
      "Loss: 0.6995155215263367\n",
      "Loss: 0.6396703720092773\n",
      "Loss: 0.7049976587295532\n",
      "Loss: 0.7273914217948914\n",
      "Loss: 0.7056347131729126\n",
      "Loss: 0.6563084721565247\n",
      "Loss: 0.5970418453216553\n",
      "Loss: 0.6756879091262817\n",
      "Loss: 0.6691206097602844\n",
      "Loss: 0.7081028819084167\n",
      "Loss: 0.6311625838279724\n",
      "Loss: 0.6301342844963074\n",
      "Loss: 0.6901177167892456\n",
      "Loss: 0.6859150528907776\n",
      "Loss: 0.7169901132583618\n",
      "Loss: 0.6106263995170593\n",
      "Loss: 0.6077426075935364\n",
      "Loss: 0.6322935819625854\n",
      "Loss: 0.637435793876648\n",
      "Loss: 0.7348392009735107\n",
      "Loss: 0.6788174510002136\n",
      "Loss: 0.5961132049560547\n",
      "Loss: 0.6663817763328552\n",
      "Loss: 0.610468327999115\n",
      "Loss: 0.6712803244590759\n",
      "Loss: 0.669075071811676\n",
      "Loss: 0.6119973659515381\n",
      "Loss: 0.6229594349861145\n",
      "Loss: 0.6879737377166748\n",
      "Loss: 0.6846845149993896\n",
      "Loss: 0.6508487462997437\n",
      "Loss: 0.6289043426513672\n",
      "Loss: 0.6638912558555603\n",
      "Loss: 0.7241966128349304\n",
      "Loss: 0.5350884795188904\n",
      "Loss: 0.6682211756706238\n",
      "Loss: 0.6447381973266602\n",
      "Loss: 0.5762907862663269\n",
      "Loss: 0.6516445875167847\n",
      "Loss: 0.6311721801757812\n",
      "Loss: 0.625421941280365\n",
      "Loss: 0.5603789687156677\n",
      "Loss: 0.6297450065612793\n",
      "Loss: 0.6160234808921814\n",
      "Loss: 0.6716278791427612\n",
      "Loss: 0.6562154293060303\n",
      "Loss: 0.6382095217704773\n",
      "Loss: 0.5984739661216736\n",
      "Loss: 0.6481125950813293\n",
      "Loss: 0.5793830752372742\n",
      "Loss: 0.5618781447410583\n",
      "Loss: 0.6650868654251099\n",
      "Loss: 0.7467153072357178\n",
      "Loss: 0.6430283784866333\n",
      "Loss: 0.6454364657402039\n",
      "Loss: 0.6921434998512268\n",
      "Loss: 0.5897250175476074\n",
      "Loss: 0.6011854410171509\n",
      "Loss: 0.6558879613876343\n",
      "Loss: 0.652184784412384\n",
      "Loss: 0.6141281127929688\n",
      "Loss: 0.7057487368583679\n",
      "Loss: 0.6360511779785156\n",
      "Loss: 0.6658904552459717\n",
      "Loss: 0.6522759199142456\n",
      "Loss: 0.6294182538986206\n",
      "Loss: 0.7245439887046814\n",
      "Loss: 0.6426359415054321\n",
      "Loss: 0.7782066464424133\n",
      "Loss: 0.6790350675582886\n",
      "Loss: 0.6568498611450195\n",
      "Loss: 0.6840230226516724\n",
      "Loss: 0.5891279578208923\n",
      "Loss: 0.5664778351783752\n",
      "Loss: 0.5873841047286987\n",
      "Loss: 0.6302555203437805\n",
      "Loss: 0.6782386898994446\n",
      "Loss: 0.7028793096542358\n",
      "Loss: 0.6182355880737305\n",
      "Loss: 0.6958298087120056\n",
      "Loss: 0.739155650138855\n",
      "Loss: 0.6380812525749207\n",
      "Loss: 0.6607054471969604\n",
      "Loss: 0.6934863328933716\n",
      "Loss: 0.7087277173995972\n",
      "Loss: 0.6614039540290833\n",
      "Loss: 0.6107252240180969\n",
      "Loss: 0.6495893001556396\n",
      "Loss: 0.6015458106994629\n",
      "Loss: 0.5764631628990173\n",
      "Loss: 0.7345412373542786\n",
      "Loss: 0.6651766896247864\n",
      "Loss: 0.6462526321411133\n",
      "Loss: 0.634418785572052\n",
      "Loss: 0.6578468680381775\n",
      "Loss: 0.6242067217826843\n",
      "Loss: 0.6689272522926331\n",
      "Loss: 0.7330743074417114\n",
      "Loss: 0.5750118494033813\n",
      "Loss: 0.6151785850524902\n",
      "Loss: 0.678351640701294\n",
      "Loss: 0.6429650783538818\n",
      "Loss: 0.6862601637840271\n",
      "Loss: 0.6208411455154419\n",
      "Loss: 0.6746488809585571\n",
      "Loss: 0.7022255063056946\n",
      "Loss: 0.6352699995040894\n",
      "Loss: 0.6946825385093689\n",
      "Loss: 0.6250180602073669\n",
      "Loss: 0.6085145473480225\n",
      "Loss: 0.622218132019043\n",
      "Loss: 0.6622613072395325\n",
      "Loss: 0.65753173828125\n",
      "Loss: 0.6601632237434387\n",
      "Loss: 0.7039013504981995\n",
      "Loss: 0.7241742014884949\n",
      "Loss: 0.6369144320487976\n",
      "Loss: 0.6441758871078491\n",
      "Loss: 0.6396527290344238\n",
      "Loss: 0.7218234539031982\n",
      "Loss: 0.6764357686042786\n",
      "Loss: 0.6280590295791626\n",
      "Loss: 0.6789801120758057\n",
      "Loss: 0.692371129989624\n",
      "Loss: 0.6637039184570312\n",
      "Loss: 0.6306705474853516\n",
      "Loss: 0.6366516351699829\n",
      "Loss: 0.7117676138877869\n",
      "Loss: 0.7144444584846497\n",
      "Loss: 0.6349972486495972\n",
      "Loss: 0.7018235325813293\n",
      "Loss: 0.6396273374557495\n",
      "Loss: 0.6495323181152344\n",
      "Loss: 0.6671938300132751\n",
      "Loss: 0.6081806421279907\n",
      "Loss: 0.6096824407577515\n",
      "Loss: 0.6618583798408508\n",
      "Loss: 0.6863500475883484\n",
      "Loss: 0.6964303851127625\n",
      "Loss: 0.6727473735809326\n",
      "Loss: 0.6706584095954895\n",
      "Loss: 0.6345309019088745\n",
      "Loss: 0.5975363254547119\n",
      "Loss: 0.6734358072280884\n",
      "Loss: 0.5693540573120117\n",
      "Loss: 0.5762726664543152\n",
      "Loss: 0.7249682545661926\n",
      "Loss: 0.6131827235221863\n",
      "Loss: 0.5816421508789062\n",
      "Loss: 0.6086504459381104\n",
      "Loss: 0.6122722625732422\n",
      "Loss: 0.6691969633102417\n",
      "Loss: 0.5898764729499817\n",
      "Loss: 0.6262828707695007\n",
      "Loss: 0.6253935098648071\n",
      "Loss: 0.6040080189704895\n",
      "Loss: 0.6844089031219482\n",
      "Loss: 0.6376951932907104\n",
      "Loss: 0.6368506550788879\n",
      "Loss: 0.6927314400672913\n",
      "Loss: 0.6090261936187744\n",
      "Loss: 0.724556028842926\n",
      "Loss: 0.6541406512260437\n",
      "Loss: 0.6509201526641846\n",
      "Loss: 0.6465907096862793\n",
      "Loss: 0.6312491297721863\n",
      "Loss: 0.6511277556419373\n",
      "Loss: 0.6818745732307434\n",
      "Loss: 0.6317194700241089\n",
      "Loss: 0.7136549353599548\n",
      "Loss: 0.7152889966964722\n",
      "Loss: 0.6744066476821899\n",
      "Loss: 0.6944843530654907\n",
      "Loss: 0.6187208890914917\n",
      "Loss: 0.6357035636901855\n",
      "Loss: 0.6909557580947876\n",
      "Loss: 0.5919687151908875\n",
      "Loss: 0.6267346143722534\n",
      "Loss: 0.6609313488006592\n",
      "Loss: 0.6934614777565002\n",
      "Loss: 0.6538359522819519\n",
      "Loss: 0.6829703450202942\n",
      "Loss: 0.6808322072029114\n",
      "Loss: 0.6787788271903992\n",
      "Loss: 0.603988766670227\n",
      "Loss: 0.628034234046936\n",
      "Loss: 0.6993154883384705\n",
      "Loss: 0.6457967758178711\n",
      "Loss: 0.6712866425514221\n",
      "Loss: 0.6352571845054626\n",
      "Loss: 0.7172512412071228\n",
      "Loss: 0.7139645218849182\n",
      "Loss: 0.6303245425224304\n",
      "Loss: 0.6608339548110962\n",
      "Loss: 0.7310703992843628\n",
      "Loss: 0.6616119742393494\n",
      "Loss: 0.7105587720870972\n",
      "Loss: 0.6081632971763611\n",
      "Loss: 0.6482042074203491\n",
      "Loss: 0.7366493940353394\n",
      "Loss: 0.6318897604942322\n",
      "Loss: 0.5948594808578491\n",
      "Loss: 0.6106777191162109\n",
      "Loss: 0.6732763648033142\n",
      "Loss: 0.6707009077072144\n",
      "Loss: 0.6427475214004517\n",
      "Loss: 0.7330566644668579\n",
      "Loss: 0.8053909540176392\n",
      "Loss: 0.5998286008834839\n",
      "Loss: 0.6319016218185425\n",
      "Loss: 0.5988994836807251\n",
      "Loss: 0.678325355052948\n",
      "Loss: 0.7197245955467224\n",
      "Loss: 0.6068591475486755\n",
      "Loss: 0.6437582969665527\n",
      "Loss: 0.637678325176239\n",
      "Loss: 0.6194378137588501\n",
      "Loss: 0.6337754726409912\n",
      "Loss: 0.7038082480430603\n",
      "Loss: 0.596159815788269\n",
      "Loss: 0.6336482167243958\n",
      "Loss: 0.6828635334968567\n",
      "Loss: 0.6468461155891418\n",
      "Loss: 0.6810680627822876\n",
      "Loss: 0.6356059312820435\n",
      "Loss: 0.664491593837738\n",
      "Loss: 0.6467651128768921\n",
      "Loss: 0.666843593120575\n",
      "Loss: 0.5629543662071228\n",
      "Loss: 0.736631453037262\n",
      "Loss: 0.6710061430931091\n",
      "Loss: 0.6620447039604187\n",
      "Loss: 0.6043307781219482\n",
      "Loss: 0.6880768537521362\n",
      "Loss: 0.6435108184814453\n",
      "Loss: 0.5850073099136353\n",
      "Loss: 0.6041494607925415\n",
      "Loss: 0.6406190991401672\n",
      "Loss: 0.6418898701667786\n",
      "Loss: 0.5878476500511169\n",
      "Loss: 0.5767530798912048\n",
      "Loss: 0.6103870272636414\n",
      "Loss: 0.6983200907707214\n",
      "Loss: 0.724011242389679\n",
      "Loss: 0.6125332117080688\n",
      "Loss: 0.6224584579467773\n",
      "Loss: 0.6805768609046936\n",
      "Loss: 0.5768601298332214\n",
      "Loss: 0.7143534421920776\n",
      "Loss: 0.6921617388725281\n",
      "Loss: 0.7006610035896301\n",
      "Loss: 0.6133248209953308\n",
      "Loss: 0.6002791523933411\n",
      "Loss: 0.6923519372940063\n",
      "Loss: 0.6337591409683228\n",
      "Loss: 0.6969126462936401\n",
      "Loss: 0.5645387172698975\n",
      "Loss: 0.6735994815826416\n",
      "Loss: 0.6503608822822571\n",
      "Loss: 0.7624595165252686\n",
      "Loss: 0.6809453368186951\n",
      "Loss: 0.6642814874649048\n",
      "Loss: 0.6197726726531982\n",
      "Loss: 0.6761223673820496\n",
      "Loss: 0.590493381023407\n",
      "Loss: 0.7591665983200073\n",
      "Loss: 0.6666471362113953\n",
      "Loss: 0.5996387004852295\n",
      "Loss: 0.6967782378196716\n",
      "Loss: 0.5710141658782959\n",
      "Loss: 0.6340608596801758\n",
      "Loss: 0.6687721014022827\n",
      "Loss: 0.6835108995437622\n",
      "Loss: 0.6674051880836487\n",
      "Loss: 0.6619904041290283\n",
      "Loss: 0.585881233215332\n",
      "Loss: 0.6635029911994934\n",
      "Loss: 0.6671422123908997\n",
      "Loss: 0.6452009677886963\n",
      "Loss: 0.6592756509780884\n",
      "Loss: 0.624350368976593\n",
      "Loss: 0.6491956114768982\n",
      "Loss: 0.6491619348526001\n",
      "Loss: 0.6411426067352295\n",
      "Loss: 0.665287971496582\n",
      "Loss: 0.6299242377281189\n",
      "Loss: 0.6121347546577454\n",
      "Loss: 0.6265465021133423\n",
      "Loss: 0.6146132946014404\n",
      "Loss: 0.6254786849021912\n",
      "Loss: 0.652010440826416\n",
      "Loss: 0.6541892886161804\n",
      "Loss: 0.6916018128395081\n",
      "Loss: 0.7040864825248718\n",
      "Loss: 0.6719345450401306\n",
      "Loss: 0.6363276243209839\n",
      "Loss: 0.6703029870986938\n",
      "Loss: 0.6574757695198059\n",
      "Loss: 0.6867249608039856\n",
      "Loss: 0.5991434454917908\n",
      "Loss: 0.6380773782730103\n",
      "Loss: 0.6193286776542664\n",
      "Loss: 0.6180422306060791\n",
      "Loss: 0.651585578918457\n",
      "Loss: 0.7624093890190125\n",
      "Loss: 0.6200856566429138\n",
      "Loss: 0.6201809048652649\n",
      "Loss: 0.625390350818634\n",
      "Loss: 0.5877947211265564\n",
      "Loss: 0.6922482252120972\n",
      "Loss: 0.6633975505828857\n",
      "Loss: 0.6236693859100342\n",
      "Loss: 0.5943572521209717\n",
      "Loss: 0.6036192178726196\n",
      "Loss: 0.7381064891815186\n",
      "Loss: 0.5491803288459778\n",
      "Loss: 0.7033550143241882\n",
      "Loss: 0.7490035891532898\n",
      "Loss: 0.736403226852417\n",
      "Loss: 0.6232929229736328\n",
      "Loss: 0.6216050386428833\n",
      "Loss: 0.6674903631210327\n",
      "Loss: 0.6116005182266235\n",
      "Loss: 0.6518056392669678\n",
      "Loss: 0.7422066926956177\n",
      "Loss: 0.5926159024238586\n",
      "Loss: 0.6504637002944946\n",
      "Loss: 0.6606401205062866\n",
      "Loss: 0.7352785468101501\n",
      "Loss: 0.6630256175994873\n",
      "Loss: 0.6720472574234009\n",
      "Loss: 0.6129968166351318\n",
      "Loss: 0.6872183680534363\n",
      "Loss: 0.6705666184425354\n",
      "Loss: 0.5732787847518921\n",
      "Loss: 0.6478273272514343\n",
      "Loss: 0.7082120776176453\n",
      "Loss: 0.6827327609062195\n",
      "Loss: 0.6293099522590637\n",
      "Loss: 0.7385486364364624\n",
      "Loss: 0.5289149284362793\n",
      "Loss: 0.6589971780776978\n",
      "Loss: 0.6113842725753784\n",
      "Loss: 0.6559716463088989\n",
      "Loss: 0.6467008590698242\n",
      "Loss: 0.6305088400840759\n",
      "Loss: 0.5950449705123901\n",
      "Loss: 0.7144623398780823\n",
      "Loss: 0.568168044090271\n",
      "Loss: 0.5703867673873901\n",
      "Loss: 0.6925767064094543\n",
      "Loss: 0.5844793319702148\n",
      "Loss: 0.7049022912979126\n",
      "Loss: 0.6427919268608093\n",
      "Loss: 0.7071763873100281\n",
      "Loss: 0.61930251121521\n",
      "Loss: 0.6559169292449951\n",
      "Loss: 0.5981340408325195\n",
      "Loss: 0.5936396718025208\n",
      "Loss: 0.6821626424789429\n",
      "Loss: 0.6277066469192505\n",
      "Loss: 0.6748425960540771\n",
      "Loss: 0.6605446934700012\n",
      "Loss: 0.5869868993759155\n",
      "Loss: 0.6635745167732239\n",
      "Loss: 0.6509402394294739\n",
      "Loss: 0.6202442049980164\n",
      "Loss: 0.6156566143035889\n",
      "Loss: 0.6860902905464172\n",
      "Loss: 0.6525249481201172\n",
      "Loss: 0.7200948596000671\n",
      "Loss: 0.6784451007843018\n",
      "Loss: 0.682766854763031\n",
      "Loss: 0.6590959429740906\n",
      "Loss: 0.697299063205719\n",
      "Loss: 0.6738995313644409\n",
      "Loss: 0.6955124139785767\n",
      "Loss: 0.604469895362854\n",
      "Loss: 0.6536048650741577\n",
      "Loss: 0.6704896688461304\n",
      "Loss: 0.5829666256904602\n",
      "Loss: 0.6047916412353516\n",
      "Loss: 0.6189582347869873\n",
      "Loss: 0.6956352591514587\n",
      "Loss: 0.611169159412384\n",
      "Loss: 0.615759015083313\n",
      "Loss: 0.623262345790863\n",
      "Loss: 0.664348840713501\n",
      "Loss: 0.646115243434906\n",
      "Loss: 0.6527835130691528\n",
      "Loss: 0.667370080947876\n",
      "Loss: 0.6560380458831787\n",
      "Loss: 0.6136625409126282\n",
      "Loss: 0.5585755109786987\n",
      "Loss: 0.6895679831504822\n",
      "Loss: 0.606083869934082\n",
      "Loss: 0.6376826167106628\n",
      "Loss: 0.6814385652542114\n",
      "Loss: 0.6870594620704651\n",
      "Loss: 0.6342952251434326\n",
      "Loss: 0.6788713335990906\n",
      "Loss: 0.6541427969932556\n",
      "Loss: 0.7355511784553528\n",
      "Loss: 0.6543977856636047\n",
      "Loss: 0.6643856763839722\n",
      "Loss: 0.6573132276535034\n",
      "Loss: 0.591393768787384\n",
      "Loss: 0.6230844259262085\n",
      "Loss: 0.6511141657829285\n",
      "Loss: 0.6083402633666992\n",
      "Loss: 0.6537452936172485\n",
      "Loss: 0.6186535954475403\n",
      "Loss: 0.6309966444969177\n",
      "Loss: 0.5524057149887085\n",
      "Loss: 0.6486436128616333\n",
      "Loss: 0.653984785079956\n",
      "Loss: 0.6358349919319153\n",
      "Loss: 0.6529234051704407\n",
      "Loss: 0.7064110636711121\n",
      "Loss: 0.6208885908126831\n",
      "Loss: 0.6037375926971436\n",
      "Loss: 0.7243760228157043\n",
      "Loss: 0.6526868343353271\n",
      "Loss: 0.7019345760345459\n",
      "Loss: 0.6023024320602417\n",
      "Loss: 0.6179497838020325\n",
      "Loss: 0.6927924752235413\n",
      "Loss: 0.703290581703186\n",
      "Loss: 0.7089865207672119\n",
      "Loss: 0.6257490515708923\n",
      "Loss: 0.6747217774391174\n",
      "Loss: 0.6620190739631653\n",
      "Loss: 0.606762170791626\n",
      "Loss: 0.6273399591445923\n",
      "Loss: 0.6644711494445801\n",
      "Loss: 0.6935520768165588\n",
      "Loss: 0.5540647506713867\n",
      "Loss: 0.6614688038825989\n",
      "Loss: 0.6374653577804565\n",
      "Loss: 0.6729520559310913\n",
      "Loss: 0.6493721008300781\n",
      "Loss: 0.6394988894462585\n",
      "Loss: 0.6275990009307861\n",
      "Loss: 0.5846413373947144\n",
      "Loss: 0.6782686710357666\n",
      "Loss: 0.6313784122467041\n",
      "Loss: 0.6000856161117554\n",
      "Loss: 0.607414186000824\n",
      "Loss: 0.6599065661430359\n",
      "Loss: 0.6108018755912781\n",
      "Loss: 0.6740769147872925\n",
      "Loss: 0.6396549940109253\n",
      "Loss: 0.6282475590705872\n",
      "Loss: 0.6216464042663574\n",
      "Loss: 0.6301543116569519\n",
      "Loss: 0.7079272866249084\n",
      "Loss: 0.7123557925224304\n",
      "Loss: 0.6422502994537354\n",
      "Loss: 0.5915098190307617\n",
      "Loss: 0.6447432041168213\n",
      "Loss: 0.6337611675262451\n",
      "Loss: 0.6882712841033936\n",
      "Loss: 0.6696287393569946\n",
      "Loss: 0.7018543481826782\n",
      "Loss: 0.6298007369041443\n",
      "Loss: 0.6017662286758423\n",
      "Loss: 0.6922397017478943\n",
      "Loss: 0.6980475187301636\n",
      "Loss: 0.6076058149337769\n",
      "Loss: 0.684044599533081\n",
      "Loss: 0.7154790759086609\n",
      "Loss: 0.611127495765686\n",
      "Loss: 0.6113430261611938\n",
      "Loss: 0.6084467172622681\n",
      "Loss: 0.6751931309700012\n",
      "Loss: 0.6324948072433472\n",
      "Loss: 0.6100113987922668\n",
      "Loss: 0.6842572093009949\n",
      "Loss: 0.7612913250923157\n",
      "Loss: 0.6919605135917664\n",
      "Loss: 0.5941758155822754\n",
      "Loss: 0.5861415863037109\n",
      "Loss: 0.6795404553413391\n",
      "Loss: 0.6295267343521118\n",
      "Loss: 0.6472069025039673\n",
      "Loss: 0.6760547757148743\n",
      "Loss: 0.5981564521789551\n",
      "Loss: 0.6657806634902954\n",
      "Loss: 0.6719457507133484\n",
      "Loss: 0.6259405612945557\n",
      "Loss: 0.5813954472541809\n",
      "Loss: 0.6915724873542786\n",
      "Loss: 0.6590620279312134\n",
      "Loss: 0.7007342576980591\n",
      "Loss: 0.6229779720306396\n",
      "Loss: 0.7168988585472107\n",
      "Loss: 0.6020625233650208\n",
      "Loss: 0.5873126983642578\n",
      "Loss: 0.638386070728302\n",
      "Loss: 0.7036575675010681\n",
      "Loss: 0.652586817741394\n",
      "Loss: 0.6497628688812256\n",
      "Loss: 0.620162308216095\n",
      "Loss: 0.6514790058135986\n",
      "Loss: 0.6677743792533875\n",
      "Loss: 0.5787571668624878\n",
      "Loss: 0.622843861579895\n",
      "Loss: 0.728682816028595\n",
      "Loss: 0.6503583788871765\n",
      "Loss: 0.6073541045188904\n",
      "Loss: 0.5826020240783691\n",
      "Loss: 0.5562867522239685\n",
      "Loss: 0.6806296110153198\n",
      "Loss: 0.7178579568862915\n",
      "Loss: 0.557939350605011\n",
      "Loss: 0.6767498254776001\n",
      "Loss: 0.5329120755195618\n",
      "Loss: 0.5867283344268799\n",
      "Loss: 0.6561919450759888\n",
      "Loss: 0.5914868712425232\n",
      "Loss: 0.6061724424362183\n",
      "Loss: 0.6432990431785583\n",
      "Loss: 0.6853482723236084\n",
      "Loss: 0.6670185327529907\n",
      "Loss: 0.6868975758552551\n",
      "Loss: 0.6064647436141968\n",
      "Loss: 0.6307058334350586\n",
      "Loss: 0.687681257724762\n",
      "Loss: 0.6935644745826721\n",
      "Loss: 0.6696533560752869\n",
      "Loss: 0.6554643511772156\n",
      "Loss: 0.6798112988471985\n",
      "Loss: 0.6116006374359131\n",
      "Loss: 0.7178470492362976\n",
      "Loss: 0.6076700687408447\n",
      "Loss: 0.6632238626480103\n",
      "Loss: 0.6499696969985962\n",
      "Loss: 0.6812628507614136\n",
      "Loss: 0.6498001217842102\n",
      "Loss: 0.6457632780075073\n",
      "Loss: 0.7016540765762329\n",
      "Loss: 0.657166600227356\n",
      "Loss: 0.6948497295379639\n",
      "Loss: 0.7798550724983215\n",
      "Loss: 0.6488224864006042\n",
      "Loss: 0.7156018018722534\n",
      "Loss: 0.6634253263473511\n",
      "Loss: 0.5889996290206909\n",
      "Loss: 0.6487881541252136\n",
      "Loss: 0.6728237867355347\n",
      "Loss: 0.6768844127655029\n",
      "Loss: 0.7076432704925537\n",
      "Loss: 0.6984596848487854\n",
      "Loss: 0.6714379191398621\n",
      "Loss: 0.5857364535331726\n",
      "Loss: 0.6455022096633911\n",
      "Loss: 0.6593651175498962\n",
      "Loss: 0.7245619297027588\n",
      "Loss: 0.6432880759239197\n",
      "Loss: 0.5744149684906006\n",
      "Loss: 0.6591084599494934\n",
      "Loss: 0.5791171193122864\n",
      "Loss: 0.7047393321990967\n",
      "Loss: 0.6681972742080688\n",
      "Loss: 0.6067225337028503\n",
      "Loss: 0.7061620950698853\n",
      "Loss: 0.6317464709281921\n",
      "Loss: 0.6389082074165344\n",
      "Loss: 0.628898024559021\n",
      "Loss: 0.6559866666793823\n",
      "Loss: 0.5160967707633972\n",
      "Loss: 0.6636285185813904\n",
      "Loss: 0.6685047745704651\n",
      "Loss: 0.6639332175254822\n",
      "Loss: 0.604731559753418\n",
      "Loss: 0.6336008310317993\n",
      "Loss: 0.7512485384941101\n",
      "Loss: 0.7040984630584717\n",
      "Loss: 0.5649303197860718\n",
      "Loss: 0.656941831111908\n",
      "Loss: 0.5814024209976196\n",
      "Loss: 0.6102537512779236\n",
      "Loss: 0.667356550693512\n",
      "Loss: 0.6325664520263672\n",
      "Loss: 0.587502658367157\n",
      "Loss: 0.6844440698623657\n",
      "Loss: 0.5787588953971863\n",
      "Loss: 0.6351871490478516\n",
      "Loss: 0.6451552510261536\n",
      "Loss: 0.6788845658302307\n",
      "Loss: 0.6602333784103394\n",
      "Loss: 0.5829250812530518\n",
      "Loss: 0.6450855135917664\n",
      "Loss: 0.6426906585693359\n",
      "Loss: 0.6611741781234741\n",
      "Loss: 0.7070775628089905\n",
      "Loss: 0.6504958271980286\n",
      "Loss: 0.6348243951797485\n",
      "Loss: 0.650765061378479\n",
      "Loss: 0.6231887340545654\n",
      "Loss: 0.6483772397041321\n",
      "Loss: 0.6139435768127441\n",
      "Loss: 0.7032705545425415\n",
      "Loss: 0.6900264620780945\n",
      "Loss: 0.6755921840667725\n",
      "Loss: 0.6357463002204895\n",
      "Loss: 0.6816169023513794\n",
      "Loss: 0.5846452116966248\n",
      "Loss: 0.5691050291061401\n",
      "Loss: 0.6919687986373901\n",
      "Loss: 0.5912353992462158\n",
      "Loss: 0.5741521716117859\n",
      "Loss: 0.7025308012962341\n",
      "Loss: 0.621199905872345\n",
      "Loss: 0.6739725470542908\n",
      "Loss: 0.6497829556465149\n",
      "Loss: 0.6880689859390259\n",
      "Loss: 0.6229222416877747\n",
      "Loss: 0.612084150314331\n",
      "Loss: 0.6697693467140198\n",
      "Loss: 0.6149441599845886\n",
      "Loss: 0.7564024329185486\n",
      "Loss: 0.6661532521247864\n",
      "Loss: 0.6056544184684753\n",
      "Loss: 0.6539148688316345\n",
      "Loss: 0.7008667588233948\n",
      "Loss: 0.5606757998466492\n",
      "Loss: 0.6568326950073242\n",
      "Loss: 0.6437274813652039\n",
      "Loss: 0.6297398805618286\n",
      "Loss: 0.6388059854507446\n",
      "Loss: 0.7110164165496826\n",
      "Loss: 0.7260132431983948\n",
      "Loss: 0.6550072431564331\n",
      "Loss: 0.7097187638282776\n",
      "Loss: 0.6643964052200317\n",
      "Loss: 0.7030317187309265\n",
      "Loss: 0.6413310170173645\n",
      "Loss: 0.638325572013855\n",
      "Loss: 0.6074912548065186\n",
      "Loss: 0.6542936563491821\n",
      "Loss: 0.5918216705322266\n",
      "Loss: 0.7259670495986938\n",
      "Loss: 0.6328476667404175\n",
      "Loss: 0.6366456151008606\n",
      "Loss: 0.6370499134063721\n",
      "Loss: 0.600447416305542\n",
      "Loss: 0.6004894971847534\n",
      "Loss: 0.6819736361503601\n",
      "Loss: 0.7384766936302185\n",
      "Loss: 0.6554109454154968\n",
      "Loss: 0.5521683692932129\n",
      "Loss: 0.606786847114563\n",
      "Loss: 0.5375623106956482\n",
      "Loss: 0.7026220560073853\n",
      "Loss: 0.6320081949234009\n",
      "Loss: 0.54097580909729\n",
      "Loss: 0.6845329403877258\n",
      "Loss: 0.6031656265258789\n",
      "Loss: 0.6146523952484131\n",
      "Loss: 0.6230088472366333\n",
      "Loss: 0.6624352931976318\n",
      "Loss: 0.5425537824630737\n",
      "Loss: 0.6515780687332153\n",
      "Loss: 0.6599323153495789\n",
      "Loss: 0.6669713258743286\n",
      "Loss: 0.6749003529548645\n",
      "Loss: 0.6265732049942017\n",
      "Loss: 0.587726354598999\n",
      "Loss: 0.6910838484764099\n",
      "Loss: 0.6955057978630066\n",
      "Loss: 0.5655329823493958\n",
      "Loss: 0.6595653891563416\n",
      "Loss: 0.6189335584640503\n",
      "Loss: 0.5943078994750977\n",
      "Loss: 0.6079146265983582\n",
      "Loss: 0.6094459891319275\n",
      "Loss: 0.6824748516082764\n",
      "Loss: 0.7304507493972778\n",
      "Loss: 0.6174674034118652\n",
      "Loss: 0.5981957912445068\n",
      "Loss: 0.6855891346931458\n",
      "Loss: 0.6376460194587708\n",
      "Loss: 0.5778838992118835\n",
      "Loss: 0.666896641254425\n",
      "Loss: 0.656629204750061\n",
      "Loss: 0.6129254698753357\n",
      "Loss: 0.7391692399978638\n",
      "Loss: 0.6462900042533875\n",
      "Loss: 0.5809698104858398\n",
      "Loss: 0.6939502358436584\n",
      "Loss: 0.6704005599021912\n",
      "Loss: 0.6386371850967407\n",
      "Loss: 0.6182049512863159\n",
      "Loss: 0.582562267780304\n",
      "Loss: 0.5092009902000427\n",
      "Loss: 0.7177807092666626\n",
      "Loss: 0.6419584155082703\n",
      "Loss: 0.6923307180404663\n",
      "Loss: 0.6320377588272095\n",
      "Loss: 0.654452919960022\n",
      "Loss: 0.6069697141647339\n",
      "Loss: 0.7132158875465393\n",
      "Loss: 0.5856747031211853\n",
      "Loss: 0.639245867729187\n",
      "Loss: 0.7019032835960388\n",
      "Loss: 0.6822511553764343\n",
      "Loss: 0.6092568635940552\n",
      "Loss: 0.6830174922943115\n",
      "Loss: 0.6806579232215881\n",
      "Loss: 0.5770954489707947\n",
      "Loss: 0.6702196002006531\n",
      "Loss: 0.6964118480682373\n",
      "Loss: 0.6451787352561951\n",
      "Loss: 0.6535770297050476\n",
      "Loss: 0.68174147605896\n",
      "Loss: 0.6707306504249573\n",
      "Loss: 0.7191489338874817\n",
      "Loss: 0.6661808490753174\n",
      "Loss: 0.6716567873954773\n",
      "Loss: 0.6893884539604187\n",
      "Loss: 0.6685246229171753\n",
      "Loss: 0.5950459837913513\n",
      "Loss: 0.7058886289596558\n",
      "Loss: 0.6777536273002625\n",
      "Loss: 0.5975738763809204\n",
      "Loss: 0.6217013597488403\n",
      "Loss: 0.6365684866905212\n",
      "Loss: 0.7200554609298706\n",
      "Loss: 0.6448352932929993\n",
      "Loss: 0.6611382365226746\n",
      "Loss: 0.7244600057601929\n",
      "Loss: 0.6478471755981445\n",
      "Loss: 0.7153154611587524\n",
      "Loss: 0.628635823726654\n",
      "Loss: 0.6137296557426453\n",
      "Loss: 0.6303112506866455\n",
      "Loss: 0.5963498950004578\n",
      "Loss: 0.6417204141616821\n",
      "Loss: 0.6838271617889404\n",
      "Loss: 0.5676349401473999\n",
      "Loss: 0.6411608457565308\n",
      "Loss: 0.5937299132347107\n",
      "Loss: 0.7058045864105225\n",
      "Loss: 0.6384369730949402\n",
      "Loss: 0.6328780651092529\n",
      "Loss: 0.6082628965377808\n",
      "Loss: 0.6803153157234192\n",
      "Loss: 0.5322527885437012\n",
      "Loss: 0.7085555195808411\n",
      "Loss: 0.6695236563682556\n",
      "Loss: 0.6877340078353882\n",
      "Loss: 0.5529647469520569\n",
      "Loss: 0.6690549254417419\n",
      "Loss: 0.7125673890113831\n",
      "Loss: 0.7067385911941528\n",
      "Loss: 0.5459636449813843\n",
      "Loss: 0.7097071409225464\n",
      "Loss: 0.5793050527572632\n",
      "Loss: 0.6140133142471313\n",
      "Loss: 0.5626673698425293\n",
      "Loss: 0.6705100536346436\n",
      "Loss: 0.6569775938987732\n",
      "Loss: 0.6693741083145142\n",
      "Loss: 0.5759207606315613\n",
      "Loss: 0.6569861769676208\n",
      "Loss: 0.5723600387573242\n",
      "Loss: 0.5993857383728027\n",
      "Loss: 0.6481891870498657\n",
      "Loss: 0.6832705736160278\n",
      "Loss: 0.6041542887687683\n",
      "Loss: 0.5852193832397461\n",
      "Loss: 0.6887738704681396\n",
      "Loss: 0.7402673959732056\n",
      "Loss: 0.734214723110199\n",
      "Loss: 0.5758358836174011\n",
      "Loss: 0.600138783454895\n",
      "Loss: 0.6686918139457703\n",
      "Loss: 0.6667192578315735\n",
      "Loss: 0.6375061273574829\n",
      "Loss: 0.7340320348739624\n",
      "Loss: 0.6906239986419678\n",
      "Loss: 0.6246146559715271\n",
      "Loss: 0.6099585294723511\n",
      "Loss: 0.6849097013473511\n",
      "Loss: 0.6744526624679565\n",
      "Loss: 0.6306524276733398\n",
      "Loss: 0.7365842461585999\n",
      "Loss: 0.7492794394493103\n",
      "Loss: 0.5908458232879639\n",
      "Loss: 0.6179430484771729\n",
      "Loss: 0.6977000832557678\n",
      "Loss: 0.6472496390342712\n",
      "Loss: 0.679862916469574\n",
      "Loss: 0.602272629737854\n",
      "Loss: 0.6500901579856873\n",
      "Loss: 0.622592568397522\n",
      "Loss: 0.6654362082481384\n",
      "Loss: 0.6245185136795044\n",
      "Loss: 0.5882805585861206\n",
      "Loss: 0.6459931135177612\n",
      "Loss: 0.7222563624382019\n",
      "Loss: 0.6540848016738892\n",
      "Loss: 0.5842578411102295\n",
      "Loss: 0.66939377784729\n",
      "Loss: 0.6587471961975098\n",
      "Loss: 0.7286509871482849\n",
      "Loss: 0.6358919143676758\n",
      "Loss: 0.6463298201560974\n",
      "Loss: 0.7075380682945251\n",
      "Loss: 0.6187864542007446\n",
      "Loss: 0.6662085652351379\n",
      "Loss: 0.6661838293075562\n",
      "Loss: 0.6730620861053467\n",
      "Loss: 0.6204750537872314\n",
      "Loss: 0.6197203397750854\n",
      "Loss: 0.6685940623283386\n",
      "Loss: 0.6519768834114075\n",
      "Loss: 0.6238205432891846\n",
      "Loss: 0.6770584583282471\n",
      "Loss: 0.670221745967865\n",
      "Loss: 0.6882054209709167\n",
      "Loss: 0.6315395832061768\n",
      "Loss: 0.6498885154724121\n",
      "Loss: 0.7049602270126343\n",
      "Loss: 0.6663734912872314\n",
      "Loss: 0.5684938430786133\n",
      "Loss: 0.6871684789657593\n",
      "Loss: 0.593774676322937\n",
      "Loss: 0.6732102632522583\n",
      "Loss: 0.7306093573570251\n",
      "Loss: 0.5967177152633667\n",
      "Loss: 0.6213372349739075\n",
      "Loss: 0.6140036582946777\n",
      "Loss: 0.5419262051582336\n",
      "Loss: 0.739180862903595\n",
      "Loss: 0.6072360873222351\n",
      "Loss: 0.5398778319358826\n",
      "Loss: 0.6216437816619873\n",
      "Loss: 0.7191054224967957\n",
      "Loss: 0.6929460763931274\n",
      "Loss: 0.541171669960022\n",
      "Loss: 0.5876168012619019\n",
      "Loss: 0.6479781270027161\n",
      "Loss: 0.6443164944648743\n",
      "Loss: 0.7129926085472107\n",
      "Loss: 0.6602295637130737\n",
      "Loss: 0.7400009036064148\n",
      "Loss: 0.7131730318069458\n",
      "Loss: 0.7110616564750671\n",
      "Loss: 0.6687975525856018\n",
      "Loss: 0.5965151786804199\n",
      "Loss: 0.6611230373382568\n",
      "Loss: 0.69614177942276\n",
      "Loss: 0.7189372181892395\n",
      "Loss: 0.6442420482635498\n",
      "Loss: 0.6058017015457153\n",
      "Loss: 0.6061474084854126\n",
      "Loss: 0.5805037617683411\n",
      "Loss: 0.699822723865509\n",
      "Loss: 0.7087180018424988\n",
      "Loss: 0.6086984872817993\n",
      "Loss: 0.6657520532608032\n",
      "Loss: 0.614470899105072\n",
      "Loss: 0.6683418154716492\n",
      "Loss: 0.6712661385536194\n",
      "Loss: 0.6253398060798645\n",
      "Loss: 0.6274435520172119\n",
      "Loss: 0.5914286375045776\n",
      "Loss: 0.6491694450378418\n",
      "Loss: 0.6601254343986511\n",
      "Loss: 0.6367060542106628\n",
      "Loss: 0.6091234683990479\n",
      "Loss: 0.6218706369400024\n",
      "Loss: 0.6025689840316772\n",
      "Loss: 0.6213516592979431\n",
      "Loss: 0.6581683158874512\n",
      "Loss: 0.6590332388877869\n",
      "Loss: 0.6739349961280823\n",
      "Loss: 0.6821688413619995\n",
      "Loss: 0.6358798146247864\n",
      "Loss: 0.5950496196746826\n",
      "Loss: 0.6555174589157104\n",
      "Loss: 0.66184401512146\n",
      "Loss: 0.6089274883270264\n",
      "Loss: 0.6408788561820984\n",
      "Loss: 0.7100386023521423\n",
      "Loss: 0.6344302296638489\n",
      "Loss: 0.6205587387084961\n",
      "Loss: 0.6604881286621094\n",
      "Loss: 0.6649181842803955\n",
      "Loss: 0.6769326329231262\n",
      "Loss: 0.5923798680305481\n",
      "Loss: 0.6460530757904053\n",
      "Loss: 0.6693127751350403\n",
      "Loss: 0.6334831714630127\n",
      "Loss: 0.6542037129402161\n",
      "Loss: 0.6167532205581665\n",
      "Loss: 0.5598160028457642\n",
      "Loss: 0.6434434652328491\n",
      "Loss: 0.648040771484375\n",
      "Loss: 0.7038155198097229\n",
      "Loss: 0.6681422591209412\n",
      "Loss: 0.6621595621109009\n",
      "Loss: 0.6295488476753235\n",
      "Loss: 0.6692425012588501\n",
      "Loss: 0.6797007918357849\n",
      "Loss: 0.6320645213127136\n",
      "Loss: 0.6548192501068115\n",
      "Loss: 0.6536573767662048\n",
      "Loss: 0.6556835174560547\n",
      "Loss: 0.6843678951263428\n",
      "Loss: 0.6698979735374451\n",
      "Loss: 0.699487566947937\n",
      "Loss: 0.6636769771575928\n",
      "Loss: 0.6517066955566406\n",
      "Loss: 0.7034920454025269\n",
      "Loss: 0.6415184736251831\n",
      "Loss: 0.6236377954483032\n",
      "Loss: 0.6321169137954712\n",
      "Loss: 0.6729978919029236\n",
      "Loss: 0.613562822341919\n",
      "Loss: 0.622417688369751\n",
      "Loss: 0.6382361650466919\n",
      "Loss: 0.671868622303009\n",
      "Loss: 0.626488447189331\n",
      "Loss: 0.6318187713623047\n",
      "Loss: 0.6504515409469604\n",
      "Loss: 0.7070082426071167\n",
      "Loss: 0.6115962862968445\n",
      "Loss: 0.5798980593681335\n",
      "Loss: 0.6399821043014526\n",
      "Loss: 0.640083909034729\n",
      "Loss: 0.6995800137519836\n",
      "Loss: 0.6005991101264954\n",
      "Loss: 0.5998704433441162\n",
      "Loss: 0.6731659173965454\n",
      "Loss: 0.6268026232719421\n",
      "Loss: 0.6143025159835815\n",
      "Loss: 0.712864339351654\n",
      "Loss: 0.6567306518554688\n",
      "Loss: 0.6275245547294617\n",
      "Loss: 0.6356378793716431\n",
      "Loss: 0.6334969997406006\n",
      "Loss: 0.6452970504760742\n",
      "Loss: 0.6592742204666138\n",
      "Loss: 0.5294126868247986\n",
      "Loss: 0.6828383207321167\n",
      "Loss: 0.6297664642333984\n",
      "Loss: 0.5687083005905151\n",
      "Loss: 0.6373690962791443\n",
      "Loss: 0.6223831176757812\n",
      "Loss: 0.6426345705986023\n",
      "Loss: 0.5848438143730164\n",
      "Loss: 0.6352051496505737\n",
      "Loss: 0.600348174571991\n",
      "Loss: 0.6221245527267456\n",
      "Loss: 0.6263765692710876\n",
      "Loss: 0.5803873538970947\n",
      "Loss: 0.6331356763839722\n",
      "Loss: 0.6414406895637512\n",
      "Loss: 0.6406713724136353\n",
      "Loss: 0.6875039935112\n",
      "Loss: 0.6323065161705017\n",
      "Loss: 0.6127890944480896\n",
      "Loss: 0.6868616342544556\n",
      "Loss: 0.6350599527359009\n",
      "Loss: 0.6304407119750977\n",
      "Loss: 0.6479715704917908\n",
      "Loss: 0.5876497626304626\n",
      "Loss: 0.582966148853302\n",
      "Loss: 0.6798619031906128\n",
      "Loss: 0.584661602973938\n",
      "Loss: 0.6650817394256592\n",
      "Loss: 0.6745092272758484\n",
      "Loss: 0.6556159257888794\n",
      "Loss: 0.5835112929344177\n",
      "Loss: 0.6431826949119568\n",
      "Loss: 0.598738968372345\n",
      "Loss: 0.656521737575531\n",
      "Loss: 0.6780043840408325\n",
      "Loss: 0.641107976436615\n",
      "Loss: 0.5881267786026001\n",
      "Loss: 0.6364256739616394\n",
      "Loss: 0.6777026057243347\n",
      "Loss: 0.6158931851387024\n",
      "Loss: 0.6633906364440918\n",
      "Loss: 0.6729021668434143\n",
      "Loss: 0.6633192300796509\n",
      "Loss: 0.5979031324386597\n",
      "Loss: 0.6127988696098328\n",
      "Loss: 0.5852139592170715\n",
      "Loss: 0.7618515491485596\n",
      "Loss: 0.6498115062713623\n",
      "Loss: 0.6271700263023376\n",
      "Loss: 0.6167882680892944\n",
      "Loss: 0.6225060224533081\n",
      "Loss: 0.6733221411705017\n",
      "Loss: 0.6546111106872559\n",
      "Loss: 0.6046266555786133\n",
      "Loss: 0.563863217830658\n",
      "Loss: 0.6579679250717163\n",
      "Loss: 0.66895991563797\n",
      "Loss: 0.6794441938400269\n",
      "Loss: 0.7010343074798584\n",
      "Loss: 0.6457120776176453\n",
      "Loss: 0.7272949814796448\n",
      "Loss: 0.6185858249664307\n",
      "Loss: 0.6370975375175476\n",
      "Loss: 0.6981720328330994\n",
      "Loss: 0.6332754492759705\n",
      "Loss: 0.6739300489425659\n",
      "Loss: 0.6239649653434753\n",
      "Loss: 0.6631789207458496\n",
      "Loss: 0.6295645236968994\n",
      "Loss: 0.6280630826950073\n",
      "Loss: 0.6268543004989624\n",
      "Loss: 0.6012765765190125\n",
      "Loss: 0.6059800982475281\n",
      "Loss: 0.7338559627532959\n",
      "Loss: 0.6920706033706665\n",
      "Loss: 0.6295669674873352\n",
      "Loss: 0.6892574429512024\n",
      "Loss: 0.6158313751220703\n",
      "Loss: 0.7100746035575867\n",
      "Loss: 0.6768624782562256\n",
      "Loss: 0.6458584666252136\n",
      "Loss: 0.6734490990638733\n",
      "Loss: 0.6777483224868774\n",
      "Loss: 0.6314020156860352\n",
      "Loss: 0.6589852571487427\n",
      "Loss: 0.6196167469024658\n",
      "Loss: 0.6850694417953491\n",
      "Loss: 0.6026946902275085\n",
      "Loss: 0.6274168491363525\n",
      "Loss: 0.64720618724823\n",
      "Loss: 0.6791134476661682\n",
      "Loss: 0.6208330392837524\n",
      "Loss: 0.5606724619865417\n",
      "Loss: 0.6261035203933716\n",
      "Loss: 0.5867387652397156\n",
      "Loss: 0.6384522914886475\n",
      "Loss: 0.7083666920661926\n",
      "Loss: 0.6736403703689575\n",
      "Loss: 0.717342734336853\n",
      "Loss: 0.6533563137054443\n",
      "Loss: 0.6143269538879395\n",
      "Loss: 0.6521555185317993\n",
      "Loss: 0.6088988780975342\n",
      "Loss: 0.6674864888191223\n",
      "Loss: 0.6521881222724915\n",
      "Loss: 0.654126763343811\n",
      "Loss: 0.7166993618011475\n",
      "Loss: 0.6952865123748779\n",
      "Loss: 0.6797990202903748\n",
      "Loss: 0.6850956678390503\n",
      "Loss: 0.6938268542289734\n",
      "Loss: 0.6374179720878601\n",
      "Loss: 0.5853878259658813\n",
      "Loss: 0.660284698009491\n",
      "Loss: 0.6348517537117004\n",
      "Loss: 0.6027795672416687\n",
      "Loss: 0.6265685558319092\n",
      "Loss: 0.6066948175430298\n",
      "Loss: 0.6287848949432373\n",
      "Loss: 0.6656506657600403\n",
      "Loss: 0.7130841016769409\n",
      "Loss: 0.7070629000663757\n",
      "Loss: 0.6892459988594055\n",
      "Loss: 0.5767172574996948\n",
      "Loss: 0.5808329582214355\n",
      "Loss: 0.6108143329620361\n",
      "Loss: 0.7110162377357483\n",
      "Loss: 0.6566888689994812\n",
      "Loss: 0.6774507761001587\n",
      "Loss: 0.6713710427284241\n",
      "Loss: 0.6348775029182434\n",
      "Loss: 0.6550657153129578\n",
      "Loss: 0.5640736818313599\n",
      "Loss: 0.5922253727912903\n",
      "Loss: 0.6130956411361694\n",
      "Loss: 0.7144039869308472\n",
      "Loss: 0.707288384437561\n",
      "Loss: 0.6844540238380432\n",
      "Loss: 0.6817447543144226\n",
      "Loss: 0.625438928604126\n",
      "Loss: 0.6993697285652161\n",
      "Loss: 0.5997332334518433\n",
      "Loss: 0.6229402422904968\n",
      "Loss: 0.6054779291152954\n",
      "Loss: 0.6245282292366028\n",
      "Loss: 0.6741470098495483\n",
      "Loss: 0.6437795758247375\n",
      "Loss: 0.5828842520713806\n",
      "Loss: 0.7028325796127319\n",
      "Loss: 0.6571871042251587\n",
      "Loss: 0.6472228169441223\n",
      "Loss: 0.7118602395057678\n",
      "Loss: 0.5795999765396118\n",
      "Loss: 0.6647865176200867\n",
      "Loss: 0.6317548751831055\n",
      "Loss: 0.7521670460700989\n",
      "Loss: 0.6649333834648132\n",
      "Loss: 0.603024959564209\n",
      "Loss: 0.5916262865066528\n",
      "Loss: 0.6417077779769897\n",
      "Loss: 0.6006677150726318\n",
      "Loss: 0.585614025592804\n",
      "Loss: 0.6961290240287781\n",
      "Loss: 0.6513664126396179\n",
      "Loss: 0.6759786009788513\n",
      "Loss: 0.5947716236114502\n",
      "Loss: 0.6186435222625732\n",
      "Loss: 0.5292235016822815\n",
      "Loss: 0.656521201133728\n",
      "Loss: 0.6383517980575562\n",
      "Loss: 0.6921602487564087\n",
      "Loss: 0.6899663805961609\n",
      "Loss: 0.6782893538475037\n",
      "Loss: 0.6245147585868835\n",
      "Loss: 0.5953028798103333\n",
      "Loss: 0.6403716206550598\n",
      "Loss: 0.5863111019134521\n",
      "Loss: 0.6268674731254578\n",
      "Loss: 0.600461483001709\n",
      "Loss: 0.7414602637290955\n",
      "Loss: 0.5136894583702087\n",
      "Loss: 0.6546055674552917\n",
      "Loss: 0.6576406359672546\n",
      "Loss: 0.6946165561676025\n",
      "Loss: 0.6068815588951111\n",
      "Loss: 0.5851718187332153\n",
      "Loss: 0.6152938008308411\n",
      "Loss: 0.668770968914032\n",
      "Loss: 0.6917751431465149\n",
      "Loss: 0.6407339572906494\n",
      "Loss: 0.6505396962165833\n",
      "Loss: 0.7063502669334412\n",
      "Loss: 0.6094927191734314\n",
      "Loss: 0.6789311170578003\n",
      "Loss: 0.6316022872924805\n",
      "Loss: 0.6477874517440796\n",
      "Loss: 0.5842748880386353\n",
      "Loss: 0.6373205184936523\n",
      "Loss: 0.6069254875183105\n",
      "Loss: 0.6715530753135681\n",
      "Loss: 0.6331931948661804\n",
      "Loss: 0.6182224750518799\n",
      "Loss: 0.6071237921714783\n",
      "Loss: 0.641625702381134\n",
      "Loss: 0.6917031407356262\n",
      "Loss: 0.7354323267936707\n",
      "Loss: 0.6994660496711731\n",
      "Loss: 0.6605992317199707\n",
      "Loss: 0.7100406885147095\n",
      "Loss: 0.6248895525932312\n",
      "Loss: 0.6061257123947144\n",
      "Loss: 0.6186110973358154\n",
      "Loss: 0.6656925678253174\n",
      "Loss: 0.6710547208786011\n",
      "Loss: 0.6425179839134216\n",
      "Loss: 0.6637142896652222\n",
      "Loss: 0.6930510401725769\n",
      "Loss: 0.6391071677207947\n",
      "Loss: 0.6505211591720581\n",
      "Loss: 0.6599727869033813\n",
      "Loss: 0.6236950159072876\n",
      "Loss: 0.6027203798294067\n",
      "Loss: 0.6118009686470032\n",
      "Loss: 0.6427780985832214\n",
      "Loss: 0.6518120169639587\n",
      "Loss: 0.6048180460929871\n",
      "Loss: 0.6547026038169861\n",
      "Loss: 0.659111738204956\n",
      "Loss: 0.5956677198410034\n",
      "Loss: 0.586979329586029\n",
      "Loss: 0.5930273532867432\n",
      "Loss: 0.592768669128418\n",
      "Loss: 0.5659964084625244\n",
      "Loss: 0.5706713199615479\n",
      "Loss: 0.7114430665969849\n",
      "Loss: 0.6588305234909058\n",
      "Loss: 0.6146606802940369\n",
      "Loss: 0.6448816657066345\n",
      "Loss: 0.6349833607673645\n",
      "Loss: 0.6261805295944214\n",
      "Loss: 0.6632376909255981\n",
      "Loss: 0.6383209228515625\n",
      "Loss: 0.7091478705406189\n",
      "Loss: 0.6679192185401917\n",
      "Loss: 0.603046715259552\n",
      "Loss: 0.6219959259033203\n",
      "Loss: 0.6705657839775085\n",
      "Loss: 0.7019869089126587\n",
      "Loss: 0.6380573511123657\n",
      "Loss: 0.6915181875228882\n",
      "Loss: 0.6522032022476196\n",
      "Loss: 0.6920999884605408\n",
      "Loss: 0.696139395236969\n",
      "Loss: 0.6216759085655212\n",
      "Loss: 0.5540217757225037\n",
      "Loss: 0.6695929169654846\n",
      "Loss: 0.6271140575408936\n",
      "Loss: 0.6525734066963196\n",
      "Loss: 0.6676082015037537\n",
      "Loss: 0.6249813437461853\n",
      "Loss: 0.6879752278327942\n",
      "Loss: 0.6660377383232117\n",
      "Loss: 0.6174262166023254\n",
      "Loss: 0.6813738942146301\n",
      "Loss: 0.647180438041687\n",
      "Loss: 0.6628162264823914\n",
      "Loss: 0.7093726992607117\n",
      "Loss: 0.6412476301193237\n",
      "Loss: 0.685317873954773\n",
      "Loss: 0.6151646375656128\n",
      "Loss: 0.5708215832710266\n",
      "Loss: 0.6521016955375671\n",
      "Loss: 0.6042633056640625\n",
      "Loss: 0.6404903531074524\n",
      "Loss: 0.6971825361251831\n",
      "Loss: 0.5640332102775574\n",
      "Loss: 0.7841358780860901\n",
      "Loss: 0.6487540006637573\n",
      "Loss: 0.7524065375328064\n",
      "Loss: 0.691517174243927\n",
      "Loss: 0.6508826017379761\n",
      "Loss: 0.6831300258636475\n",
      "Loss: 0.6601941585540771\n",
      "Loss: 0.580379843711853\n",
      "Loss: 0.6528943181037903\n",
      "Loss: 0.6164256930351257\n",
      "Loss: 0.5204588770866394\n",
      "Loss: 0.7208683490753174\n",
      "Loss: 0.5902078151702881\n",
      "Loss: 0.6317732930183411\n",
      "Loss: 0.5887755751609802\n",
      "Loss: 0.6994339227676392\n",
      "Loss: 0.6521450281143188\n",
      "Loss: 0.6295846104621887\n",
      "Loss: 0.6357969641685486\n",
      "Loss: 0.6152693033218384\n",
      "Loss: 0.6421861052513123\n",
      "Loss: 0.6186289191246033\n",
      "Loss: 0.6812010407447815\n",
      "Loss: 0.6814230680465698\n",
      "Loss: 0.6494868397712708\n",
      "Loss: 0.6418312191963196\n",
      "Loss: 0.5291411876678467\n",
      "Loss: 0.6900805234909058\n",
      "Loss: 0.6766670346260071\n",
      "Loss: 0.5641126036643982\n",
      "Loss: 0.6121402978897095\n",
      "Loss: 0.6282936334609985\n",
      "Loss: 0.636275053024292\n",
      "Loss: 0.6293228268623352\n",
      "Loss: 0.7345272302627563\n",
      "Loss: 0.5943721532821655\n",
      "Loss: 0.6918960809707642\n",
      "Loss: 0.6765119433403015\n",
      "Loss: 0.6945313215255737\n",
      "Loss: 0.6736689805984497\n",
      "Loss: 0.6451631784439087\n",
      "Loss: 0.6387572288513184\n",
      "Loss: 0.6205297708511353\n",
      "Loss: 0.6867755055427551\n",
      "Loss: 0.6541016697883606\n",
      "Loss: 0.6366345882415771\n",
      "Loss: 0.6415689587593079\n",
      "Loss: 0.6889902949333191\n",
      "Loss: 0.5312607884407043\n",
      "Loss: 0.6472954154014587\n",
      "Loss: 0.6620818972587585\n",
      "Loss: 0.6131464242935181\n",
      "Loss: 0.623953104019165\n",
      "Loss: 0.6327422857284546\n",
      "Loss: 0.63960200548172\n",
      "Loss: 0.6754339933395386\n",
      "Loss: 0.6646908521652222\n",
      "Loss: 0.6056438684463501\n",
      "Loss: 0.7100128531455994\n",
      "Loss: 0.7208116054534912\n",
      "Loss: 0.6843505501747131\n",
      "Loss: 0.6045664548873901\n",
      "Loss: 0.6851327419281006\n",
      "Loss: 0.6283716559410095\n",
      "Loss: 0.5599160194396973\n",
      "Loss: 0.652377724647522\n",
      "Loss: 0.6884540915489197\n",
      "Loss: 0.6534103155136108\n",
      "Loss: 0.6993468999862671\n",
      "Loss: 0.6102532148361206\n",
      "Loss: 0.6121552586555481\n",
      "Loss: 0.6806856393814087\n",
      "Loss: 0.6113566160202026\n",
      "Loss: 0.5396048426628113\n",
      "Loss: 0.6423788070678711\n",
      "Loss: 0.7292788624763489\n",
      "Loss: 0.6741273403167725\n",
      "Loss: 0.5799785852432251\n",
      "Loss: 0.654248833656311\n",
      "Loss: 0.66250079870224\n",
      "Loss: 0.5988549590110779\n",
      "Loss: 0.7236802577972412\n",
      "Loss: 0.6712185740470886\n",
      "Loss: 0.6309307813644409\n",
      "Loss: 0.6235882043838501\n",
      "Loss: 0.6501661539077759\n",
      "Loss: 0.6642179489135742\n",
      "Loss: 0.6023524403572083\n",
      "Loss: 0.6454748511314392\n",
      "Loss: 0.5646834373474121\n",
      "Loss: 0.6034479141235352\n",
      "Loss: 0.6235527396202087\n",
      "Loss: 0.5933643579483032\n",
      "Loss: 0.6963325142860413\n",
      "Loss: 0.6899941563606262\n",
      "Loss: 0.6719062924385071\n",
      "Loss: 0.6746214032173157\n",
      "Loss: 0.7049967646598816\n",
      "Loss: 0.6138447523117065\n",
      "Loss: 0.7024207711219788\n",
      "Loss: 0.598331093788147\n",
      "Loss: 0.5894029140472412\n",
      "Loss: 0.6129044890403748\n",
      "Loss: 0.710509717464447\n",
      "Loss: 0.6032654047012329\n",
      "Loss: 0.7280867695808411\n",
      "Loss: 0.6433243155479431\n",
      "Loss: 0.61513352394104\n",
      "Loss: 0.7479285001754761\n",
      "Loss: 0.6857845783233643\n",
      "Loss: 0.683466374874115\n",
      "Loss: 0.6301628351211548\n",
      "Loss: 0.6827512979507446\n",
      "Loss: 0.6354497075080872\n",
      "Loss: 0.701215386390686\n",
      "Loss: 0.6656967997550964\n",
      "Loss: 0.6650011539459229\n",
      "Loss: 0.6450803279876709\n",
      "Loss: 0.7583385705947876\n",
      "Loss: 0.6575734615325928\n",
      "Loss: 0.6246423125267029\n",
      "Loss: 0.7144321799278259\n",
      "Loss: 0.6566818952560425\n",
      "Loss: 0.6394969820976257\n",
      "Loss: 0.5618609189987183\n",
      "Loss: 0.6529340744018555\n",
      "Loss: 0.6902191042900085\n",
      "Loss: 0.5875122547149658\n",
      "Loss: 0.6542471647262573\n",
      "Loss: 0.6715706586837769\n",
      "Loss: 0.5819920897483826\n",
      "Loss: 0.6657994389533997\n",
      "Loss: 0.5848623514175415\n",
      "Loss: 0.6367026567459106\n",
      "Loss: 0.664905846118927\n",
      "Loss: 0.6718084812164307\n",
      "Loss: 0.6415516138076782\n",
      "Loss: 0.6613247990608215\n",
      "Loss: 0.7179710268974304\n",
      "Loss: 0.680072009563446\n",
      "Loss: 0.73835688829422\n",
      "Loss: 0.7154430747032166\n",
      "Loss: 0.6389645338058472\n",
      "Loss: 0.6873340010643005\n",
      "Loss: 0.6587400436401367\n",
      "Loss: 0.6648977398872375\n",
      "Loss: 0.6678606271743774\n",
      "Loss: 0.6292096376419067\n",
      "Loss: 0.5790190100669861\n",
      "Loss: 0.6285957098007202\n",
      "Loss: 0.6033577919006348\n",
      "Loss: 0.6157289743423462\n",
      "Loss: 0.6582242846488953\n",
      "Loss: 0.6403564810752869\n",
      "Loss: 0.7096444964408875\n",
      "Loss: 0.6958674192428589\n",
      "Loss: 0.7442643642425537\n",
      "Loss: 0.6227582097053528\n",
      "Loss: 0.7047777771949768\n",
      "Loss: 0.7285837531089783\n",
      "Loss: 0.699317991733551\n",
      "Loss: 0.6338289976119995\n",
      "Loss: 0.6536914110183716\n",
      "Loss: 0.6358723640441895\n",
      "Loss: 0.6277239918708801\n",
      "Loss: 0.62394118309021\n",
      "Loss: 0.5994030237197876\n",
      "Loss: 0.6462221145629883\n",
      "Loss: 0.6479476094245911\n",
      "Loss: 0.66338050365448\n",
      "Loss: 0.6494524478912354\n",
      "Loss: 0.6624392867088318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6466858915436624, 0.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_rates = [0.4, 0.4, 0.4] # also try [0.5, 0.5, 0.5]  # Dropout rates for each layer except output\n",
    "model = Net([x_train.shape[1], 20, 10, 10, y_train.shape[1]], dropout_rates)\n",
    "model.run(train_loader, verbose=True, n_epochs=2)\n",
    "model.predict(test_loader, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=40, out_features=20, bias=True)\n",
      "    (1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (5): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Dropout(p=0.4, inplace=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (9): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Dropout(p=0.4, inplace=False)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=10, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Net                                      --\n",
       "â”œâ”€Sequential: 1-1                        --\n",
       "â”‚    â””â”€Linear: 2-1                       820\n",
       "â”‚    â””â”€BatchNorm1d: 2-2                  40\n",
       "â”‚    â””â”€Dropout: 2-3                      --\n",
       "â”‚    â””â”€ReLU: 2-4                         --\n",
       "â”‚    â””â”€Linear: 2-5                       210\n",
       "â”‚    â””â”€BatchNorm1d: 2-6                  20\n",
       "â”‚    â””â”€Dropout: 2-7                      --\n",
       "â”‚    â””â”€ReLU: 2-8                         --\n",
       "â”‚    â””â”€Linear: 2-9                       110\n",
       "â”‚    â””â”€BatchNorm1d: 2-10                 20\n",
       "â”‚    â””â”€Dropout: 2-11                     --\n",
       "â”‚    â””â”€ReLU: 2-12                        --\n",
       "â”‚    â””â”€Linear: 2-13                      77\n",
       "=================================================================\n",
       "Total params: 1,297\n",
       "Trainable params: 1,297\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3a7d749700>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(model.training_loss, label='Training Loss', marker='x')\n",
    "plt.plot(model.validation_loss, label='Validation Loss', marker='x')\n",
    "# plt.yscale('log')\n",
    "# plt.xlim([0, 10])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.773938156238295, 0.7521526592340195]\n",
      "[0.6466858915436624]\n"
     ]
    }
   ],
   "source": [
    "print(model.training_loss)\n",
    "print(model.validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from typing import Callable, Tuple\n",
    "\n",
    "DATA_LOADER_INPUT_INDEX = 0\n",
    "DATA_LOADER_LABEL_INDEX = 1\n",
    "DATA_LOADER_EXTRA_INDEX = 2\n",
    "\n",
    "default_error_func = lambda x, y: np.abs(x - y) # MAE\n",
    "def model_error_prediction(model: Net, dataloader:DataLoader, labels: List[str], scalar:preprocessing.StandardScaler, error_func:Callable = default_error_func) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    model = model.eval()\n",
    "    model_cpu = model.cpu()\n",
    "    row_count, _ = dataloader.dataset[:][1].shape\n",
    "    if type(dataloader.batch_size) == int:\n",
    "        batch_size = dataloader.batch_size\n",
    "    else:\n",
    "        raise ValueError(\"Bad\")\n",
    "    \n",
    "    error_df = np.zeros((row_count, len(labels)))\n",
    "    prediction_df = np.zeros((row_count, len(labels)))\n",
    "\n",
    "    # Go through the data one batch at a time (This prevents loading the entire data at once and possibly running\n",
    "    # into memory issues)\n",
    "    with torch.no_grad():\n",
    "        for index, data in enumerate(dataloader):\n",
    "            x = data[DATA_LOADER_INPUT_INDEX].cpu()     # Numpy operations require the data to be on the CPU\n",
    "            y = data[DATA_LOADER_LABEL_INDEX].cpu()    # Numpy operations require the data to be on the CPU\n",
    "            predictions = scalar.inverse_transform(model_cpu(x))\n",
    "            ground_truth = scalar.inverse_transform(y)\n",
    "            error = error_func(predictions, ground_truth)\n",
    "            # Store both the errors and predictions (in that order)\n",
    "            left_pointer = index * batch_size\n",
    "            right_pointer = left_pointer + len(x)\n",
    "            error_df[left_pointer:right_pointer, :] = error\n",
    "            prediction_df[left_pointer:right_pointer, :] = predictions\n",
    "    error_names = [label + \" Error\" for label in labels]\n",
    "    prediction_names = [\"Predicted \" + label for label in labels]\n",
    "    error_df = pd.DataFrame(data=error_df, columns=error_names)\n",
    "    prediction_df = pd.DataFrame(data=prediction_df, columns=prediction_names)\n",
    "    return error_df, prediction_df\n",
    "\n",
    "train_error, train_pred = model_error_prediction(model, train_loader, y_columns, y_scaler)\n",
    "test_error, test_pred = model_error_prediction(model, test_loader, y_columns, y_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1700x800 with 21 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BIN_COUNT = 32\n",
    "BATCH_SIZE = 4096\n",
    "\n",
    "# Plot error distributions\n",
    "fig_dist, axes = plt.subplots(3, len(y_columns), squeeze=True, figsize=(17, 8), sharey=True)\n",
    "# train_data = y_scaler.inverse_transform(train_dataset.cpu())    #index variable\n",
    "train_data = y_scaler.inverse_transform(train_dataset[:][1].cpu()) \n",
    "val_data = y_scaler.inverse_transform(test_dataset[:][1].cpu())\n",
    "\n",
    "if len(axes.shape) == 1:\n",
    "    axes = axes.reshape(3, 1)\n",
    "\n",
    "for i in range(len(y_columns)):\n",
    "    xlim = [min(train_data[:, i].min(), val_data[:, i].min()), max(train_data[:, i].max(), val_data[:, i].max())]\n",
    "    # Plot Errors\n",
    "    ax = axes[0, i]\n",
    "    plt.sca(ax)\n",
    "    column_name = train_error.columns[i]\n",
    "    weights = np.ones(len(train_error[column_name])) / (len(train_error[column_name]) + len(test_error[column_name]))\n",
    "    plt.hist(train_error[column_name], bins=BIN_COUNT, color='blue', alpha=0.5, label='Train', weights=weights)\n",
    "    plt.hist(test_error[column_name], bins=BIN_COUNT, color='orange', alpha=0.5, label='Validation', weights=weights[:len(test_error[column_name])])\n",
    "    axes[0, i].set_xlim(xlim)\n",
    "    \n",
    "    # Plot Predictions\n",
    "    ax = axes[1, i]\n",
    "    plt.sca(ax)\n",
    "    column_name = train_pred.columns[i]\n",
    "    weights = np.ones(len(train_pred[column_name])) / (len(train_pred[column_name]) + len(test_pred[column_name]))\n",
    "    plt.hist(train_pred[column_name], bins=BIN_COUNT, color='blue', alpha=0.5, label='Train', weights=weights)\n",
    "    plt.hist(test_pred[column_name], bins=BIN_COUNT, color='orange', alpha=0.5, label='Validation', weights=weights[:len(test_pred[column_name])])\n",
    "    axes[1, i].set_xlim(xlim)\n",
    "    \n",
    "    # Plot Ground Truth\n",
    "    ax = axes[2, i]\n",
    "    plt.sca(ax)\n",
    "    weights = np.ones(len(train_data[:, i])) / (len(train_data[:, i]) + len(val_data[:, i]))\n",
    "    plt.hist(train_data[:, i], bins=BIN_COUNT, color='blue', alpha=0.5, label='Train', weights=weights)\n",
    "    plt.hist(val_data[:, i], bins=BIN_COUNT, color='orange', alpha=0.5, label='Validation', weights=weights[:len(val_data[:, i])])\n",
    "    axes[2, i].set_xlim(xlim)\n",
    "\n",
    "    # X Label for the bottommost row\n",
    "    plt.xlabel(y_columns[i])\n",
    "    \n",
    "# # Add text to the left of each row of plots\n",
    "# for i, label in enumerate(['MAE Error', 'Prediction', 'Ground Truth']):\n",
    "#     fig_dist.text(0, (2.5-i)/3, label, ha='center', va='center', rotation='vertical')\n",
    "\n",
    "# Y Labels\n",
    "axes_labels = ['MAE Error', 'Prediction', 'Ground Truth']\n",
    "for i in range(axes.shape[0]):\n",
    "    axes[i, 0].set_ylabel(axes_labels[i])\n",
    "\n",
    "# Add labels to top-left subplot\n",
    "axes[0, 0].legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/model1_yscaler']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_name = \"model1\"\n",
    "\n",
    "# Save the model weights\n",
    "torch.save(model.state_dict(), rf'models/{model_name}_weights.pth')\n",
    "# joblib.dump(x_scaler, rf'../models/{model_name}_xscaler') # stores in folder 2 levels up and in models folder\n",
    "# joblib.dump(y_scaler, rf'../models/{model_name}_yscaler')\n",
    "joblib.dump(x_scaler, rf'models/{model_name}_xscaler')\n",
    "joblib.dump(y_scaler, rf'models/{model_name}_yscaler')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the old model doesn't exist here. Not sure why but new model will contain old model layers. Cannot create new model while old model exists..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=40, out_features=20, bias=True)\n",
      "    (1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (5): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Dropout(p=0.4, inplace=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (9): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Dropout(p=0.4, inplace=False)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=10, out_features=7, bias=True)\n",
      "    (13): Linear(in_features=40, out_features=20, bias=True)\n",
      "    (14): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (15): Dropout(p=0.4, inplace=False)\n",
      "    (16): ReLU()\n",
      "    (17): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (18): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): Dropout(p=0.4, inplace=False)\n",
      "    (20): ReLU()\n",
      "    (21): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (22): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (23): Dropout(p=0.4, inplace=False)\n",
      "    (24): ReLU()\n",
      "    (25): Linear(in_features=10, out_features=7, bias=True)\n",
      "    (26): Linear(in_features=40, out_features=20, bias=True)\n",
      "    (27): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (28): Dropout(p=0.4, inplace=False)\n",
      "    (29): ReLU()\n",
      "    (30): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (31): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): Dropout(p=0.4, inplace=False)\n",
      "    (33): ReLU()\n",
      "    (34): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (35): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): Dropout(p=0.4, inplace=False)\n",
      "    (37): ReLU()\n",
      "    (38): Linear(in_features=10, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Net:\n\tMissing key(s) in state_dict: \"model.13.weight\", \"model.13.bias\", \"model.14.weight\", \"model.14.bias\", \"model.14.running_mean\", \"model.14.running_var\", \"model.17.weight\", \"model.17.bias\", \"model.18.weight\", \"model.18.bias\", \"model.18.running_mean\", \"model.18.running_var\", \"model.21.weight\", \"model.21.bias\", \"model.22.weight\", \"model.22.bias\", \"model.22.running_mean\", \"model.22.running_var\", \"model.25.weight\", \"model.25.bias\", \"model.26.weight\", \"model.26.bias\", \"model.27.weight\", \"model.27.bias\", \"model.27.running_mean\", \"model.27.running_var\", \"model.30.weight\", \"model.30.bias\", \"model.31.weight\", \"model.31.bias\", \"model.31.running_mean\", \"model.31.running_var\", \"model.34.weight\", \"model.34.bias\", \"model.35.weight\", \"model.35.bias\", \"model.35.running_mean\", \"model.35.running_var\", \"model.38.weight\", \"model.38.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load the saved weights\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_weights.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mnew_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/research/tfo_inverse_modelling/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Net:\n\tMissing key(s) in state_dict: \"model.13.weight\", \"model.13.bias\", \"model.14.weight\", \"model.14.bias\", \"model.14.running_mean\", \"model.14.running_var\", \"model.17.weight\", \"model.17.bias\", \"model.18.weight\", \"model.18.bias\", \"model.18.running_mean\", \"model.18.running_var\", \"model.21.weight\", \"model.21.bias\", \"model.22.weight\", \"model.22.bias\", \"model.22.running_mean\", \"model.22.running_var\", \"model.25.weight\", \"model.25.bias\", \"model.26.weight\", \"model.26.bias\", \"model.27.weight\", \"model.27.bias\", \"model.27.running_mean\", \"model.27.running_var\", \"model.30.weight\", \"model.30.bias\", \"model.31.weight\", \"model.31.bias\", \"model.31.running_mean\", \"model.31.running_var\", \"model.34.weight\", \"model.34.bias\", \"model.35.weight\", \"model.35.bias\", \"model.35.running_mean\", \"model.35.running_var\", \"model.38.weight\", \"model.38.bias\". "
     ]
    }
   ],
   "source": [
    "dropout_rates = [0.4, 0.4, 0.4]\n",
    "\n",
    "model_name = \"model1\"\n",
    "\n",
    "# Create an instance of the model\n",
    "new_model = Net([40, 20, 10, 10, 7], dropout_rates)\n",
    "print(new_model)\n",
    "\n",
    "# Load the saved weights\n",
    "model_weights = rf'models/{model_name}_weights.pth'\n",
    "new_model.load_state_dict(torch.load(model_weights))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
